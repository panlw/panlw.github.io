<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  Spring Boot cache with Redis - Junkman
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="Junkman" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:panlw.github.io ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; Junkman</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
       
       <li><a href="index.html">HOME</a></li>
    <li><a href="archives.html">Archives</a></li>
    <li><a href="about.html">ABOUT</a></li>

    <li><label>Categories</label></li>

        
            <li><a href="Infra.html">Infra</a></li>
        
            <li><a href="Coding.html">Coding</a></li>
        
            <li><a href="Modeling.html">Modeling</a></li>
        
            <li><a href="Archtecting.html">Archtecting</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
  $(function(){
    $('#menu_item_index').addClass('is_active');
  });
</script>
<div class="row">
  <div class="large-8 medium-8 columns">
      <div class="markdown-body article-wrap">
       <div class="article">
          
          <h1>Spring Boot cache with Redis</h1>
     
        <div class="read-more clearfix">
          <span class="date">2018/11/18</span>

          <span>posted in&nbsp;</span> 
          
              <span class="posted-in"><a href='Spring.html'>Spring</a></span>
           
         
          <span class="comments">
            

            
          </span>

        </div>
      </div><!-- article -->

      <div class="article-content">
      <blockquote>
<p><a href="https://medium.com/@MatthewFTech/spring-boot-cache-with-redis-56026f7da83a">https://medium.com/@MatthewFTech/spring-boot-cache-with-redis-56026f7da83a</a></p>
</blockquote>

<p>Each of us met the situation when application was working slowly. Even the best code will fall on knees at high load. Caching can be fast and relatively cheap way to increase performance and reduce response time.<br/>
<img src="media/15425204595510/15425206105845.jpg" alt=""/></p>

<p>In simple words caching is one of performance strategies when you must face with long running services. Invocation result can be placed inside fast <br/>
in-memory storage and used next time without expensive method execution. Following the green flow, you may notice if we found requested data in cache (called <u>“cache hit”)</u> we save time and resources. Red flow represents worst scenario (called <u>“cache miss”</u>) when cache doesn’t store expected data and you need to load and recalculate it from the beginning with an extra trip to cache which increases response time. So how it works underneath?<br/>
<img src="media/15425204595510/15425206180856.jpg" alt=""/></p>

<p>With big simplification when new data arrives, they are placed in the first empty bucket, but when cache is full, cleaning process is performed according to selected eviction algorithm. Some data are safe, they are used very often or meet other conditions for chosen algorithm. Rest of the data are candidates to remove. In ideal world cache will evict only old data until it found place for new ones. With Spring and Redis we will try to build simple app and consider how different factors can impact on our caching layer.</p>

<p></section></p>

<p><section></p>

<hr/>

<h3 id="toc_0">A Piece of Code</h3>

<p>A little bit of background. Lets imagine that you work with social site where users are able to create own content, top most read posts are good candidates to find place in cache. Post structure will look more and less like code below, pretty simple but enough in this case.</p>

<pre><code class="language-java">public class Post implements Serializable {

    private String id;
    private String title;
    private String description;
    private String image;
    private int shares;
    private Author author;
    //getters setters and constructors
}
</code></pre>

<blockquote>
<p><a href="https://gist.github.com/matthewfrank/2030aad230ca40d6c6a6e25e2d83ef7c#file-postchunk-java">https://gist.github.com/matthewfrank/2030aad230ca40d6c6a6e25e2d83ef7c#file-postchunk-java</a></p>
</blockquote>

<h4 id="toc_1">Configuration and dependencies</h4>

<p>Spring need <code>spring-boot-started-data-redis</code> as cache dependency. <br/>
Basic configuration can be set from <a href="https://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html">properties</a> level.</p>

<pre>spring.cache.type=redis
spring.redis.host=192.168.99.100
spring.redis.port=6379</pre>

<h4 id="toc_2">Cache abstraction</h4>

<p>Spring Framework provides an abstraction layer with set of annotations for caching support and can work together with various cache implementation like Redis, EhCache, Hazelcast, Infinispan and <a href="http://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-caching.html">many more</a>. Loose coupling is always very welcome :)</p>

<p><strong>@Cacheable — </strong>Fulfill cache after method execution, next invocation with the same arguments will be omitted and result will be loaded from cache. Annotation provide useful feature called conditional caching. In some case no all data should be cached e.g. you want store in memory only most popular posts.</p>

<pre><code class="language-java">@Cacheable(value = &quot;post-single&quot;, key = &quot;#id&quot;, unless = &quot;#result.shares &lt; 500&quot;)
@GetMapping(&quot;/{id}&quot;)
public Post getPostByID(@PathVariable String id) throws PostNotFoundException {
    log.info(&quot;get post with id {}&quot;, id);
    return postService.getPostByID(id);
}
@Cacheable(value = &quot;post-top&quot;)
@GetMapping(&quot;/top&quot;)
public List&lt;Post&gt; getTopPosts() {
    return postService.getTopPosts();
}
</code></pre>

<blockquote>
<p><a href="https://gist.github.com/matthewfrank/7e67901a2122b23df3ddd5d6f7864305#file-cacheablecontrollermethods-java">https://gist.github.com/matthewfrank/7e67901a2122b23df3ddd5d6f7864305#file-cacheablecontrollermethods-java</a></p>
</blockquote>

<p><strong>@CachePut — </strong>Annotation allows to update entry in cache and support same options like Cacheable annotation. Code below updates post and return it for cache provider to change entry with new value.</p>

<pre><code class="language-java">@CachePut(value = &quot;post-single&quot;, key = &quot;#post.id&quot;)
@PutMapping(&quot;/update&quot;)
public Post updatePostByID(@RequestBody Post post) throws PostNotFoundException {
    log.info(&quot;update post with id {}&quot;, post.getId());
    postService.updatePost(post);
    return post;
}
</code></pre>

<blockquote>
<p><a href="https://gist.github.com/matthewfrank/fdc85c0c04be6697cce39eebddc05eb0#file-cacheputcontrollermethod-java">https://gist.github.com/matthewfrank/fdc85c0c04be6697cce39eebddc05eb0#file-cacheputcontrollermethod-java</a></p>
</blockquote>

<p><strong>@CacheEvict — </strong>Remove entry from cache, can be both conditional and global to all entries in specific cache.</p>

<pre><code class="language-java">@CacheEvict(value = &quot;post-single&quot;, key = &quot;#id&quot;)
@DeleteMapping(&quot;/delete/{id}&quot;)
public void deletePostByID(@PathVariable String id) throws PostNotFoundException {
    log.info(&quot;delete post with id {}&quot;, id);
    postService.deletePost(id);
}

@CacheEvict(value = &quot;post-top&quot;)
@GetMapping(&quot;/top/evict&quot;)
public void evictTopPosts() {
    log.info(&quot;Evict post-top&quot;);
}
</code></pre>

<blockquote>
<p><a href="https://gist.github.com/matthewfrank/84797873672c189823d59eb61c0b37fb#file-cacheevictcontrollermethod-java">https://gist.github.com/matthewfrank/84797873672c189823d59eb61c0b37fb#file-cacheevictcontrollermethod-java</a></p>
</blockquote>

<p><strong>@EnableCaching — </strong>Annotation ensure that post processor will check all beans trying to find demarcated methods and will create proxy to intercept all invocations.</p>

<p><strong>@Caching — </strong>Aggregate multiple annotations of the same type when e.g. you need to use different conditions and caches.</p>

<p><strong>@CacheConfig — </strong>Class level annotation allows to specify global values for annotations like cache name or key generator.</p>

<h3 id="toc_3">Redis cache</h3>

<p>Redis is popular open source in-memory data store used as a database, message broker and cache, for now only last use-case is important for us. <br/>
Download official Redis image from docker hub typing <code>docker pull redis</code> after this command new image should be present in your local repository (type <code>docker images</code> to check it). Of course it can installed on bare metal but for our case docker internal overhead is negligible. Standard Redis image will work well as storage but for cache we should consider few important things like maximum memory, eviction algorithms and durability.</p>

<p><strong>Maximum memory — </strong>By default redis have no memory limits on 64-bit systems and 3 GB on 32-bit systems. Large memory can contain more data and increase hit ratio, one of the most important metrics but at a certain limit of memory the hit rate will be at the same level.</p>

<p><strong>Eviction algorithms — </strong>When cache size reaches the memory limit, old data is removed to make place for new one. Access pattern is a keyword when you thinking about eviction policies, each strategy will be good for specific case:</p>

<ul>
<li>  <strong>Last Recently Used (LRU)</strong> track when key was used last time. So probably it will be still used in future, but what if it was only <u>‘one shot’</u> before long idle time? Key will be stored to next eviction cycle.</li>
<li>  <strong>Least Frequently Used (LFU)[Available from Redis 4.0]</strong> will count how many times key was used. The most popular keys will survive eviction cycle. Problem appears when key was used very often some time ago. Another key starts to being requested but it still have smaller counter and will be candidate to eviction (Redis team solved problem with long lived keys by decreasing counter after some period of time).</li>
</ul>

<p><strong>Durability — </strong>For some reasons you may want to persist your cache. After startup, cache is initially empty, it will be useful to fulfill it with snapshot data in case of recovery after outage. Redis support three types of persistence:</p>

<ul>
<li>  <strong>RDB</strong> point-in-time snapshots after specific interval of time or amount of writes. Rare snapshots should not harm performance but it will be a good task trying to find balance between snapshot interval and to avoid serving obsolete data after outage.</li>
<li>  <strong>AOF</strong> create persistence logs with every write operation. If you consider this level of durability, you should read about different fsync policies under <code>appendfsync</code> configuration parameter.</li>
<li>  Both RDB and AOF.</li>
</ul>

<p>Every additional fork or other operations like <u>fsync()</u> will consume power, <br/>
if warming-up is not important, disable all persistence options.</p>

<p></section></p>

<p><section></p>

<hr/>

<h4 id="toc_4">Redis configuration</h4>

<p>All aspects mentioned before are configurable from <a href="http://download.redis.io/redis-stable/redis.conf">redis.conf</a> level. Its up to you how much memory you will allocate and what type of eviction algorithm you will choose. Eviction policy can be switched on the fly, but Redis will need some time to collect all keys metadata proper for chosen algorithm.</p>

<pre>**#memory limit up to 128MB (up to you)**
maxmemory 128mb
**#remove the last recently used (LRU) keys first**
maxmemory-policy allkeys-lru
**#eviction precision (up to you)**
`maxmemory-samples 10`</pre>

<p></section></p>

<p><section></p>

<hr/>

<h4 id="toc_5">Metrics worth to track</h4>

<p><strong>Hit/miss ratio — </strong>Describes cache efficiency and give us relevant information about rightness of our approach. Low hit ratio is a signal to reflect on nature of stored data. It’s easy to fall into the trap of premature optimization at the early stages of project when you can only guess relying on experience what data should be cached.</p>

<pre>**λ:** redis-cli info stats
**...
keyspace_hits:142   #Successful lookups
keyspace_misses:26  #Failed lookups
...**</pre>

<p>Redis delivers information about amount of lookups, ratio can be calculated using below formula.</p>

<pre>**hit_ratio ** =(keyspace_hits)/(keyspace_hits + keyspace_misses)
**miss_ratio =** (keyspace_misses)/(keyspace_hits + keyspace_misses)</pre>

<p><strong>Latency —</strong> Maximum delay between request and respond. First place where we can find if something bad happen with your cache. Many factors can impact on latency like VM overhead, slow commands or I/O operations.</p>

<pre>**λ:** redis-cli --latency -h 127.0.0.1 -p 6379
min: 0, max: 16, avg: 0.15 (324531 samples)...</pre>

<p><strong>Fragmentation Ratio —</strong> Redis will always use more memory than you declared in <code>maxmemory</code> for himself and e.g. to keeps keys metadata but high ratio can be first signal of memory fragmentation.</p>

<ul>
<li>  ratio &lt;1.0 —Memory allocator need more than you can give him. Old data will be swapped to disk what occurs resources consumption and increase latency. (In case of cache usage, swapping should be disabled)</li>
<li>  ratio &gt; ~1.5 — Operation system slice memory segment into pieces, Redis use more physical memory than he requested for.</li>
</ul>

<pre>**λ:** redis-cli info memory
**...** used_memory_human:41.22M
**...**
used_memory_rss_human:50.01M
...
**mem_fragmentation_ratio:1.21 #used_memory_rss/used_memory
...**</pre>

<p><strong>Evicted keys — </strong>When cache size exceeds <code>maxmemory</code> limit Redis removes data using chosen eviction policy. Constantly fast growing value can be signal of insufficient cache size.</p>

<pre>**λ:** redis-cli info stats
**...
evicted_keys:14 #14 keys removed since operation time
...**</pre>

<p></section></p>

<p><section></p>

<hr/>

<h4 id="toc_6">Run and Test</h4>

<p>Docker knowledge will be advantage. In short words, commands below will download redis image and run container with custom configuration. Container will run as daemon, last two command runs bash and redis-cli.</p>

<pre>**λ:** docker pull redis
**λ:** docker run -p 6379:6379 -d --name redis-cache       
   \-v /usr/configs:/usr/redis_config 
   \redis redis-server /usr/redis_config/redis.conf
**λ:** docker exec -it redis-cache /bin/bash
**λ:** redis-cli</pre>

<p>Example application is available on GitHub <a href="https://github.com/matthewfrank/spring-boot-redis-cache">here</a>.</p>

<pre>**λ:** for /l %N in (1 1 5) do
   \curl -o /dev/null -s -w "%{time_total}\n"  
   \localhost:8080/post/IDX001
...
**1.012 #cache miss**
0.009 **#cache hit**
0.009 **#cache hit**
0.011 **#cache hit**
0.010 **#cache hit**</pre>

<p>It’s good time to check what is exactly stored by Redis. For more human readable key name, please check other <code>RedisSerializer.java</code> implementations.</p>

<pre>**λ:** redis-cli keys * **#Or more efficient scan 0 instead of** **keys ***
1) "post-single:\xac\xed\x00\x05t\x00\x06IDX001"</pre>

<p>Application work like we expected, after first invocation cache is fulfilled for given key, next request use cached data.</p>

<hr/>

<h4 id="toc_7">Traps</h4>

<p><strong>Stale data.</strong> High dynamic data become outdated very quickly. Without update or expiration mechanism cache will serve obsolete content.</p>

<p><strong>Large memory is not always equal bigger hit ratio.</strong> When you reach specific amount of memory, hit ratio will not increase. In this place many things will depend on eviction policies and nature of data.</p>

<p><strong>Premature optimization.</strong> Let test your services without cache, may be your fears will proved groundless, <u>“Premature optimization is the root of all evil”.</u></p>

<p><strong>Hiding bad performance.</strong> Cache is not always an answer for slow services, try to optimize them before, because when you put them after cache layer, you will hide possible architectural mistakes.</p>

<p><strong>Don’t share your redis cache.</strong> Redis works on single thread. Other teams may use your store for other extensive purposes. Every data bumps, heavy commands (KEYS, SORT etc.) may block your cache and increase execution time. In case of performance problems, check <a href="https://redis.io/commands/slowlog">SLOWLOG</a> command.</p>

<p><strong>Config param [maxmemory].</strong> If you consider run your cache with snapshot persistence you should use less than half of available memory as <code>maxmemory</code> to avoid memory errors.</p>

<p><strong>Monitoring.</strong> You should monitor your cache, from time to time <a href="https://redis.io/commands/info">INFO</a> will not generate performance issues but <a href="https://redis.io/commands/monitor">MONITOR</a> can reduce the throughput dramatically.</p>

<h4 id="toc_8">Repository</h4>

<p><a href="https://github.com/matthewfrank/spring-boot-redis-cache" title="https://github.com/matthewfrank/spring-boot-redis-cache"><strong>matthewfrank/spring-boot-redis-cache</strong><br/>
<u>Contribute to spring-boot-redis-cache development by creating an account on GitHub.</u>github.com</a><a href="https://github.com/matthewfrank/spring-boot-redis-cache"></a></p>

<h4 id="toc_9">Further Reading</h4>

<ul>
<li>  <a href="https://docs.spring.io/spring/docs/current/spring-framework-reference/html/cache.html">Cache Abstraction in Spring</a></li>
<li>  <a href="https://spring.io/guides/gs/caching/">Caching Data with Spring</a></li>
<li>  <a href="https://redis.io/topics/lru-cache">Using Redis as an LRU cache</a></li>
<li>  <a href="https://redis.io/topics/latency">Redis latency</a></li>
<li>  <a href="https://redis.io/topics/persistence">Redis persistence</a></li>
<li>  <a href="http://oldblog.antirez.com/post/redis-as-LRU-cache.html">Redis as an LRU cache</a></li>
<li><p><a href="http://oldblog.antirez.com/post/redis-persistence-demystified.html">Redis persistence demystified</a></p></li>
<li><p><a href="https://medium.com/tag/redis?source=post">Redis</a></p></li>
<li><p><a href="https://medium.com/tag/spring-boot?source=post">Spring Boot</a></p></li>
<li><p><a href="https://medium.com/tag/cache?source=post">Cache</a></p></li>
<li><p><a href="https://medium.com/tag/java?source=post">Java</a></p></li>
</ul>


    

      </div>

      <div class="row">
        <div class="large-6 columns">
        <p class="text-left" style="padding:15px 0px;">
      
          <a href="15431218451169.html" 
          title="Previous Post: DAGOR：微信微服务过载控制系统">&laquo; DAGOR：微信微服务过载控制系统</a>
      
        </p>
        </div>
        <div class="large-6 columns">
      <p class="text-right" style="padding:15px 0px;">
      
          <a  href="15423821810758.html" 
          title="Next Post: 如何使用Journalctl查看和操作Systemd日志">如何使用Journalctl查看和操作Systemd日志 &raquo;</a>
      
      </p>
        </div>
      </div>
      <div class="comments-wrap">
        <div class="share-comments">
          <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5ae58078c0d7b2ab"></script>

          

          
        </div>
      </div>
    </div><!-- article-wrap -->
  </div><!-- large 8 -->




 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="./asset/img/logo.jpg" /></div>
            
                <h1>Junkman</h1>
                <div class="site-des">“拾荒者”一词来自凯文・凯利的《失控》中关于机器学习的故事（“收集癖好机”如何完成他的收集工作）。</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="https://github.com/panlw/" title="GitHub">GitHub</a>

  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Infra.html"><strong>Infra</strong></a>
        
            <a href="Coding.html"><strong>Coding</strong></a>
        
            <a href="Modeling.html"><strong>Modeling</strong></a>
        
            <a href="Archtecting.html"><strong>Archtecting</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15517999043443.html">The Art of Crafting Architectural Diagrams</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15517997955971.html">为什么说我们需要软件架构图？</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15516128677869.html">DNS Servers That Offer Privacy and Filtering</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15516123108194.html">Airbnb's Migration from Monolith to Services</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15516097487470.html">Events As First-Class Citizens</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    <script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
