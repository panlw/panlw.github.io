<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Junkman]]></title>
  <link href="http://panlw.github.io/atom.xml" rel="self"/>
  <link href="http://panlw.github.io/"/>
  <updated>2018-04-29T19:15:07+08:00</updated>
  <id>http://panlw.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Learn to visualize data with this free D3.js course]]></title>
    <link href="http://panlw.github.io/15248848757950.html"/>
    <updated>2018-04-28T11:07:55+08:00</updated>
    <id>http://panlw.github.io/15248848757950.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://medium.freecodecamp.org/learn-to-visualize-data-with-this-free-d3-js-course-2433b060f9dc">https://medium.freecodecamp.org/learn-to-visualize-data-with-this-free-d3-js-course-2433b060f9dc</a></p>

<p>Per Harald Borgen, 2018/4/13</p>
</blockquote>

<p>D3.js is a JavaScript library which allows you to bring data to life using HTML, SVG, and CSS. Learning it will give you super powers when it comes to extracting value from data, as you’ll basically be able to create any visualization you can think of.</p>

<p>However, it’s not the easiest library to learn, so getting started can be a bit tricky. That’s why we’ve teamed up with web developer and instructor <a href="https://medium.com/@sohaib.nehal">Sohaib Nehal</a> and created a <a href="https://scrimba.com/g/gd3js">free full-length course on it.</a> Throughout the course, Sohaib will give you a soft introduction to the powerful library.</p>

<p>Let’s have a look at how it’s laid out!</p>

<h3 id="toc_0">The content</h3>

<p>The course consists of 10 screencasts which in total last less than an hour. It starts off with the most basic concepts, like selection, manipulation, data loading, and more. This lays the ground work for the various visualizations you’ll learn to create throughout the rest of the course.</p>

<h4 id="toc_1">#1: Course introduction</h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*QTASftirCvIEkkzu09ZNcw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*QTASftirCvIEkkzu09ZNcw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*QTASftirCvIEkkzu09ZNcw.png" alt=""/></p>

<p>As usual with Scrimba courses, it begins with a quick walk-through of the course content, along with an intro to D3.js and the instructor.</p>

<h4 id="toc_2">#2: Selection and Manipulation</h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*H-7cY_zluQqHuYdvNMbFGw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*H-7cY_zluQqHuYdvNMbFGw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*H-7cY_zluQqHuYdvNMbFGw.png" alt=""/></p>

<p>The first thing you need to learn is how to select and manipulate DOM elements with D3.js. The library is actually pretty powerful in terms of manipulating the DOM, so you could theoretically use it as a <a href="https://blog.webkid.io/replacing-jquery-with-d3/">replacement for jQuery.</a></p>

<h4 id="toc_3">#3: Data Loading and Binding</h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*5sEb4D4exhT8YZnpts-T9w.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*5sEb4D4exhT8YZnpts-T9w.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*5sEb4D4exhT8YZnpts-T9w.png" alt=""/></p>

<p>As you’re going to create visuializations, it’s important to learn how to load data in and also how to bind it to the DOM. So in this lecture you’ll learn that.</p>

<h4 id="toc_4">#4: Creating a simple bar chart</h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*Jm03LA1t_o3-GKjt84MLrA.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*Jm03LA1t_o3-GKjt84MLrA.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*Jm03LA1t_o3-GKjt84MLrA.png" alt=""/></p>

<p>In the third lecture, you’ll learn how to build your very first visualization: a simple bar chart. The reason we’re introducing you to building stuff so early on is because it’s much more fun to create visualizations than simply talking about theory. So we think you’ll enjoy this lesson.</p>

<h4 id="toc_5">#5: Creating labels</h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*sDp-GORp42nSv5xEuddOcw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*sDp-GORp42nSv5xEuddOcw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*sDp-GORp42nSv5xEuddOcw.png" alt=""/></p>

<p>The next step is to add labels to the bar chart, as you often would want to do this in real-life. This is a short and simple lecture. Here, I’d recommend you to play around with the positions of the labels, as that’s a simple and fun way of interacting with the code.</p>

<h4 id="toc_6">#6: Scales</h4>

<p>Scales are a critical concept in D3. They allow you to map your data to other relevant ranges, for example the amount of space you have available. So in this lecture, you’ll learn about the <code>scaleLinear()</code> method:</p>

<pre><code class="language-js">var yScale = d3.scaleLinear()
    .domain([0, d3.max(dataset)])
    .range([0, svgHeight]);
</code></pre>

<h4 id="toc_7">#7: Axes</h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*nag8GxIZpnUrvtfM9HaYNg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*nag8GxIZpnUrvtfM9HaYNg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*nag8GxIZpnUrvtfM9HaYNg.png" alt=""/></p>

<p>Axes are an integral part of any chart, and D3 provides you a few simple methods for creating them. This lesson builds upon the last one, as it takes advantage of scales when creating the axes. It also sets you up for understanding the super-cool line chart you’ll learn in the final screencast of the course.</p>

<h4 id="toc_8">#8: Creating SVG elements</h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*FZdi_TA96EMc0B8I-Tt6Cg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*FZdi_TA96EMc0B8I-Tt6Cg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*FZdi_TA96EMc0B8I-Tt6Cg.png" alt=""/></p>

<p>Even though you’ve already created SVG elements previously in the course, it’s such an important concept that it deserves its own lecture. In it, you’ll learn about the <code>&lt;rect&gt;</code>, <code>&lt;circle&gt;</code> , and <code>&lt;line&gt;</code> elements.</p>

<h4 id="toc_9">#9: Creating a pie chart</h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*JvNCACLTK_o7Q1D2AlMVuw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*JvNCACLTK_o7Q1D2AlMVuw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*JvNCACLTK_o7Q1D2AlMVuw.png" alt=""/></p>

<p>Pie charts are handy in many cases, so in this lecture you’ll learn how to create one. D3 provides a simple API for doing this, so it shouldn’t be difficult for you at this point.</p>

<h4 id="toc_10">#10: Creating a line chart</h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*NSDd3qCL8-xYDsTnOMQ5KA.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*NSDd3qCL8-xYDsTnOMQ5KA.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*NSDd3qCL8-xYDsTnOMQ5KA.png" alt=""/></p>

<p>Finally, you’ll learn how to create a line chart to visualize the Bitcoin price. To get the data, you’ll use an external API. This project will also tie together a lot of the concepts you’ve learned throughout the course, so it’s a great visualization to end with.</p>

<p>And that’s it! After going through these ten lessons, you should be well set up for starting to use D3.js in your job or for personal projects.</p>

<p>If you reach this point, we’d really appreciate if you’d give <a href="https://medium.com/@sohaib.nehal">Sohaib</a> a shout-out on <a href="https://twitter.com/Sohaib_Nehal">Twitter</a>!</p>

<h3 id="toc_11">The Scrimba format</h3>

<p>Before you leave, let’s also have a quick look at the technology behind the course. It’s built using <a href="http://scrimba.com">Scrimba</a>, an interactive coding screencast tool. A “scrim” looks like normal video, however it’s fully interactive. This means that you can edit the code inside the screencast.</p>

<p>Here’s a gif which explains the concept:<br/>
<img src="https://cdn-images-1.medium.com/max/1000/1*4PWxbgV--7ZHlB-YVqavJg.gif" alt=""/></p>

<p>This is great for when you feel you need to experiment with the code in order to properly understand it, or when you simply want to copy a piece of the code.</p>

<p>So what are you waiting for? Head over to Scrimba and take the free course today!</p>

<p>Thanks for reading! I’m Per Borgen, co-founder of Scrimba. Feel free to connect with me via Twitter.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Modularizing your GraphQL schema code]]></title>
    <link href="http://panlw.github.io/15248846042998.html"/>
    <updated>2018-04-28T11:03:24+08:00</updated>
    <id>http://panlw.github.io/15248846042998.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://dev-blog.apollodata.com/modularizing-your-graphql-schema-code-d7f71d5ed5f2">https://dev-blog.apollodata.com/modularizing-your-graphql-schema-code-d7f71d5ed5f2</a></p>
</blockquote>

<h2 id="toc_0">How to split up your schema definition, resolvers, and Query type into multiple files</h2>

<p><img src="media/15248846042998/15248847656531.png" alt=""/></p>

<p>As your GraphQL application grows from demo, to proof of concept, to production, the complexity of your schema and resolvers will grow in tandem. To organize your code, you’ll want to split up your schema types and the associated resolvers into multiple files.</p>

<p>We get this question frequently since there are a lot of different approaches to splitting up your schema code, and it might seem that you need a complex setup to get a good result. But it turns out that we can arrange our schema and resolver code in separate files with just a few simple JavaScript concepts.</p>

<p>In this post, we present a straightforward method for modularizing schemas built with <code>graphql-tools</code> that you can tweak to match your tastes and your codebase.</p>

<h3 id="toc_1">Schema</h3>

<p>If you’re just starting out and have your entire schema defined in one file, it might look much like the below snippet. Here, we’ll call it <code>schema.js</code>:</p>

<pre><code class="language-js">// schema.js 

const typeDefs = `
  type Query {
    author(id: Int!): Post
    book(id: Int!): Post
  }
  
  type Author {
    id: Int!
    firstName: String
    lastName: String
    books: [Book]
  }
  
  type Book {
    title: String
    author: Author
  }
`;

makeExecutableSchema({
  typeDefs: typeDefs,
  resolvers: {},
});
</code></pre>

<p>Ideally, instead of having everything in one schema definition string, we’d like to put the schema types for <code>Author</code> and <code>Book</code> in files called <code>author.js</code> and <code>book.js</code>.</p>

<p>At the end of the day, the schema definitions we’ve written in the Schema Definition Language (SDL) are just strings. Treating them as such, we have a simple way of importing type definitions across different files: Split up the string into multiple strings that we can combine later. This is what <code>author.js</code> would look like:</p>

<pre><code class="language-js">// author.js
export const typeDef = `
  type Author {
    id: Int!
    firstName: String
    lastName: String
    books: [Book]
  }
`;
</code></pre>

<p>Here’s <code>book.js</code>:</p>

<pre><code class="language-js">// book.js
export const typeDef = `
  type Book {
    title: String
    author: Author
  }
`;
</code></pre>

<p>Finally, we pull it all together in <code>schema.js</code>:</p>

<pre><code class="language-js">// schema.js
import { typeDef as Author } from &#39;./author.js&#39;;
import { typeDef as Book } from &#39;./book.js&#39;;
</code></pre>

<pre><code class="language-js">const Query = `
  type Query {
    author(id: Int!): Post
    book(id: Int!): Post
  }
`;
</code></pre>

<pre><code class="language-js">makeExecutableSchema({
  typeDefs: [ Query, Author, Book ],
  resolvers: {},
});
</code></pre>

<p>We’re not doing anything fancy here: we’re just importing strings that happen to contain some SDL. Note that for convenience you don’t need to combine the strings yourself — <code>makeExecutableSchema</code> can actually accept an array of type definitions directly to facilitate this approach.</p>

<h3 id="toc_2">Resolvers</h3>

<p>Now that we have a way to chop up our schema into logical parts, we want to be able to move each resolver with its associated part of the schema as well. In general, we want to keep resolvers for a certain type in the same file as the schema definition for that type.</p>

<p>Expanding on our previous example, here’s our <code>schema.js</code> file with some resolvers added into the picture:</p>

<pre><code class="language-js">// schema.js
import { typeDef as Author } from &#39;./author.js&#39;;
import { typeDef as Book } from &#39;./book.js&#39;;
</code></pre>

<pre><code class="language-js">const Query = `
  type Query {
    author(id: Int!): Post
    book(id: Int!): Post
  }
`;
</code></pre>

<pre><code class="language-js">const resolvers = {
  Query: {
    author: () =&gt; { ... },
    book: () =&gt; { ... },
  },
  Author: {
    name: () =&gt; { ... },
  },
  Book: {
    title: () =&gt; { ... },
  },
};
</code></pre>

<pre><code class="language-js">makeExecutableSchema({
  typeDefs: [ Query, Author, Book ],
  resolvers,
});
</code></pre>

<p>Just like we split up the schema definition string, we can split up the <code>resolvers</code> object. We can put a piece of it in <code>author.js</code>, another in <code>book.js</code>, and then import them and use the <code>lodash.merge</code> function to put it all together in <code>schema.js</code>.</p>

<p>Here’s what <code>author.js</code> would look like in that case:</p>

<pre><code class="language-js">// author.js
export const typeDef = `
  type Author {
    id: Int!
    firstName: String
    lastName: String
    books: [Book]
  }
`;
</code></pre>

<pre><code class="language-js">export const resolvers = {
  Author: {
    books: () =&gt; { ... },
  }
};
</code></pre>

<p>Here’s <code>book.js</code>:</p>

<pre><code class="language-js">// book.js
export const typeDef = `
  type Book {
    title: String
    author: Author
  }
`;
</code></pre>

<pre><code class="language-js">export const resolvers = {
  Book: {
    author: () =&gt; { ... },
  }
};
</code></pre>

<p>Then, we apply <code>lodash.merge</code> in <code>schema.js</code> to put everything together:</p>

<pre><code class="language-js">import { merge } from &#39;lodash&#39;;
</code></pre>

<pre><code class="language-js">import { 
  typeDef as Author, 
  resolvers as authorResolvers,
} from &#39;./author.js&#39;;
</code></pre>

<pre><code class="language-js">import { 
  typeDef as Book, 
  resolvers as bookResolvers,
} from &#39;./book.js&#39;;
</code></pre>

<pre><code class="language-js">const Query = `
  type Query {
    author(id: Int!): Author
    book(id: Int!): Book
  }
`;
</code></pre>

<pre><code class="language-js">const resolvers = {
  Query: { 
    ...,
  }
};
</code></pre>

<pre><code class="language-js">makeExecutableSchema({
  typeDefs: [ Query, Author, Book ],
  resolvers: merge(resolvers, authorResolvers, bookResolvers),
});
</code></pre>

<p>And that gives us the <code>resolvers</code> structure that we started out with!</p>

<h3 id="toc_3">Extending types in multiple files</h3>

<p>We’re still defining <code>authors</code> and <code>books</code> as top-level fields on <code>Query</code> within <code>schema.js</code>, even though these are logically tied to <code>Author</code> and <code>Book</code> and should live in <code>author.js</code> and <code>book.js</code>.</p>

<p>To accomplish that, we can use type extensions. We can define our existing <code>Query</code> type like this:</p>

<pre><code class="language-js">const Query = `
  type Query {
    _empty: String
  }

  extend type Query {
    author(id: Int!): Author 
  }

  extend type Query {
    book(id: Int!): Book 
  }
`;
</code></pre>

<p>_Note: In the current version of GraphQL, you can’t have an empty type even if you intend to extend it later. So we need to make sure the Query type has at least one field — in this case we can add a fake <u>empty field. Hopefully in future versions it will be possible to have an empty type to be extended later.</u></p>

<p>Basically, the <code>extend</code> keyword lets us add fields to an already-defined type. We can use this keyword in order to define Query fields relevant to those types in <code>book.js</code> and <code>author.js</code>. We should then also move to defining the Query resolvers for those types in the same place.</p>

<p>Here’s what <code>author.js</code> looks like with this approach:</p>

<pre><code class="language-js">// author.js
</code></pre>

<pre><code class="language-js">export const typeDef = `
  extend type Query {
    author(id: Int!): Author
  }
  ```
  
```js
  type Author {
    id: Int!
    firstName: String
    lastName: String
    books: [Book]
  }
`;
</code></pre>

<pre><code class="language-js">export const resolvers = {
  Query: {
    author: () =&gt; { ... },
  },
  Author: {
    books: () =&gt; { ... },
  }
};
</code></pre>

<p>This is what <code>book.js</code> looks like:</p>

<pre><code class="language-js">// book.js
</code></pre>

<pre><code class="language-js">export const typeDef = `
  extend type Query {
    book(id: Int!): Book
  }
  ```
  
```js
  type Book {
    title: String
    author: Author
  }
`;
</code></pre>

<pre><code class="language-js">export const resolvers = {
  Query: {
    book: () =&gt; { ... },
  },
  Book: {
    author: () =&gt; { ... },
  }
};
</code></pre>

<p>Just as before, we put it all together in <code>schema.js</code>:</p>

<pre><code class="language-js">import { merge } from &#39;lodash&#39;;
</code></pre>

<pre><code class="language-js">import { 
  typeDef as Author, 
  resolvers as authorResolvers,
} from &#39;./author.js&#39;;
</code></pre>

<pre><code class="language-js">import { 
  typeDef as Book, 
  resolvers as bookResolvers,
} from &#39;./book.js&#39;;
</code></pre>

<pre><code class="language-js">// If you had Query fields not associated with a
// specific type you could put them here
const Query = `
  type Query {
    _empty: String
  }
`;
</code></pre>

<pre><code class="language-js">const resolvers = {};
</code></pre>

<pre><code class="language-js">makeExecutableSchema({
  typeDefs: [ Query, Author, Book ],
  resolvers: merge(resolvers, authorResolvers, bookResolvers),
});
</code></pre>

<p>Now, the schema and resolver definitions are properly co-located with the associated types!</p>

<h3 id="toc_4">Final tips</h3>

<p>We’ve just been through the mechanics of modularizing your server code. Here are a few additional tips that may be helpful in figuring out how to carve up your codebase:</p>

<ol>
<li> When learning, prototyping or even building a POC, putting your whole schema in a single file is likely fine: There are benefits to be able to go through your whole schema really quickly, or explain it to a coworker.</li>
<li> You can organize your schema and resolvers by feature: for example, putting the stuff related to the checkout system together might make sense in an ecommerce site.</li>
<li> Keep your resolvers in the same file as the schema definition for the fields they implement. This will allow you to reason about your code efficiently.</li>
<li> Wrap your SDL type definitions with a <code>gql</code> tag using <a href="https://github.com/apollographql/graphql-tag">graphql-tag</a>. If you’re using a GraphQL plugin for your editor or formatting your code with Prettier, you’ll be able to get syntax highlighting for SDL within your code editor as long as you prefix it with the <code>gql</code> tag.</li>
</ol>

<p>Now, go forth and organize your code!</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Basics of Web Workers - HTML5 Rocks]]></title>
    <link href="http://panlw.github.io/15248840485977.html"/>
    <updated>2018-04-28T10:54:08+08:00</updated>
    <id>http://panlw.github.io/15248840485977.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://www.html5rocks.com/en/tutorials/workers/basics/">https://www.html5rocks.com/en/tutorials/workers/basics/</a></p>

<p>Eric Bidelman, July 26th, 2010</p>
</blockquote>

<h2 id="toc_0">The Problem: JavaScript Concurrency</h2>

<p>There are a number of bottlenecks preventing interesting applications from being ported (say, from server-heavy implementations) to client-side JavaScript. Some of these include browser compatibility, static typing, accessibility, and performance. Fortunately, the latter is quickly becoming a thing of the past as browser vendors rapidly improve the speed of their JavaScript engines.</p>

<p>One thing that&#39;s remained a hindrance for JavaScript is actually the language itself. JavaScript is a single-threaded environment, meaning multiple scripts cannot run at the same time. As an example, imagine a site that needs to handle UI events, query and process large amounts of API data, and manipulate the DOM. Pretty common, right? Unfortunately all of that can&#39;t be simultaneous due to limitations in browsers&#39; JavaScript runtime. Script execution happens within a single thread.</p>

<p>Developers mimic &#39;concurrency&#39; by using techniques like <code>setTimeout()</code>, <code>setInterval()</code>, <code>XMLHttpRequest</code>, and event handlers. Yes, all of these features run asynchronously, but non-blocking doesn&#39;t necessarily mean concurrency. Asynchronous events are processed after the current executing script has yielded. The good news is that HTML5 gives us something better than these hacks!</p>

<h2 id="toc_1">Introducing Web Workers: Bring Threading to JavaScript</h2>

<p>The <a href="http://www.whatwg.org/specs/web-workers/current-work/">Web Workers</a> specification defines an API for spawning background scripts in your web application. Web Workers allow you to do things like fire up long-running scripts to handle computationally intensive tasks, but without blocking the UI or other scripts to handle user interactions. They&#39;re going to help put and end to that nasty &#39;unresponsive script&#39; dialog that we&#39;ve all come to love:</p>

<p><img src="/static/images/screenshots/workers/unresponsive_script.gif" alt="Unresponsive script dialog" title="Unresponsive script dialog"/> Common unresponsive script dialog.</p>

<p>Workers utilize thread-like message passing to achieve parallelism. They&#39;re perfect for keeping your UI refresh, performant, and responsive for users.</p>

<h3 id="toc_2">Types of Web Workers</h3>

<p>It&#39;s worth noting that the <a href="http://www.whatwg.org/specs/web-workers/current-work/">specification</a> discusses two kinds of Web Workers, <a href="http://www.whatwg.org/specs/web-workers/current-work/#dedicated-workers-and-the-worker-interface">Dedicated Workers</a> and <a href="http://www.whatwg.org/specs/web-workers/current-work/#sharedworker">Shared Workers</a>. This article will only cover dedicated workers and I&#39;ll refer to them as &#39;web workers&#39; or &#39;workers&#39; throughout.</p>

<h2 id="toc_3">Getting Started</h2>

<p>Web Workers run in an isolated thread. As a result, the code that they execute needs to be contained in a separate file. But before we do that, the first thing to do is create a new <code>Worker</code> object in your main page. The constructor takes the name of the worker script:</p>

<pre><code class="language-js">var worker = new Worker(&#39;task.js&#39;);
</code></pre>

<p>If the specified file exists, the browser will spawn a new worker thread, which is downloaded asynchronously. The worker will not begin until the file has completely downloaded and executed. If the path to your worker returns an 404, the worker will fail silently.</p>

<p>After creating the worker, start it by calling the <code>postMessage()</code> method:</p>

<pre><code class="language-js">worker.postMessage(); // Start the worker.
</code></pre>

<h3 id="toc_4">Communicating with a Worker via Message Passing</h3>

<p>Communication between a work and its parent page is done using an event model and the <code>postMessage()</code> method. Depending on your browser/version, <code>postMessage()</code> can accept either a string or JSON object as its single argument. The latest versions of the modern browsers support passing a JSON object.</p>

<p>Below is a example of using a string to pass &#39;Hello World&#39; to a worker in doWork.js. The worker simply returns the message that is passed to it.</p>

<p>Main script:</p>

<pre><code class="language-js">var worker = new Worker(&#39;doWork.js&#39;);

worker.addEventListener(&#39;message&#39;, function(e) {
  console.log(&#39;Worker said: &#39;, e.data);
}, false);

worker.postMessage(&#39;Hello World&#39;); // Send data to our worker.
</code></pre>

<p>doWork.js (the worker):</p>

<pre><code class="language-js">self.addEventListener(&#39;message&#39;, function(e) {
  self.postMessage(e.data);
}, false);
</code></pre>

<p>When <code>postMessage()</code> is called from the main page, our worker handles that message by defining an <code>onmessage</code> handler for the <code>message</code> event. The message payload (in this case &#39;Hello World&#39;) is accessible in <code>Event.data</code>. Although this particular example isn&#39;t very exciting, it demonstrates that <code>postMessage()</code> is also your means for passing data back to the main thread. Convenient!</p>

<p>Messages passed between the main page and workers are copied, not shared. For example, in the next example the &#39;msg&#39; property of the JSON message is accessible in both locations. It appears that the object is being passed directly to the worker even though it&#39;s running in a separate, dedicated space. In actuality, what is happening is that the object is being serialized as it&#39;s handed to the worker, and subsequently, de-serialized on the other end. The page and worker do not share the same instance, so the end result is that a duplicate is created on each pass. Most browsers implement this feature by automatically JSON encoding/decoding the value on either end.</p>

<p>The following is a more complex example that passes messages using JSON objects.</p>

<p>Main script:</p>

<pre><code class="language-js">&lt;button onclick=&quot;sayHI()&quot;&gt;Say HI&lt;/button&gt;
&lt;button onclick=&quot;unknownCmd()&quot;&gt;Send unknown command&lt;/button&gt;
&lt;button onclick=&quot;stop()&quot;&gt;Stop worker&lt;/button&gt;
&lt;output id=&quot;result&quot;&gt;&lt;/output&gt;

&lt;script&gt;
  function sayHI() {
    worker.postMessage({&#39;cmd&#39;: &#39;start&#39;, &#39;msg&#39;: &#39;Hi&#39;});
  }

  function stop() {
    // worker.terminate() from this script would also stop the worker.
    worker.postMessage({&#39;cmd&#39;: &#39;stop&#39;, &#39;msg&#39;: &#39;Bye&#39;});
  }

  function unknownCmd() {
    worker.postMessage({&#39;cmd&#39;: &#39;foobard&#39;, &#39;msg&#39;: &#39;???&#39;});
  }

  var worker = new Worker(&#39;doWork2.js&#39;);

  worker.addEventListener(&#39;message&#39;, function(e) {
    document.getElementById(&#39;result&#39;).textContent = e.data;
  }, false);
&lt;/script&gt;
</code></pre>

<p>doWork2.js:</p>

<pre><code class="language-js">self.addEventListener(&#39;message&#39;, function(e) {
  var data = e.data;
  switch (data.cmd) {
    case &#39;start&#39;:
      self.postMessage(&#39;WORKER STARTED: &#39; + data.msg);
      break;
    case &#39;stop&#39;:
      self.postMessage(&#39;WORKER STOPPED: &#39; + data.msg +
                       &#39;. (buttons will no longer work)&#39;);
      self.close(); // Terminates the worker.
      break;
    default:
      self.postMessage(&#39;Unknown command: &#39; + data.msg);
  };
}, false);
</code></pre>

<p><strong>Note</strong>: There are two ways to stop a worker: by calling <code>worker.terminate()</code> from the main page or by calling <code>self.close()</code> inside of the worker itself.</p>

<p><strong>Example</strong>: Run this worker!</p>

<p><button onclick="sayHI()">Say HI</button> <button onclick="unknownCmd()">Send unknown command</button> <button onclick="stop()">Stop worker</button></p>

<h2 id="toc_5">Transferrable objects</h2>

<p>Most browsers implement the <a href="http://updates.html5rocks.com/2011/09/Workers-ArrayBuffer">structured cloning</a> algorithm, which allows you to pass more complex types in/out of Workers such as <code>File</code>, <code>Blob</code>, <code>ArrayBuffer</code>, and JSON objects. However, when passing these types of data using <code>postMessage()</code>, a copy is still made. Therefore, if you&#39;re passing a large 50MB file (for example), there&#39;s a noticeable overhead in getting that file between the worker and the main thread.</p>

<p>Structured cloning is great, but a copy can take hundreds of milliseconds. To combat the perf hit, you can use <a href="http://www.w3.org/html/wg/drafts/html/master/infrastructure.html#transferable-objects">Transferable Objects</a>.</p>

<p>With Transferable Objects, data is transferred from one context to another. It is zero-copy, which vastly improves the performance of sending data to a Worker. Think of it as pass-by-reference if you&#39;re from the C/C++ world. However, unlike pass-by-reference, the &#39;version&#39; from the calling context is no longer available once transferred to the new context. For example, when transferring an ArrayBuffer from your main app to Worker, the original <code>ArrayBuffer</code> is cleared and no longer usable. Its contents are (quiet literally) transferred to the Worker context.</p>

<p>To use transferrable objects, use a slightly different signature of <code>postMessage()</code>:</p>

<pre><code class="language-js">worker.postMessage(arrayBuffer, [arrayBuffer]);
window.postMessage(arrayBuffer, targetOrigin, [arrayBuffer]);
</code></pre>

<p>The worker case, the first argument is the data and the second is the list of items that should be transferred. The first argument doesn&#39;t have to be an <code>ArrayBuffer</code> by the way. For example, it can be a JSON object:</p>

<pre><code class="language-js">worker.postMessage({data: int8View, moreData: anotherBuffer},
                   [int8View.buffer, anotherBuffer]);
</code></pre>

<p>The important point being: the second argument must be an array of <code>ArrayBuffer</code>s. This is your list of transferrable items.</p>

<p>To see the speed improvement of transferrables, check out this <a href="http://html5-demos.appspot.com/static/workers/transferables/index.html">DEMO</a>. For more information on transferrables, see our <a href="http://updates.html5rocks.com/2011/12/Transferable-Objects-Lightning-Fast">HTML5Rock post</a>.</p>

<h2 id="toc_6">The Worker Environment</h2>

<h3 id="toc_7">Worker Scope</h3>

<p>In the context of a worker, both <code>self</code> and <code>this</code> reference the global scope for the worker. Thus, the previous example could also be written as:</p>

<pre><code class="language-js">addEventListener(&#39;message&#39;, function(e) {
  var data = e.data;
  switch (data.cmd) {
    case &#39;start&#39;:
      postMessage(&#39;WORKER STARTED: &#39; + data.msg);
      break;
    case &#39;stop&#39;:
  ...
}, false);
</code></pre>

<p>Alternatively, you could set the <code>onmessage</code> event handler directly (though <code>addEventListener</code> is always encouraged by JavaScript ninjas).</p>

<pre><code class="language-js">onmessage = function(e) {
  var data = e.data;
  ...
};
</code></pre>

<h3 id="toc_8">Features Available to Workers</h3>

<p>Due to their multi-threaded behavior, web workers only has access to a subset of JavaScript&#39;s features:</p>

<ul>
<li>  The <code>navigator</code> object</li>
<li>  The <code>location</code> object (read-only)</li>
<li>  <code>XMLHttpRequest</code></li>
<li>  <code>setTimeout()/clearTimeout()</code> and <code>setInterval()/clearInterval()</code></li>
<li>  The <a href="/tutorials/appcache/beginner/">Application Cache</a></li>
<li>  Importing external scripts using the <code>importScripts()</code> method</li>
<li>  <a href="#toc-enviornment-subworkers">Spawning other web workers</a></li>
</ul>

<p>Workers do NOT have access to:</p>

<ul>
<li>  The DOM (it&#39;s not thread-safe)</li>
<li>  The <code>window</code> object</li>
<li>  The <code>document</code> object</li>
<li>  The <code>parent</code> object</li>
</ul>

<h3 id="toc_9">Loading External Scripts</h3>

<p>You can load external script files or libraries into a worker with the <code>importScripts()</code> function. The method takes zero or more strings representing the filenames for the resources to import.</p>

<p>This example loads <code>script1.js</code> and <code>script2.js</code> into the worker:</p>

<p>worker.js:</p>

<pre><code class="language-js">importScripts(&#39;script1.js&#39;);
importScripts(&#39;script2.js&#39;);
</code></pre>

<p>Which can also be written as a single import statement:</p>

<pre><code class="language-js">importScripts(&#39;script1.js&#39;, &#39;script2.js&#39;);
</code></pre>

<h3 id="toc_10">Subworkers</h3>

<p>Workers have the ability to spawn child workers. This is great for further breaking up large tasks at runtime. However, subworkers come with a few caveats:</p>

<ul>
<li>  Subworkers must be hosted within the same origin as the parent page.</li>
<li>  URIs within subworkers are resolved relative to their parent worker&#39;s location (as opposed to the main page).</li>
</ul>

<p>Keep in mind most browsers spawn separate processes for each worker. Before you go spawning a worker farm, be cautious about hogging too many of the user&#39;s system resources. One reason for this is that messages passed between main pages and workers are copied, not shared. See <a href="#toc-gettingstarted-workercomm">Communicating with a Worker via Message Passing</a>.</p>

<p>For an sample of how to spawn a subworker, see <a href="http://www.whatwg.org/specs/web-workers/current-work/#delegation">the example</a> in the specification.</p>

<h2 id="toc_11">Inline Workers</h2>

<p>What if you want to create your worker script on the fly, or create a self-contained page without having to create separate worker files? With <code>Blob()</code>, you can &quot;inline&quot; your worker in the same HTML file as your main logic by creating a URL handle to the worker code as a string:</p>

<pre><code class="language-js">var blob = new Blob([&quot;onmessage = function(e) { postMessage(&#39;msg from worker&#39;); }&quot;]);

// Obtain a blob URL reference to our worker &#39;file&#39;.
var blobURL = window.URL.createObjectURL(blob);

var worker = new Worker(blobURL);
worker.onmessage = function(e) {
  // e.data == &#39;msg from worker&#39;
};
worker.postMessage(); // Start the worker.
</code></pre>

<h3 id="toc_12">Blob URLs</h3>

<p>The magic comes with the call to <a href="http://dev.w3.org/2006/webapi/FileAPI/#dfn-createObjectURL"><code>window.URL.createObjectURL()</code></a>. This method creates a simple URL string which can be used to reference data stored in a DOM <code>File</code> or <code>Blob</code> object. For example:</p>

<pre><code class="language-js">blob:http://localhost/c745ef73-ece9-46da-8f66-ebes574789b1
</code></pre>

<p>Blob URLs are unique and last for the lifetime of your application (e.g. until the <code>document</code> is unloaded). If you&#39;re creating many Blob URLs, it&#39;s a good idea to release references that are no longer needed. You can explicitly release a Blob URLs by passing it to <a href="http://dev.w3.org/2006/webapi/FileAPI/#dfn-revokeObjectURL"><code>window.URL.revokeObjectURL()</code></a>:</p>

<pre><code class="language-js">window.URL.revokeObjectURL(blobURL);
</code></pre>

<p>In Chrome, there&#39;s a nice page to view all of the created blob URLs: <code>chrome://blob-internals/</code>.</p>

<h3 id="toc_13">Full Example</h3>

<p>Taking this one step further, we can get clever with how the worker&#39;s JS code is inlined in our page. This technique uses a <code>&lt;script&gt;</code> tag to define the worker:</p>

<pre><code class="language-js">&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta charset=&quot;utf-8&quot; /&gt;
&lt;/head&gt;
&lt;body&gt;

  &lt;div id=&quot;log&quot;&gt;&lt;/div&gt;

  &lt;script id=&quot;worker1&quot; type=&quot;javascript/worker&quot;&gt;
    // This script won&#39;t be parsed by JS engines
    // because its type is javascript/worker.
    self.onmessage = function(e) {
      self.postMessage(&#39;msg from worker&#39;);
    };
    // Rest of your worker code goes here.
  &lt;/script&gt;

  &lt;script&gt;
    function log(msg) {
      // Use a fragment: browser will only render/reflow once.
      var fragment = document.createDocumentFragment();
      fragment.appendChild(document.createTextNode(msg));
      fragment.appendChild(document.createElement(&#39;br&#39;));

      document.querySelector(&quot;#log&quot;).appendChild(fragment);
    }

    var blob = new Blob([document.querySelector(&#39;#worker1&#39;).textContent]);

    var worker = new Worker(window.URL.createObjectURL(blob));
    worker.onmessage = function(e) {
      log(&quot;Received: &quot; + e.data);
    }
    worker.postMessage(); // Start the worker.
  &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>In my opinion, this new approach is a bit cleaner and more legible. It defines a script tag with <var>id=&quot;worker1&quot;</var> and <var>type=&#39;javascript/worker&#39;</var> (so the browser doesn&#39;t parse the JS). That code is extracted as a string using <code>document.querySelector(&#39;#worker1&#39;).textContent</code> and passed to <code>Blob()</code> to create the file.</p>

<h3 id="toc_14">Loading External Scripts</h3>

<p>When using these techniques to inline your worker code, <code>importScripts()</code> will only work if you supply an absolute URI. If you attempt to pass a relative URI, the browser will complain with a security error. The reason being: the worker (now created from a blob URL) will be resolved with a <code>blob:</code> prefix, while your app will be running from a different (presumably <code>http://</code>) scheme. Hence, the failure will be due to cross origin restrictions.</p>

<p>One way to utilize <code>importScripts()</code> in an inline worker is to &quot;inject&quot; the current url of your main script is running from by passing it to the inline worker and constructing the absolute URL manually. This will insure the external script is imported from the same origin. Assuming your main app is running from <a href="http://example.com/index.html">http://example.com/index.html</a>:</p>

<pre><code class="language-js">...
&lt;script id=&quot;worker2&quot; type=&quot;javascript/worker&quot;&gt;
self.onmessage = function(e) {
  var data = e.data;

  if (data.url) {
    var url = data.url.href;
    var index = url.indexOf(&#39;index.html&#39;);
    if (index != -1) {
      url = url.substring(0, index);
    }
    importScripts(url + &#39;engine.js&#39;);
  }
  ...
};
&lt;/script&gt;
&lt;script&gt;
  var worker = new Worker(window.URL.createObjectURL(bb.getBlob()));
  worker.postMessage(**{url: document.location}**);
&lt;/script&gt;
</code></pre>

<h2 id="toc_15">Handling Errors</h2>

<p>As with any JavaScript logic, you&#39;ll want to handle any errors that are thrown in your web workers. If an error occurs while a worker is executing, the an <code>ErrorEvent</code> is fired. The interface contains three useful properties for figuring out what went wrong: <code>filename</code> - the name of the worker script that caused the error, <code>lineno</code> - the line number where the error occurred, and <code>message</code> - a meaningful description of the error. Here is an example of setting up an <code>onerror</code> event handler to print the properties of the error:</p>

<pre><code class="language-js">&lt;output id=&quot;error&quot; style=&quot;color: red;&quot;&gt;&lt;/output&gt;
&lt;output id=&quot;result&quot;&gt;&lt;/output&gt;

&lt;script&gt;
  function onError(e) {
    document.getElementById(&#39;error&#39;).textContent = [
      &#39;ERROR: Line &#39;, e.lineno, &#39; in &#39;, e.filename, &#39;: &#39;, e.message
    ].join(&#39;&#39;);
  }

  function onMsg(e) {
    document.getElementById(&#39;result&#39;).textContent = e.data;
  }

  var worker = new Worker(&#39;workerWithError.js&#39;);
  worker.addEventListener(&#39;message&#39;, onMsg, false);
  worker.addEventListener(&#39;error&#39;, onError, false);
  worker.postMessage(); // Start worker without a message.
&lt;/script&gt;
</code></pre>

<p><strong>Example</strong>: workerWithError.js tries to perform 1/x, where x is undefined.</p>

<p><button onclick="startErrorWorker()">Run it</button></p>

<p>workerWithError.js:</p>

<pre><code class="language-js">self.addEventListener(&#39;message&#39;, function(e) {
  postMessage(1/x); // Intentional error.
};
</code></pre>

<h2 id="toc_16">A Word on Security</h2>

<h3 id="toc_17">Restrictions with Local Access</h3>

<p>Due to Google Chrome&#39;s security restrictions, workers will not run locally (e.g. from <code>file://</code>) in the latest versions of the browser. Instead, they fail silently! To run your app from the <code>file://</code> scheme, run Chrome with the <code>--allow-file-access-from-files</code> flag set. <strong>NOTE</strong>: It is not recommended to run your primary browser with this flag set. It should only be used for testing purposes and not regular browsing.</p>

<p>Other browsers do not impose the same restriction.</p>

<h3 id="toc_18">Same Origin Considerations</h3>

<p>Worker scripts must be external files with the same scheme as their calling page. Thus, you cannot load a script from a <code>data:</code> URL or <code>javascript:</code> URL, and an <code>https:</code> page cannot start worker scripts that begin with <code>http:</code> URLs.</p>

<h2 id="toc_19">Use Cases</h2>

<p>So what kind app would utilize web workers? Unfortunately, web workers are still relatively new and the majority of samples/tutorials out there involve computing prime numbers. Although that isn&#39;t very interesting, it&#39;s useful for understanding the concepts of web workers. Here are a few more ideas to get your brain churning:</p>

<ul>
<li>  Prefetching and/or caching data for later use</li>
<li>  Code syntax highlighting or other real-time text formatting</li>
<li>  Spell checker</li>
<li>  Analyzing video or audio data</li>
<li>  Background I/O or polling of webservices</li>
<li>  Processing large arrays or humungous JSON responses</li>
<li>  Image filtering in <code>&lt;canvas/&gt;</code></li>
<li>  Updating many rows of a local web database</li>
</ul>

<h2 id="toc_20">Demos</h2>

<ul>
<li>  Example from <a href="http://slides.html5rocks.com/#web-workers">HTML5Rocks slides</a></li>
<li>  <a href="http://htmlfive.appspot.com/static/tracker1.html">Motion tracker</a></li>
<li>  <a href="http://people.mozilla.com/%7Eprouget/demos/worker_and_simulatedannealing/index.xhtml">Simulated Annealing</a></li>
<li>  <a href="http://html5demos.com/worker">HTML5demos sample</a></li>
</ul>

<h2 id="toc_21">References</h2>

<ul>
<li>  <a href="http://www.whatwg.org/specs/web-workers/current-work/">Web Workers</a> specification</li>
<li>  <a href="http://developer.mozilla.org/en/Using_web_workers">&quot;Using web workers&quot;</a> from Mozilla Developer Network</li>
<li>  <a href="http://dev.opera.com/articles/view/web-workers-rise-up/">&quot;Web Workers rise up!&quot;</a> from Dev.Opera</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A tale of Webpack 4 and how to finally configure it in the right way]]></title>
    <link href="http://panlw.github.io/15248829536577.html"/>
    <updated>2018-04-28T10:35:53+08:00</updated>
    <id>http://panlw.github.io/15248829536577.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://hackernoon.com/a-tale-of-webpack-4-and-how-to-finally-configure-it-in-the-right-way-4e94c8e7e5c1">https://hackernoon.com/a-tale-of-webpack-4-and-how-to-finally-configure-it-in-the-right-way-4e94c8e7e5c1</a></p>
</blockquote>

<p>There are a million tutorials online, so you probably have seen a thousand different ways to configure Webpack file. And all of them will be working examples. Why is it so? Webpack itself has been evolving really fast and a lot of loaders and plugins have to keep up. This is a major reason why the configuration files are so different: with a different version combination of the same tools things might work, or break.</p>

<p>Let me just say one thing, and this is my sincere opinion: a lot of people have been complaining about webpack and how cumbersome it is. This is true in many ways, although I have to say with my experience of working with gulp and grunt, you stumble upon the same type of errors there too, meaning that when you use npm modules, it’s inevitable that some versions would be incompatible.</p>

<p>Webpack 4 so far is the popular module bundler that has just undergone a massive update. There is a lot of new things it has to offer, such as zero configuration, reasonable defaults, performance improvement, optimisation tools out of the box.</p>

<p>If you are completely new to webpack, a great way to start would be to read the docs. <a href="https://webpack.js.org/concepts/">Webpack has a pretty nice documentation</a> with many parts explained, so I will go through them very briefly.</p>

<p>Zero config: webpack 4 does not require a configuration file, this is new for the version 4. Webpack kinda grows step by step, so there is no need to do a monstrous configuration from the start.</p>

<p>Performance improvement: webpack 4 is the fastest version of webpack so far.</p>

<p>Reasonable defaults: webpack 4main concepts are <u>entry, output, loaders, plugins</u>. I will not cover these in details, although the difference between loaders and plugins is very vague. It all depends on how library author has implemented it.</p>

<h3 id="toc_0">Core concepts</h3>

<h4 id="toc_1">Entry</h4>

<p>This should be your _.js_ file. Now you will probably see a few configurations where people include _.scss_ or _.css_ file there. This is a major hack and can lead to a lot of unexpected errors. Also sometimes you see an entry with a few _.js_ files. While some solutions allow you to do so, I would say it usually adds more complexity and only do it when you really know why you are doing it.</p>

<h4 id="toc_2">Output</h4>

<p>This is your <u>build/</u> or <u>dist/</u> or <u>wateveryounameit/</u> folder where your end js file will be hosted. This is your end result comprised of modules.</p>

<h4 id="toc_3">Loaders</h4>

<p>They mostly compile or transpile your code, like postcss-loader will go through different plugins. You will see it later.</p>

<h4 id="toc_4">Plugins</h4>

<p>Plugins play a vital role in outputting your code into files.</p>

<h3 id="toc_5">Quickstart</h3>

<p>Create a new directory and move into it:</p>

<pre><code>mkdir webpack-4-tutorial
cd webpack-4-tutorial
</code></pre>

<p>Initialize a package.json :</p>

<pre><code>npm init
</code></pre>

<p>We need to download webpack v4 as a module and webpack-cli to run it from your terminal.</p>

<pre><code>npm install webpack webpack-cli --save-dev
</code></pre>

<p>Make sure you have version 4 installed, if not, you can explicitly specify it in your <u>package.json</u> file. Now open up <u>package.json</u> and add a build script:</p>

<pre><code>&quot;scripts&quot;: {
  &quot;dev&quot;: &quot;webpack&quot;
}
</code></pre>

<p>You will most likely see a warning:</p>

<pre><code>WARNING in configuration

The ‘mode’ option has not been set, webpack will fallback to ‘production’ for this value. Set ‘mode’ option to ‘development’ or ‘production’ to enable defaults for each environment.

You can also set it to ‘none’ to disable any default behavior. Learn more: [https://webpack.js.org/concepts/mode/](https://webpack.js.org/concepts/mode/)
</code></pre>

<h3 id="toc_6">Webpack 4 modes</h3>

<p>You need to edit your script to contain mode flag:</p>

<pre><code>&quot;scripts&quot;: {
 &quot;dev&quot;: &quot;webpack --mode development&quot;
}

ERROR in Entry module not found: Error: Can’t resolve ‘./src’ in ‘~/webpack-4-quickstart’
</code></pre>

<p>This means webpack is looking for a folder _.src/_ with an <u>index.js</u> file. This is a default behaviour for webpack 4 since it requires zero configuration.</p>

<p>Let`s go create a directory with a _.js_ file like this ./src/index.js and put some code there.</p>

<pre><code>console.log(&quot;hello, world&quot;);
</code></pre>

<p>Now run the dev script:</p>

<pre><code>npm run dev
</code></pre>

<p>Now you have a ./dist/main.js directory. This is great since we know our code compiled. But what did just happen?</p>

<blockquote>
<p>By default, webpack requires zero configuration meaning you do not have to fiddle with webpack.config.js to get started using it. Because of that, it had to assume some default behaviour, such that it will always look for ./src folder by default and index.js in it and output to ./dist/main.js main.js is your compiled file with dependencies.</p>
</blockquote>

<p>Having 2 configuration files is a common practice in webpack, especially in big projects. Usually you would have one file for development and one for production. In webpack 4 you have modes: <u>production</u> and <u>development</u>. That eliminates the need for having two files (for medium-sized projects).</p>

<pre><code>&quot;scripts&quot;: {
  &quot;dev&quot;: &quot;webpack --mode development&quot;,
  &quot;build&quot;: &quot;webpack --mode production&quot;
}
</code></pre>

<p>If you paid close attention, you have checked your <u>main.js</u> file and saw it was not minified.</p>

<p><u>I will use build script in this example since it provides a lot of optimisation out of the box, but feel free to use any of them from now on. The core difference between build and dev scripts is how they output files. Build is created for production code. Dev is created for development, meaning that it supports hot module replacement, dev server, and a lot of things that assist your dev work.</u></p>

<p>You can override defaults in npm scripts easily, just use flags:</p>

<pre><code>&quot;scripts&quot;: {
  &quot;dev&quot;: &quot;webpack --mode development ./src/index.js --output ./dist/main.js&quot;,
  &quot;build&quot;: &quot;webpack --mode production ./src/index.js --output ./dist/main.js&quot;
}
</code></pre>

<p>This will override the default option without having to configure anything yet.</p>

<p>As an exercise, try also these flags:</p>

<ul>
<li>  — watch flag for enabling watch mode. It will watch your file changes and recompile every time some file has been updated.</li>
</ul>

<pre><code>&quot;scripts&quot;: {
  &quot;dev&quot;: &quot;webpack --mode development ./src/index.js --output ./dist/main.js --watch&quot;, 
  &quot;build&quot;: &quot;webpack --mode production ./src/index.js --output ./dist/main.js --watch&quot;
}
</code></pre>

<ul>
<li>  — entry flag. Works exactly like output, but rewrites the entry path.</li>
</ul>

<h3 id="toc_7">Transpile your .js code</h3>

<p>Modern JS code is mostly written is ES6, and ES6 is not supported by all the browsers. So you need to transpile it — a fancy word for turn your ES6 code into ES5. You can use babel for that — the most popular tool to transpile things now. Of course, we do not only do it for ES6 code, but for many JS implementations such as TypeScript, React, etc.</p>

<pre><code>npm install babel-core babel-loader babel-preset-env --save-dev
</code></pre>

<p>This is the part when you need to create a config file for babel.</p>

<pre><code>nano .babelrc
</code></pre>

<p>paste there:</p>

<pre><code>{  
  &quot;presets&quot;: [&quot;env&quot;]
}
</code></pre>

<p>We have two options for configuring babel-loader:</p>

<ul>
<li>  using a configuration file webpack.config.js</li>
<li>  using --module-bind in your npm scripts</li>
</ul>

<p>You can technically do a lot with new flags webpack introduces but I would prefer webpack.config.js for simplicity reasons.</p>

<h3 id="toc_8">Configuration file</h3>

<p>Although webpack advertises itself as a zero-configuration platform, it mostly applies to general defaults such as entry and output.</p>

<p>At this point we will create webpack.config.js with the following content:</p>

<pre><code>// webpack v4

const path = require(&#39;path&#39;);

module.exports = {
  entry: { main: &#39;./src/index.js&#39; },
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;main.js&#39;
  },
  module: {
    rules: [
      {
        test: /\.js$/,
        exclude: /node_modules/,
        use: {
          loader: &quot;babel-loader&quot;
        }
      }
    ]
  }
};
</code></pre>

<p>also we will remove flags from our npm scripts now.</p>

<pre><code>&quot;scripts&quot;: {
  &quot;build&quot;: &quot;webpack --mode production&quot;,
  &quot;dev&quot;: &quot;webpack --mode development&quot;
},
</code></pre>

<p>Now when we run <u>npm run dev</u>it should output us a nice minified _.js_ file into _./dist/main.js_ If not, try re-installing babel-loader.</p>

<blockquote>
<p>The most common pattern of webpack is to use it to compile react application. While this is true, we will not concentrate on React part in this tutorial since I want it to be framework agnostic. Instead, I will show you how to proceed and create your .html and .css configuration.</p>
</blockquote>

<h3 id="toc_9">HTML and CSS imports</h3>

<p>Lets create a small <u>index.html</u> file first in our _./dist_ folder</p>

<pre><code>&lt;html&gt;
  &lt;head&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot;&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div&gt;Hello, world!&lt;/div&gt;
    &lt;script src=&quot;main.js&quot;&gt;&lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>As you can see, we are importing here <u>style.css</u> Lets configure it! As we agreed, we ca only have one entry point for webpack. Sow were do we put our css to?</p>

<p>Create a <u>style.css</u> in our _./src_ folder</p>

<pre><code>div {
  color: red;
}
</code></pre>

<p>Do not forget to include it into your .js file:</p>

<pre><code>import &quot;./style.css&quot;;
console.log(&quot;hello, world&quot;);
</code></pre>

<p>In webpack create a new rule for css files:</p>

<pre><code>// webpack v4
const path = require(&#39;path&#39;);
const ExtractTextPlugin = require(&#39;extract-text-webpack-plugin&#39;);

module.exports = {
  entry: { main: &#39;./src/index.js&#39; },
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;main.js&#39;
  },
  module: {
    rules: [
      {
        test: /\.js$/,
        exclude: /node_modules/,
        use: {
          loader: &quot;babel-loader&quot;
        }
      },
      {
        test: /\.css$/,
        use: ExtractTextPlugin.extract(
          {
            fallback: &#39;style-loader&#39;,
            use: [&#39;css-loader&#39;]
          })
      }
    ]
  }
};
</code></pre>

<p>in terminal run</p>

<pre><code>npm install extract-text-webpack-plugin --save-dev
npm install style-loader css-loader --save-dev
</code></pre>

<p>We need yo use extract text plugin to compile our .css. As you can see, we also added a new rule for .css.</p>

<blockquote>
<p>A quick description of how rules usually work:</p>
</blockquote>

<pre><code>{
  test: /\.YOUR_FILE_EXTENSION$/,
  exclude: /SOMETHING THAT IS THAT EXTENSION BUT SHOULD NOT BE PROCESSED/,
  use: { loader: &quot;loader for your file extension  or a group of loaders&quot; }
}
</code></pre>

<p>We need to use ExtractTextPlugin because webpack be default only understands _.js_ format. ExtractTextPlugin gets your_ .css_ and extracts it into a separate _.css_ file in your _./dist_ directory.</p>

<blockquote>
<p>Spoiler: in certain articles, you will hear that ExtractTextPlugin does not work with webpack 4 but it worked for me :) It proves my point of modules ambiguity in set-up and if it absolutely does not work for you, you can switch to MiniCssExtractPlugin. I will show you how to configure another one later in this article.</p>
</blockquote>

<pre><code>// webpack v4
const path = require(&#39;path&#39;);
const ExtractTextPlugin = require(&#39;extract-text-webpack-plugin&#39;);

module.exports = {
  entry: { main: &#39;./src/index.js&#39; },
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;main.js&#39;
  },
  module: {
    rules: [
      {
        test: /\.js$/,
        exclude: /node_modules/,
        use: {
          loader: &quot;babel-loader&quot;
        }
      },
      {
        test: /\.css$/,
        use: ExtractTextPlugin.extract(
          {
            fallback: &#39;style-loader&#39;,
            use: [&#39;css-loader&#39;]
          })
      }
    ]
  },
  plugins: [ 
    new ExtractTextPlugin({filename: &#39;style.css&#39;})
  ]
};;
</code></pre>

<p>Since version 4, Webpack 4 has problems with this plugin, so you might run into this error:</p>

<p><a href="https://github.com/webpack-contrib/extract-text-webpack-plugin/issues/701" title="https://github.com/webpack-contrib/extract-text-webpack-plugin/issues/701">Webpack 4 compatibility · Issue #701 · webpack-contrib/extract-text-webpack-plugin<br/>
<u>I&#39;m trying to use this plugin with webpack 4 alpha 5 and getting the following error: Error: Chunk.entrypoints: Use…</u>github.com</a><a href="https://github.com/webpack-contrib/extract-text-webpack-plugin/issues/701"></a></p>

<p>To fix it, you can run</p>

<pre><code>npm install -D extract-text-webpack-plugin@next
</code></pre>

<blockquote>
<p>Pro tip: google errors you get and try to find similar question in Github issues or just ask a question on StackOverflow.</p>
</blockquote>

<p>After that, your css code should compile to _./dist/style.css_</p>

<p>At this point in my package.json my dev dependencies look like this:</p>

<pre><code>&quot;devDependencies&quot;: {
    &quot;babel-core&quot;: &quot;^6.26.0&quot;,
    &quot;babel-loader&quot;: &quot;^7.1.4&quot;,
    &quot;babel-preset-env&quot;: &quot;^1.6.1&quot;,
    &quot;css-loader&quot;: &quot;^0.28.11&quot;,
    &quot;extract-text-webpack-plugin&quot;: &quot;^4.0.0-beta.0&quot;,
    &quot;style-loader&quot;: &quot;^0.20.3&quot;,
    &quot;webpack&quot;: &quot;^4.4.1&quot;,
    &quot;webpack-cli&quot;: &quot;^2.0.12&quot;
  }
</code></pre>

<p>Please, note that another combination might not work since even updating webpack-cli v2.0.12 to 2.0.13 can break it. #justwebpackthings</p>

<p>So now it should output your <u>style.css</u> into _./dist_ folder.</p>

<p><img src="media/15248829536577/15248838758588.png" alt=""/></p>

<h3 id="toc_10">Configure support for SCSS</h3>

<p>It is very common to develop websites with SASS and POSTCSS, they are very helpful. So we will include support for SASS first. Let`s rename our _./src/style.css_ and create another folder to store _.scss_ files in there. Now we need to add support for _.scss_ formatting.</p>

<pre><code>npm install node-sass sass-loader --save-dev
</code></pre>

<p>replace style.scss with _./scss/main.scss_ in your _.js_ file.</p>

<h3 id="toc_11">HTML template</h3>

<p>Now lets create _.html_ file template. Add <u>index.html</u> to _./src_ file with exactly the same structure.</p>

<pre><code>&lt;html&gt;
  &lt;head&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot;&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div&gt;Hello, world!&lt;/div&gt;
    &lt;script src=&quot;main.js&quot;&gt;&lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>We will need to use html plugin for this file in order to use it as a template.</p>

<pre><code>npm install html-webpack-plugin --save-dev
</code></pre>

<p>Add it to your webpack file:</p>

<pre><code>// webpack v4
const path = require(&#39;path&#39;);
const ExtractTextPlugin = require(&#39;extract-text-webpack-plugin&#39;);
const HtmlWebpackPlugin = require(&#39;html-webpack-plugin&#39;);

module.exports = {
  entry: { main: &#39;./src/index.js&#39; },
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;main.js&#39;
  },
  module: {
    rules: [
      {
        test: /\.js$/,
        exclude: /node_modules/,
        use: {
          loader: &quot;babel-loader&quot;
        }
      },
      {
        test: /\.scss$/,
        use: ExtractTextPlugin.extract(
          {
            fallback: &#39;style-loader&#39;,
            use: [&#39;css-loader&#39;, &#39;sass-loader&#39;]
          })
      }
    ]
  },
  plugins: [ 
    new ExtractTextPlugin(
      {filename: &#39;style.css&#39;}
    ),
    new HtmlWebpackPlugin({
      inject: false,
      hash: true,
      template: &#39;./src/index.html&#39;,
      filename: &#39;index.html&#39;
    })
  ]
};
</code></pre>

<p>Now your file from _./src/index.html_ is a template for your final index.html file. To check that everything works, delete every file from _./dist_ folder and the folder itself.</p>

<pre><code>rm -rf /dist
npm run dev
</code></pre>

<p>You will see that _./dist_ folder was created on its own and there are three files: index.html, style.css, script.js.</p>

<h3 id="toc_12">Caching and Hashing</h3>

<p>One of the most common problems in development is implementing caching. It is very important to understand how it works since you want your users to always have the best latest version of your code.</p>

<p>Since this blogpost is mainly about webpack configuration, we will not concentrate on how caching works in details. I will just say that one of the most popular ways to solve caching problems is adding a <u>hash number</u> to asset files, such <u>style.css</u> and <u>script.js</u>. You can read about it <a href="https://developers.google.com/web/fundamentals/performance/webpack/use-long-term-caching#split-the-code-into-routes-and-pages">here</a>. Hashing is needed to teach our browser to only request changed files.</p>

<p>Webpack 4 has a prebuilt functionality for it implemented via <a href="https://webpack.js.org/guides/caching/">chunkhash</a>. It can be done with:</p>

<pre><code>// webpack v4
const path = require(&#39;path&#39;);
const ExtractTextPlugin = require(&#39;extract-text-webpack-plugin&#39;);
const HtmlWebpackPlugin = require(&#39;html-webpack-plugin&#39;);

module.exports = {
  entry: { main: &#39;./src/index.js&#39; },
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;[name].[chunkhash].js&#39;
  },
  module: {
    rules: [
      {
        test: /\.js$/,
        exclude: /node_modules/,
        use: {
          loader: &quot;babel-loader&quot;
        }
      },
      {
        test: /\.scss$/,
        use: ExtractTextPlugin.extract(
          {
            fallback: &#39;style-loader&#39;,
            use: [&#39;css-loader&#39;, &#39;sass-loader&#39;]
          })
      }
    ]
  },
  plugins: [ 
    new ExtractTextPlugin(
      {filename: &#39;style.[chunkhash].css&#39;, disable: false, allChunks: true}
    ),
    new HtmlWebpackPlugin({
      inject: false,
      hash: true,
      template: &#39;./src/index.html&#39;,
      filename: &#39;index.html&#39;
    }),
  ]
};
</code></pre>

<p>In your_./src/index.html_ file add</p>

<pre><code>&lt;html&gt;
  &lt;head&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;&lt;%=htmlWebpackPlugin.files.chunks.main.css %&gt;&quot;&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div&gt;Hello, world!&lt;/div&gt;
    &lt;script src=&quot;&lt;%= htmlWebpackPlugin.files.chunks.main.entry %&gt;&quot;&gt;&lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>This syntax will teach your template to use hashed files. This is a new feature implemented after this issue:</p>

<p><a href="https://github.com/jantimon/html-webpack-plugin/pull/14" title="https://github.com/jantimon/html-webpack-plugin/pull/14">Support for .css and .manifest files and cache busting by jantimon · Pull Request #14 ·…<br/>
<u>This pull request deprecates the usage of {%=o.htmlWebpackPlugin.assets%} and creates a new representation called…</u>github.com</a><a href="https://github.com/jantimon/html-webpack-plugin/pull/14"></a></p>

<p>We will use htmlWebpackPlugin.files.chunks.main pattern described there.</p>

<p>now in our _./dist_ file index.html</p>

<p><img src="media/15248829536577/15248839087986.png" alt=""/></p>

<p>Now if we do not change anything in our _.js_ and. <u>css</u> file and run</p>

<pre><code>npm run dev
</code></pre>

<p>no matter how many times you run it, the numbers in hashes should be identical to each other in both files.</p>

<h3 id="toc_13">Problem with hashing and how to solve it</h3>

<p>Although we have the working implementation here, it is not perfect yet. What if we change some code in our _.scss_ file? Go ahead, change some scss there and run dev script again. Now the new file hash is not generated</p>

<p>What if we add a new console.log to our _.js_ file like this:</p>

<pre><code>import &quot;./style.css&quot;;
console.log(&quot;hello, world&quot;);
console.log(&quot;Hello, world 2&quot;);
</code></pre>

<p>If you run a dev script again, you will see that hash number has been updated in both files.</p>

<p>This issue is known and there is even a stack overflow question about it:</p>

<p><a href="https://stackoverflow.com/questions/44491064/updating-chunkhash-in-both-css-and-js-file-in-webpack" title="https://stackoverflow.com/questions/44491064/updating-chunkhash-in-both-css-and-js-file-in-webpack">Updating chunkhash in both css and js file in webpack<br/>
<u>I have only got the JS file in the output whereas i have used the ExtractTextPlugin to extract the Css file.Both have…</u>stackoverflow.com</a><a href="https://stackoverflow.com/questions/44491064/updating-chunkhash-in-both-css-and-js-file-in-webpack"></a></p>

<h4 id="toc_14">Now how to fix that?</h4>

<p>After trying a lot of plugins that claim they solve this problem I have finally came to two types of solution:</p>

<h4 id="toc_15">Solution 1</h4>

<p>Replace [chukhash] with just [hash] in _.css_ extract plugin. This was one of the solutions to the <a href="https://github.com/webpack-contrib/extract-text-webpack-plugin/issues/763">issue</a>. This appears to be a conflict with webpack 4.3 which introduced a <code>[contenthash]</code> variable of its <a href="https://github.com/webpack/webpack/releases/tag/v4.3.0">own</a>. In conjunction, use this plugin: <a href="https://www.npmjs.com/package/webpack-md5-hash">webpack-md5-hash</a></p>

<p>Now if you make changes to your <u>main.scss</u> file and run dev script, only a new <u>style.css</u> should be generated with a new hash.</p>

<pre><code>// webpack v4
const path = require(&#39;path&#39;);
const ExtractTextPlugin = require(&#39;extract-text-webpack-plugin&#39;);
const HtmlWebpackPlugin = require(&#39;html-webpack-plugin&#39;);
const WebpackMd5Hash = require(&#39;webpack-md5-hash&#39;);

module.exports = {
  entry: { main: &#39;./src/index.js&#39; },
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;[name].[chunkhash].js&#39;
  },
  module: {
    rules: [
      {
        test: /\.js$/,
        exclude: /node_modules/,
        use: {
          loader: &quot;babel-loader&quot;
        }
      },
      {
        test: /\.scss$/,
        use: ExtractTextPlugin.extract(
          {
            fallback: &#39;style-loader&#39;,
            use: [&#39;css-loader&#39;, &#39;sass-loader&#39;]
          })
      }
    ]
  },
  plugins: [ 
    new ExtractTextPlugin(
      {filename: &#39;style.[hash].css&#39;, disable: false, allChunks: true}
    ),
    new HtmlWebpackPlugin({
      inject: false,
      hash: true,
      template: &#39;./src/index.html&#39;,
      filename: &#39;index.html&#39;
    }),
    new WebpackMd5Hash()
  ]
};
</code></pre>

<p>Now lets test our _.js_ files. Now both files change hash.</p>

<h4 id="toc_16">Solution 2</h4>

<p>There might also be some conflicts still, so now lets try <a href="https://github.com/webpack-contrib/mini-css-extract-plugin">mini-css-extract plugin</a>.</p>

<h3 id="toc_17">Mini-CSS plugin</h3>

<p>The Mini CSS plugin is meant to replace extract-text plugin and provide you with better future compatibility.</p>

<p>I have restructured my webpack file to compile style.css with <a href="https://github.com/webpack-contrib/mini-css-extract-plugin" title="https://github.com/webpack-contrib/mini-css-extract-plugin">/mini-css-extract-plugin</a> and it works for me.</p>

<pre><code>// webpack v4
const path = require(&#39;path&#39;);
// const ExtractTextPlugin = require(&#39;extract-text-webpack-plugin&#39;);
const HtmlWebpackPlugin = require(&#39;html-webpack-plugin&#39;);
const WebpackMd5Hash = require(&#39;webpack-md5-hash&#39;);
const MiniCssExtractPlugin = require(&quot;mini-css-extract-plugin&quot;);

module.exports = {
  entry: { main: &#39;./src/index.js&#39; },
  output: {
    path: path.resolve(__dirname, &#39;dist&#39;),
    filename: &#39;[name].[chunkhash].js&#39;
  },
  module: {
    rules: [
      {
        test: /\.js$/,
        exclude: /node_modules/,
        use: {
          loader: &quot;babel-loader&quot;
        }
      },
      {
        test: /\.scss$/,
        use:  [  &#39;style-loader&#39;, MiniCssExtractPlugin.loader, &#39;css-loader&#39;, &#39;sass-loader&#39;]
      }
    ]
  },
  plugins: [
    // new ExtractTextPlugin(
    //   {filename: &#39;style.[hash].css&#39;, disable: false, allChunks: true }
    // ),
    new MiniCssExtractPlugin({
      filename: &#39;style.[contenthash].css&#39;,
    }),
    new HtmlWebpackPlugin({
      inject: false,
      hash: true,
      template: &#39;./src/index.html&#39;,
      filename: &#39;index.html&#39;
    }),
    new WebpackMd5Hash()
  ]
};
</code></pre>

<blockquote>
<p>Now when I edit <u>main.scss</u> a new hash for style_.css_ is generated. And when I edit css only css hash changes and when I edit _./src/script.js_ only <u>script.js</u> hash changes!</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[理解JWT的使用场景和优劣]]></title>
    <link href="http://panlw.github.io/15248824810738.html"/>
    <updated>2018-04-28T10:28:01+08:00</updated>
    <id>http://panlw.github.io/15248824810738.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://www.cnkirito.moe/2018/04/20/jwt-learn-3/">https://www.cnkirito.moe/2018/04/20/jwt-learn-3/</a></p>
</blockquote>

<p>经过前面两篇文章《<a href="https://www.cnkirito.moe/2018/04/14/jwt-learn/">JSON Web Token - 在Web应用间安全地传递信息</a>》《<a href="https://www.cnkirito.moe/2018/04/14/jwt-learn-2/">八幅漫画理解使用JSON Web Token设计单点登录系统</a>》的科普，相信大家应该已经知道了 JWT 协议是什么了。至少看到</p>

<p>这样形如 A.B.C 的字符串时能敏感地认出这是使用了 jwt。发了这两篇文章后，有不少读者在文末留言，表达了对 jwt 使用方式的一些疑惑，以及到底哪些场景适合使用 jwt。我并不是 jwt 方面的专家，和不少读者一样，起初研究时我也存在相同疑惑，甚至在逐渐接触后产生了更大的疑惑，经过这段时间项目中的使用和一些自己思考，把个人的总结整理成此文。</p>

<h3 id="toc_0"><a href="#%E7%BC%96%E7%A0%81%EF%BC%8C%E7%AD%BE%E5%90%8D%EF%BC%8C%E5%8A%A0%E5%AF%86" title="编码，签名，加密"></a>编码，签名，加密</h3>

<p>这些基础知识简单地介绍下，千万别搞混了三个概念。在 jwt 中恰好同时涉及了这三个概念，笔者用大白话来做下通俗的讲解（非严谨定义，供个人理解）</p>

<h4 id="toc_1"><a href="#%E7%BC%96%E7%A0%81-encode-%E5%92%8C%E8%A7%A3%E7%A0%81-decode" title="编码(encode)和解码(decode)"></a>编码(encode)和解码(decode)</h4>

<p>一般是编码解码是为了方便以字节的方式表示数据，便于存储和网络传输。整个 jwt 串会被置于 http 的 Header 或者 url 中，为了不出现乱码解析错误等意外，编码是有必要的。在 jwt 中以 <code>.</code> 分割的三个部分都经过 base64 编码(secret 部分是否进行 base64 编码是可选的，header 和 payload 则是必须进行 base64 编码)。注意，编码的一个特点：编码和解码的整个过程是可逆的。得知编码方式后，整个 jwt 串便是明文了，随意找个网站验证下解码后的内容：</p>

<p><img src="media/15248824810738/15248826502697.png" alt="base64"/></p>

<p>所以注意一点，<strong>payload 是一定不能够携带敏感数据如密码等信息的</strong>。</p>

<h4 id="toc_2"><a href="#%E7%AD%BE%E5%90%8D-signature" title="签名(signature)"></a>签名(signature)</h4>

<p>签名的目的主要是为了验证我是“我”。jwt 中常用的签名算法是 HS256，可能大多数人对这个签名算法不熟悉，但 md5,sha 这样的签名算法肯定是为人熟知的，签名算法共同的特点是整个过程是不可逆的。由于签名之前的主体内容(header,payload)会携带在 jwt 字符串中，所以需要使用带有密钥(yuè)的签名算法，密钥是服务器和签发者共享的。header 部分和 payload 部分如果被篡改，由于篡改者不知道密钥是什么，也无法生成新的 signature 部分，服务端也就无法通过，在 jwt 中，消息体是透明的，使用签名可以保证消息不被篡改。</p>

<blockquote>
<p>前面转载的文章中，原作者将 HS256 称之为加密算法，不太严谨。</p>
</blockquote>

<h4 id="toc_3"><a href="#%E5%8A%A0%E5%AF%86-encryption" title="加密(encryption)"></a>加密(encryption)</h4>

<p>加密是将明文信息改变为难以读取的密文内容，使之不可读。只有拥有解密方法的对象，经由解密过程，才能将密文还原为正常可读的内容。加密算法通常按照加密方式的不同分为对称加密(如 AES)和非对称加密(如 RSA)。你可能会疑惑：“jwt 中哪儿涉及加密算法了？”，其实 jwt 的 第一部分(header) 中的 alg 参数便可以指定不同的算法来生成第三部分(signature)，大部分支持 jwt 的框架至少都内置 rsa 这种非对称加密方式。这里诞生了第一个疑问</p>

<blockquote>
<p>疑问：一提到 rsa，大多数人第一想到的是非对称加密算法，而 jwt 的第三部分明确的英文定义是 signature，这不是矛盾吗？</p>
</blockquote>

<p>划重点！</p>

<p><strong>rsa 加密</strong>和<strong>rsa 签名</strong> 是两个概念！(吓得我都换行了)</p>

<p>这两个用法很好理解：</p>

<ul>
<li>  既然是加密，自然是不希望别人知道我的消息，只有我自己才能解密，所以<strong>公钥负责加密，私钥负责解密</strong>。这是大多数的使用场景，使用 rsa 来加密。</li>
<li>  既然是签名，自然是希望别人不能冒充我发消息，只有我才能发布签名，所以<strong>私钥负责签名，公钥负责验证</strong>。</li>
</ul>

<p>所以，在客户端使用 rsa 算法生成 jwt 串时，是使用私钥来“加密”的，而公钥是公开的，谁都可以解密，内容也无法变更（篡改者无法得知私钥）。</p>

<p>所以，在 jwt 中并没有纯粹的加密过程，而是使加密之虚，行签名之实。</p>

<h3 id="toc_4"><a href="#%E4%BB%80%E4%B9%88%E5%9C%BA%E6%99%AF%E8%AF%A5%E9%80%82%E5%90%88%E4%BD%BF%E7%94%A8jwt%EF%BC%9F" title="什么场景该适合使用jwt？"></a>什么场景该适合使用jwt？</h3>

<p>来聊聊几个场景，注意，以下的几个场景不是都和jwt贴合。</p>

<ol>
<li> 一次性验证</li>
</ol>

<p>比如用户注册后需要发一封邮件让其激活账户，通常邮件中需要有一个链接，这个链接需要具备以下的特性：能够标识用户，该链接具有时效性（通常只允许几小时之内激活），不能被篡改以激活其他可能的账户…这种场景就和 jwt 的特性非常贴近，jwt 的 payload 中固定的参数：iss 签发者和 exp 过期时间正是为其做准备的。</p>

<ol>
<li> restful api的无状态认证</li>
</ol>

<p>使用 jwt 来做 restful api 的身份认证也是值得推崇的一种使用方案。客户端和服务端共享 secret；过期时间由服务端校验，客户端定时刷新；签名信息不可被修改…spring security oauth jwt 提供了一套完整的 jwt 认证体系，以笔者的经验来看：使用 oauth2 或 jwt 来做 restful api 的认证都没有大问题，oauth2 功能更多，支持的场景更丰富，后者实现简单。</p>

<ol>
<li> 使用 jwt 做单点登录+会话管理(不推荐)</li>
</ol>

<p>在《<a href="https://www.cnkirito.moe/2018/04/14/jwt-learn-2/">八幅漫画理解使用JSON Web Token设计单点登录系统</a>》一文中提及了使用 jwt 来完成单点登录，本文接下来的内容主要就是围绕这一点来进行讨论。如果你正在考虑使用 jwt+cookie 代替 session+cookie ，我强力不推荐你这么做。</p>

<p>首先明确一点：使用 jwt 来设计单点登录系统是一个不太严谨的说法。首先 cookie+jwt 的方案前提是非跨域的单点登录(cookie 无法被自动携带至其他域名)，其次单点登录系统包含了很多技术细节，至少包含了身份认证和会话管理，这还不涉及到权限管理。如果觉得比较抽象，不妨用传统的 session+cookie 单点登录方案来做类比，通常我们可以选择 spring security（身份认证和权限管理的安全框架）和 spring session（session 共享）来构建，而选择用 jwt 设计单点登录系统需要解决很多传统方案中同样存在和本不存在的问题，以下一一详细罗列。</p>

<h3 id="toc_5"><a href="#jwt-token%E6%B3%84%E9%9C%B2%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F" title="jwt token泄露了怎么办？"></a>jwt token泄露了怎么办？</h3>

<p>前面的文章下有不少人留言提到这个问题，我则认为这不是问题。传统的 session+cookie 方案，如果泄露了 sessionId，别人同样可以盗用你的身份。扬汤止沸不如釜底抽薪，不妨来追根溯源一下，什么场景会导致你的 jwt 泄露。</p>

<p>遵循如下的实践可以尽可能保护你的 jwt 不被泄露：使用 https 加密你的应用，返回 jwt 给客户端时设置 httpOnly=true 并且使用 cookie 而不是 LocalStorage 存储 jwt，这样可以防止 XSS 攻击和 CSRF 攻击（对这两种攻击感兴趣的童鞋可以看下 spring security 中对他们的介绍<a href="https://docs.spring.io/spring-security/site/docs/current/reference/html/csrf.html">CSRF</a>,<a href="https://docs.spring.io/spring-security/site/docs/current/reference/html/headers.html#headers-xss-protection">XSS</a>）</p>

<p>你要是正在使用 jwt 访问一个接口，这个时候你的同事跑过来把你的 jwt 抄走了，这种泄露，恕在下无力</p>

<h3 id="toc_6"><a href="#secret%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1" title="secret如何设计"></a>secret如何设计</h3>

<p>jwt 唯一存储在服务端的只有一个 secret，个人认为这个 secret 应该设计成和用户相关的，而不是一个所有用户公用的统一值。这样可以有效的避免一些注销和修改密码时遇到的窘境。</p>

<h3 id="toc_7"><a href="#%E6%B3%A8%E9%94%80%E5%92%8C%E4%BF%AE%E6%94%B9%E5%AF%86%E7%A0%81" title="注销和修改密码"></a>注销和修改密码</h3>

<p>传统的 session+cookie 方案用户点击注销，服务端清空 session 即可，因为状态保存在服务端。但 jwt 的方案就比较难办了，因为 jwt 是无状态的，服务端通过计算来校验有效性。没有存储起来，所以即使客户端删除了 jwt，但是该 jwt 还是在有效期内，只不过处于一个游离状态。分析下痛点：注销变得复杂的原因在于 jwt 的无状态。我提供几个方案，视具体的业务来决定能不能接受。</p>

<ul>
<li>  仅仅清空客户端的 cookie，这样用户访问时就不会携带 jwt，服务端就认为用户需要重新登录。这是一个典型的假注销，对于用户表现出退出的行为，实际上这个时候携带对应的 jwt 依旧可以访问系统。</li>
<li>  清空或修改服务端的用户对应的 secret，这样在用户注销后，jwt 本身不变，但是由于 secret 不存在或改变，则无法完成校验。这也是为什么将 secret 设计成和用户相关的原因。</li>
<li>  借助第三方存储自己管理 jwt 的状态，可以以 jwt 为 key，实现去 redis 一类的缓存中间件中去校验存在性。方案设计并不难，但是引入 redis 之后，就把无状态的 jwt 硬生生变成了有状态了，违背了 jwt 的初衷。实际上这个方案和 session 都差不多了。</li>
</ul>

<p>修改密码则略微有些不同，假设号被到了，修改密码（是用户密码，不是 jwt 的 secret）之后，盗号者在原 jwt 有效期之内依旧可以继续访问系统，所以仅仅清空 cookie 自然是不够的，这时，需要强制性的修改 secret。在我的实践中就是这样做的。</p>

<h3 id="toc_8"><a href="#%E7%BB%AD%E7%AD%BE%E9%97%AE%E9%A2%98" title="续签问题"></a>续签问题</h3>

<p>续签问题可以说是我抵制使用 jwt 来代替传统 session 的最大原因，因为 jwt 的设计中我就没有发现它将续签认为是自身的一个特性。传统的 cookie 续签方案一般都是框架自带的，session 有效期 30 分钟，30 分钟内如果有访问，session 有效期被刷新至 30 分钟。而 jwt 本身的 payload 之中也有一个 exp 过期时间参数，来代表一个 jwt 的时效性，而 jwt 想延期这个 exp 就有点身不由己了，因为 payload 是参与签名的，一旦过期时间被修改，整个 jwt 串就变了，jwt 的特性天然不支持续签！</p>

<p>如果你一定要使用 jwt 做会话管理（payload 中存储会话信息），也不是没有解决方案，但个人认为都不是很令人满意</p>

<ol>
<li> 每次请求刷新 jwt</li>
</ol>

<p>jwt 修改 payload 中的 exp 后整个 jwt 串就会发生改变，那…就让它变好了，每次请求都返回一个新的 jwt 给客户端。太暴力了，不用我赘述这样做是多么的不优雅，以及带来的性能问题。</p>

<p>但，至少这是最简单的解决方案。</p>

<ol>
<li> 只要快要过期的时候刷新 jwt</li>
</ol>

<p>一个上述方案的改造点是，只在最后的几分钟返回给客户端一个新的 jwt。这样做，触发刷新 jwt 基本就要看运气了，如果用户恰巧在最后几分钟访问了服务器，触发了刷新，万事大吉；如果用户连续操作了 27 分钟，只有最后的 3 分钟没有操作，导致未刷新 jwt，无疑会令用户抓狂。</p>

<ol>
<li> 完善 refreshToken</li>
</ol>

<p>借鉴 oauth2 的设计，返回给客户端一个 refreshToken，允许客户端主动刷新 jwt。一般而言，jwt 的过期时间可以设置为数小时，而 refreshToken 的过期时间设置为数天。</p>

<p>我认为该方案并可行性是存在的，但是为了解决 jwt 的续签把整个流程改变了，为什么不考虑下 oauth2 的 password 模式和 client 模式呢？</p>

<ol>
<li> 使用 redis 记录独立的过期时间</li>
</ol>

<p>实际上我的项目中由于历史遗留问题，就是使用 jwt 来做登录和会话管理的，为了解决续签问题，我们在 redis 中单独会每个 jwt 设置了过期时间，每次访问时刷新 jwt 的过期时间，若 jwt 不存在与 redis 中则认为过期。</p>

<blockquote>
<p>tips:精确控制 redis 的过期时间不是件容易的事，可以参考我最近的一篇借助于 spring session 讲解 redis 过期时间的排坑记录。</p>
</blockquote>

<p>同样改变了 jwt 的流程，不过嘛，世间安得两全法。我只能奉劝各位还未使用 jwt 做会话管理的朋友，尽量还是选用传统的 session+cookie 方案，有很多成熟的分布式 session 框架和安全框架供你开箱即用。</p>

<h3 id="toc_9"><a href="#jwt-oauth2-session%E5%8D%83%E4%B8%9D%E4%B8%87%E7%BC%95%E7%9A%84%E8%81%94%E7%B3%BB" title="jwt,oauth2,session千丝万缕的联系"></a>jwt,oauth2,session千丝万缕的联系</h3>

<p>具体的对比不在此文介绍，就一位读者的留言回复下它的提问</p>

<blockquote>
<p>这么长一个字符串，还不如我把数据存到数据库，给一个长的很难碰撞的key来映射，也就是专用token。</p>
</blockquote>

<p>这位兄弟认为 jwt 太长了，是不是可以考虑使用和 oauth2 一样的 uuid 来映射。这里面自然是有问题的，jwt 不仅仅是作为身份的认证（验证签名是否正确，签发者是否存在，有限期是否过期），还在其 payload 中存储着会话信息，这是 jwt 和 session 的最大区别，一个在客户端携带会话信息，一个在服务端存储会话信息。如果真的是要将 jwt 的信息置于在共享存储中，那再找不到任何使用 jwt 的意义了。</p>

<p>jwt 和 oauth2 都可以用于 restful 的认证，就我个人的使用经验来看，spring security oauth2 可以很好的使用多种认证模式：client 模式，password 模式，implicit 模式（authorization code 模式不算单纯的接口认证模式），也可以很方便的实现权限控制，什么样的 api 需要什么样的权限，什么样的资源需要什么样的 scope…而 jwt 我只用它来实现过身份认证，功能较为单一（可能是我没发现更多用法）。</p>

<h3 id="toc_10"><a href="#%E6%80%BB%E7%BB%93" title="总结"></a>总结</h3>

<p>在 web 应用中，使用 jwt 代替 session 存在不小的风险，你至少得解决本文中提及的那些问题，绝大多数情况下，传统的 cookie-session 机制工作得更好。jwt 适合做简单的 restful api 认证，颁发一个固定有效期的 jwt，降低 jwt 暴露的风险，不要对 jwt 做服务端的状态管理，这样才能体现出 jwt 无状态的优势。</p>

<p>可能对 jwt 的使用场景还有一些地方未被我察觉，后续会研究下 spring security oauth jwt 的源码，不知到时会不会有新发现。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[阿里云Redis开发规范]]></title>
    <link href="http://panlw.github.io/15246678052226.html"/>
    <updated>2018-04-25T22:50:05+08:00</updated>
    <id>http://panlw.github.io/15246678052226.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://yq.aliyun.com/articles/531067">https://yq.aliyun.com/articles/531067</a></p>
</blockquote>

<h2 id="toc_0">一、键值设计</h2>

<h3 id="toc_1">1. key名设计</h3>

<ul>
<li>  (1)【建议】: 可读性和可管理性</li>
</ul>

<p>以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id</p>

<pre><code>ugc:video:1
</code></pre>

<ul>
<li>  (2)【建议】：简洁性</li>
</ul>

<p>保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：</p>

<pre><code>user:{uid}:friends:messages:{mid}简化为u:{uid}:fr:m:{mid}。
</code></pre>

<ul>
<li>  (3)【强制】：不要包含特殊字符</li>
</ul>

<p>反例：包含空格、换行、单双引号以及其他转义字符</p>

<h3 id="toc_2">2. value设计</h3>

<ul>
<li>  (1)【强制】：拒绝bigkey(防止网卡流量、慢查询)</li>
</ul>

<p>string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。</p>

<p>反例：一个包含200万个元素的list。</p>

<p>非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，<a href="#cc1">查找方法</a>和<a href="#cc2">删除方法</a></p>

<ul>
<li>  (2)【推荐】：选择适合的数据类型。</li>
</ul>

<p>例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡)</p>

<p>反例：</p>

<pre><code>set user:1:name tom
set user:1:age 19
set user:1:favor football
</code></pre>

<p>正例:</p>

<pre><code>hmset user:1 name tom age 19 favor football
</code></pre>

<h3 id="toc_3">3.【推荐】：控制key的生命周期，redis不是垃圾桶。</h3>

<p>建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。</p>

<h3 id="toc_4">二、命令使用</h3>

<h3 id="toc_5">1.【推荐】 O(N)命令关注N的数量</h3>

<p>例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。</p>

<h3 id="toc_6">2.【推荐】：禁用命令</h3>

<p>禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。</p>

<h3 id="toc_7">3.【推荐】合理使用select</h3>

<p>redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。</p>

<h3 id="toc_8">4.【推荐】使用批量操作提高效率</h3>

<pre><code>原生命令：例如mget、mset。
非原生命令：可以使用pipeline提高效率。
</code></pre>

<p>但要注意控制一次批量操作的<strong>元素个数</strong>(例如500以内，实际也和元素字节数有关)。</p>

<p>注意两者不同：</p>

<pre><code>1\. 原生是原子操作，pipeline是非原子操作。
2\. pipeline可以打包不同的命令，原生做不到
3\. pipeline需要客户端和服务端同时支持。
</code></pre>

<h3 id="toc_9">5.【建议】Redis事务功能较弱，不建议过多使用</h3>

<p>Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决)</p>

<h3 id="toc_10">6.【建议】Redis集群版本在使用Lua上有特殊要求：</h3>

<ul>
<li>  1.所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，&quot;-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array&quot;</li>
<li>  2.所有key，必须在1个slot上，否则直接返回error, &quot;-ERR eval/evalsha command keys must in same slot&quot;</li>
</ul>

<h3 id="toc_11">7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。</h3>

<h3 id="toc_12">三、客户端使用</h3>

<h3 id="toc_13">1.【推荐】</h3>

<p>避免多个应用使用一个Redis实例</p>

<p>正例：不相干的业务拆分，公共数据做服务化。</p>

<h3 id="toc_14">2.【推荐】</h3>

<p>使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式：</p>

<pre><code>执行命令如下：
Jedis jedis = null;
try {
    jedis = jedisPool.getResource();
    //具体的命令
    jedis.executeCommand()
} catch (Exception e) {
    logger.error(&quot;op key {} error: &quot; + e.getMessage(), key, e);
} finally {
    //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。
    if (jedis != null) 
        jedis.close();
}
</code></pre>

<p>下面是JedisPool优化方法的文章:</p>

<ul>
<li>  <a href="https://yq.aliyun.com/articles/236384">Jedis常见异常汇总</a></li>
<li>  <a href="https://yq.aliyun.com/articles/236383">JedisPool资源池优化</a></li>
</ul>

<h3 id="toc_15">3.【建议】</h3>

<p>高并发下建议客户端添加熔断功能(例如netflix hystrix)</p>

<h3 id="toc_16">4.【推荐】</h3>

<p>设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持）</p>

<h3 id="toc_17">5.【建议】</h3>

<p>根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。</p>

<p>默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。</p>

<h4 id="toc_18">其他策略如下：</h4>

<ul>
<li>  allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。</li>
<li>  allkeys-random：随机删除所有键，直到腾出足够空间为止。</li>
<li>  volatile-random:随机删除过期键，直到腾出足够空间为止。</li>
<li>  volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。</li>
<li>  noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息&quot;(error) OOM command not allowed when used memory&quot;，此时Redis只响应读操作。</li>
</ul>

<h3 id="toc_19">四、相关工具</h3>

<h4 id="toc_20">1.【推荐】：数据同步</h4>

<p>redis间数据同步可以使用：redis-port</p>

<p><a></a></p>

<h4 id="toc_21">2.【推荐】：big key搜索</h4>

<p><a href="https://yq.aliyun.com/articles/117042">redis大key搜索工具</a></p>

<h4 id="toc_22">3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)</h4>

<p><a href="https://github.com/facebookarchive/redis-faina">facebook的redis-faina</a></p>

<pre><code>阿里云Redis已经在内核层面解决热点key问题，欢迎使用。
</code></pre>

<p><a></a></p>

<h2 id="toc_23">五 附录：删除bigkey</h2>

<pre><code>1\. 下面操作可以使用pipeline加速。
2\. redis 4.0已经支持key的异步删除，欢迎使用。
</code></pre>

<h4 id="toc_24">1. Hash删除: hscan + hdel</h4>

<pre><code>public void delBigHash(String host, int port, String password, String bigHashKey) {
    Jedis jedis = new Jedis(host, port);
    if (password != null &amp;&amp; !&quot;&quot;.equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = &quot;0&quot;;
    do {
        ScanResult&lt;Entry&lt;String, String&gt;&gt; scanResult = jedis.hscan(bigHashKey, cursor, scanParams);
        List&lt;Entry&lt;String, String&gt;&gt; entryList = scanResult.getResult();
        if (entryList != null &amp;&amp; !entryList.isEmpty()) {
            for (Entry&lt;String, String&gt; entry : entryList) {
                jedis.hdel(bigHashKey, entry.getKey());
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!&quot;0&quot;.equals(cursor));

    //删除bigkey
    jedis.del(bigHashKey);
}
</code></pre>

<h4 id="toc_25">2. List删除: ltrim</h4>

<pre><code>public void delBigList(String host, int port, String password, String bigListKey) {
    Jedis jedis = new Jedis(host, port);
    if (password != null &amp;&amp; !&quot;&quot;.equals(password)) {
        jedis.auth(password);
    }
    long llen = jedis.llen(bigListKey);
    int counter = 0;
    int left = 100;
    while (counter &lt; llen) {
        //每次从左侧截掉100个
        jedis.ltrim(bigListKey, left, llen);
        counter += left;
    }
    //最终删除key
    jedis.del(bigListKey);
}
</code></pre>

<h4 id="toc_26">3. Set删除: sscan + srem</h4>

<pre><code>public void delBigSet(String host, int port, String password, String bigSetKey) {
    Jedis jedis = new Jedis(host, port);
    if (password != null &amp;&amp; !&quot;&quot;.equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = &quot;0&quot;;
    do {
        ScanResult&lt;String&gt; scanResult = jedis.sscan(bigSetKey, cursor, scanParams);
        List&lt;String&gt; memberList = scanResult.getResult();
        if (memberList != null &amp;&amp; !memberList.isEmpty()) {
            for (String member : memberList) {
                jedis.srem(bigSetKey, member);
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!&quot;0&quot;.equals(cursor));

    //删除bigkey
    jedis.del(bigSetKey);
}
</code></pre>

<h4 id="toc_27">4. SortedSet删除: zscan + zrem</h4>

<pre><code>public void delBigZset(String host, int port, String password, String bigZsetKey) {
    Jedis jedis = new Jedis(host, port);
    if (password != null &amp;&amp; !&quot;&quot;.equals(password)) {
        jedis.auth(password);
    }
    ScanParams scanParams = new ScanParams().count(100);
    String cursor = &quot;0&quot;;
    do {
        ScanResult&lt;Tuple&gt; scanResult = jedis.zscan(bigZsetKey, cursor, scanParams);
        List&lt;Tuple&gt; tupleList = scanResult.getResult();
        if (tupleList != null &amp;&amp; !tupleList.isEmpty()) {
            for (Tuple tuple : tupleList) {
                jedis.zrem(bigZsetKey, tuple.getElement());
            }
        }
        cursor = scanResult.getStringCursor();
    } while (!&quot;0&quot;.equals(cursor));

    //删除bigkey
    jedis.del(bigZsetKey);
}
</code></pre>

<h3 id="toc_28">招聘：<a href="https://job.alibaba.com/zhaopin/position_detail.htm?positionId=40132">阿里云-技术专家-KVstore</a></h3>

<p>岗位描述：</p>

<ul>
<li>  负责阿里云Redis源码开发维护</li>
<li>  负责阿里云Redis cluster开发与设计</li>
</ul>

<p>岗位要求：</p>

<ul>
<li>  精通C/C++，熟悉TCP， Linux Kernel等优先</li>
<li>  数据结构，算法等基础知识扎实</li>
<li>  5年后台系统的设计与开发，或3年分布式系统的设计与开发，运维过大型分布式系统</li>
<li>  精通至少一项开源NoSQL产品。Redis，mongodb,memcached等优先。</li>
<li>  有云服务产品或基于SSD的系统开发经验优先</li>
<li>  善于创新，乐于挑战，有责任心，良好团队精神</li>
<li>  良好的表达能力，能够清晰和准确地描述问题，发现并解决问题能力</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Native Extension for Node.js]]></title>
    <link href="http://panlw.github.io/15244133646661.html"/>
    <updated>2018-04-23T00:09:24+08:00</updated>
    <id>http://panlw.github.io/15244133646661.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://www.nan-labs.com/blog/native-extensions-for-nodejs/">https://www.nan-labs.com/blog/native-extensions-for-nodejs/</a></p>

<p><u>If you are a Spanish reader you can read this post in Spanish here: <a href="http://laplatajs.github.io/blog/2018/02/27/extensiones-nativas.html">Extensiones Nativas: ¿dónde empezar?</a></u></p>

<p>In this article we will talk about the most important concepts to develop native extensions for NodeJS. Later, I will show how to build our first native extension with a practical example. And finally, I will leave some links to read more about it.</p>
</blockquote>

<h2 id="toc_0">The basics to get started with native extensions</h2>

<p>In simple terms, we can say that a native extension is a set of C++ implemented logic that can be invoked from JavaScript code.</p>

<p>At this point, it’s interesting for us to clarify how NodeJS works and which are the parts involved in it. It’s important to know why we can talk about two languages (JavaScript &amp; C++) under the NodeJS context.</p>

<p>I like to explain it this way:</p>

<ul>
<li>  <strong>JavaScript</strong>: it’s the coding language.</li>
<li>  <strong>V8</strong>: it’s the engine that runs our JavaScript code.</li>
<li>  <strong>Libuv</strong>: it’s a C library that provides us with asynchronous execution.</li>
</ul>

<p>Now, where can we place native extensions? I will choose write/read disk action as an example to explain it. Neither JavaScript nor V8 provides us with disk access. Libuv provides asynchronous execution. But, with NodeJS we can write/read to disk, right? Well, this is the point where native extensions get into the match. The fs module is implemented using C++ (it has disk access) and eventually exposes methods (like writeFile and readFile) which can be invoked from JavaScript.</p>

<p><img src="media/15244133646661/15244134699236.jpg" alt="Interaction with native extensions diagram"/></p>

<p>Once we have learned this, we can start taking our first steps in native extensions. Let’s talk about the tools we need.</p>

<h2 id="toc_1">Basic tooling to build a native extension</h2>

<h3 id="toc_2">Binding.gyp file</h3>

<p>This file allows us to specify how we need to compile our native extension. One of the main thing that we need to define are the files that will be compiled and how we will call the final binary. It has a JSON like structure, and the keys to get this configured are sources and target.</p>

<h3 id="toc_3"><a href="https://github.com/nodejs/node-gyp">Node-gyp</a></h3>

<p>It’s the tool that allows us to compile our native extension. It’s implemented in NodeJS and it’s bundled with npm so we can just run npm install and that will compile our native extension. When we run npm install, it will detect our binding.gyp file included in our root folder and then it will start compiling.</p>

<p>Also, it allows us to make release(default) or debug builds. As a result, a binary file with .node extension will be created inside a release or debug folder, depending on how it was configured.</p>

<h3 id="toc_4"><a href="https://github.com/TooTallNate/node-bindings">Bindings</a></h3>

<p>It’s a NodeJS package which allows us to export our native extension. It’s in charge of searching in a build or release folder for us.</p>

<h3 id="toc_5"><a href="https://nodejs.org/api/n-api.html">N-API</a></h3>

<p>It’s C API that allows us to interact with our engine in a completely abstract way. For me, it’s the result of an evolution that tries to port node to different architectures.</p>

<p>N-API provides stability and compatibility between different node versions. That is, if my native extension is compiled to node 8.1, I don’t need to compile it again for node 8.6 or 9.3. Thus making the life of the maintainers and contributors easier.</p>

<p>At this moment, N-API is under <a href="https://nodejs.org/docs/latest/api/n-api.html#n_api_n_api">experimental state</a>.</p>

<h3 id="toc_6"><a href="https://github.com/nodejs/node-addon-api">Node addon api</a></h3>

<p>This NodeJS module provides us with a C++ implementation of N-API and allows us to use the language advantages.</p>

<h2 id="toc_7">First steps in the native extension world</h2>

<p><u>Note: For this example, I used node 9.3.</u></p>

<p>To get initiated on the native extension world we will use the classic hello world example. The idea is to not overload the code with extra logic so we can focus on the minimum necessary code.</p>

<p>We start initializing npm so that we can then install our dependencies:</p>

<p><code>npm init</code></p>

<p>Now, as we said, we install our dependencies:</p>

<p><code>npm i node-addon-api bindings</code></p>

<p>At this point we need to create our C file with our logic:</p>

<p><link rel="stylesheet" href="https://assets-cdn.github.com/assets/gist-embed-1baaff35daab552f019ad459494450f1.css"></p>

<pre><code class="language-cpp">#include &lt;napi.h&gt;

Napi::String SayHi(const Napi::CallbackInfo&amp; info) {
  Napi::Env env = info.Env();

  return Napi::String::New(env, &quot;Hi!&quot;);
}

Napi::Object init(Napi::Env env, Napi::Object exports) {
    exports.Set(Napi::String::New(env, &quot;sayHi&quot;), Napi::Function::New(env, SayHi));
    return exports;
};

NODE_API_MODULE(hello_world, init);
</code></pre>

<blockquote>
<p><a href="https://gist.github.com/nanlabsweb/d6c985ee9842fab274d4116c2fb0f443/raw/188b287e5092727700cfe1ddff8f6cbc402f3e3e/hello_world.cc">view raw</a> <a href="https://gist.github.com/nanlabsweb/d6c985ee9842fab274d4116c2fb0f443#file-hello_world-cc">hello_world.cc</a> hosted with ❤ by <a href="https://github.com">GitHub</a></p>
</blockquote>

<p>This file has three important parts that will be explained from bottom to top:</p>

<ul>
<li>  <strong>NODE_API_MODULE</strong> (Line 14): The first argument is the native extension name and the second one is the name of the function that initializes our extension.</li>
<li>  <strong>Init</strong> (Line 10): This is the function that will initialize our native extension. In this function we must export the functions that will be invoked from JavaScript code. To do this, we need to set the name of the function to the exports object and the function itself that will be invoked. This init function must return the exports object.</li>
<li>  <strong>SayHi</strong> (Line 3): This function is what will be executed when we invoke our native extension from our JavaScript.</li>
</ul>

<p>Later, we need to create our <strong>binding.gyp</strong> file that will contain our native extension configuration:</p>

<p><link rel="stylesheet" href="https://assets-cdn.github.com/assets/gist-embed-1baaff35daab552f019ad459494450f1.css"></p>

<pre><code class="language-json">{
  &quot;targets&quot;: [
    { 
      &quot;cflags!&quot;: [ &quot;-fno-exceptions&quot; ],
      &quot;cflags_cc!&quot;: [ &quot;-fno-exceptions&quot; ],
      &quot;include_dirs&quot; : [
        &quot;&lt;!@(node -p \&quot;require(&#39;node-addon-api&#39;).include\&quot;)&quot;
      ],
      &quot;target_name&quot;: &quot;hello_world&quot;,
      &quot;sources&quot;: [ &quot;hello_world.cc&quot; ],
      &#39;defines&#39;: [ &#39;NAPI_DISABLE_CPP_EXCEPTIONS&#39; ]
    }
  ]
}
</code></pre>

<blockquote>
<p><a href="https://gist.github.com/nanlabsweb/ebbc7d0c2dd5249b5f833e8a2b845f5d/raw/61068384831764b78bc8a7ace9deedefb1faadc5/binding.gyp">view raw</a> <a href="https://gist.github.com/nanlabsweb/ebbc7d0c2dd5249b5f833e8a2b845f5d#file-binding-gyp">binding.gyp</a> hosted with ❤ by <a href="https://github.com">GitHub</a></p>
</blockquote>

<p>Finally, the JavaScript code that will require our extension and invoke it.</p>

<p><link rel="stylesheet" href="https://assets-cdn.github.com/assets/gist-embed-1baaff35daab552f019ad459494450f1.css"></p>

<pre><code>const hello_world = require(&#39;bindings&#39;)(&#39;hello_world&#39;)

console.log(hello_world.sayHi());
</code></pre>

<blockquote>
<p><a href="https://gist.github.com/nanlabsweb/30019fc7ae72f3898f93623d535d8790/raw/a43850af02bfb800bad0ab82426c64b307f50e1c/index.js">view raw</a> <a href="https://gist.github.com/nanlabsweb/30019fc7ae72f3898f93623d535d8790#file-index-js">index.js</a> hosted with ❤ by <a href="https://github.com">GitHub</a></p>
</blockquote>

<p>Now, we just need to compile our extension running npm install and run the JavaScript file that is used:</p>

<p><img src="media/15244133646661/15244136958142.gif" alt="Native extensions gif demonstrating real usage."/></p>

<p>And that’s it. We just run our native extension.</p>

<h2 id="toc_8">What we had before N-API?</h2>

<p>I find it important to know the context and history of native extensions since it gives access to a lot of documentation and examples. The idea is for N-API to eventually replace NAN. For that reason we should look back to NAN for a moment.</p>

<p>NAN? Yes, <a href="https://github.com/nodejs/nan">Native Abstraction for Node.js</a>. NAN is a C++ library that provides us with V8 abstraction, but it doesn’t allow us to abstract ourselves from the V8.<br/>
In new NodeJS releases, there could be V8 changes that could break our native extension. Using NAN is a way to avoid this problem.</p>

<h2 id="toc_9">Further steps to develop your native extensions</h2>

<p>As I said, knowing about NAN allows us to learn from its examples and documentation. It’s a good complement to our native extension learning process.</p>

<ul>
<li>  NAPI examples can be found in <a href="https://github.com/nodejs/node/tree/master/test/addons-napi">here</a>.</li>
<li>  Node-addon-api examples can be found in <a href="https://github.com/nodejs/abi-stable-node-addon-examples">here</a>.</li>
<li>  Nan examples can be found in <a href="https://github.com/nodejs/nan/tree/master/test">here</a>.</li>
<li>  Another good source are tests <a href="https://github.com/nodejs/node-addon-api/tree/master/test">here</a>.</li>
<li>  To learn more about native extensions <a href="https://nodeaddons.com/">here</a>.</li>
</ul>

<h2 id="toc_10">Conclusion</h2>

<p>Learning about native extensions helped me to understand how NodeJS works and how it’s composed. There are more than one scenario where we can use them, such as performance boosts, C/C++ library integrations, or integration with legacy code.</p>

<p>In summary, it’s an excellent way to learn about NodeJS internals.</p>

<p>If you have any doubt, please post a comment and I will help you.</p>

<h3 id="toc_11">Taking part in the community</h3>

<p>I made this post for a contribution to <a href="http://laplatajs.github.io/">LaPlataJS</a>. It’s a local JavaScript community where I participate helping with talks, events organization, or posts. I think that whenever you can you should join a community. For me, it has a lot of benefits. You can know really good people, share ideas, learn things and, sometimes, go for a beer with your folks.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A GraphQL & Node.js Express Tutorial: Powerful E-Commerce with GraphCMS]]></title>
    <link href="http://panlw.github.io/15244093031262.html"/>
    <updated>2018-04-22T23:01:43+08:00</updated>
    <id>http://panlw.github.io/15244093031262.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://snipcart.com/blog/graphql-nodejs-express-tutorial">https://snipcart.com/blog/graphql-nodejs-express-tutorial</a></p>

<p>In a rush? Skip <a href="https://snipcart.com/blog/graphql-nodejs-express-tutorial#tutorial">tutorial steps</a> or <a href="https://snipcart.com/blog/graphql-nodejs-express-tutorial#conclusion">GitHub repo &amp; live demo</a>.</p>
</blockquote>

<p>Trends... they come and go.</p>

<p>Take those fidget spinners for instance, aren&#39;t we all tired of seeing them everywhere, right?</p>

<p>Chances are we&#39;re still stuck with them for a little while, and then we&#39;ll never hear from them again.</p>

<p>Nowhere is the &quot;trend&quot; phenomenon more obvious than in our developer universe, where technologies and shiny new toys appear every day. In this post, I want to try something new that, unlike spinners, is probably here to stay.</p>

<p>I&#39;m talking about <a href="http://graphql.org/"><strong>GraphQL</strong></a>.<br/>
<img src="https://lh3.googleusercontent.com/-7x7a96dgNeo/WuVwY03sBPI/AAAAAAAAACY/xSkMmaV3dG01sNsh4vm7sSXOLaZ8zbQ5wCHMYCw/I/15244094735531.png" alt=""/></p>

<p>Today, we’ll take part in this up-and-coming technology by sharing a GraphQL tutorial, while at the same time trying to capitalize on the last breath of the spinners trend by setting up our own online shop. We&#39;ll integrate GraphQL with <strong>Node.js Express</strong> to create a small e-commerce app.</p>

<p>In fact, we&#39;ll be using the GraphQL-based <a href="https://snipcart.com/blog/intro-api-first-headless-cms-directus">headless content management system</a>, <a href="https://graphcms.com/"><strong>GraphCMS</strong></a> and <a href="http://www.apollodata.com/"><strong>Apollo</strong></a>.</p>

<p>Live demo and full code repo included at the end. ;)</p>

<p><img src="https://lh3.googleusercontent.com/-kILqQsAY-P8/WuVwZEygETI/AAAAAAAAACc/rdEoJRc1zPAa51kDuwMlr2UvluHKj25kQCHMYCw/I/15244095062275.png" alt="GraphCMS logo"/></p>

<p>Let’s <u>spin</u> our way (see what I did there?) into all of the following:</p>

<ol>
<li> Creating a Node.js Express app</li>
<li> Setting up GraphCMS</li>
<li> Querying the GraphQL API using Apollo client</li>
<li> Creating our shop with Snipcart</li>
</ol>

<p>But let’s not get ahead of ourselves and start by digging deeper into what we&#39;re working with here.</p>

<h2 id="toc_0">What is GraphQL?</h2>

<p><strong>GraphQL is a new syntax for your API that defines how to fetch data from one or many databases.</strong></p>

<p>Since this new <u>query language</u> for APIs was open sourced in 2015 by a small company named Facebook (which used it for its mobile apps since 2012), a growing community has been supporting and developing it.</p>

<p>It has been created to solve some structural problems developers encountered when they started to create apps that were way more complex than before.</p>

<p>As for Facebook’s use case, they wanted to put all of the website features into the users&#39; hands, with their mobile apps, back in 2011. That’s when they started to think about a new way of doing things. A way that would make traffic between clients and servers simpler, more organized.</p>

<p>GraphQL was the result.</p>

<p><img src="media/15244093031262/15244098515128.png" alt="What is GraphQL"/></p>

<p>They made it possible to manage data over a single endpoint via HTTP. Each query you send to your API gets you exactly what you want. What I mean here is that you will receive on the other end <u>nothing more</u> and <u>nothing less</u> than what you need. The data needed is determined client side instead of letting servers control it, helping to build apps that are way <u>faster</u> and <u>more stable</u>.</p>

<p>Its <a href="https://dev-blog.apollodata.com/the-anatomy-of-a-graphql-query-6dffa9e9e747">_type schema system_</a> regroups all the data you can access, no matter where it is stored, under different fields. You can relate these to one another in order to get the information needed in one simple request.</p>

<p>Now, this is just a quick GraphQL overview. We won’t get into all the specifics here since it’s not the goal of this post. But there are plenty of helpful resources available should you want to learn more:</p>

<ul>
<li>  <a href="http://graphql.org/learn/best-practices/">Here’s a nice tool</a> to help you get started with it.</li>
<li>  To dive straight into it, take a look at the <a href="https://facebook.github.io/graphql/#">GraphQL specs</a>.</li>
</ul>

<h3 id="toc_1">Why GraphQL over REST APIs?</h3>

<p>This topic has already caused a lot of discussions on dev forums, and what you get out of these is that you can’t compare both <u>directly</u>. <a href="https://philsturgeon.uk/api/2017/01/24/graphql-vs-rest-overview/">They are not the same</a>, and GraphQL won’t take over REST APIs tomorrow morning. Whereas the first is, as I already mentioned, a query language, the other is an <u>architectural concept</u>.</p>

<p>You can actually <a href="https://www.youtube.com/embed/UBGzsb2UkeY">wrap a REST API in GraphQL</a>. This is good to know if you want to try GraphQL without throwing away your existing infrastructure.</p>

<p>Still, more and more developers will turn towards GraphQL for their new APIs, because it solves a lot of the problems that pushed them to scratch their heads with REST’s multiple endpoints.</p>

<p><img src="media/15244093031262/15244097343716.png" alt="REST API vs GraphQL"/></p>

<p>GraphQL vs REST API queries <a href="https://medium.com/@ottovw/rest-api-downfalls-and-dawn-of-graphql-dd00991a0eb8">[source]</a></p>

<p>The latter means you have to make different calls to different endpoints for a single request, like loading a page. It made the process slower as you create more complex architectures. And it can rapidly become a real mess with REST APIs for that reason.</p>

<h3 id="toc_2">So, what should you do?</h3>

<p>It’s entirely up to you, but there are situations where GraphQL starts to look like the best option:</p>

<ul>
<li>  If you have multiple clients, because they simply write their own queries, in the language of their choice, GraphQL supports them all;</li>
<li>  If you work on different platforms: web, mobile, apps, etc;</li>
<li>  If your API is highly customizable.</li>
</ul>

<p>Speaking of <u>highly customizable</u>, we&#39;ll try to determine how we can fit Snipcart into all of this, with the help of an Express app. Before jumping in the demo, let&#39;s learn a bit more about this Node.js Express framework we&#39;ll use.</p>

<h2 id="toc_3">What is Node.js Express?</h2>

<p><strong>Express is a fast, unopinionated, minimalist web framework for Node.js.</strong></p>

<p>We&#39;ve <a href="https://snipcart.com/blog/nodejs-ecommerce-harp-js-static">already played with Node before</a>, but here we&#39;ll use Express for the server-side of our demo. It&#39;s probably the most well-known framework for Node.js right now. <a href="https://expressjs.com/en/starter/installing.html">Official docs over here</a>.</p>

<p>It&#39;s a simple framework that adds fundamental web application features on top of Node.js. It was one of the first out there and is widely used by lots of companies that work with Node.js (IBM, Uber &amp; more).</p>

<p>There&#39;s a ton of modules you can add on top of it to handle most use cases. Like a body parser we&#39;ll use today to deal with JSON payloads.</p>

<p>Although there are some alternatives such as <a href="http://koajs.com/">Koa</a> and <a href="http://sailsjs.com/">SailsJS</a>, I decided to go with the classic and stick to what I know best.</p>

<p>It&#39;s now time to put these awesome tools to use; let&#39;s sell some spinners!</p>

<h2 id="toc_4">Building an e-commerce app: Node.js Express &amp; GraphQL demo</h2>

<p>In this demo, we&#39;ll craft a small shop web application from scratch. Other than Express we&#39;ll be using several technologies to achieve this goal.</p>

<p>Namely, <code>apollo-client</code> from folks at <strong>Apollo</strong>, a very neat framework that makes it easy to query a GraphQL API.</p>

<p>The GraphQL API will be handled by <strong>GraphCMS</strong>.</p>

<p>On top of that, we&#39;ll add our e-commerce solution, Snipcart. ;)</p>

<h3 id="toc_5">Getting started with Node.js Express</h3>

<p>We&#39;ll start by initializing a new node project.</p>

<pre><code>npm init

</code></pre>

<p>Answer the quick questions that the CLI will ask you.</p>

<p>This will create the <code>project.json</code> file and then we&#39;ll be ready to start for real.</p>

<p>We&#39;ll first need to add <code>express</code> npm package.</p>

<pre><code>npm install express --save

</code></pre>

<p>Then, we&#39;ll create the entry file of our application. Let&#39;s name it <code>server.js</code>.</p>

<pre><code>// /server.js

const express = require(&#39;express&#39;)
const app = express()

app.listen(3000, function() {
    console.log(&#39;Listening on port 3000.&#39;);
})

</code></pre>

<p>The first thing we&#39;ll do is to set the view engine we are going to use. In our case, we&#39;ll go ahead with <code>pug</code>.</p>

<pre><code>npm install pug --save

</code></pre>

<p>Then we&#39;ll add these lines to the <code>server.js</code> file.</p>

<pre><code>// /server.js

app.set(&#39;view engine&#39;, &#39;pug&#39;)
app.set(&#39;views&#39;, path.join(__dirname, &#39;/app/views&#39;))

</code></pre>

<p>This will set our default view engine and the path where our views will be located.</p>

<p>We&#39;ll then need to create a router to show the list of our products. Create a new directory named <code>app</code> in your root folder and then create another folder named <code>routers</code> in the former.</p>

<p>We&#39;ll create a router named <code>products.js</code>.</p>

<pre><code>// /app/routers/products.js

const express = require(&#39;express&#39;)
const router = express.Router()

router.get(&#39;/&#39;, (req, res) =&gt; {
})

</code></pre>

<p>We&#39;ll need to register this router in our app. Add these lines to <code>server.js</code> file:</p>

<pre><code>// /server.js

const products = require(&#39;./app/routers/products&#39;)
app.use(&#39;/&#39;, products)

</code></pre>

<h3 id="toc_6">Setting up GraphCMS</h3>

<p>Now for GraphCMS. You&#39;ll need an account: create one <a href="https://app.graphcms.com/">here</a>.</p>

<p>Once logged in, create a new project. I named mine <code>Snipcart demo</code>. Once the project is created, click on Content and then on Add Content Model.</p>

<p><img src="media/15244093031262/15244098950968.png" alt="add-content-model"/></p>

<p>We&#39;ll now define the fields of the product, add the necessary fields so your model looks like this:</p>

<p><img src="media/15244093031262/15244099157106.png" alt="product-fields"/></p>

<p>You can then create a few products. When it&#39;s done we&#39;ll need to get the GraphQL API endpoint and make it readable.</p>

<p>Click on Settings in the menu, and enable Public API Access.</p>

<p><img src="media/15244093031262/15244108383474.png" alt="public-api-access"/></p>

<p>Then note your <strong>Simple Endpoint</strong> URL in the Endpoints section.</p>

<h3 id="toc_7">Querying our GraphQL API</h3>

<p>Back to the code now. We&#39;ll need to change our <code>products.js</code> router to fetch the items from the API. Before that, we&#39;ll create a small service module that&#39;ll interact with the API using Apollo client.</p>

<p>Let&#39;s install the modules we&#39;ll need from npm.</p>

<pre><code>npm install apollo-client graphql-tag node-fetch url numeral --save

</code></pre>

<p>We also install <code>node-fetch</code> because the <code>fetch</code> method used by <code>apollo-client</code> is not yet available in Node.js.</p>

<p><code>url</code> and <code>numeral</code> package will be used for display purposes that we&#39;ll see later.</p>

<p>We&#39;ll also create a configuration file in our project root containing things such as an API endpoint URL and Snipcart API key.</p>

<pre><code>// /config.json

{
    &quot;apiEndpoint&quot;: &quot;https://api.graphcms.com/simple/v1/cj3c0azkizxa6018532qd1tmh&quot;,
    &quot;snipcartApiKey&quot;: &quot;MzMxN2Y0ODMtOWNhMy00YzUzLWFiNTYtZjMwZTRkZDcxYzM4&quot;
}

</code></pre>

<p>Create a new directory named <code>services</code> in the <code>app</code> folder. We&#39;ll add a new file named <code>products.js</code> in it.</p>

<pre><code>// /app/services/products.js

fetch = require(&#39;node-fetch&#39;)
const config = require(&#39;./../../config.json&#39;)
const Apollo = require(&#39;apollo-client&#39;)
const gql = require(&#39;graphql-tag&#39;)
const ApolloClient = Apollo.ApolloClient
const createNetworkInterface = Apollo.createNetworkInterface

const client = new ApolloClient({
    networkInterface: createNetworkInterface({
        uri: config.apiEndpoint
    })
})

module.exports = {
    getAllProducts: () =&gt; {
        return new Promise((resolve, reject) =&gt; {
            client.query({
                query: gql`
                   query {
                        allProducts {
                            name,
                            id,
                            sku,
                            price,
                            description,
                            image {
                                url
                            }
                        }
                    }
                `
            })
            .then((response) =&gt; {
                resolve(response.data.allProducts)
            })
        })
    },
    getProductById: (id) =&gt; {
        return new Promise((resolve, reject) =&gt; {
            client.query({
                query: gql`
                    query {
                        Product(id: &quot;${id}&quot;) {
                            name,
                            id,
                            image {
                                url
                            },
                            description,
                            price,
                            sku
                        }
                    }
                `
            })
            .then((response) =&gt; {
                resolve(response.data.Product)
            })
        })
    }
}

</code></pre>

<h3 id="toc_8">Creating the store with Snipcart</h3>

<p>So we now have a way to fetch our data. We can retrieve a list of products and a product by its id. Should be enough for our humble tutorial.</p>

<p>Let&#39;s start by listing all our products. Open the router file <code>products.js</code>.</p>

<pre><code>// /app/routers/products.js

const express = require(&#39;express&#39;)
const router = express.Router()
const productsService = require (&#39;./../services/products&#39;)

router.get(&#39;/&#39;, (req, res) =&gt; {
    productsService.getAllProducts()
        .then(function (data) {
            res.render(&#39;products/index&#39;, {
                products: data
            })
        })
})

module.exports = router

</code></pre>

<p>We fetch the products from the GraphQL API, then render a view that we&#39;ll need to create.</p>

<p>Let&#39;s start with the views we need. We&#39;ll start by putting together our base layout. Place a file named <code>layout.pug</code> in <code>/app/views</code> directory.</p>

<pre><code>// /app/views/layout.pug

html
    head
        if title
            title #{ title }
        else
            title Awesome shop powered by GraphCMS and Snipcart

        block styles
            link(href=&#39;https://cdnjs.cloudflare.com/ajax/libs/bulma/0.4.2/css/bulma.min.css&#39;, rel=&#39;stylesheet&#39;, type=&quot;text/css&quot;)
            link(href=&quot;https://cdn.snipcart.com/themes/2.0/base/snipcart.min.css&quot;, type=&quot;text/css&quot;, rel=&quot;stylesheet&quot;)
            link(href=&#39;https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css&#39;, type=&#39;text/css&#39;, rel=&#39;stylesheet&#39;)

        block scripts
            script(src=&quot;https://ajax.googleapis.com/ajax/libs/jquery/2.2.2/jquery.min.js&quot;)
            script(src=&quot;https://cdn.snipcart.com/scripts/2.0/snipcart.js&quot;, id=&quot;snipcart&quot;, data-api-key=snipcartApiKey)

    body
        .container
            nav.nav.has-shadow
                .nav-left
                    a(href=&#39;/&#39;).nav-item.is-active.is-tab Spinners

                .nav-right.nav-menu
                    a.nav-item.is-tab.snipcart-summary.snipcart-checkout
                        i.fa.fa-shopping-cart &amp;nbsp;
                        | View cart (
                        span.snipcart-total-items 0
                        | )
        block content

</code></pre>

<p>You will notice that I added some files in there already. First, I included <a href="http://bulma.io/">Bulma</a> to make a decent looking application quickly, FontAwesome for the icons, then jQuery and <a href="https://app.snipcart.com/register">Snipcart</a>&#39;s required files.</p>

<p>I also added a nav bar with the cart content summary in it.</p>

<p>Now that we have a layout, we&#39;ll generate the view that will list the products.</p>

<p>Insert a new file named <code>index.pug</code> in <code>/app/views/products</code> folder.</p>

<pre><code>// /app/views/products/index.pug

extends ../layout.pug
include ../_mixins/snipcart.pug

block content
    .section
        .container
            .heading
                h1.title Our spinners

    .section
        .container
            .columns.is-multiline
                each p in products
                    .column.is-half
                        article.media
                            figure.media-left
                                p.image.is-64x64
                                    img(src=p.image.url)
                            .media-content
                                .content
                                    p
                                        strong #{ p.name }
                                        small  #{ formatMoney(p.price) }
                                        br
                                        | !{ p.description }
                                nav.level
                                    .level-left
                                        +snipcart_button(p).level-item(title=&#39;Add to cart&#39;)
                                            span.icon.is-small
                                                i.fa.fa-cart-plus
                                        a(href=`/products/${p.id}`, title=&#39;View details&#39;).level-item
                                            span.icon.is-small
                                                i.fa.fa-info

</code></pre>

<p>This template will render each product, with its details and two buttons: one to get to the product details and another one to add it to the cart.</p>

<p>You will notice that I used some methods to display things such as <code>formatMoney</code> and a <code>mixin</code> named <code>snipcart_button</code>.</p>

<p>Here&#39;s the code for the mixin:</p>

<pre><code>// /app/views/_mixins/snipcart.pug

mixin snipcart_button(product)
    a(href=&#39;#&#39;).snipcart-add-item&amp;attributes(attributes)(
        data-item-name=product.name
        data-item-id=product.sku
        data-item-price=product.price
        data-item-image=product.image.url
        data-item-url=fullUrl(`/products/${product.id}/json`)
    )
        block

</code></pre>

<p>We&#39;ll see later what&#39;s up with the <code>products/${product.id}/json</code> URL.</p>

<p>The <code>formatMoney</code> will be added to the <code>locals</code>. Open the <code>server.js</code> file and modify it:</p>

<pre><code>// /server.js

const express = require(&#39;express&#39;)
const app = express()
const products = require(&#39;./app/routers/products&#39;)
const path = require(&#39;path&#39;)
const config = require(&#39;./config.json&#39;)

// We need these two packages for display purposes
const numeral = require(&#39;numeral&#39;)
const url = require(&#39;url&#39;)

// We add the methods and properties we need to the response locals.

app.use((req, res, next) =&gt; {
    res.locals = {
        snipcartApiKey: config.snipcartApiKey,
        formatMoney: (number) =&gt; {
            return numeral(number).format(&#39;0.00$&#39;)
        },
        fullUrl: (path) =&gt; {
            return url.format({
                protocol: req.protocol,
                host: req.get(&#39;host&#39;),
                pathname: path
            })
        }
    }
    next()
})

app.use(&#39;/&#39;, products)

app.use((req, res, next) =&gt; {
    res.status(404)
});

app.set(&#39;view engine&#39;, &#39;pug&#39;)
app.set(&#39;views&#39;, path.join(__dirname, &#39;/app/views&#39;))

app.listen(3000, function() {
    console.log(&#39;Listening on port 3000.&#39;);
})

</code></pre>

<p>We&#39;ll then have access to the Snipcart API key and two helper methods in our templates.</p>

<p>If you type: <code>node server.js</code> in your command prompt you should see something like:</p>

<p><img src="media/15244093031262/15244108647779.png" alt="store"/></p>

<p>Pretty neat! Remember when I said we&#39;d come back to the <code>/json</code> route? Now&#39;s the time. One feature we offer that isn&#39;t used enough, in my opinion, is our <a href="https://docs.snipcart.com/configuration/json-crawler">JSON crawler</a>. It&#39;s very useful when you have access to an API or server-side language like we have here.</p>

<p>So we&#39;ll generate a new route that will return the product details in a JSON format that Snipcart can understand. Open <code>products.js</code> router file and add this route handler:</p>

<pre><code>// /app/routers/products.js

router.get(&#39;/products/:id/json&#39;, (req, res, next) =&gt; {
    res.setHeader(&#39;Content-Type&#39;, &#39;application/json&#39;)
    productsService.getProductById(req.params.id)
        .then((product) =&gt; {
            if (!product) {
                next()
            }

            return res.send({
                id: product.sku,
                price: product.price
            })
        })
})

</code></pre>

<p>Whenever we&#39;ll hit this route our app will return a <code>json</code> object that our crawler will understand.</p>

<p>In this file, we are also going to add the route to show the single product details template.</p>

<pre><code>// /app/routers/products.js

router.get(&#39;/products/:id&#39;, (req, res) =&gt; {
    productsService.getProductById(req.params.id)
        .then((product) =&gt; {
            return res.render(&#39;products/details&#39;, {
                product: product
            })
        })
})

</code></pre>

<p>As we did for the products listing, we&#39;ll need to create the <code>products/details.pug</code> view.</p>

<pre><code>// /app/views/products/details.pug

extends ../layout.pug
include ../_mixins/snipcart.pug

block content
    .section
        .container
            .columns
                .card.column.is-half.is-offset-one-quarter
                    .card-image
                        figure.image.is-128x128
                            img(src=product.image.url)
                    .card-content
                        p.title.is-4 #{ product.name }
                            small  #{ formatMoney(product.price) }
                        p #{ product.description }

                    .card-content
                        +snipcart_button(product)
                            span.icon.is-large
                                i.fa.fa-cart-plus                 

</code></pre>

<p>We&#39;ll be using the same <code>mixin</code> that we used earlier to render the buy button.</p>

<h2 id="toc_9">GraphQL &amp; Node.js Express live demo</h2>

<p>You can now browse our demo website, view product details and add them to the cart.</p>

<blockquote>
<p><a href="https://github.com/snipcart/snipcart-graphcms-nodejs">See GitHub code repo</a></p>

<p><a href="https://snipcart-graphcms-nodejs.herokuapp.com/">See live demo</a></p>
</blockquote>

<p>Hope you find the fidget spinner you&#39;re looking for in there!</p>

<h3 id="toc_10">Closing thoughts</h3>

<p>GraphCMS makes it effortless to create easily consumable GraphQL API. The whole demo took me about 2 hours to write, including the learning curve for Apollo and querying a GraphQL API. I hope this will help and inspire you to try these tools! I&#39;m pretty sure that, as developers, we&#39;ll all have to work with this new query language in the near future so it&#39;s a good thing to start learning about it right now.</p>

<p><a href="https://twitter.com/home?status=As%20for%20Express%2C%20it&#x27;s%20very%20easy%20to%20get%20started%20with.%20http%3A%2F%2Fbit.ly%2F2ire4oM%20via%20%40snipcart%20%23nodejs">As for Express, it&#39;s very easy to get started with.</a> Only a few lines of code and you have a web server running that can handle HTTP requests.</p>

<p>If you feel inspired you can visit the <a href="https://github.com/chentsulin/awesome-graphql">GraphQL Awesome list</a> to see all the current possibilities of GraphQL. You can also follow the <a href="https://graphqlweekly.com/">GraphQL Newsletter</a> to stay in the loop!</p>

<hr/>

<p><u>If you found this post valuable, please take a second to <a href="https://twitter.com/home?status=GraphQL%20CMS%20Tutorial%3A%20E-Commerce%20with%20GraphCMS,%20Node.js%20and%20Apollo%20http%3A//bit.ly/2ire4oM%20%40graphcms%20%23graphql%20%23ecommerce">share it on twitter</a>. Found something we missed? Want to discuss your experience with GraphQL, GraphCMS, Node.js or Apollo? Comments are all yours!</u></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advanced Node.js Project Structure Tutorial]]></title>
    <link href="http://panlw.github.io/15244030785891.html"/>
    <updated>2018-04-22T21:17:58+08:00</updated>
    <id>http://panlw.github.io/15244030785891.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://blog.codeship.com/advanced-node-js-project-structure-tutorial/">https://blog.codeship.com/advanced-node-js-project-structure-tutorial/</a></p>

<p><u>This article was originally published on <a href="https://blog.risingstack.com/node-js-project-structure-tutorial-node-js-at-scale/">the RisingStack blog</a> by <a href="https://twitter.com/@tthndrs">András Tóth</a>. With their kind permission, we’re sharing it here for Codeship readers.</u></p>
</blockquote>

<p>Project structuring is an important topic because the way you bootstrap your application can determine the whole development experience throughout the life of the project.</p>

<p>In this Node.js project structure tutorial I’ll answer some of the most common questions we receive at <a href="https://trace.risingstack.com/">RisingStack</a> about structuring advanced Node applications, and help you with structuring a complex project.</p>

<p><strong>These are the goals that we are aiming for:</strong></p>

<ul>
<li>  Writing an application that is easy to scale and maintain.</li>
<li>  The config is well separated from the business logic.</li>
<li>  Our application can consist of multiple process types.</li>
</ul>

<blockquote>
<p><strong>Node.js at Scale</strong> is <a href="http://chapters">a collection of articles</a> focusing on the needs of companies with bigger Node.js installations and advanced Node developers.</p>
</blockquote>

<h2 id="toc_0">The Node.js Project Structure</h2>

<p>Our example application is listening on Twitter tweets and tracks certain keywords. In case of a keyword match, the tweet will be sent to a RabbitMQ queue, which will be processed and saved to Redis. We will also have a REST API exposing the tweets we have saved.</p>

<p>You can take a look at the code on <a href="https://github.com/RisingStack/multi-process-nodejs-example">GitHub</a>. The file structure for this project looks like the following:</p>

<pre><code>.
|-- config
|   |-- components
|   |   |-- common.js
|   |   |-- logger.js
|   |   |-- rabbitmq.js
|   |   |-- redis.js
|   |   |-- server.js
|   |   `-- twitter.js
|   |-- index.js
|   |-- social-preprocessor-worker.js
|   |-- twitter-stream-worker.js
|   `-- web.js
|-- models
|   |-- redis
|   |   |-- index.js
|   |   `-- redis.js
|   |-- tortoise
|   |   |-- index.js
|   |   `-- tortoise.js
|   `-- twitter
|       |-- index.js
|       `-- twitter.js
|-- scripts
|-- test
|   `-- setup.js
|-- web
|   |-- middleware
|   |   |-- index.js
|   |   `-- parseQuery.js
|   |-- router
|   |   |-- api
|   |   |   |-- tweets
|   |   |   |   |-- get.js
|   |   |   |   |-- get.spec.js
|   |   |   |   `-- index.js
|   |   |   `-- index.js
|   |   `-- index.js
|   |-- index.js
|   `-- server.js
|-- worker
|   |-- social-preprocessor
|   |   |-- index.js
|   |   `-- worker.js
|   `-- twitter-stream
|       |-- index.js
|       `-- worker.js
|-- index.js
`-- package.json
</code></pre>

<p>In this example we have 3 processes:</p>

<ul>
<li>  <code>twitter-stream-worker</code>: The process is listening on Twitter for keywords and sends the tweets to a RabbitMQ queue.</li>
<li>  <code>social-preprocessor-worker</code>: The process is listening on the RabbitMQ queue and saves the tweets to Redis and removes old ones.</li>
<li>  <code>web</code>: The process is serving a REST API with a single endpoint: <code>GET /api/v1/tweets?limit&amp;offset</code>.</li>
</ul>

<p>We will get to what differentiates a <code>web</code> and a <code>worker</code> process, but let’s start with the config.</p>

<h3 id="toc_1">How to handle different environments and configurations</h3>

<p>Load your deployment specific configurations from environment variables and never add them to the codebase as constants. These are the configurations that can vary between deployments and runtime environments, like CI, staging or production. Basically, you can have the same code running everywhere.</p>

<p>A good test for whether the config is correctly separated from the application internals is that the codebase could be made public at any moment. This means that you can be protected from accidentally leaking secrets or compromising credentials on version control.</p>

<p><a href="https://twitter.com/share?text=A+config+is+properly+separated+from+an+app%27s+internals+if+the+code+could+go+public+at+any+moment.&amp;url=https://blog.codeship.com/advanced-node-js-project-structure-tutorial/">A config is properly separated from an app’s internals if the code could go public at any moment.</a></p>

<p><a href="https://twitter.com/share?text=A+config+is+properly+separated+from+an+app%27s+internals+if+the+code+could+go+public+at+any+moment.&amp;url=https://blog.codeship.com/advanced-node-js-project-structure-tutorial/">Click To Tweet</a></p>

<p>The environment variables can be accessed via the <code>process.env</code> object. Keep in mind that all the values have a type of <code>String</code>, so you might need to use type conversions.</p>

<pre><code>// config/config.js
&#39;use strict&#39;

// required environment variables
[
  &#39;NODE_ENV&#39;,
  &#39;PORT&#39;
].forEach((name) =&gt; {
  if (!process.env[name]) {
    throw new Error(`Environment variable ${name} is missing`)
  }
})

const config = {
  env: process.env.NODE_ENV,
  logger: {
    level: process.env.LOG_LEVEL || &#39;info&#39;,
    enabled: process.env.BOOLEAN ? process.env.BOOLEAN.toLowerCase() === &#39;true&#39; : false
  },
  server: {
    port: Number(process.env.PORT)
  }
  // ...
}

module.exports = config
</code></pre>

<h3 id="toc_2">Config validation</h3>

<p>Validating environment variables is also a quite useful technique. It can help you catching configuration errors on startup before your application does anything else. You can read more about the benefits of early error detection of configurations by <a href="https://blog.acolyer.org/2016/11/29/early-detection-of-configuration-errors-to-reduce-failure-damage/">Adrian Colyer in this blog post</a>.</p>

<p>This is how our improved config file looks like with schema validation using the <code>joi</code> validator:</p>

<pre><code>// config/config.js
&#39;use strict&#39;

const joi = require(&#39;joi&#39;)

const envVarsSchema = joi.object({
  NODE_ENV: joi.string()
    .allow([&#39;development&#39;, &#39;production&#39;, &#39;test&#39;, &#39;provision&#39;])
    .required(),
  PORT: joi.number()
    .required(),
  LOGGER_LEVEL: joi.string()
    .allow([&#39;error&#39;, &#39;warn&#39;, &#39;info&#39;, &#39;verbose&#39;, &#39;debug&#39;, &#39;silly&#39;])
    .default(&#39;info&#39;),
  LOGGER_ENABLED: joi.boolean()
    .truthy(&#39;TRUE&#39;)
    .truthy(&#39;true&#39;)
    .falsy(&#39;FALSE&#39;)
    .falsy(&#39;false&#39;)
    .default(true)
}).unknown()
  .required()

const { error, value: envVars } = joi.validate(process.env, envVarsSchema)
if (error) {
  throw new Error(`Config validation error: ${error.message}`)
}

const config = {
  env: envVars.NODE_ENV,
  isTest: envVars.NODE_ENV === &#39;test&#39;,
  isDevelopment: envVars.NODE_ENV === &#39;development&#39;,
  logger: {
    level: envVars.LOGGER_LEVEL,
    enabled: envVars.LOGGER_ENABLED
  },
  server: {
    port: envVars.PORT
  }
  // ...
}

module.exports = config
</code></pre>

<h3 id="toc_3">Config splitting</h3>

<p>Splitting the configuration by components can be a good solution to forego a single, growing config file.</p>

<pre><code>// config/components/logger.js
&#39;use strict&#39;

const joi = require(&#39;joi&#39;)

const envVarsSchema = joi.object({
  LOGGER_LEVEL: joi.string()
    .allow([&#39;error&#39;, &#39;warn&#39;, &#39;info&#39;, &#39;verbose&#39;, &#39;debug&#39;, &#39;silly&#39;])
    .default(&#39;info&#39;),
  LOGGER_ENABLED: joi.boolean()
    .truthy(&#39;TRUE&#39;)
    .truthy(&#39;true&#39;)
    .falsy(&#39;FALSE&#39;)
    .falsy(&#39;false&#39;)
    .default(true)
}).unknown()
  .required()

const { error, value: envVars } = joi.validate(process.env, envVarsSchema)
if (error) {
  throw new Error(`Config validation error: ${error.message}`)
}

const config = {
  logger: {
    level: envVars.LOGGER_LEVEL,
    enabled: envVars.LOGGER_ENABLED
  }
}

module.exports = config
</code></pre>

<p>Then in the <code>config.js</code> file, we only need to combine the components.</p>

<pre><code>// config/config.js
&#39;use strict&#39;

const common = require(&#39;./components/common&#39;)
const logger = require(&#39;./components/logger&#39;)
const redis = require(&#39;./components/redis&#39;)
const server = require(&#39;./components/server&#39;)

module.exports = Object.assign({}, common, logger, redis, server)
</code></pre>

<p>You should never group your config together into “environment” specific files, like config/production.js for production. It doesn’t scale well as your app expands into more deployments over time.</p>

<p><a href="https://twitter.com/share?text=Never+group+your+config+together+into+environment+specific+files.+It+doesn%E2%80%99t+scale+well%21&amp;url=https://blog.codeship.com/advanced-node-js-project-structure-tutorial/">Never group your config together into environment specific files. It doesn’t scale well!</a></p>

<p><a href="https://twitter.com/share?text=Never+group+your+config+together+into+environment+specific+files.+It+doesn%E2%80%99t+scale+well%21&amp;url=https://blog.codeship.com/advanced-node-js-project-structure-tutorial/">Click To Tweet</a></p>

<h3 id="toc_4">How to organize a multi-process application</h3>

<p>The process is the main building block of a modern application. An app can have multiple stateless processes, just like in our example. HTTP requests can be handled by a web process and long-running or scheduled background tasks by a worker. They are stateless, because any data that needs to be persisted is stored in a stateful database. For this reason, adding more concurrent processes are very simple. These processes can be independently scaled based on the load or other metrics.</p>

<p>In the previous section, we saw how to break down the config into components. This comes very handy when having different process types. Each type can have its own config only requiring the components it needs, without expecting unused environment variables.</p>

<p>In the <code>config/index.j</code>s file:</p>

<pre><code>// config/index.js
&#39;use strict&#39;

const processType = process.env.PROCESS_TYPE

let config
try {
  config = require(`./${processType}`)
} catch (ex) {
  if (ex.code === &#39;MODULE_NOT_FOUND&#39;) {
    throw new Error(`No config for process type: ${processType}`)
  }

  throw ex
}

module.exports = config
</code></pre>

<p>In the root <code>index.js</code> file, we start the process selected with the <code>PROCESS_TYPE</code> environment variable:</p>

<pre><code>// index.js
&#39;use strict&#39;

const processType = process.env.PROCESS_TYPE

if (processType === &#39;web&#39;) {
  require(&#39;./web&#39;)
} else if (processType === &#39;twitter-stream-worker&#39;) {
  require(&#39;./worker/twitter-stream&#39;)
} else if (processType === &#39;social-preprocessor-worker&#39;) {
  require(&#39;./worker/social-preprocessor&#39;)
} else {
  throw new Error(`${processType} is an unsupported process type. Use one of: &#39;web&#39;, &#39;twitter-stream-worker&#39;, &#39;social-preprocessor-worker&#39;!`)
}
</code></pre>

<p>The nice thing about this is that we still got one application, but we have managed to split it into multiple, independent processes. Each of them can be started and scaled individually, without influencing the other parts. You can achieve this without sacrificing your DRY codebase, because parts of the code, like the models, can be shared between the different processes.</p>

<h3 id="toc_5">How to organize your test files</h3>

<p>Place your test files next to the tested modules using some kind of naming convention, like <code>&lt;module_name&gt;.spec.js</code> and <code>&lt;/module_name&gt;&lt;module_name&gt;.e2e.spec.js</code>. Your tests should live together with the tested modules, keeping them in sync. It would be really hard to find and maintain the tests and the corresponding functionality when the test files are completely separated from the business logic.</p>

<p><a href="https://twitter.com/share?text=Place+your+test+files+next+to+the+tested+modules+using+some+kind+of+naming+convention.&amp;url=https://blog.codeship.com/advanced-node-js-project-structure-tutorial/">Place your test files next to the tested modules using some kind of naming convention.</a></p>

<p><a href="https://twitter.com/share?text=Place+your+test+files+next+to+the+tested+modules+using+some+kind+of+naming+convention.&amp;url=https://blog.codeship.com/advanced-node-js-project-structure-tutorial/">Click To Tweet</a></p>

<p>A separated <code>/test</code> folder can hold all the additional test setup and utilities not used by the application itself.</p>

<h3 id="toc_6">Where to put your build and script files</h3>

<p>We tend to create a <code>/scripts</code> folder where we put our bash and node scripts for database synchronization, front-end builds and so on. This folder separates them from your application code and prevents you from putting too many script files into the root directory. List them in your <a href="https://docs.npmjs.com/misc/scripts">npm scripts</a> for easier usage.</p>

<h3 id="toc_7">Conclusion</h3>

<p>I hope you enjoyed this article on project structuring. I highly recommend to check out our previous article on the subject, where we laid out the <a href="https://blog.risingstack.com/node-hero-node-js-project-structure-tutorial/">5 fundamentals of Node.js project structuring</a>.</p>

<p>If you have any questions, please let me know in the comments. In the next chapter of the Node.js at Scale series, we’re going to dive deep into <a href="https://blog.risingstack.com/javascript-clean-coding-best-practices-node-js-at-scale/">JavaScript clean coding</a>.</p>

<p><a href="https://twitter.com/share?text=%22Advanced+Node.js+Project+Structure+Tutorial%22+via+%40tthndrs&amp;url=https://blog.codeship.com/advanced-node-js-project-structure-tutorial/">“Advanced Node.js Project Structure Tutorial” via @tthndrs</a></p>

<p><a href="https://twitter.com/share?text=%22Advanced+Node.js+Project+Structure+Tutorial%22+via+%40tthndrs&amp;url=https://blog.codeship.com/advanced-node-js-project-structure-tutorial/">Click To Tweet</a></summery></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[curl 网站开发指南]]></title>
    <link href="http://panlw.github.io/15243906809509.html"/>
    <updated>2018-04-22T17:51:20+08:00</updated>
    <id>http://panlw.github.io/15243906809509.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://www.ruanyifeng.com/blog/2011/09/curl.html">http://www.ruanyifeng.com/blog/2011/09/curl.html</a><br/>
作者： <a href="http://www.ruanyifeng.com/">阮一峰</a> 日期： <a href="http://www.ruanyifeng.com/blog/2011/09/">2011年9月 4日</a></p>
</blockquote>

<p><a href="http://curl.haxx.se/">curl</a>是一种命令行工具，作用是发出网络请求，然后得到和提取数据，显示在&quot;标准输出&quot;（stdout）上面。<br/>
它支持多种协议，下面举例讲解如何将它用于网站开发。</p>

<h3 id="toc_0"><strong>一、查看网页源码</strong></h3>

<p>直接在curl命令后加上网址，就可以看到网页源码。我们以网址www.sina.com为例（选择该网址，主要因为它的网页代码较短）：</p>

<pre><code>  $ curl www.sina.com
  &lt;!DOCTYPE HTML PUBLIC &quot;-//IETF//DTD HTML 2.0//EN&quot;&gt;
  &lt;html&gt;&lt;head&gt;
  &lt;title&gt;301 Moved Permanently&lt;/title&gt;
  &lt;/head&gt;&lt;body&gt;
  &lt;h1&gt;Moved Permanently&lt;/h1&gt;
  &lt;p&gt;The document has moved &lt;a href=&quot;http://www.sina.com.cn/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
  &lt;/body&gt;&lt;/html&gt;
</code></pre>

<p>如果要把这个网页保存下来，可以使用<code>-o</code>参数，这就相当于使用wget命令了。</p>

<pre><code>  $ curl -o [文件名] www.sina.com
</code></pre>

<h3 id="toc_1"><strong>二、自动跳转</strong></h3>

<p>有的网址是自动跳转的。使用<code>-L</code>参数，curl就会跳转到新的网址。</p>

<pre><code>  $ curl -L www.sina.com
</code></pre>

<p>键入上面的命令，结果就自动跳转为www.sina.com.cn。</p>

<h3 id="toc_2"><strong>三、显示头信息</strong></h3>

<p><code>-i</code>参数可以显示http response的头信息，连同网页代码一起。</p>

<pre><code>  $ curl -i www.sina.com
  HTTP/1.0 301 Moved Permanently
  Date: Sat, 03 Sep 2011 23:44:10 GMT
  Server: Apache/2.0.54 (Unix)
  Location: http://www.sina.com.cn/
  Cache-Control: max-age=3600
  Expires: Sun, 04 Sep 2011 00:44:10 GMT
  Vary: Accept-Encoding
  Content-Length: 231
  Content-Type: text/html; charset=iso-8859-1
  Age: 3239
  X-Cache: HIT from sh201-9.sina.com.cn
  Connection: close
  
  &lt;!DOCTYPE HTML PUBLIC &quot;-//IETF//DTD HTML 2.0//EN&quot;&gt;
   &lt;html&gt;&lt;head&gt;
   &lt;title&gt;301 Moved Permanently&lt;/title&gt;
   &lt;/head&gt;&lt;body&gt;
   &lt;h1&gt;Moved Permanently&lt;/h1&gt;
   &lt;p&gt;The document has moved &lt;a href=&quot;http://www.sina.com.cn/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
   &lt;/body&gt;&lt;/html&gt;
</code></pre>

<p><code>-I</code>参数则是只显示http response的头信息。</p>

<h3 id="toc_3"><strong>四、显示通信过程</strong></h3>

<p><code>-v</code>参数可以显示一次http通信的整个过程，包括端口连接和http request头信息。</p>

<pre><code>  $ curl -v www.sina.com
  * About to connect() to www.sina.com port 80 (#0)
  * Trying 61.172.201.195... connected
  * Connected to www.sina.com (61.172.201.195) port 80 (#0)
  &gt; GET / HTTP/1.1
  &gt; User-Agent: curl/7.21.3 (i686-pc-linux-gnu) libcurl/7.21.3 OpenSSL/0.9.8o zlib/1.2.3.4 libidn/1.18
  &gt; Host: www.sina.com
  &gt; Accept: */*
  &gt; 
  * HTTP 1.0, assume close after body
  &lt; HTTP/1.0 301 Moved Permanently
  &lt; Date: Sun, 04 Sep 2011 00:42:39 GMT
  &lt; Server: Apache/2.0.54 (Unix)
  &lt; Location: http://www.sina.com.cn/
  &lt; Cache-Control: max-age=3600
  &lt; Expires: Sun, 04 Sep 2011 01:42:39 GMT
  &lt; Vary: Accept-Encoding
  &lt; Content-Length: 231
  &lt; Content-Type: text/html; charset=iso-8859-1
  &lt; X-Cache: MISS from sh201-19.sina.com.cn
  &lt; Connection: close
  &lt; 
  &lt;!DOCTYPE HTML PUBLIC &quot;-//IETF//DTD HTML 2.0//EN&quot;&gt;
  &lt;html&gt;&lt;head&gt;
  &lt;title&gt;301 Moved Permanently&lt;/title&gt;
  &lt;/head&gt;&lt;body&gt;
  &lt;h1&gt;Moved Permanently&lt;/h1&gt;
  &lt;p&gt;The document has moved &lt;a href=&quot;http://www.sina.com.cn/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
  &lt;/body&gt;&lt;/html&gt;
  * Closing connection #0
</code></pre>

<p>如果你觉得上面的信息还不够，那么下面的命令可以查看更详细的通信过程。</p>

<pre><code>  $ curl --trace output.txt www.sina.com
</code></pre>

<p>或者</p>

<pre><code>  $ curl --trace-ascii output.txt www.sina.com
</code></pre>

<p>运行后，请打开output.txt文件查看。</p>

<h3 id="toc_4"><strong>五、发送表单信息</strong></h3>

<p>发送表单信息有GET和POST两种方法。GET方法相对简单，只要把数据附在网址后面就行。</p>

<pre><code>  $ curl example.com/form.cgi?data=xxx
</code></pre>

<p>POST方法必须把数据和网址分开，curl就要用到--data参数。</p>

<pre><code>  $ curl -X POST --data &quot;data=xxx&quot; example.com/form.cgi
</code></pre>

<p>如果你的数据没有经过表单编码，还可以让curl为你编码，参数是<code>--data-urlencode</code>。</p>

<pre><code>  $ curl -X POST--data-urlencode &quot;date=April 1&quot; example.com/form.cgi
</code></pre>

<h3 id="toc_5"><strong>六、HTTP动词</strong></h3>

<p>curl默认的HTTP动词是GET，使用<code>-X</code>参数可以支持其他动词。</p>

<pre><code>  $ curl -X POST www.example.com
  $ curl -X DELETE www.example.com
</code></pre>

<h3 id="toc_6"><strong>七、文件上传</strong></h3>

<p>假定文件上传的表单是下面这样：</p>

<pre><code>  &lt;form method=&quot;POST&quot; enctype=&#39;multipart/form-data&#39; action=&quot;upload.cgi&quot;&gt;
    &lt;input type=file name=upload&gt;
    &lt;input type=submit name=press value=&quot;OK&quot;&gt;
  &lt;/form&gt;
</code></pre>

<p>你可以用curl这样上传文件：</p>

<pre><code>  $ curl --form upload=@localfilename --form press=OK [URL]
</code></pre>

<h3 id="toc_7"><strong>八、Referer字段</strong></h3>

<p>有时你需要在http request头信息中，提供一个referer字段，表示你是从哪里跳转过来的。</p>

<pre><code>  $ curl --referer http://www.example.com http://www.example.com
</code></pre>

<h3 id="toc_8"><strong>九、User Agent字段</strong></h3>

<p>这个字段是用来表示客户端的设备信息。服务器有时会根据这个字段，针对不同设备，返回不同格式的网页，比如手机版和桌面版。<br/>
iPhone4的User Agent是</p>

<pre><code>  Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_0 like Mac OS X; en-us) AppleWebKit/532.9 (KHTML, like Gecko) Version/4.0.5 Mobile/8A293 Safari/6531.22.7
</code></pre>

<p>curl可以这样模拟：</p>

<pre><code>  $ curl --user-agent &quot;[User Agent]&quot; [URL]
</code></pre>

<h3 id="toc_9"><strong>十、cookie</strong></h3>

<p>使用<code>--cookie</code>参数，可以让curl发送cookie。</p>

<pre><code>  $ curl --cookie &quot;name=xxx&quot; www.example.com
</code></pre>

<p>至于具体的cookie的值，可以从http response头信息的<code>Set-Cookie</code>字段中得到。<br/>
<code>-c cookie-file</code>可以保存服务器返回的cookie到文件，<code>-b cookie-file</code>可以使用这个文件作为cookie信息，进行后续的请求。</p>

<pre><code>  $ curl -c cookies http://example.com
  $ curl -b cookies http://example.com
</code></pre>

<h3 id="toc_10"><strong>十一、增加头信息</strong></h3>

<p>有时需要在http request之中，自行增加一个头信息。<code>--header</code>参数就可以起到这个作用。</p>

<pre><code>  $ curl --header &quot;Content-Type:application/json&quot; http://example.com
</code></pre>

<h3 id="toc_11"><strong>十二、HTTP认证</strong></h3>

<p>有些网域需要HTTP认证，这时curl需要用到<code>--user</code>参数。</p>

<pre><code>  $ curl --user name:password example.com
</code></pre>

<h2 id="toc_12"><strong>参考资料</strong></h2>

<ul>
<li><a href="http://curl.haxx.se/docs/httpscripting.html">Using cURL to automate HTTP jobs</a></li>
<li><a href="http://bbs.et8.net/bbs/showthread.php?t=568472">教你学用CURL</a></li>
<li><a href="https://httpkit.com/resources/HTTP-from-the-Command-Line/">9 uses for cURL worth knowing</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[撰写 Adblock Plus 过滤规则]]></title>
    <link href="http://panlw.github.io/adblo.html"/>
    <updated>2018-04-22T15:20:16+08:00</updated>
    <id>http://panlw.github.io/adblo.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://adblockplus.org/zh_CN/filters">https://adblockplus.org/zh_CN/filters</a></p>
</blockquote>

<p>当前的 Adblock Plus 版本允许您通过许多不同的方法来优化过滤规则。本文档就是告诉您如何做。</p>

<p><u>声明</u>：这里给出的过滤规则只是示例，不一定能直接使用。</p>

<h2 id="toc_0">AdBlock Plus 过滤规则介绍</h2>

<p>本章节描述的过滤规则属性，对偶尔才写过滤规则的用户来说足矣。</p>

<h3 id="toc_1">基本过滤规则</h3>

<p>最简单的过滤规则当然就是您想阻挡的横幅广告地址，但是这些地址常常会在您每次打开页面时改变。例如： <code>http://example.com/ads/banner123.gif</code>，其中 123 是一个随机数字。在这里阻挡整个图片地址是没用的，您需要创建一条更通用的过滤规则 —— 如 <code>http://example.com/ads/banner*.gif</code>。或者更为通用一些的，如 <code>http://example.com/ads/*</code>。</p>

<p><u>注</u>：不要使用通配符来代替过多的字符。过滤规则 <code>http://example.com/*</code> 固然可以阻挡所有的横幅广告， 但也会阻挡 example.com 下其它一些您想看的内容。</p>

<h3 id="toc_2">定义例外规则</h3>

<p>有时您可能会发现某个过滤规则平时挡广告挡得很好，但在某些情况下，会阻挡一些不该挡的内容。您不想移除这条过滤规则，但也不希望它阻挡不该挡的内容。</p>

<p>这就是例外规则的好处——它们允许您定义过滤规则不被使用的情况。例如，您不满意过滤规则 <code>adv</code> 阻挡了 <code>http://example.com/advice.html</code>，您就可以定义一条例外规则 <code>@@advice</code> 。 例外规则和过滤规则没什么两样，您可以使用通配符或正则表达式。您只需在规则前添加 <code>@@</code> 来声明这是一个例外规则。</p>

<p>Exception rules can do more. If you specify <code>$document</code> option you will get an exception for the entire page. For example, if your exception rule is <code>@@||example.com^$document</code> and you open some page from example.com — Adblock Plus will be entirely disabled on this page and nothing will be blocked.</p>

<h3 id="toc_3">匹配网址开头 / 结尾</h3>

<p>通常 Adblock Plus 处理过滤规则时，会自己假设在过滤规则的开头与结尾都有一个通配符，例如，过滤规则 <code>ad</code> 和 <code>*ad*</code> 是一样。 正常情况下这没什么问题，但有时您可能想要定义可以匹配以网址开头或结尾的过滤规则。例如，您想要阻挡所有的 Flash，但如果您添加过滤规则 <code>swf</code> 地址 <code>http://example.com/swf/index.html</code> 同样也将被阻挡。</p>

<p>这个问题的解决方法：使用管线符号（|）来表示地址的最前端或最末端。例如这条过滤规则 <code>swf|</code> 会阻挡 <code>http://example.com/annoyingflash.swf</code> 但不会阻挡 <code>http://example.com/swf/index.html</code>。这条过滤规则 <code>|http://baddomain.example/</code> 会阻挡 <code>http://baddomain.example/banner.gif</code> 但不会阻挡 <code>http://gooddomain.example/analyze?http://baddomain.example</code>。</p>

<p>有时您想阻挡 <code>http://example.com/banner.gif</code> 以及 <code>https://example.com/banner.gif</code> 和 <code>http://www.example.com/banner.gif</code>。这时只需在过滤规则的域名前面加上两个管线符号（||）：<code>||example.com/banner.gif</code> 将会阻挡上面的地址而不会阻挡 <code>http://badexample.com/banner.gif</code> 或者 <code>http://gooddomain.example/analyze?http://example.com/banner.gif</code>（需要 Adblock Plus 1.1 或更高版本）。</p>

<h3 id="toc_4">标记分隔符</h3>

<p>通常您需要接受过滤规则的任何分隔符。例如，您可能写这样一个规则阻挡 <code>http://example.com/</code> 和 <code>http://example.com:8000/</code> 但不能阻挡 <code>http://example.com.ar/</code>。在这里，符号 (<sup>)</sup> 用作一个分隔符。 <code>http://example.com^</code>（需要 Adblock Plus 1.1 或更高版本）。</p>

<p>分隔符可以是除了字母、数字或者 _ - . % 之外的任何字符。 这个地址的结尾也是作为一个分隔符，下面的例子中所有的分隔符以红色标记出： http:<strong>//</strong>example.com<strong>:</strong>8000<strong>/</strong>foo.bar<strong>?</strong>a<strong>=</strong>12<strong>&amp;</strong>b<strong>=</strong>%D1%82%D0%B5%D1%81%D1%82。所以这个地址可以通过这些过滤规则过滤 <code>^example.com^</code> 或 <code>^%D1%82%D0%B5%D1%81%D1%82^</code> 或 <code>^foo.bar^</code> 。</p>

<h3 id="toc_5">注释</h3>

<p>任何以感叹号 (!) 开始的规则，都被视为注释。在过滤规则的列表中，仍然会显示这些规则，但会用灰色的字来显示，而不是黑色。Adblock Plus 在判断规则时，会忽略这些注释，所以我们可以写下任何我们想写的东西。您可以在一条规则上面写下这条规则是做什么用的。也可以在过滤列表的上方写上作者信息（大多数过滤列表的作者已经这样做了）。</p>

<h4 id="toc_6">特殊注释</h4>

<p>特殊注释只在下载的过滤规则列表中生效，在自定义列表中无效。 它们可以为该过滤规则列表设置许多参数：</p>

<ul>
<li><p><code>! Homepage: http://example.com/</code></p>

<p>此注释表明哪个网页是该过滤规则列表的首页。</p></li>
<li><p><code>! Title: FooList</code></p>

<p>此注释为该过滤规则列表设置一个固定的标题。 如果此注释存在，用户不能再更改该标题。</p></li>
<li><p><code>! Expires: 5 days</code></p>

<p>此注释设置该过滤规则列表的更新间隔，指定的值为天数（例如<code>5 days</code>）或者小时数（例如<code>8 hours</code>）。 可以提供 1 小时至 14 天之间的值。 注意：更新并不一定会在指定的间隔到达时发生。 实际的更新时间会稍微随机化并取决于一些额外因素，以减少服务器负载。</p></li>
<li><p><code>! Checksum: OaopkIiiAl77sSHk/VAWDA</code></p>

<p>此注释确保数据的意外损坏不会导致出现过滤规则的意外损坏。 举例来说，一些防火墙软件可能会在下载时修改像是 <code>*/adnetwork/*</code> 的过滤规则来试图保护用户免于广告。 但这会导致移除过滤规则的部分内容，Adblock Plus 将只会看到过滤规则像是 <code>**</code>。 过滤规则列表中的校验和注释就是为了防止这种情况，任何修改将导致该校验和不再与内容相匹配，然后 Adblock Plus 将忽略该数据。</p>

<p>计算该校验和需要执行下列步骤：</p>

<ul>
<li>  移除现存的校验和及注释（如果有）。</li>
<li>  使用 UTF-8 编码对过滤规则列表的文本进行编码。</li>
<li>  转换所有换行符为 Unix 样式（替换掉 <code>\r</code> 用 <code>\n</code> ，如果有）。</li>
<li>  移除空行（用 <code>\n</code> 字符替换掉连续的 <code>\n</code> 字符）。</li>
<li>  计算该文本的 MD5 校验和的 Base64 编码，去除结尾的 <code>=</code> 字符（如有）。</li>
</ul>

<p>您也可以看看基于 Python 实现的 <a href="https://hg.adblockplus.org/adblockplus/file/tip/validateChecksum.py">验证校验和</a>和 <a href="https://hg.adblockplus.org/adblockplus/file/tip/addChecksum.py">添加校验和到文件</a>作为参考。</p></li>
<li><p><code>! Redirect: http://example.com/list.txt</code></p>

<p>此注释表明该过滤规则列表已被转移到一个新的下载地址。 Adblock Plus 将忽略此注释后的任何文件内容并立即尝试从新的地址下载。 如果成功，过滤规则列表的地址将按此设置被更新。 如果新的地址与当前地址相同，此注释将被忽略，并意味着它可以作为该过滤规则列表的 “权威” 地址使用。</p></li>
<li><p><code>! Version: 1234</code></p>

<p>此注释定义过滤规则列表的数字版本。 此版本号将显示在问题报告中，并且可以用于验证报告指向的是否是过滤规则列表的当前版本。</p></li>
</ul>

<h3 id="toc_7">进阶功能</h3>

<p>本章节描述的特性通常只有高级用户和维护过滤列表的作者才会看。普通用户可跳过。</p>

<h4 id="toc_8">指定过滤规则选项</h4>

<p>Adblock Plus 允许您指定某些选项来改变某条规则的行为。您列举这些选项的时候将它们放在美元符号 ($) 后面并用逗号 (,) 分割这些选项，放在过滤规则的最后面，例如：</p>

<pre>*/ads/*$script,match-case
</pre>

<p>这里的 <code>*/ads/*</code> 是真实的过滤规则 <code>script</code> 和 <code>match-case</code> 是其指定的选项。下面是目前支持的选项：</p>

<ul>
<li>  类型选项：判定过滤规则（或例外规则）过滤元素的类型。过滤规则可以指定多个类型选项来过滤指定的元素类型。可以指定的类型包括：

<ul>
<li>  <code>script</code> —— 外部脚本，由 HTML script 标签加载</li>
<li>  <code>image</code> —— 正常图片，通常由 HTML 的 img 标签所载入</li>
<li>  <code>stylesheet</code> —— 外部 CSS 样式文件</li>
<li>  <code>object</code> —— 由浏览器插件处理的内容，例如 Flash 或 Java</li>
<li>  <code>xmlhttprequest</code> — requests started using the <a href="https://xhr.spec.whatwg.org/"><code>XMLHttpRequest</code> object</a> or <a href="https://fetch.spec.whatwg.org/"><code>fetch()</code> API</a></li>
<li>  <code>object-subrequest</code> —— 插件的请求，比如 Flash</li>
<li>  <code>subdocument</code> —— 内嵌的页面，通常通过 HTML 的框架方式内嵌</li>
<li>  <code>ping</code> — requests started by <a href="https://developer.mozilla.org/docs/Web/HTML/Element/a#attr-ping"><code>&lt;a ping&gt;</code></a> or <a href="https://developer.mozilla.org/docs/Web/API/Navigator/sendBeacon"><code>navigator.sendBeacon()</code></a> (Adblock Plus 2.7.1 or higher required)</li>
<li>  <code>websocket</code> — requests initiated via <a href="https://developer.mozilla.org/docs/Web/API/WebSocket"><code>WebSocket</code> object</a> (Adblock Plus 2.8 or higher required)</li>
<li>  <code>webrtc</code> — connections opened via <a href="https://developer.mozilla.org/docs/Web/API/RTCPeerConnection"><code>RTCPeerConnection</code> instances</a> to ICE servers (Adblock Plus 1.13.3 for Chrome and Opera, 3.0 for Firefox, or higher required)</li>
<li>  <code>document</code> —— 网页本身（只适用于 <a href="#whitelist">例外规则</a> ）</li>
<li>  <code>elemhide</code> —— 只适用于例外规则，类似于<code>document</code> 但是只禁用页面上的<a href="#elemhide">隐藏规则</a>而不是所有规则（需要 Adblock Plus 1.2 或更高版本）</li>
<li>  <code>generichide</code> — for exception rules only, similar to <code>elemhide</code> but only disables <a href="#generic-specific">generic</a> element hiding rules on the page (Adblock Plus 2.6.12 or higher required)</li>
<li>  <code>genericblock</code> — for exception rules only, just like <code>generichide</code> but disables <a href="#generic-specific">generic</a> blocking rules (Adblock Plus 2.6.12 or higher required)</li>
<li>  <code>popup</code> — pages opened in a new tab or window</li>
<li>  <code>other</code> —— 其他不在上面的类型的请求The type options <code>background</code>, <code>xbl</code> and <code>dtd</code> are outdated and should no longer be used.</li>
</ul></li>
<li>  反转类型选项：指定过滤规则<strong>不</strong>应用的元素类型。可以指定的类型选项： <code>~script</code>, <code>~image</code>, <code>~stylesheet</code>, <code>~object</code>, <code>~xmlhttprequest</code>, <code>~object-subrequest</code>, <code>~subdocument</code>, <code>~document</code>, <code>~elemhide</code>, <code>~other</code></li>
<li>  third-party/first-party 请求限制：如果指定了 <code>third-party</code> 选项， 则过滤规则只适用于来源与当前正在浏览的页面的不同的请求。类似地，<code>~third-party</code> 适用于来源与当前浏览页面相同的请求。</li>
<li>  域名限定：选项 <code>domain=example.com</code> 指过滤规则只适用于 &quot;example.com&quot; 下的页面 。多个域名可以用 &quot;|&quot; 分隔： 过滤规则 <code>domain=example.com|example.net</code> 将只适用于 &quot;example.com&quot; 或 &quot;example.net&quot; 的页面。如果一个域名是前面有 &quot;~&quot;，则该过滤规则<strong>不</strong>适用于这个域名的页面。例如： <code>domain=~example.com</code> 指过滤规则适用于除了 example.com 之外的任何域名的页面而 <code>domain=example.com|~foo.example.com</code> 限定了过滤规则适用于 &quot;example.com&quot; 但不包括 &quot;foo.example.com&quot; 。</li>
<li>  Sitekey 限制：选项 <code>sitekey=abcdsitekeydcba</code> 意味着该过滤规则应该只在页面上提供了一个与过滤规则内含有的非常相似的（但没有 = 后缀的）公钥和一个可被验证的签名时应用。可以使用 “|” 作为分隔指定多个 sitekey：使用 <code>sitekey=abcdsitekeydcba|bcdesitekeyedcb</code> 作为过滤规则的选项时，将只会在页面提供了 “abcdsitekeydcba” 或者 “bcdesitekeyedcb” 的 sitekey 时应用。这类似于域名限制，但这允许单条过滤规则应用到相当多的域。注意，sitekey 限制需要<a href="#sitekey_server">服务器侧的修改</a>。</li>
<li>  <code>match-case</code> —— 使过滤规则只适用于匹配地址，例如：过滤规则 <code>*/BannerAd.gif$match-case</code> 会阻挡 <code>http://example.com/BannerAd.gif</code> 但不会阻挡 <code>http://example.com/bannerad.gif</code>。</li>
<li>  <code>collapse</code> — 这个选项将覆盖全局 &quot;隐藏已屏蔽元素的占位符&quot; 选项，并确保过滤规则总是隐藏这些元素。类似地，<code>~collapse</code> 选项将确保过滤规则不隐藏这些元素。</li>
<li>  <code>donottrack</code> —— 对有该选项的阻挡规则匹配到且有该选项的例外规则未匹配到的地址会发送一个 <a href="http://donottrack.us/">Do-Not-Track 头</a> (需要 Adblock Plus 1.3.5 或更高版本)。 为了向后兼容，使用此选项时建议使用矛盾的组合类型选项，防止此规则在早期版本的 Adblock Plus 中阻挡任何东西： <code>*$donottrack,image,~image</code></li>
</ul>

<h4 id="toc_9">使用正则表达式</h4>

<p>如果您想更好地控制您的过滤规则，什么匹配，什么不匹配，您可以使用正则表达式。例如过滤规则 <code>/banner\d+/</code> 会匹配 <code>banner123</code> 和 <code>banner321</code> 而不会匹配 <code>banners</code>。 您可以查看<a href="https://developer.mozilla.org/en/Core_JavaScript_1.5_Guide/Regular_Expressions#Creating_a_Regular_Expression">正则表达式的文档</a>来学习如何写正则表达式。</p>

<p><u>注</u>： 由于性能原因，建议尽可能避免使用正则表达式。</p>

<h2 id="toc_10">元素隐藏</h2>

<h3 id="toc_11">基本规则</h3>

<p>有时您可能会发现无法阻挡某些内嵌在网页中的文字广告。如果查看源码的话，可能发现类似这样的代码：</p>

<pre><div class="textad">
Cheapest tofu, only here and now!
</div>
<div id="sponsorad">
Really cheap tofu, click here!
</div>
<textad>
Only here you get the best tofu!
</textad>
</pre>

<p>因为您必须下载页面的内容，所以您也必须下载这些广告。对于这种情况，您可以做的就是把这些广告藏起来，这样您就不会看到他们了。这也就是元素隐藏的意义所在。</p>

<p>上面代码中的第一则广告是在一个 class 属性为 “textad” 的 div 容器内。过滤规则 <code>##.textad</code> 。 这里的 ## 表明这是一条元素隐藏规则，剩下的就是定义需要隐藏元素的选择器，同样的，您可以通过他们的 id 属性来隐藏 <code>###sponsorad</code> 会隐藏第二个广告。您不需要指定元素的名称， 过滤规则 <code>##textad</code> 同样也可以。您也可以仅指定要阻挡的元素名称来隐藏，例如：<code>{4}</code> 可以隐藏第三则广告。</p>

<p>在不查看页面源码的情况下，<a href="/zh_CN/elemhidehelper">Element Hiding Helper 扩展</a> 可以帮助选择正确的元素并写出相应的规则。基础的 HTML 知识还是很有用的。</p>

<p><u>注</u>：元素隐藏规则与普通过滤规则的工作方式有很大的差别。元素隐藏规则不支持通配符。</p>

<h3 id="toc_12">限定在特定域名的规则</h3>

<p>通常您只想要隐藏特定网站的特定广告，而不希望规则会作用于其他网站。例如，过滤规则 <code>##.sponsor</code> 可能会把某些网站的有效代码也隐藏了。但如果你把它写成 <code>example.com##.sponsor</code> 就只会在 <code>http://example.com/</code> 和 <code>http://something.example.com/</code> 生效了，而不是 <code>http://example.org/</code>。 你也可以指定多个域名——只要用逗号（,）分隔即可：<code>domain1.example,domain2.example,domain3.example##.sponsor</code> 。</p>

<p>如果在域名之前有 &quot;~&quot;，该过滤规则<strong>不</strong>适用于这个域名的页面（需要 AdBlock Plus 1.1 或更高版本）。例如， <code>~example.com##.sponsor</code> 将适用于除了 &quot;example.com&quot; 之外的域名，<code>example.com,~foo.example.com##.sponsor</code> 适用于 &quot;example.com&quot; 但不适用于 &quot;foo.example.com&quot; 子域名。</p>

<p><u>注</u>：由于元素隐藏实现方式的关系，您只可以将隐藏规则限定在完整的域名。您不能使用网址的其他部份，也不可用 <code>domain</code> 代替 <code>domain.example,domain.test</code> 。</p>

<p><u>注</u>： 限定域名的元素隐藏规则也可用来隐藏浏览器的使用界面。例如，过滤规则 <code>browser##menuitem#javascriptConsole</code> 会隐藏 Firefox 工具菜单中的 JavaScript 控制台。</p>

<h3 id="toc_13">属性选择符</h3>

<p>一些广告隐藏起来并不容易——它们广告不仅没有 id 也没有 class 属性。您可以使用其他属性来隐藏，例如 <code>##table[width=&quot;80%&quot;]</code> 可以隐藏 width 属性值为 80% 的表格元素。 如果您不想指定属性的完整值，<code>##div[title*=&quot;adv&quot;]</code> 会隐藏所有 title 属性包含 adv 字符的 div 元素。您还可以检查属性的开始和结束字符，例如 <code>##div[title^=&quot;adv&quot;][title$=&quot;ert&quot;]</code> 会隐藏 titile 属性以 adv 开始并且以 ert 结束的 div 元素。正如您所见，你可以使用多个条件 —— <code>table[width=&quot;80%&quot;][bgcolor=&quot;white&quot;]</code> 会匹配到 width 属性为 80%、bgcolor 属性为 white 的表格元素。</p>

<h3 id="toc_14">高级选择符</h3>

<p>通常情况下，Firefox 支持的 CSS 选择器都可用于元素隐藏。例如：下面的过滤规则会隐藏 class 的属性为 adheader 的 div 元素相邻的元素： <code>##.adheader + *</code>。完整的 CSS 列表请查看 <a href="http://www.w3.org/TR/css3-selectors/">W3C CSS 规范</a> （Firefox 目前并没有支持所有的选择器）。 Please keep in mind that browsers are slower to process these selectors than selectors based on <code>class</code> or <code>id</code> attribute only.</p>

<p><u>注</u>：这个功能只是给高级用户使用的，您可以很舒服地通过 CSS 选择符去使用它。Adblock Plus 无法检查您添加的选择器的语法是否正确，如果您使用无效的 CSS 语法，可能会破坏其它已有的有效过滤规则。建议使用 JavaScript 控制台检查是否有 CSS 错误。</p>

<h3 id="toc_15">Extended CSS selectors (Adblock Plus specific)</h3>

<p>Sometimes the standard CSS selectors aren&#39;t powerful enough to hide an advertisement. For those cases we have added some new selectors, namely <code>:-abp-has()</code>, <code>:-abp-contains()</code> and <code>:-abp-properties()</code> (requires Adblock Plus 1.13.3 or higher for Chrome and Opera).</p>

<p>When writing an element hiding filter that makes use of these extended selectors you must use the <code>#?#</code> syntax, e.g. <code>example.com#?#selector</code>. But it&#39;s important to note that doing so carries a performance impact, so do so sparingly and make sure those filters are specific to as few domains and elements as possible.</p>

<h4 id="toc_16">:-abp-properties()</h4>

<p><code>:-abp-properties(properties)</code> will select elements based upon stylesheet properties. For example <code>:-abp-properties(width:300px;height:250px;)</code> will select elements that have a corresponding CSS rule in a stylesheet which sets the <code>width</code> and <code>height</code> to the values <code>300px</code> and <code>250px</code> respectively. Property names are matched case-insensitively. Furthermore, wildcards can be used so that <code>:-abp-properties(width:*px;height:250px;)</code> will match any width specified in pixels and a height of 250 pixels.</p>

<p>You can also use <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions">regular expressions</a> by surrounding the properties expression with &quot;/&quot;. For example, <code>:-abp-properties(/width:30[2-8]px;height:250px;/)</code> will match widths between 302 and 308 pixels and a height of 250 pixels.</p>

<p><u>Note</u>: The <a href="https://adblockplus.org/development-builds/new-css-property-filter-syntax">older syntax</a> for the CSS property filters is deprecated and will be automatically converted to the new format . The syntax to select the style properties remain the same. For example, <code>[-abp-properties=&#39;width:300px;height:250px;&#39;]</code> will be converted to <code>:-abp-properties(width:300px;height:250px;)</code>.</p>

<p><code>:-abp-properties()</code> will also select elements using the style properties found in their pseudo-elements, like <code>::before</code> and <code>::after</code>. For example, <code>:-abp-properties(content:&#39;Advertisment&#39;)</code> will match elements where the string <u>Advertisment</u> is found in either their <code>::before</code> or <code>::after</code> pseudo element.</p>

<h4 id="toc_17">:-abp-has()</h4>

<p><code>:-abp-has(selector)</code> will select elements based on their content. For example <code>:-abp-has(&gt; div &gt; a.advertiser)</code> will select elements that contain as a direct descendant a <code>&lt;div&gt;</code> that contains an <code>&lt;a&gt;</code> with the class <code>advertiser</code>. The inner selector can be relative to the element scope, and can use any of the pseudo-selectors, including <code>:-abp-has()</code> and will determine whether the selection will occur.</p>

<h4 id="toc_18">:-abp-contains()</h4>

<p><code>:-abp-contains(text)</code> will select elements based on their text content. For example, <code>div.sidebar &gt; span:-abp-contains(Advertisment)</code> will select the <code>&lt;span&gt;</code> elements within a <code>&lt;div&gt;</code>, with a class of <code>sidebar</code> that contains the word &quot;Advertisment&quot;. In practice, you&#39;d want to combine this with a <code>:-abp-has()</code> to select the outer container — something like <code>div.sidebar &gt; div:-abp-has(span:-abp-contains(Advertisment))</code> to select the container that would contain an advertisement label.</p>

<h3 id="toc_19">例外规则</h3>

<p>例外规则的作用是在特定域名中禁用已有的规则。 这对于那些与其他订阅组配合使用，且无法更改该订阅组的作者来说较为有用。 例如，如要让 <code>##.textad</code> 规则禁用于 <code>example.com</code>，可以使用 <code>example.com#@#.textad</code>。 这条组合规则就等同于 <code>~example.com##.textad</code>。 建议您仅在无法调整全局隐藏规则时才使用例外规则，否则请首选限定在特定域名的规则。 These exceptions will be applied to <a href="#elemhide-emulation">advanced pseudo-selector rules</a> as well.</p>

<h3 id="toc_20">Generic / Specific filters</h3>

<p>With the <code>$generichide</code> and <code>$genericblock</code> filter options the distinction between generic and specific filters becomes important.</p>

<p>We classify a filter to be <strong>specific</strong> if it matches one or more domains or matches a sitekey. If a filter has no domains specified (or only domain exceptions) and no sitekey then it counts as <strong>generic</strong>. For example, <code>example.com##.textad</code> is a specific filter, whereas both <code>##.textad</code> and <code>~example.com##.textad</code> are generic.</p>

<p>Note that with blocking rules the domain must be specified under the \(domain option for them to be considered specific. For example, `||example.com^` is considered generic whereas `*/ads/*\)domain=example.com` is site-specific.</p>

<h2 id="toc_21">在服务器上实施 sitekey</h2>

<p>若想完成一个采用 <a href="#options">sitekey 限制的过滤规则</a>，一个网页需要返回 Base64 编码的公钥版本和 Adblock Plus 可以验证的签名。目前来说，这需要在 HTTP 相应头中包含（<code>X-Adblock-Key: abcdpublickeydcba_abcdsignaturedcba</code>）及 document 的根标签中（<code>&lt;html data-adblockkey=&quot;abcdpublickeydcba_abcdsignaturedcba&quot;&gt;</code>）。</p>

<p>首先，您需要创建一个专用的 RSA 密钥（最好是 512 位以保证较低传输负担）和一个公钥的 DER 表示。</p>

<p>创建签名使用的数据是一个请求变量的连续列表（即 URI、Host 和 User Agent），分隔符是 <code>NUL</code> 字符，即 “\0”。举例来说：</p>

<pre>  /index.html?q=foo\0www.example.com\0Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:30.0) Gecko/20100101 Firefox/30.0
</pre>

<p>最后，使用 SEC_OID_ISO_SHA_WITH_RSA_SIGNATURE 签名算法生成此字符串的签名（是使用 OpenSSL 时的默认值）。</p>

]]></content>
  </entry>
  
</feed>
