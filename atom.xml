<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Junkman]]></title>
  <link href="http://panlw.github.io/atom.xml" rel="self"/>
  <link href="http://panlw.github.io/"/>
  <updated>2018-08-10T23:47:47+08:00</updated>
  <id>http://panlw.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Java 8 Concurrency Tutorial: Atomic Variables and ConcurrentMap]]></title>
    <link href="http://panlw.github.io/15358820607055.html"/>
    <updated>2018-09-02T17:54:20+08:00</updated>
    <id>http://panlw.github.io/15358820607055.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://winterbe.com/posts/2015/05/22/java8-concurrency-tutorial-atomic-concurrent-map-examples/">https://winterbe.com/posts/2015/05/22/java8-concurrency-tutorial-atomic-concurrent-map-examples/</a></p>
</blockquote>

<p>Welcome to the third part of my tutorial series about multi-threaded programming in Java 8. This tutorial covers two important parts of the Concurrency API: Atomic Variables and Concurrent Maps. Both have been greatly improved with the introduction of lambda expressions and functional programming in the latest Java 8 release. All those new features are described with a bunch of easily understood code samples. Enjoy!</p>

<ul>
<li>  Part 1: <a href="/posts/2015/04/07/java8-concurrency-tutorial-thread-executor-examples/">Threads and Executors</a></li>
<li>  Part 2: <a href="/posts/2015/04/30/java8-concurrency-tutorial-synchronized-locks-examples/">Synchronization and Locks</a></li>
<li>  Part 3: Atomic Variables and ConcurrentMap</li>
</ul>

<p>For simplicity the code samples of this tutorial make use of the two helper methods <code>sleep(seconds)</code> and <code>stop(executor)</code> as defined <a href="https://github.com/winterbe/java8-tutorial/blob/master/src/com/winterbe/java8/samples/concurrent/ConcurrentUtils.java">here</a>.</p>

<h3 id="toc_0">AtomicInteger<a href="#atomicinteger" title="Permalink to this section">#</a></h3>

<p>The package <code>java.concurrent.atomic</code> contains many useful classes to perform atomic operations. An operation is atomic when you can safely perform the operation in parallel on multiple threads without using the <code>synchronized</code> keyword or locks as shown in my <a href="/posts/2015/04/30/java8-concurrency-tutorial-synchronized-locks-examples/">previous tutorial</a>.</p>

<p>Internally, the atomic classes make heavy use of <a href="http://en.wikipedia.org/wiki/Compare-and-swap">compare-and-swap</a> (CAS), an atomic instruction directly supported by most modern CPUs. Those instructions usually are much faster than synchronizing via locks. So my advice is to prefer atomic classes over locks in case you just have to change a single mutable variable concurrently.</p>

<p>Now let&#39;s pick one of the atomic classes for a few examples: <code>AtomicInteger</code></p>

<pre><code>AtomicInteger atomicInt = new AtomicInteger(0);

ExecutorService executor = Executors.newFixedThreadPool(2);

IntStream.range(0, 1000)
    .forEach(i -&gt; executor.submit(atomicInt::incrementAndGet));

stop(executor);

System.out.println(atomicInt.get());    // =&gt; 1000

</code></pre>

<p>By using <code>AtomicInteger</code> as a replacement for <code>Integer</code> we&#39;re able to increment the number concurrently in a thread-safe manor without synchronizing the access to the variable. The method <code>incrementAndGet()</code> is an atomic operation so we can safely call this method from multiple threads.</p>

<p>AtomicInteger supports various kinds of atomic operations. The method <code>updateAndGet()</code> accepts a lambda expression in order to perform arbitrary arithmetic operations upon the integer:</p>

<pre><code>AtomicInteger atomicInt = new AtomicInteger(0);

ExecutorService executor = Executors.newFixedThreadPool(2);

IntStream.range(0, 1000)
    .forEach(i -&gt; {
        Runnable task = () -&gt;
            atomicInt.updateAndGet(n -&gt; n + 2);
        executor.submit(task);
    });

stop(executor);

System.out.println(atomicInt.get());    // =&gt; 2000

</code></pre>

<p>The method <code>accumulateAndGet()</code> accepts another kind of lambda expression of type <code>IntBinaryOperator</code>. We use this method to sum up all values from 0 to 1000 concurrently in the next sample:</p>

<pre><code>AtomicInteger atomicInt = new AtomicInteger(0);

ExecutorService executor = Executors.newFixedThreadPool(2);

IntStream.range(0, 1000)
    .forEach(i -&gt; {
        Runnable task = () -&gt;
            atomicInt.accumulateAndGet(i, (n, m) -&gt; n + m);
        executor.submit(task);
    });

stop(executor);

System.out.println(atomicInt.get());    // =&gt; 499500

</code></pre>

<p>Other useful atomic classes are <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/AtomicBoolean.html">AtomicBoolean</a>, <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/AtomicLong.html">AtomicLong</a> and <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/atomic/AtomicReference.html">AtomicReference</a>.</p>

<h3 id="toc_1">LongAdder<a href="#longadder" title="Permalink to this section">#</a></h3>

<p>The class <code>LongAdder</code> as an alternative to <code>AtomicLong</code> can be used to consecutively add values to a number.</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);

IntStream.range(0, 1000)
    .forEach(i -&gt; executor.submit(adder::increment));

stop(executor);

System.out.println(adder.sumThenReset());   // =&gt; 1000

</code></pre>

<p>LongAdder provides methods <code>add()</code> and <code>increment()</code> just like the atomic number classes and is also thread-safe. But instead of summing up a single result this class maintains a set of variables internally to reduce contention over threads. The actual result can be retrieved by calling <code>sum()</code> or <code>sumThenReset()</code>.</p>

<p>This class is usually preferable over atomic numbers when updates from multiple threads are more common than reads. This is often the case when capturing statistical data, e.g. you want to count the number of requests served on a web server. The drawback of <code>LongAdder</code> is higher memory consumption because a set of variables is held in-memory.</p>

<h3 id="toc_2">LongAccumulator<a href="#longaccumulator" title="Permalink to this section">#</a></h3>

<p>LongAccumulator is a more generalized version of LongAdder. Instead of performing simple add operations the class <code>LongAccumulator</code> builds around a lambda expression of type <code>LongBinaryOperator</code> as demonstrated in this code sample:</p>

<pre><code>LongBinaryOperator op = (x, y) -&gt; 2 * x + y;
LongAccumulator accumulator = new LongAccumulator(op, 1L);

ExecutorService executor = Executors.newFixedThreadPool(2);

IntStream.range(0, 10)
    .forEach(i -&gt; executor.submit(() -&gt; accumulator.accumulate(i)));

stop(executor);

System.out.println(accumulator.getThenReset());     // =&gt; 2539

</code></pre>

<p>We create a LongAccumulator with the function <code>2 * x + y</code> and an initial value of one. With every call to <code>accumulate(i)</code> both the current result and the value <code>i</code> are passed as parameters to the lambda expression.</p>

<p>A <code>LongAccumulator</code> just like <code>LongAdder</code> maintains a set of variables internally to reduce contention over threads.</p>

<h3 id="toc_3">ConcurrentMap<a href="#concurrentmap" title="Permalink to this section">#</a></h3>

<p>The interface <code>ConcurrentMap</code> extends the map interface and defines one of the most useful concurrent collection types. Java 8 introduces functional programming by adding new methods to this interface.</p>

<p>In the next code snippets we use the following sample map to demonstrates those new methods:</p>

<pre><code>ConcurrentMap&lt;String, String&gt; map = new ConcurrentHashMap&lt;&gt;();
map.put(&quot;foo&quot;, &quot;bar&quot;);
map.put(&quot;han&quot;, &quot;solo&quot;);
map.put(&quot;r2&quot;, &quot;d2&quot;);
map.put(&quot;c3&quot;, &quot;p0&quot;);

</code></pre>

<p>The method <code>forEach()</code> accepts a lambda expression of type <code>BiConsumer</code> with both the key and value of the map passed as parameters. It can be used as a replacement to for-each loops to iterate over the entries of the concurrent map. The iteration is performed sequentially on the current thread.</p>

<pre><code>map.forEach((key, value) -&gt; System.out.printf(&quot;%s = %s\n&quot;, key, value));

</code></pre>

<p>The method <code>putIfAbsent()</code> puts a new value into the map only if no value exists for the given key. At least for the <code>ConcurrentHashMap</code> implementation of this method is thread-safe just like <code>put()</code> so you don&#39;t have to synchronize when accessing the map concurrently from different threads:</p>

<pre><code>String value = map.putIfAbsent(&quot;c3&quot;, &quot;p1&quot;);
System.out.println(value);    // p0

</code></pre>

<p>The method <code>getOrDefault()</code> returns the value for the given key. In case no entry exists for this key the passed default value is returned:</p>

<pre><code>String value = map.getOrDefault(&quot;hi&quot;, &quot;there&quot;);
System.out.println(value);    // there

</code></pre>

<p>The method <code>replaceAll()</code> accepts a lambda expression of type <code>BiFunction</code>. BiFunctions take two parameters and return a single value. In this case the function is called with the key and the value of each map entry and returns a new value to be assigned for the current key:</p>

<pre><code>map.replaceAll((key, value) -&gt; &quot;r2&quot;.equals(key) ? &quot;d3&quot; : value);
System.out.println(map.get(&quot;r2&quot;));    // d3

</code></pre>

<p>Instead of replacing all values of the map <code>compute()</code> let&#39;s us transform a single entry. The method accepts both the key to be computed and a bi-function to specify the transformation of the value.</p>

<pre><code>map.compute(&quot;foo&quot;, (key, value) -&gt; value + value);
System.out.println(map.get(&quot;foo&quot;));   // barbar

</code></pre>

<p>In addition to <code>compute()</code> two variants exist: <code>computeIfAbsent()</code> and <code>computeIfPresent()</code>. The functional parameters of these methods only get called if the key is absent or present respectively.</p>

<p>Finally, the method <code>merge()</code> can be utilized to unify a new value with an existing value in the map. Merge accepts a key, the new value to be merged into the existing entry and a bi-function to specify the merging behavior of both values:</p>

<pre><code>map.merge(&quot;foo&quot;, &quot;boo&quot;, (oldVal, newVal) -&gt; newVal + &quot; was &quot; + oldVal);
System.out.println(map.get(&quot;foo&quot;));   // boo was foo

</code></pre>

<h3 id="toc_4">ConcurrentHashMap<a href="#concurrenthashmap" title="Permalink to this section">#</a></h3>

<p>All those methods above are part of the <code>ConcurrentMap</code> interface, thereby available to all implementations of that interface. In addition the most important implementation <code>ConcurrentHashMap</code> has been further enhanced with a couple of new methods to perform parallel operations upon the map.</p>

<p>Just like parallel streams those methods use a special <code>ForkJoinPool</code> available via <code>ForkJoinPool.commonPool()</code> in Java 8. This pool uses a preset parallelism which depends on the number of available cores. Four CPU cores are available on my machine which results in a parallelism of three:</p>

<pre><code>System.out.println(ForkJoinPool.getCommonPoolParallelism());  // 3

</code></pre>

<p>This value can be decreased or increased by setting the following JVM parameter:</p>

<pre><code>-Djava.util.concurrent.ForkJoinPool.common.parallelism=5

</code></pre>

<p>We use the same example map for demonstrating purposes but this time we work upon the concrete implementation <code>ConcurrentHashMap</code> instead of the interface <code>ConcurrentMap</code>, so we can access all public methods from this class:</p>

<pre><code>ConcurrentHashMap&lt;String, String&gt; map = new ConcurrentHashMap&lt;&gt;();
map.put(&quot;foo&quot;, &quot;bar&quot;);
map.put(&quot;han&quot;, &quot;solo&quot;);
map.put(&quot;r2&quot;, &quot;d2&quot;);
map.put(&quot;c3&quot;, &quot;p0&quot;);

</code></pre>

<p>Java 8 introduces three kinds of parallel operations: <code>forEach</code>, <code>search</code> and <code>reduce</code>. Each of those operations are available in four forms accepting functions with keys, values, entries and key-value pair arguments.</p>

<p>All of those methods use a common first argument called <code>parallelismThreshold</code>. This threshold indicates the minimum collection size when the operation should be executed in parallel. E.g. if you pass a threshold of 500 and the actual size of the map is 499 the operation will be performed sequentially on a single thread. In the next examples we use a threshold of one to always force parallel execution for demonstrating purposes.</p>

<h4 id="toc_5">ForEach<a href="#foreach" title="Permalink to this section">#</a></h4>

<p>The method <code>forEach()</code> is capable of iterating over the key-value pairs of the map in parallel. The lambda expression of type <code>BiConsumer</code> is called with the key and value of the current iteration step. In order to visualize parallel execution we print the current threads name to the console. Keep in mind that in my case the underlying <code>ForkJoinPool</code> uses up to a maximum of three threads.</p>

<pre><code>map.forEach(1, (key, value) -&gt;
    System.out.printf(&quot;key: %s; value: %s; thread: %s\n&quot;,
        key, value, Thread.currentThread().getName()));

// key: r2; value: d2; thread: main
// key: foo; value: bar; thread: ForkJoinPool.commonPool-worker-1
// key: han; value: solo; thread: ForkJoinPool.commonPool-worker-2
// key: c3; value: p0; thread: main

</code></pre>

<h4 id="toc_6">Search<a href="#search" title="Permalink to this section">#</a></h4>

<p>The method <code>search()</code> accepts a <code>BiFunction</code> returning a non-null search result for the current key-value pair or <code>null</code> if the current iteration doesn&#39;t match the desired search criteria. As soon as a non-null result is returned further processing is suppressed. Keep in mind that <code>ConcurrentHashMap</code> is unordered. The search function should not depend on the actual processing order of the map. If multiple entries of the map match the given search function the result may be non-deterministic.</p>

<pre><code>String result = map.search(1, (key, value) -&gt; {
    System.out.println(Thread.currentThread().getName());
    if (&quot;foo&quot;.equals(key)) {
        return value;
    }
    return null;
});
System.out.println(&quot;Result: &quot; + result);

// ForkJoinPool.commonPool-worker-2
// main
// ForkJoinPool.commonPool-worker-3
// Result: bar

</code></pre>

<p>Here&#39;s another example searching solely on the values of the map:</p>

<pre><code>String result = map.searchValues(1, value -&gt; {
    System.out.println(Thread.currentThread().getName());
    if (value.length() &gt; 3) {
        return value;
    }
    return null;
});

System.out.println(&quot;Result: &quot; + result);

// ForkJoinPool.commonPool-worker-2
// main
// main
// ForkJoinPool.commonPool-worker-1
// Result: solo

</code></pre>

<h4 id="toc_7">Reduce<a href="#reduce" title="Permalink to this section">#</a></h4>

<p>The method <code>reduce()</code> already known from Java 8 Streams accepts two lambda expressions of type <code>BiFunction</code>. The first function transforms each key-value pair into a single value of any type. The second function combines all those transformed values into a single result, ignoring any possible <code>null</code> values.</p>

<pre><code>String result = map.reduce(1,
    (key, value) -&gt; {
        System.out.println(&quot;Transform: &quot; + Thread.currentThread().getName());
        return key + &quot;=&quot; + value;
    },
    (s1, s2) -&gt; {
        System.out.println(&quot;Reduce: &quot; + Thread.currentThread().getName());
        return s1 + &quot;, &quot; + s2;
    });

System.out.println(&quot;Result: &quot; + result);

// Transform: ForkJoinPool.commonPool-worker-2
// Transform: main
// Transform: ForkJoinPool.commonPool-worker-3
// Reduce: ForkJoinPool.commonPool-worker-3
// Transform: main
// Reduce: main
// Reduce: main
// Result: r2=d2, c3=p0, han=solo, foo=bar

</code></pre>

<p>I hope you&#39;ve enjoyed reading the third part of my tutorial series about Java 8 Concurrency. The code samples from this tutorial are <a href="https://github.com/winterbe/java8-tutorial">hosted on GitHub</a> along with many other Java 8 code snippets. You&#39;re welcome to fork the repo and try it by your own.</p>

<p>If you want to support my work, please share this tutorial with your friends. You should also <a href="https://twitter.com/winterbe_">follow me on Twitter</a> as I constantly tweet about Java and programming related stuff.</p>

<ul>
<li>  Part 1: <a href="/posts/2015/04/07/java8-concurrency-tutorial-thread-executor-examples/">Threads and Executors</a></li>
<li>  Part 2: <a href="/posts/2015/04/30/java8-concurrency-tutorial-synchronized-locks-examples/">Synchronization and Locks</a></li>
<li>  Part 3: Atomic Variables and ConcurrentMap</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java 8 Concurrency Tutorial: Synchronization and Locks]]></title>
    <link href="http://panlw.github.io/15358774987730.html"/>
    <updated>2018-09-02T16:38:18+08:00</updated>
    <id>http://panlw.github.io/15358774987730.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://winterbe.com/posts/2015/04/30/java8-concurrency-tutorial-synchronized-locks-examples/">https://winterbe.com/posts/2015/04/30/java8-concurrency-tutorial-synchronized-locks-examples/</a></p>
</blockquote>

<p>Welcome to the second part of my Java 8 Concurrency Tutorial out of a series of guides teaching multi-threaded programming in Java 8 with easily understood code examples. In the next 15 min you learn how to synchronize access to mutable shared variables via the synchronized keyword, locks and semaphores.</p>

<ul>
<li>  Part 1: <a href="/posts/2015/04/07/java8-concurrency-tutorial-thread-executor-examples/">Threads and Executors</a></li>
<li>  Part 2: Synchronization and Locks</li>
<li>  Part 3: <a href="/posts/2015/05/22/java8-concurrency-tutorial-atomic-concurrent-map-examples/">Atomic Variables and ConcurrentMap</a></li>
</ul>

<p>The majority of concepts shown in this article also work in older versions of Java. However the code samples focus on Java 8 and make heavy use of lambda expressions and new concurrency features. If you&#39;re not yet familiar with lambdas I recommend reading my <a href="/posts/2014/03/16/java-8-tutorial/">Java 8 Tutorial</a> first.</p>

<p>For simplicity the code samples of this tutorial make use of the two helper methods <code>sleep(seconds)</code> and <code>stop(executor)</code> as defined <a href="https://github.com/winterbe/java8-tutorial/blob/master/src/com/winterbe/java8/samples/concurrent/ConcurrentUtils.java">here</a>.</p>

<h3 id="toc_0">Synchronized<a href="#synchronized" title="Permalink to this section">#</a></h3>

<p>In the <a href="(/posts/2015/04/07/java8-concurrency-tutorial-thread-executor-examples/)">previous tutorial</a> we&#39;ve learned how to execute code in parallel via executor services. When writing such multi-threaded code you have to pay particular attention when accessing shared mutable variables concurrently from multiple threads. Let&#39;s just say we want to increment an integer which is accessible simultaneously from multiple threads.</p>

<p>We define a field <code>count</code> with a method <code>increment()</code> to increase count by one:</p>

<pre><code>int count = 0;

void increment() {
    count = count + 1;
}

</code></pre>

<p>When calling this method concurrently from multiple threads we&#39;re in serious trouble:</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);

IntStream.range(0, 10000)
    .forEach(i -&gt; executor.submit(this::increment));

stop(executor);

System.out.println(count);  // 9965

</code></pre>

<p>Instead of seeing a constant result count of 10000 the actual result varies with every execution of the above code. The reason is that we share a mutable variable upon different threads without synchronizing the access to this variable which results in a <a href="http://en.wikipedia.org/wiki/Race_condition">race condition</a>.</p>

<p>Three steps have to be performed in order to increment the number: (i) read the current value, (ii) increase this value by one and (iii) write the new value to the variable. If two threads perform these steps in parallel it&#39;s possible that both threads perform step 1 simultaneously thus reading the same current value. This results in lost writes so the actual result is lower. In the above sample 35 increments got lost due to concurrent unsynchronized access to count but you may see different results when executing the code by yourself.</p>

<p>Luckily Java supports thread-synchronization since the early days via the <code>synchronized</code> keyword. We can utilize <code>synchronized</code> to fix the above race conditions when incrementing the count:</p>

<pre><code>synchronized void incrementSync() {
    count = count + 1;
}

</code></pre>

<p>When using <code>incrementSync()</code> concurrently we get the desired result count of 10000. No race conditions occur any longer and the result is stable with every execution of the code:</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);

IntStream.range(0, 10000)
    .forEach(i -&gt; executor.submit(this::incrementSync));

stop(executor);

System.out.println(count);  // 10000

</code></pre>

<p>The <code>synchronized</code> keyword is also available as a block statement.</p>

<pre><code>void incrementSync() {
    synchronized (this) {
        count = count + 1;
    }
}

</code></pre>

<p>Internally Java uses a so called <u>monitor</u> also known as <a href="https://docs.oracle.com/javase/tutorial/essential/concurrency/locksync.html">monitor lock or intrinsic lock</a> in order to manage synchronization. This monitor is bound to an object, e.g. when using synchronized methods each method share the same monitor of the corresponding object.</p>

<p>All implicit monitors implement the <u>reentrant</u> characteristics. Reentrant means that locks are bound to the current thread. A thread can safely acquire the same lock multiple times without running into deadlocks (e.g. a synchronized method calls another synchronized method on the same object).</p>

<h3 id="toc_1">Locks<a href="#locks" title="Permalink to this section">#</a></h3>

<p>Instead of using implicit locking via the <code>synchronized</code> keyword the Concurrency API supports various explicit locks specified by the <code>Lock</code> interface. Locks support various methods for finer grained lock control thus are more expressive than implicit monitors.</p>

<p>Multiple lock implementations are available in the standard JDK which will be demonstrated in the following sections.</p>

<h4 id="toc_2">ReentrantLock<a href="#reentrantlock" title="Permalink to this section">#</a></h4>

<p>The class <code>ReentrantLock</code> is a mutual exclusion lock with the same basic behavior as the implicit monitors accessed via the <code>synchronized</code> keyword but with extended capabilities. As the name suggests this lock implements reentrant characteristics just as implicit monitors.</p>

<p>Let&#39;s see how the above sample looks like using <code>ReentrantLock</code>:</p>

<pre><code>ReentrantLock lock = new ReentrantLock();
int count = 0;

void increment() {
    lock.lock();
    try {
        count++;
    } finally {
        lock.unlock();
    }
}

</code></pre>

<p>A lock is acquired via <code>lock()</code> and released via <code>unlock()</code>. It&#39;s important to wrap your code into a <code>try/finally</code> block to ensure unlocking in case of exceptions. This method is thread-safe just like the synchronized counterpart. If another thread has already acquired the lock subsequent calls to <code>lock()</code> pause the current thread until the lock has been unlocked. Only one thread can hold the lock at any given time.</p>

<p>Locks support various methods for fine grained control as seen in the next sample:</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);
ReentrantLock lock = new ReentrantLock();

executor.submit(() -&gt; {
    lock.lock();
    try {
        sleep(1);
    } finally {
        lock.unlock();
    }
});

executor.submit(() -&gt; {
    System.out.println(&quot;Locked: &quot; + lock.isLocked());
    System.out.println(&quot;Held by me: &quot; + lock.isHeldByCurrentThread());
    boolean locked = lock.tryLock();
    System.out.println(&quot;Lock acquired: &quot; + locked);
});

stop(executor);

</code></pre>

<p>While the first task holds the lock for one second the second task obtains different information about the current state of the lock:</p>

<pre><code>Locked: true
Held by me: false
Lock acquired: false

</code></pre>

<p>The method <code>tryLock()</code> as an alternative to <code>lock()</code> tries to acquire the lock without pausing the current thread. The boolean result must be used to check if the lock has actually been acquired before accessing any shared mutable variables.</p>

<h4 id="toc_3">ReadWriteLock<a href="#readwritelock" title="Permalink to this section">#</a></h4>

<p>The interface <code>ReadWriteLock</code> specifies another type of lock maintaining a pair of locks for read and write access. The idea behind read-write locks is that it&#39;s usually safe to read mutable variables concurrently as long as nobody is writing to this variable. So the read-lock can be held simultaneously by multiple threads as long as no threads hold the write-lock. This can improve performance and throughput in case that reads are more frequent than writes.</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);
Map&lt;String, String&gt; map = new HashMap&lt;&gt;();
ReadWriteLock lock = new ReentrantReadWriteLock();

executor.submit(() -&gt; {
    lock.writeLock().lock();
    try {
        sleep(1);
        map.put(&quot;foo&quot;, &quot;bar&quot;);
    } finally {
        lock.writeLock().unlock();
    }
});

</code></pre>

<p>The above example first acquires a write-lock in order to put a new value to the map after sleeping for one second. Before this task has finished two other tasks are being submitted trying to read the entry from the map and sleep for one second:</p>

<pre><code>Runnable readTask = () -&gt; {
    lock.readLock().lock();
    try {
        System.out.println(map.get(&quot;foo&quot;));
        sleep(1);
    } finally {
        lock.readLock().unlock();
    }
};

executor.submit(readTask);
executor.submit(readTask);

stop(executor);

</code></pre>

<p>When you execute this code sample you&#39;ll notice that both read tasks have to wait the whole second until the write task has finished. After the write lock has been released both read tasks are executed in parallel and print the result simultaneously to the console. They don&#39;t have to wait for each other to finish because read-locks can safely be acquired concurrently as long as no write-lock is held by another thread.</p>

<h4 id="toc_4">StampedLock<a href="#stampedlock" title="Permalink to this section">#</a></h4>

<p>Java 8 ships with a new kind of lock called <code>StampedLock</code> which also support read and write locks just like in the example above. In contrast to <code>ReadWriteLock</code> the locking methods of a <code>StampedLock</code> return a stamp represented by a <code>long</code> value. You can use these stamps to either release a lock or to check if the lock is still valid. Additionally stamped locks support another lock mode called <u>optimistic locking</u>.</p>

<p>Let&#39;s rewrite the last example code to use <code>StampedLock</code> instead of <code>ReadWriteLock</code>:</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);
Map&lt;String, String&gt; map = new HashMap&lt;&gt;();
StampedLock lock = new StampedLock();

executor.submit(() -&gt; {
    long stamp = lock.writeLock();
    try {
        sleep(1);
        map.put(&quot;foo&quot;, &quot;bar&quot;);
    } finally {
        lock.unlockWrite(stamp);
    }
});

Runnable readTask = () -&gt; {
    long stamp = lock.readLock();
    try {
        System.out.println(map.get(&quot;foo&quot;));
        sleep(1);
    } finally {
        lock.unlockRead(stamp);
    }
};

executor.submit(readTask);
executor.submit(readTask);

stop(executor);

</code></pre>

<p>Obtaining a read or write lock via <code>readLock()</code> or <code>writeLock()</code> returns a stamp which is later used for unlocking within the finally block. Keep in mind that stamped locks don&#39;t implement reentrant characteristics. Each call to lock returns a new stamp and blocks if no lock is available even if the same thread already holds a lock. So you have to pay particular attention not to run into deadlocks.</p>

<p>Just like in the previous <code>ReadWriteLock</code> example both read tasks have to wait until the write lock has been released. Then both read tasks print to the console simultaneously because multiple reads doesn&#39;t block each other as long as no write-lock is held.</p>

<p>The next example demonstrates <u>optimistic locking</u>:</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);
StampedLock lock = new StampedLock();

executor.submit(() -&gt; {
    long stamp = lock.tryOptimisticRead();
    try {
        System.out.println(&quot;Optimistic Lock Valid: &quot; + lock.validate(stamp));
        sleep(1);
        System.out.println(&quot;Optimistic Lock Valid: &quot; + lock.validate(stamp));
        sleep(2);
        System.out.println(&quot;Optimistic Lock Valid: &quot; + lock.validate(stamp));
    } finally {
        lock.unlock(stamp);
    }
});

executor.submit(() -&gt; {
    long stamp = lock.writeLock();
    try {
        System.out.println(&quot;Write Lock acquired&quot;);
        sleep(2);
    } finally {
        lock.unlock(stamp);
        System.out.println(&quot;Write done&quot;);
    }
});

stop(executor);

</code></pre>

<p>An optimistic read lock is acquired by calling <code>tryOptimisticRead()</code> which always returns a stamp without blocking the current thread, no matter if the lock is actually available. If there&#39;s already a write lock active the returned stamp equals zero. You can always check if a stamp is valid by calling <code>lock.validate(stamp)</code>.</p>

<p>Executing the above code results in the following output:</p>

<pre><code>Optimistic Lock Valid: true
Write Lock acquired
Optimistic Lock Valid: false
Write done
Optimistic Lock Valid: false

</code></pre>

<p>The optimistic lock is valid right after acquiring the lock. In contrast to normal read locks an optimistic lock doesn&#39;t prevent other threads to obtain a write lock instantaneously. After sending the first thread to sleep for one second the second thread obtains a write lock without waiting for the optimistic read lock to be released. From this point the optimistic read lock is no longer valid. Even when the write lock is released the optimistic read locks stays invalid.</p>

<p>So when working with optimistic locks you have to validate the lock every time <u>after</u> accessing any shared mutable variable to make sure the read was still valid.</p>

<p>Sometimes it&#39;s useful to convert a read lock into a write lock without unlocking and locking again. <code>StampedLock</code> provides the method <code>tryConvertToWriteLock()</code> for that purpose as seen in the next sample:</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);
StampedLock lock = new StampedLock();

executor.submit(() -&gt; {
    long stamp = lock.readLock();
    try {
        if (count == 0) {
            stamp = lock.tryConvertToWriteLock(stamp);
            if (stamp == 0L) {
                System.out.println(&quot;Could not convert to write lock&quot;);
                stamp = lock.writeLock();
            }
            count = 23;
        }
        System.out.println(count);
    } finally {
        lock.unlock(stamp);
    }
});

stop(executor);

</code></pre>

<p>The task first obtains a read lock and prints the current value of field <code>count</code> to the console. But if the current value is zero we want to assign a new value of <code>23</code>. We first have to convert the read lock into a write lock to not break potential concurrent access by other threads. Calling <code>tryConvertToWriteLock()</code> doesn&#39;t block but may return a zero stamp indicating that no write lock is currently available. In that case we call <code>writeLock()</code> to block the current thread until a write lock is available.</p>

<h3 id="toc_5">Semaphores<a href="#semaphores" title="Permalink to this section">#</a></h3>

<p>In addition to locks the Concurrency API also supports counting semaphores. Whereas locks usually grant exclusive access to variables or resources, a semaphore is capable of maintaining whole sets of permits. This is useful in different scenarios where you have to limit the amount concurrent access to certain parts of your application.</p>

<p>Here&#39;s an example how to limit access to a long running task simulated by <code>sleep(5)</code>:</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(10);

Semaphore semaphore = new Semaphore(5);

Runnable longRunningTask = () -&gt; {
    boolean permit = false;
    try {
        permit = semaphore.tryAcquire(1, TimeUnit.SECONDS);
        if (permit) {
            System.out.println(&quot;Semaphore acquired&quot;);
            sleep(5);
        } else {
            System.out.println(&quot;Could not acquire semaphore&quot;);
        }
    } catch (InterruptedException e) {
        throw new IllegalStateException(e);
    } finally {
        if (permit) {
            semaphore.release();
        }
    }
}

IntStream.range(0, 10)
    .forEach(i -&gt; executor.submit(longRunningTask));

stop(executor);

</code></pre>

<p>The executor can potentially run 10 tasks concurrently but we use a semaphore of size 5, thus limiting concurrent access to 5. It&#39;s important to use a <code>try/finally</code> block to properly release the semaphore even in case of exceptions.</p>

<p>Executing the above code results in the following output:</p>

<pre><code>Semaphore acquired
Semaphore acquired
Semaphore acquired
Semaphore acquired
Semaphore acquired
Could not acquire semaphore
Could not acquire semaphore
Could not acquire semaphore
Could not acquire semaphore
Could not acquire semaphore

</code></pre>

<p>The semaphores permits access to the actual long running operation simulated by <code>sleep(5)</code> up to a maximum of 5. Every subsequent call to <code>tryAcquire()</code> elapses the maximum wait timeout of one second, resulting in the appropriate console output that no semaphore could be acquired.</p>

<p>This was the second part out of a series of concurrency tutorials. More parts will be released in the near future, so stay tuned. As usual you find all code samples from this article on <a href="https://github.com/winterbe/java8-tutorial">GitHub</a>, so feel free to fork the repo and try it by your own.</p>

<p>I hope you&#39;ve enjoyed this article. If you have any further questions send me your feedback in the comments below. You should also <a href="https://twitter.com/winterbe_">follow me on Twitter</a> for more dev-related stuff!</p>

<ul>
<li>  Part 1: <a href="/posts/2015/04/07/java8-concurrency-tutorial-thread-executor-examples/">Threads and Executors</a></li>
<li>  Part 2: Synchronization and Locks</li>
<li>  Part 3: <a href="/posts/2015/05/22/java8-concurrency-tutorial-atomic-concurrent-map-examples/">Atomic Variables and ConcurrentMap</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java 8 Concurrency Tutorial: Threads and Executors]]></title>
    <link href="http://panlw.github.io/15358757119900.html"/>
    <updated>2018-09-02T16:08:31+08:00</updated>
    <id>http://panlw.github.io/15358757119900.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://winterbe.com/posts/2015/04/07/java8-concurrency-tutorial-thread-executor-examples/">https://winterbe.com/posts/2015/04/07/java8-concurrency-tutorial-thread-executor-examples/</a></p>
</blockquote>

<p>Welcome to the first part of my Java 8 Concurrency tutorial. This guide teaches you <a href="http://en.wikipedia.org/wiki/Concurrent_computing">concurrent programming</a> in Java 8 with easily understood code examples. It&#39;s the first part out of a series of tutorials covering the Java Concurrency API. In the next 15 min you learn how to execute code in parallel via threads, tasks and executor services.</p>

<ul>
<li>  Part 1: Threads and Executors</li>
<li>  Part 2: <a href="/posts/2015/04/30/java8-concurrency-tutorial-synchronized-locks-examples/">Synchronization and Locks</a></li>
<li>  Part 3: <a href="/posts/2015/05/22/java8-concurrency-tutorial-atomic-concurrent-map-examples/">Atomic Variables and ConcurrentMap</a></li>
</ul>

<p>The <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/package-summary.html">Concurrency API</a> was first introduced with the release of Java 5 and then progressively enhanced with every new Java release. The majority of concepts shown in this article also work in older versions of Java. However my code samples focus on Java 8 and make heavy use of lambda expressions and other new features. If you&#39;re not yet familiar with lambdas I recommend reading my <a href="/posts/2014/03/16/java-8-tutorial/">Java 8 Tutorial</a> first.</p>

<h3 id="toc_0">Threads and Runnables<a href="#threads-and-runnables" title="Permalink to this section">#</a></h3>

<p>All modern operating systems support concurrency both via <a href="http://en.wikipedia.org/wiki/Process_(computing)">processes</a> and <a href="http://en.wikipedia.org/wiki/Thread_%28computing%29">threads</a>. Processes are instances of programs which typically run independent to each other, e.g. if you start a java program the operating system spawns a new process which runs in parallel to other programs. Inside those processes we can utilize threads to execute code concurrently, so we can make the most out of the available cores of the CPU.</p>

<p>Java supports <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html">Threads</a> since JDK 1.0. Before starting a new thread you have to specify the code to be executed by this thread, often called the <u>task</u>. This is done by implementing <code>Runnable</code> - a functional interface defining a single void no-args method <code>run()</code> as demonstrated in the following example:</p>

<pre><code>Runnable task = () -&gt; {
    String threadName = Thread.currentThread().getName();
    System.out.println(&quot;Hello &quot; + threadName);
};

task.run();

Thread thread = new Thread(task);
thread.start();

System.out.println(&quot;Done!&quot;);

</code></pre>

<p>Since <code>Runnable</code> is a functional interface we can utilize Java 8 lambda expressions to print the current threads name to the console. First we execute the runnable directly on the main thread before starting a new thread.</p>

<p>The result on the console might look like this:</p>

<pre><code>Hello main
Hello Thread-0
Done!

</code></pre>

<p>Or that:</p>

<pre><code>Hello main
Done!
Hello Thread-0

</code></pre>

<p>Due to concurrent execution we cannot predict if the runnable will be invoked before or after printing &#39;done&#39;. The order is non-deterministic, thus making concurrent programming a complex task in larger applications.</p>

<p>Threads can be put to sleep for a certain duration. This is quite handy to simulate long running tasks in the subsequent code samples of this article:</p>

<pre><code>Runnable runnable = () -&gt; {
    try {
        String name = Thread.currentThread().getName();
        System.out.println(&quot;Foo &quot; + name);
        TimeUnit.SECONDS.sleep(1);
        System.out.println(&quot;Bar &quot; + name);
    }
    catch (InterruptedException e) {
        e.printStackTrace();
    }
};

Thread thread = new Thread(runnable);
thread.start();

</code></pre>

<p>When you run the above code you&#39;ll notice the one second delay between the first and the second print statement. <code>TimeUnit</code> is a useful enum for working with units of time. Alternatively you can achieve the same by calling <code>Thread.sleep(1000)</code>.</p>

<p>Working with the <code>Thread</code> class can be very tedious and error-prone. Due to that reason the <strong>Concurrency API</strong> has been introduced back in 2004 with the release of Java 5. The API is located in package <code>java.util.concurrent</code> and contains many useful classes for handling concurrent programming. Since that time the Concurrency API has been enhanced with every new Java release and even Java 8 provides new classes and methods for dealing with concurrency.</p>

<p>Now let&#39;s take a deeper look at one of the most important parts of the Concurrency API - the executor services.</p>

<h3 id="toc_1">Executors<a href="#executors" title="Permalink to this section">#</a></h3>

<p>The Concurrency API introduces the concept of an <code>ExecutorService</code> as a higher level replacement for working with threads directly. Executors are capable of running asynchronous tasks and typically manage a pool of threads, so we don&#39;t have to create new threads manually. All threads of the internal pool will be reused under the hood for revenant tasks, so we can run as many concurrent tasks as we want throughout the life-cycle of our application with a single executor service.</p>

<p>This is how the first thread-example looks like using executors:</p>

<pre><code>ExecutorService executor = Executors.newSingleThreadExecutor();
executor.submit(() -&gt; {
    String threadName = Thread.currentThread().getName();
    System.out.println(&quot;Hello &quot; + threadName);
});

// =&gt; Hello pool-1-thread-1

</code></pre>

<p>The class <code>Executors</code> provides convenient factory methods for creating different kinds of executor services. In this sample we use an executor with a thread pool of size one.</p>

<p>The result looks similar to the above sample but when running the code you&#39;ll notice an important difference: the java process never stops! Executors have to be stopped explicitly - otherwise they keep listening for new tasks.</p>

<p>An <code>ExecutorService</code> provides two methods for that purpose: <code>shutdown()</code> waits for currently running tasks to finish while <code>shutdownNow()</code> interrupts all running tasks and shut the executor down immediately.</p>

<p>This is the preferred way how I typically shutdown executors:</p>

<pre><code>try {
    System.out.println(&quot;attempt to shutdown executor&quot;);
    executor.shutdown();
    executor.awaitTermination(5, TimeUnit.SECONDS);
}
catch (InterruptedException e) {
    System.err.println(&quot;tasks interrupted&quot;);
}
finally {
    if (!executor.isTerminated()) {
        System.err.println(&quot;cancel non-finished tasks&quot;);
    }
    executor.shutdownNow();
    System.out.println(&quot;shutdown finished&quot;);
}

</code></pre>

<p>The executor shuts down softly by waiting a certain amount of time for termination of currently running tasks. After a maximum of five seconds the executor finally shuts down by interrupting all running tasks.</p>

<h4 id="toc_2">Callables and Futures<a href="#callables-and-futures" title="Permalink to this section">#</a></h4>

<p>In addition to <code>Runnable</code> executors support another kind of task named <code>Callable</code>. Callables are functional interfaces just like runnables but instead of being <code>void</code> they return a value.</p>

<p>This lambda expression defines a callable returning an integer after sleeping for one second:</p>

<pre><code>Callable&lt;Integer&gt; task = () -&gt; {
    try {
        TimeUnit.SECONDS.sleep(1);
        return 123;
    }
    catch (InterruptedException e) {
        throw new IllegalStateException(&quot;task interrupted&quot;, e);
    }
};

</code></pre>

<p>Callables can be submitted to executor services just like runnables. But what about the callables result? Since <code>submit()</code> doesn&#39;t wait until the task completes, the executor service cannot return the result of the callable directly. Instead the executor returns a special result of type <code>Future</code> which can be used to retrieve the actual result at a later point in time.</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(1);
Future&lt;Integer&gt; future = executor.submit(task);

System.out.println(&quot;future done? &quot; + future.isDone());

Integer result = future.get();

System.out.println(&quot;future done? &quot; + future.isDone());
System.out.print(&quot;result: &quot; + result);

</code></pre>

<p>After submitting the callable to the executor we first check if the future has already been finished execution via <code>isDone()</code>. I&#39;m pretty sure this isn&#39;t the case since the above callable sleeps for one second before returning the integer.</p>

<p>Calling the method <code>get()</code> blocks the current thread and waits until the callable completes before returning the actual result <code>123</code>. Now the future is finally done and we see the following result on the console:</p>

<pre><code>future done? false
future done? true
result: 123

</code></pre>

<p>Futures are tightly coupled to the underlying executor service. Keep in mind that every non-terminated future will throw exceptions if you shutdown the executor:</p>

<pre><code>executor.shutdownNow();
future.get();

</code></pre>

<p>You might have noticed that the creation of the executor slightly differs from the previous example. We use <code>newFixedThreadPool(1)</code> to create an executor service backed by a thread-pool of size one. This is equivalent to <code>newSingleThreadExecutor()</code> but we could later increase the pool size by simply passing a value larger than one.</p>

<h4 id="toc_3">Timeouts<a href="#timeouts" title="Permalink to this section">#</a></h4>

<p>Any call to <code>future.get()</code> will block and wait until the underlying callable has been terminated. In the worst case a callable runs forever - thus making your application unresponsive. You can simply counteract those scenarios by passing a timeout:</p>

<pre><code>ExecutorService executor = Executors.newFixedThreadPool(1);

Future&lt;Integer&gt; future = executor.submit(() -&gt; {
    try {
        TimeUnit.SECONDS.sleep(2);
        return 123;
    }
    catch (InterruptedException e) {
        throw new IllegalStateException(&quot;task interrupted&quot;, e);
    }
});

future.get(1, TimeUnit.SECONDS);

</code></pre>

<p>Executing the above code results in a <code>TimeoutException</code>:</p>

<pre><code>Exception in thread &quot;main&quot; java.util.concurrent.TimeoutException
    at java.util.concurrent.FutureTask.get(FutureTask.java:205)

</code></pre>

<p>You might already have guessed why this exception is thrown: We specified a maximum wait time of one second but the callable actually needs two seconds before returning the result.</p>

<h4 id="toc_4">InvokeAll<a href="#invokeall" title="Permalink to this section">#</a></h4>

<p>Executors support batch submitting of multiple callables at once via <code>invokeAll()</code>. This method accepts a collection of callables and returns a list of futures.</p>

<pre><code>ExecutorService executor = Executors.newWorkStealingPool();

List&lt;Callable&lt;String&gt;&gt; callables = Arrays.asList(
        () -&gt; &quot;task1&quot;,
        () -&gt; &quot;task2&quot;,
        () -&gt; &quot;task3&quot;);

executor.invokeAll(callables)
    .stream()
    .map(future -&gt; {
        try {
            return future.get();
        }
        catch (Exception e) {
            throw new IllegalStateException(e);
        }
    })
    .forEach(System.out::println);

</code></pre>

<p>In this example we utilize Java 8 functional streams in order to process all futures returned by the invocation of <code>invokeAll</code>. We first map each future to its return value and then print each value to the console. If you&#39;re not yet familiar with streams read my <a href="/posts/2014/07/31/java8-stream-tutorial-examples/">Java 8 Stream Tutorial</a>.</p>

<h4 id="toc_5">InvokeAny<a href="#invokeany" title="Permalink to this section">#</a></h4>

<p>Another way of batch-submitting callables is the method <code>invokeAny()</code> which works slightly different to <code>invokeAll()</code>. Instead of returning future objects this method blocks until the first callable terminates and returns the result of that callable.</p>

<p>In order to test this behavior we use this helper method to simulate callables with different durations. The method returns a callable that sleeps for a certain amount of time until returning the given result:</p>

<pre><code>Callable&lt;String&gt; callable(String result, long sleepSeconds) {
    return () -&gt; {
        TimeUnit.SECONDS.sleep(sleepSeconds);
        return result;
    };
}

</code></pre>

<p>We use this method to create a bunch of callables with different durations from one to three seconds. Submitting those callables to an executor via <code>invokeAny()</code> returns the string result of the fastest callable - in that case task2:</p>

<pre><code>ExecutorService executor = Executors.newWorkStealingPool();

List&lt;Callable&lt;String&gt;&gt; callables = Arrays.asList(
    callable(&quot;task1&quot;, 2),
    callable(&quot;task2&quot;, 1),
    callable(&quot;task3&quot;, 3));

String result = executor.invokeAny(callables);
System.out.println(result);

// =&gt; task2

</code></pre>

<p>The above example uses yet another type of executor created via <code>newWorkStealingPool()</code>. This factory method is part of Java 8 and returns an executor of type <code>ForkJoinPool</code> which works slightly different than normal executors. Instead of using a fixed size thread-pool <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ForkJoinPool.html">ForkJoinPools</a> are created for a given parallelism size which per default is the number of available cores of the hosts CPU.</p>

<p>ForkJoinPools exist since Java 7 and will be covered in detail in a later tutorial of this series. Let&#39;s finish this tutorial by taking a deeper look at scheduled executors.</p>

<h3 id="toc_6">Scheduled Executors<a href="#scheduled-executors" title="Permalink to this section">#</a></h3>

<p>We&#39;ve already learned how to submit and run tasks once on an executor. In order to periodically run common tasks multiple times, we can utilize scheduled thread pools.</p>

<p>A <code>ScheduledExecutorService</code> is capable of scheduling tasks to run either periodically or once after a certain amount of time has elapsed.</p>

<p>This code sample schedules a task to run after an initial delay of three seconds has passed:</p>

<pre><code>ScheduledExecutorService executor = Executors.newScheduledThreadPool(1);

Runnable task = () -&gt; System.out.println(&quot;Scheduling: &quot; + System.nanoTime());
ScheduledFuture&lt;?&gt; future = executor.schedule(task, 3, TimeUnit.SECONDS);

TimeUnit.MILLISECONDS.sleep(1337);

long remainingDelay = future.getDelay(TimeUnit.MILLISECONDS);
System.out.printf(&quot;Remaining Delay: %sms&quot;, remainingDelay);

</code></pre>

<p>Scheduling a task produces a specialized future of type <code>ScheduledFuture</code> which - in addition to <code>Future</code> - provides the method <code>getDelay()</code> to retrieve the remaining delay. After this delay has elapsed the task will be executed concurrently.</p>

<p>In order to schedule tasks to be executed periodically, executors provide the two methods <code>scheduleAtFixedRate()</code> and <code>scheduleWithFixedDelay()</code>. The first method is capable of executing tasks with a fixed time rate, e.g. once every second as demonstrated in this example:</p>

<pre><code>ScheduledExecutorService executor = Executors.newScheduledThreadPool(1);

Runnable task = () -&gt; System.out.println(&quot;Scheduling: &quot; + System.nanoTime());

int initialDelay = 0;
int period = 1;
executor.scheduleAtFixedRate(task, initialDelay, period, TimeUnit.SECONDS);

</code></pre>

<p>Additionally this method accepts an initial delay which describes the leading wait time before the task will be executed for the first time.</p>

<p>Please keep in mind that <code>scheduleAtFixedRate()</code> doesn&#39;t take into account the actual duration of the task. So if you specify a period of one second but the task needs 2 seconds to be executed then the thread pool will working to capacity very soon.</p>

<p>In that case you should consider using <code>scheduleWithFixedDelay()</code> instead. This method works just like the counterpart described above. The difference is that the wait time period applies between the end of a task and the start of the next task. For example:</p>

<pre><code>ScheduledExecutorService executor = Executors.newScheduledThreadPool(1);

Runnable task = () -&gt; {
    try {
        TimeUnit.SECONDS.sleep(2);
        System.out.println(&quot;Scheduling: &quot; + System.nanoTime());
    }
    catch (InterruptedException e) {
        System.err.println(&quot;task interrupted&quot;);
    }
};

executor.scheduleWithFixedDelay(task, 0, 1, TimeUnit.SECONDS);

</code></pre>

<p>This example schedules a task with a fixed delay of one second between the end of an execution and the start of the next execution. The initial delay is zero and the tasks duration is two seconds. So we end up with an execution interval of 0s, 3s, 6s, 9s and so on. As you can see <code>scheduleWithFixedDelay()</code> is handy if you cannot predict the duration of the scheduled tasks.</p>

<p>This was the first part out of a series of concurrency tutorials. I recommend practicing the shown code samples by your own. You find all code samples from this article on <a href="https://github.com/winterbe/java8-tutorial">GitHub</a>, so feel free to fork the repo and <a href="https://github.com/winterbe/java8-tutorial/stargazers">give me star</a>.</p>

<p>I hope you&#39;ve enjoyed this article. If you have any further questions send me your feedback in the comments below or via <a href="https://twitter.com/winterbe_">Twitter</a>.</p>

<ul>
<li>  Part 1: Threads and Executors</li>
<li>  Part 2: <a href="/posts/2015/04/30/java8-concurrency-tutorial-synchronized-locks-examples/">Synchronization and Locks</a></li>
<li>  Part 3: <a href="/posts/2015/05/22/java8-concurrency-tutorial-atomic-concurrent-map-examples/">Atomic Variables and ConcurrentMap</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java 8 Stream Tutorial]]></title>
    <link href="http://panlw.github.io/15358756631902.html"/>
    <updated>2018-09-02T16:07:43+08:00</updated>
    <id>http://panlw.github.io/15358756631902.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://winterbe.com/posts/2014/07/31/java8-stream-tutorial-examples/">https://winterbe.com/posts/2014/07/31/java8-stream-tutorial-examples/</a></p>
</blockquote>

<p>This example-driven tutorial gives an in-depth overview about Java 8 streams. When I first read about the <code>Stream</code> API, I was confused about the name since it sounds similar to <code>InputStream</code> and <code>OutputStream</code> from Java I/O. But Java 8 streams are a completely different thing. Streams are <a href="http://en.wikipedia.org/wiki/Monad_%28functional_programming%29">Monads</a>, thus playing a big part in bringing <u>functional programming</u> to Java:</p>

<blockquote>
<p>In functional programming, a monad is a structure that represents computations defined as sequences of steps. A type with a monad structure defines what it means to chain operations, or nest functions of that type together.</p>
</blockquote>

<p>This guide teaches you how to work with Java 8 streams and how to use the different kind of available stream operations. You&#39;ll learn about the processing order and how the ordering of stream operations affect runtime performance. The more powerful stream operations <code>reduce</code>, <code>collect</code> and <code>flatMap</code> are covered in detail. The tutorial ends with an in-depth look at parallel streams.</p>

<p>If you&#39;re not yet familiar with Java 8 lambda expressions, functional interfaces and method references, you probably want to read my <a href="http://winterbe.com/posts/2014/03/16/java-8-tutorial/">Java 8 Tutorial</a> first before starting with this tutorial.</p>

<h3 id="toc_0">How streams work<a href="#how-streams-work" title="Permalink to this section">#</a></h3>

<p>A stream represents a sequence of elements and supports different kind of operations to perform computations upon those elements:</p>

<pre><code>List&lt;String&gt; myList =
    Arrays.asList(&quot;a1&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;c2&quot;, &quot;c1&quot;);

myList
    .stream()
    .filter(s -&gt; s.startsWith(&quot;c&quot;))
    .map(String::toUpperCase)
    .sorted()
    .forEach(System.out::println);

// C1
// C2

</code></pre>

<p>Stream operations are either intermediate or terminal. Intermediate operations return a stream so we can chain multiple intermediate operations without using semicolons. Terminal operations are either void or return a non-stream result. In the above example <code>filter</code>, <code>map</code> and <code>sorted</code> are intermediate operations whereas <code>forEach</code> is a terminal operation. For a full list of all available stream operations see the <a href="http://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html">Stream Javadoc</a>. Such a chain of stream operations as seen in the example above is also known as <u>operation pipeline</u>.</p>

<p>Most stream operations accept some kind of lambda expression parameter, a functional interface specifying the exact behavior of the operation. Most of those operations must be both <u>non-interfering</u> and <u>stateless</u>. What does that mean?</p>

<p>A function is <a href="http://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html#NonInterference">non-interfering</a> when it does not modify the underlying data source of the stream, e.g. in the above example no lambda expression does modify <code>myList</code> by adding or removing elements from the collection.</p>

<p>A function is <a href="http://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html#Statelessness">stateless</a> when the execution of the operation is deterministic, e.g. in the above example no lambda expression depends on any mutable variables or states from the outer scope which might change during execution.</p>

<h3 id="toc_1">Different kind of streams<a href="#different-kind-of-streams" title="Permalink to this section">#</a></h3>

<p>Streams can be created from various data sources, especially collections. Lists and Sets support new methods <code>stream()</code> and <code>parallelStream()</code> to either create a sequential or a parallel stream. Parallel streams are capable of operating on multiple threads and will be covered in a later section of this tutorial. We focus on sequential streams for now:</p>

<pre><code>Arrays.asList(&quot;a1&quot;, &quot;a2&quot;, &quot;a3&quot;)
    .stream()
    .findFirst()
    .ifPresent(System.out::println);  // a1

</code></pre>

<p>Calling the method <code>stream()</code> on a list of objects returns a regular object stream. But we don&#39;t have to create collections in order to work with streams as we see in the next code sample:</p>

<pre><code>Stream.of(&quot;a1&quot;, &quot;a2&quot;, &quot;a3&quot;)
    .findFirst()
    .ifPresent(System.out::println);  // a1

</code></pre>

<p>Just use <code>Stream.of()</code> to create a stream from a bunch of object references.</p>

<p>Besides regular object streams Java 8 ships with special kinds of streams for working with the primitive data types <code>int</code>, <code>long</code> and <code>double</code>. As you might have guessed it&#39;s <code>IntStream</code>, <code>LongStream</code> and <code>DoubleStream</code>.</p>

<p>IntStreams can replace the regular for-loop utilizing <code>IntStream.range()</code>:</p>

<pre><code>IntStream.range(1, 4)
    .forEach(System.out::println);

// 1
// 2
// 3

</code></pre>

<p>All those primitive streams work just like regular object streams with the following differences: Primitive streams use specialized lambda expressions, e.g. <code>IntFunction</code> instead of <code>Function</code> or <code>IntPredicate</code> instead of <code>Predicate</code>. And primitive streams support the additional terminal aggregate operations <code>sum()</code> and <code>average()</code>:</p>

<pre><code>Arrays.stream(new int[] {1, 2, 3})
    .map(n -&gt; 2 * n + 1)
    .average()
    .ifPresent(System.out::println);  // 5.0

</code></pre>

<p>Sometimes it&#39;s useful to transform a regular object stream to a primitive stream or vice versa. For that purpose object streams support the special mapping operations <code>mapToInt()</code>, <code>mapToLong()</code> and <code>mapToDouble</code>:</p>

<pre><code>Stream.of(&quot;a1&quot;, &quot;a2&quot;, &quot;a3&quot;)
    .map(s -&gt; s.substring(1))
    .mapToInt(Integer::parseInt)
    .max()
    .ifPresent(System.out::println);  // 3

</code></pre>

<p>Primitive streams can be transformed to object streams via <code>mapToObj()</code>:</p>

<pre><code>IntStream.range(1, 4)
    .mapToObj(i -&gt; &quot;a&quot; + i)
    .forEach(System.out::println);

// a1
// a2
// a3

</code></pre>

<p>Here&#39;s a combined example: the stream of doubles is first mapped to an int stream and than mapped to an object stream of strings:</p>

<pre><code>Stream.of(1.0, 2.0, 3.0)
    .mapToInt(Double::intValue)
    .mapToObj(i -&gt; &quot;a&quot; + i)
    .forEach(System.out::println);

// a1
// a2
// a3

</code></pre>

<h3 id="toc_2">Processing Order<a href="#processing-order" title="Permalink to this section">#</a></h3>

<p>Now that we&#39;ve learned how to create and work with different kinds of streams, let&#39;s dive deeper into how stream operations are processed under the hood.</p>

<p>An important characteristic of intermediate operations is laziness. Look at this sample where a terminal operation is missing:</p>

<pre><code>Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;)
    .filter(s -&gt; {
        System.out.println(&quot;filter: &quot; + s);
        return true;
    });

</code></pre>

<p>When executing this code snippet, nothing is printed to the console. That is because intermediate operations will only be executed when a terminal operation is present.</p>

<p>Let&#39;s extend the above example by the terminal operation <code>forEach</code>:</p>

<pre><code>Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;)
    .filter(s -&gt; {
        System.out.println(&quot;filter: &quot; + s);
        return true;
    })
    .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s));

</code></pre>

<p>Executing this code snippet results in the desired output on the console:</p>

<pre><code>filter:  d2
forEach: d2
filter:  a2
forEach: a2
filter:  b1
forEach: b1
filter:  b3
forEach: b3
filter:  c
forEach: c

</code></pre>

<p>The order of the result might be surprising. A naive approach would be to execute the operations horizontally one after another on all elements of the stream. But instead each element moves along the chain vertically. The first string &quot;d2&quot; passes <code>filter</code> then <code>forEach</code>, only then the second string &quot;a2&quot; is processed.</p>

<p>This behavior can reduce the actual number of operations performed on each element, as we see in the next example:</p>

<pre><code>Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;)
    .map(s -&gt; {
        System.out.println(&quot;map: &quot; + s);
        return s.toUpperCase();
    })
    .anyMatch(s -&gt; {
        System.out.println(&quot;anyMatch: &quot; + s);
        return s.startsWith(&quot;A&quot;);
    });

// map:      d2
// anyMatch: D2
// map:      a2
// anyMatch: A2

</code></pre>

<p>The operation <code>anyMatch</code> returns <code>true</code> as soon as the predicate applies to the given input element. This is true for the second element passed &quot;A2&quot;. Due to the vertical execution of the stream chain, <code>map</code> has only to be executed twice in this case. So instead of mapping all elements of the stream, <code>map</code> will be called as few as possible.</p>

<h4 id="toc_3">Why order matters<a href="#why-order-matters" title="Permalink to this section">#</a></h4>

<p>The next example consists of two intermediate operations <code>map</code> and <code>filter</code> and the terminal operation <code>forEach</code>. Let&#39;s once again inspect how those operations are being executed:</p>

<pre><code>Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;)
    .map(s -&gt; {
        System.out.println(&quot;map: &quot; + s);
        return s.toUpperCase();
    })
    .filter(s -&gt; {
        System.out.println(&quot;filter: &quot; + s);
        return s.startsWith(&quot;A&quot;);
    })
    .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s));

// map:     d2
// filter:  D2
// map:     a2
// filter:  A2
// forEach: A2
// map:     b1
// filter:  B1
// map:     b3
// filter:  B3
// map:     c
// filter:  C

</code></pre>

<p>As you might have guessed both <code>map</code> and <code>filter</code> are called five times for every string in the underlying collection whereas <code>forEach</code> is only called once.</p>

<p>We can greatly reduce the actual number of executions if we change the order of the operations, moving <code>filter</code> to the beginning of the chain:</p>

<pre><code>Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;)
    .filter(s -&gt; {
        System.out.println(&quot;filter: &quot; + s);
        return s.startsWith(&quot;a&quot;);
    })
    .map(s -&gt; {
        System.out.println(&quot;map: &quot; + s);
        return s.toUpperCase();
    })
    .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s));

// filter:  d2
// filter:  a2
// map:     a2
// forEach: A2
// filter:  b1
// filter:  b3
// filter:  c

</code></pre>

<p>Now, <code>map</code> is only called once so the operation pipeline performs much faster for larger numbers of input elements. Keep that in mind when composing complex method chains.</p>

<p>Let&#39;s extend the above example by an additional operation, <code>sorted</code>:</p>

<pre><code>Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;)
    .sorted((s1, s2) -&gt; {
        System.out.printf(&quot;sort: %s; %s\n&quot;, s1, s2);
        return s1.compareTo(s2);
    })
    .filter(s -&gt; {
        System.out.println(&quot;filter: &quot; + s);
        return s.startsWith(&quot;a&quot;);
    })
    .map(s -&gt; {
        System.out.println(&quot;map: &quot; + s);
        return s.toUpperCase();
    })
    .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s));

</code></pre>

<p>Sorting is a special kind of intermediate operation. It&#39;s a so called <u>stateful operation</u> since in order to sort a collection of elements you have to maintain state during ordering.</p>

<p>Executing this example results in the following console output:</p>

<pre><code>sort:    a2; d2
sort:    b1; a2
sort:    b1; d2
sort:    b1; a2
sort:    b3; b1
sort:    b3; d2
sort:    c; b3
sort:    c; d2
filter:  a2
map:     a2
forEach: A2
filter:  b1
filter:  b3
filter:  c
filter:  d2

</code></pre>

<p>First, the sort operation is executed on the entire input collection. In other words <code>sorted</code> is executed horizontally. So in this case <code>sorted</code> is called eight times for multiple combinations on every element in the input collection.</p>

<p>Once again we can optimize the performance by reordering the chain:</p>

<pre><code>Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;)
    .filter(s -&gt; {
        System.out.println(&quot;filter: &quot; + s);
        return s.startsWith(&quot;a&quot;);
    })
    .sorted((s1, s2) -&gt; {
        System.out.printf(&quot;sort: %s; %s\n&quot;, s1, s2);
        return s1.compareTo(s2);
    })
    .map(s -&gt; {
        System.out.println(&quot;map: &quot; + s);
        return s.toUpperCase();
    })
    .forEach(s -&gt; System.out.println(&quot;forEach: &quot; + s));

// filter:  d2
// filter:  a2
// filter:  b1
// filter:  b3
// filter:  c
// map:     a2
// forEach: A2

</code></pre>

<p>In this example <code>sorted</code> is never been called because <code>filter</code> reduces the input collection to just one element. So the performance is greatly increased for larger input collections.</p>

<h3 id="toc_4">Reusing Streams<a href="#reusing-streams" title="Permalink to this section">#</a></h3>

<p>Java 8 streams cannot be reused. As soon as you call any terminal operation the stream is closed:</p>

<pre><code>Stream&lt;String&gt; stream =
    Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;)
        .filter(s -&gt; s.startsWith(&quot;a&quot;));

stream.anyMatch(s -&gt; true);    // ok
stream.noneMatch(s -&gt; true);   // exception

</code></pre>

<p>Calling <code>noneMatch</code> after <code>anyMatch</code> on the same stream results in the following exception:</p>

<pre><code>java.lang.IllegalStateException: stream has already been operated upon or closed
    at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:229)
    at java.util.stream.ReferencePipeline.noneMatch(ReferencePipeline.java:459)
    at com.winterbe.java8.Streams5.test7(Streams5.java:38)
    at com.winterbe.java8.Streams5.main(Streams5.java:28)

</code></pre>

<p>To overcome this limitation we have to to create a new stream chain for every terminal operation we want to execute, e.g. we could create a stream supplier to construct a new stream with all intermediate operations already set up:</p>

<pre><code>Supplier&lt;Stream&lt;String&gt;&gt; streamSupplier =
    () -&gt; Stream.of(&quot;d2&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;b3&quot;, &quot;c&quot;)
            .filter(s -&gt; s.startsWith(&quot;a&quot;));

streamSupplier.get().anyMatch(s -&gt; true);   // ok
streamSupplier.get().noneMatch(s -&gt; true);  // ok

</code></pre>

<p>Each call to <code>get()</code> constructs a new stream on which we are save to call the desired terminal operation.</p>

<h3 id="toc_5">Advanced Operations<a href="#advanced-operations" title="Permalink to this section">#</a></h3>

<p>Streams support plenty of different operations. We&#39;ve already learned about the most important operations like <code>filter</code> or <code>map</code>. I leave it up to you to discover all other available operations (see <a href="http://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html">Stream Javadoc</a>). Instead let&#39;s dive deeper into the more complex operations <code>collect</code>, <code>flatMap</code> and <code>reduce</code>.</p>

<p>Most code samples from this section use the following list of persons for demonstration purposes:</p>

<pre><code>class Person {
    String name;
    int age;

    Person(String name, int age) {
        this.name = name;
        this.age = age;
    }

    @Override
    public String toString() {
        return name;
    }
}

List&lt;Person&gt; persons =
    Arrays.asList(
        new Person(&quot;Max&quot;, 18),
        new Person(&quot;Peter&quot;, 23),
        new Person(&quot;Pamela&quot;, 23),
        new Person(&quot;David&quot;, 12));

</code></pre>

<h4 id="toc_6">Collect<a href="#collect" title="Permalink to this section">#</a></h4>

<p>Collect is an extremely useful terminal operation to transform the elements of the stream into a different kind of result, e.g. a <code>List</code>, <code>Set</code> or <code>Map</code>. Collect accepts a <code>Collector</code> which consists of four different operations: a <u>supplier</u>, an <u>accumulator</u>, a <u>combiner</u> and a <u>finisher</u>. This sounds super complicated at first, but the good part is Java 8 supports various built-in collectors via the <code>Collectors</code> class. So for the most common operations you don&#39;t have to implement a collector yourself.</p>

<p>Let&#39;s start with a very common usecase:</p>

<pre><code>List&lt;Person&gt; filtered =
    persons
        .stream()
        .filter(p -&gt; p.name.startsWith(&quot;P&quot;))
        .collect(Collectors.toList());

System.out.println(filtered);    // [Peter, Pamela]

</code></pre>

<p>As you can see it&#39;s very simple to construct a list from the elements of a stream. Need a set instead of list - just use <code>Collectors.toSet()</code>.</p>

<p>The next example groups all persons by age:</p>

<pre><code>Map&lt;Integer, List&lt;Person&gt;&gt; personsByAge = persons
    .stream()
    .collect(Collectors.groupingBy(p -&gt; p.age));

personsByAge
    .forEach((age, p) -&gt; System.out.format(&quot;age %s: %s\n&quot;, age, p));

// age 18: [Max]
// age 23: [Peter, Pamela]
// age 12: [David]

</code></pre>

<p>Collectors are extremely versatile. You can also create aggregations on the elements of the stream, e.g. determining the average age of all persons:</p>

<pre><code>Double averageAge = persons
    .stream()
    .collect(Collectors.averagingInt(p -&gt; p.age));

System.out.println(averageAge);     // 19.0

</code></pre>

<p>If you&#39;re interested in more comprehensive statistics, the summarizing collectors return a special built-in summary statistics object. So we can simply determine <u>min</u>, <u>max</u> and arithmetic <u>average</u> age of the persons as well as the <u>sum</u> and <u>count</u>.</p>

<pre><code>IntSummaryStatistics ageSummary =
    persons
        .stream()
        .collect(Collectors.summarizingInt(p -&gt; p.age));

System.out.println(ageSummary);
// IntSummaryStatistics{count=4, sum=76, min=12, average=19.000000, max=23}

</code></pre>

<p>The next example joins all persons into a single string:</p>

<pre><code>String phrase = persons
    .stream()
    .filter(p -&gt; p.age &gt;= 18)
    .map(p -&gt; p.name)
    .collect(Collectors.joining(&quot; and &quot;, &quot;In Germany &quot;, &quot; are of legal age.&quot;));

System.out.println(phrase);
// In Germany Max and Peter and Pamela are of legal age.

</code></pre>

<p>The join collector accepts a delimiter as well as an optional prefix and suffix.</p>

<p>In order to transform the stream elements into a map, we have to specify how both the keys and the values should be mapped. Keep in mind that the mapped keys must be unique, otherwise an <code>IllegalStateException</code> is thrown. You can optionally pass a merge function as an additional parameter to bypass the exception:</p>

<pre><code>Map&lt;Integer, String&gt; map = persons
    .stream()
    .collect(Collectors.toMap(
        p -&gt; p.age,
        p -&gt; p.name,
        (name1, name2) -&gt; name1 + &quot;;&quot; + name2));

System.out.println(map);
// {18=Max, 23=Peter;Pamela, 12=David}

</code></pre>

<p>Now that we know some of the most powerful built-in collectors, let&#39;s try to build our own special collector. We want to transform all persons of the stream into a single string consisting of all names in upper letters separated by the <code>|</code> pipe character. In order to achieve this we create a new collector via <code>Collector.of()</code>. We have to pass the four ingredients of a collector: a <u>supplier</u>, an <u>accumulator</u>, a <u>combiner</u> and a <u>finisher</u>.</p>

<pre><code>Collector&lt;Person, StringJoiner, String&gt; personNameCollector =
    Collector.of(
        () -&gt; new StringJoiner(&quot; | &quot;),          // supplier
        (j, p) -&gt; j.add(p.name.toUpperCase()),  // accumulator
        (j1, j2) -&gt; j1.merge(j2),               // combiner
        StringJoiner::toString);                // finisher

String names = persons
    .stream()
    .collect(personNameCollector);

System.out.println(names);  // MAX | PETER | PAMELA | DAVID

</code></pre>

<p>Since strings in Java are immutable, we need a helper class like <code>StringJoiner</code> to let the collector construct our string. The supplier initially constructs such a StringJoiner with the appropriate delimiter. The accumulator is used to add each persons upper-cased name to the StringJoiner. The combiner knows how to merge two StringJoiners into one. In the last step the finisher constructs the desired String from the StringJoiner.</p>

<h4 id="toc_7">FlatMap<a href="#flatmap" title="Permalink to this section">#</a></h4>

<p>We&#39;ve already learned how to transform the objects of a stream into another type of objects by utilizing the <code>map</code> operation. Map is kinda limited because every object can only be mapped to exactly one other object. But what if we want to transform one object into multiple others or none at all? This is where <code>flatMap</code> comes to the rescue.</p>

<p>FlatMap transforms each element of the stream into a stream of other objects. So each object will be transformed into zero, one or multiple other objects backed by streams. The contents of those streams will then be placed into the returned stream of the <code>flatMap</code> operation.</p>

<p>Before we see <code>flatMap</code> in action we need an appropriate type hierarchy:</p>

<pre><code>class Foo {
    String name;
    List&lt;Bar&gt; bars = new ArrayList&lt;&gt;();

    Foo(String name) {
        this.name = name;
    }
}

class Bar {
    String name;

    Bar(String name) {
        this.name = name;
    }
}

</code></pre>

<p>Next, we utilize our knowledge about streams to instantiate a couple of objects:</p>

<pre><code>List&lt;Foo&gt; foos = new ArrayList&lt;&gt;();

// create foos
IntStream
    .range(1, 4)
    .forEach(i -&gt; foos.add(new Foo(&quot;Foo&quot; + i)));

// create bars
foos.forEach(f -&gt;
    IntStream
        .range(1, 4)
        .forEach(i -&gt; f.bars.add(new Bar(&quot;Bar&quot; + i + &quot; &lt;- &quot; + f.name))));

</code></pre>

<p>Now we have a list of three foos each consisting of three bars.</p>

<p>FlatMap accepts a function which has to return a stream of objects. So in order to resolve the bar objects of each foo, we just pass the appropriate function:</p>

<pre><code>foos.stream()
    .flatMap(f -&gt; f.bars.stream())
    .forEach(b -&gt; System.out.println(b.name));

// Bar1 &lt;- Foo1
// Bar2 &lt;- Foo1
// Bar3 &lt;- Foo1
// Bar1 &lt;- Foo2
// Bar2 &lt;- Foo2
// Bar3 &lt;- Foo2
// Bar1 &lt;- Foo3
// Bar2 &lt;- Foo3
// Bar3 &lt;- Foo3

</code></pre>

<p>As you can see, we&#39;ve successfully transformed the stream of three foo objects into a stream of nine bar objects.</p>

<p>Finally, the above code example can be simplified into a single pipeline of stream operations:</p>

<pre><code>IntStream.range(1, 4)
    .mapToObj(i -&gt; new Foo(&quot;Foo&quot; + i))
    .peek(f -&gt; IntStream.range(1, 4)
        .mapToObj(i -&gt; new Bar(&quot;Bar&quot; + i + &quot; &lt;- &quot; f.name))
        .forEach(f.bars::add))
    .flatMap(f -&gt; f.bars.stream())
    .forEach(b -&gt; System.out.println(b.name));

</code></pre>

<p>FlatMap is also available for the <code>Optional</code> class introduced in Java 8. Optionals <code>flatMap</code> operation returns an optional object of another type. So it can be utilized to prevent nasty <code>null</code> checks.</p>

<p>Think of a highly hierarchical structure like this:</p>

<pre><code>class Outer {
    Nested nested;
}

class Nested {
    Inner inner;
}

class Inner {
    String foo;
}

</code></pre>

<p>In order to resolve the inner string <code>foo</code> of an outer instance you have to add multiple null checks to prevent possible NullPointerExceptions:</p>

<pre><code>Outer outer = new Outer();
if (outer != null &amp;&amp; outer.nested != null &amp;&amp; outer.nested.inner != null) {
    System.out.println(outer.nested.inner.foo);
}

</code></pre>

<p>The same behavior can be obtained by utilizing optionals <code>flatMap</code> operation:</p>

<pre><code>Optional.of(new Outer())
    .flatMap(o -&gt; Optional.ofNullable(o.nested))
    .flatMap(n -&gt; Optional.ofNullable(n.inner))
    .flatMap(i -&gt; Optional.ofNullable(i.foo))
    .ifPresent(System.out::println);

</code></pre>

<p>Each call to <code>flatMap</code> returns an <code>Optional</code> wrapping the desired object if present or <code>null</code> if absent.</p>

<h4 id="toc_8">Reduce<a href="#reduce" title="Permalink to this section">#</a></h4>

<p>The reduction operation combines all elements of the stream into a single result. Java 8 supports three different kind of <code>reduce</code> methods. The first one reduces a stream of elements to exactly one element of the stream. Let&#39;s see how we can use this method to determine the oldest person:</p>

<pre><code>persons
    .stream()
    .reduce((p1, p2) -&gt; p1.age &gt; p2.age ? p1 : p2)
    .ifPresent(System.out::println);    // Pamela

</code></pre>

<p>The <code>reduce</code> method accepts a <code>BinaryOperator</code> accumulator function. That&#39;s actually a <code>BiFunction</code> where both operands share the same type, in that case <code>Person</code>. BiFunctions are like <code>Function</code> but accept two arguments. The example function compares both persons ages in order to return the person with the maximum age.</p>

<p>The second <code>reduce</code> method accepts both an identity value and a <code>BinaryOperator</code> accumulator. This method can be utilized to construct a new Person with the aggregated names and ages from all other persons in the stream:</p>

<pre><code>Person result =
    persons
        .stream()
        .reduce(new Person(&quot;&quot;, 0), (p1, p2) -&gt; {
            p1.age += p2.age;
            p1.name += p2.name;
            return p1;
        });

System.out.format(&quot;, result.name, result.age);
// name=MaxPeterPamelaDavid; age=76

</code></pre>

<p>The third <code>reduce</code> method accepts three parameters: an identity value, a <code>BiFunction</code> accumulator and a combiner function of type <code>BinaryOperator</code>. Since the identity values type is not restricted to the <code>Person</code> type, we can utilize this reduction to determine the sum of ages from all persons:</p>

<pre><code>Integer ageSum = persons
    .stream()
    .reduce(0, (sum, p) -&gt; sum += p.age, (sum1, sum2) -&gt; sum1 + sum2);

System.out.println(ageSum);  // 76

</code></pre>

<p>As you can see the result is <u>76</u>, but what&#39;s happening exactly under the hood? Let&#39;s extend the above code by some debug output:</p>

<pre><code>Integer ageSum = persons
    .stream()
    .reduce(0,
        (sum, p) -&gt; {
            System.out.format(&quot;accumulator: sum=%s; person=%s\n&quot;, sum, p);
            return sum += p.age;
        },
        (sum1, sum2) -&gt; {
            System.out.format(&quot;combiner: sum1=%s; sum2=%s\n&quot;, sum1, sum2);
            return sum1 + sum2;
        });

// accumulator: sum=0; person=Max
// accumulator: sum=18; person=Peter
// accumulator: sum=41; person=Pamela
// accumulator: sum=64; person=David

</code></pre>

<p>As you can see the accumulator function does all the work. It first get called with the initial identity value <u>0</u> and the first person <u>Max</u>. In the next three steps <code>sum</code> continually increases by the age of the last steps person up to a total age of <u>76</u>.</p>

<p>Wait wat? The combiner never gets called? Executing the same stream in parallel will lift the secret:</p>

<pre><code>Integer ageSum = persons
    .parallelStream()
    .reduce(0,
        (sum, p) -&gt; {
            System.out.format(&quot;accumulator: sum=%s; person=%s\n&quot;, sum, p);
            return sum += p.age;
        },
        (sum1, sum2) -&gt; {
            System.out.format(&quot;combiner: sum1=%s; sum2=%s\n&quot;, sum1, sum2);
            return sum1 + sum2;
        });

// accumulator: sum=0; person=Pamela
// accumulator: sum=0; person=David
// accumulator: sum=0; person=Max
// accumulator: sum=0; person=Peter
// combiner: sum1=18; sum2=23
// combiner: sum1=23; sum2=12
// combiner: sum1=41; sum2=35

</code></pre>

<p>Executing this stream in parallel results in an entirely different execution behavior. Now the combiner is actually called. Since the accumulator is called in parallel, the combiner is needed to sum up the separate accumulated values.</p>

<p>Let&#39;s dive deeper into parallel streams in the next chapter.</p>

<h3 id="toc_9">Parallel Streams<a href="#parallel-streams" title="Permalink to this section">#</a></h3>

<p>Streams can be executed in parallel to increase runtime performance on large amount of input elements. Parallel streams use a common <code>ForkJoinPool</code> available via the static <code>ForkJoinPool.commonPool()</code> method. The size of the underlying thread-pool uses up to five threads - depending on the amount of available physical CPU cores:</p>

<pre><code>ForkJoinPool commonPool = ForkJoinPool.commonPool();
System.out.println(commonPool.getParallelism());    // 3

</code></pre>

<p>On my machine the common pool is initialized with a parallelism of 3 per default. This value can be decreased or increased by setting the following JVM parameter:</p>

<pre><code>-Djava.util.concurrent.ForkJoinPool.common.parallelism=5

</code></pre>

<p>Collections support the method <code>parallelStream()</code> to create a parallel stream of elements. Alternatively you can call the intermediate method <code>parallel()</code> on a given stream to convert a sequential stream to a parallel counterpart.</p>

<p>In order to understate the parallel execution behavior of a parallel stream the next example prints information about the current thread to <code>sout</code>:</p>

<pre><code>Arrays.asList(&quot;a1&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;c2&quot;, &quot;c1&quot;)
    .parallelStream()
    .filter(s -&gt; {
        System.out.format(&quot;filter: %s [%s]\n&quot;,
            s, Thread.currentThread().getName());
        return true;
    })
    .map(s -&gt; {
        System.out.format(&quot;map: %s [%s]\n&quot;,
            s, Thread.currentThread().getName());
        return s.toUpperCase();
    })
    .forEach(s -&gt; System.out.format(&quot;forEach: %s [%s]\n&quot;,
        s, Thread.currentThread().getName()));

</code></pre>

<p>By investigating the debug output we should get a better understanding which threads are actually used to execute the stream operations:</p>

<pre><code>filter:  b1 [main]
filter:  a2 [ForkJoinPool.commonPool-worker-1]
map:     a2 [ForkJoinPool.commonPool-worker-1]
filter:  c2 [ForkJoinPool.commonPool-worker-3]
map:     c2 [ForkJoinPool.commonPool-worker-3]
filter:  c1 [ForkJoinPool.commonPool-worker-2]
map:     c1 [ForkJoinPool.commonPool-worker-2]
forEach: C2 [ForkJoinPool.commonPool-worker-3]
forEach: A2 [ForkJoinPool.commonPool-worker-1]
map:     b1 [main]
forEach: B1 [main]
filter:  a1 [ForkJoinPool.commonPool-worker-3]
map:     a1 [ForkJoinPool.commonPool-worker-3]
forEach: A1 [ForkJoinPool.commonPool-worker-3]
forEach: C1 [ForkJoinPool.commonPool-worker-2]

</code></pre>

<p>As you can see the parallel stream utilizes all available threads from the common <code>ForkJoinPool</code> for executing the stream operations. The output may differ in consecutive runs because the behavior which particular thread is actually used is non-deterministic.</p>

<p>Let&#39;s extend the example by an additional stream operation, <code>sort</code>:</p>

<pre><code>Arrays.asList(&quot;a1&quot;, &quot;a2&quot;, &quot;b1&quot;, &quot;c2&quot;, &quot;c1&quot;)
    .parallelStream()
    .filter(s -&gt; {
        System.out.format(&quot;filter: %s [%s]\n&quot;,
            s, Thread.currentThread().getName());
        return true;
    })
    .map(s -&gt; {
        System.out.format(&quot;map: %s [%s]\n&quot;,
            s, Thread.currentThread().getName());
        return s.toUpperCase();
    })
    .sorted((s1, s2) -&gt; {
        System.out.format(&quot;sort: %s &lt;&gt; %s [%s]\n&quot;,
            s1, s2, Thread.currentThread().getName());
        return s1.compareTo(s2);
    })
    .forEach(s -&gt; System.out.format(&quot;forEach: %s [%s]\n&quot;,
        s, Thread.currentThread().getName()));

</code></pre>

<p>The result may look strange at first:</p>

<pre><code>filter:  c2 [ForkJoinPool.commonPool-worker-3]
filter:  c1 [ForkJoinPool.commonPool-worker-2]
map:     c1 [ForkJoinPool.commonPool-worker-2]
filter:  a2 [ForkJoinPool.commonPool-worker-1]
map:     a2 [ForkJoinPool.commonPool-worker-1]
filter:  b1 [main]
map:     b1 [main]
filter:  a1 [ForkJoinPool.commonPool-worker-2]
map:     a1 [ForkJoinPool.commonPool-worker-2]
map:     c2 [ForkJoinPool.commonPool-worker-3]
sort:    A2 &lt;&gt; A1 [main]
sort:    B1 &lt;&gt; A2 [main]
sort:    C2 &lt;&gt; B1 [main]
sort:    C1 &lt;&gt; C2 [main]
sort:    C1 &lt;&gt; B1 [main]
sort:    C1 &lt;&gt; C2 [main]
forEach: A1 [ForkJoinPool.commonPool-worker-1]
forEach: C2 [ForkJoinPool.commonPool-worker-3]
forEach: B1 [main]
forEach: A2 [ForkJoinPool.commonPool-worker-2]
forEach: C1 [ForkJoinPool.commonPool-worker-1]

</code></pre>

<p>It seems that <code>sort</code> is executed sequentially on the main thread only. Actually, <code>sort</code> on a parallel stream uses the new Java 8 method <code>Arrays.parallelSort()</code> under the hood. As stated in <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Arrays.html#parallelSort-T:A-">Javadoc</a> this method decides on the length of the array if sorting will be performed sequentially or in parallel:</p>

<blockquote>
<p>If the length of the specified array is less than the minimum granularity, then it is sorted using the appropriate Arrays.sort method.</p>
</blockquote>

<p>Coming back to the <code>reduce</code> example from the last section. We already found out that the combiner function is only called in parallel but not in sequential streams. Let&#39;s see which threads are actually involved:</p>

<pre><code>List&lt;Person&gt; persons = Arrays.asList(
    new Person(&quot;Max&quot;, 18),
    new Person(&quot;Peter&quot;, 23),
    new Person(&quot;Pamela&quot;, 23),
    new Person(&quot;David&quot;, 12));

persons
    .parallelStream()
    .reduce(0,
        (sum, p) -&gt; {
            System.out.format(&quot;accumulator: sum=%s; person=%s [%s]\n&quot;,
                sum, p, Thread.currentThread().getName());
            return sum += p.age;
        },
        (sum1, sum2) -&gt; {
            System.out.format(&quot;combiner: sum1=%s; sum2=%s [%s]\n&quot;,
                sum1, sum2, Thread.currentThread().getName());
            return sum1 + sum2;
        });

</code></pre>

<p>The console output reveals that both the <u>accumulator</u> and the <u>combiner</u> functions are executed in parallel on all available threads:</p>

<pre><code>accumulator: sum=0; person=Pamela; [main]
accumulator: sum=0; person=Max;    [ForkJoinPool.commonPool-worker-3]
accumulator: sum=0; person=David;  [ForkJoinPool.commonPool-worker-2]
accumulator: sum=0; person=Peter;  [ForkJoinPool.commonPool-worker-1]
combiner:    sum1=18; sum2=23;     [ForkJoinPool.commonPool-worker-1]
combiner:    sum1=23; sum2=12;     [ForkJoinPool.commonPool-worker-2]
combiner:    sum1=41; sum2=35;     [ForkJoinPool.commonPool-worker-2]

</code></pre>

<p>In summary, it can be stated that parallel streams can bring be a nice performance boost to streams with a large amount of input elements. But keep in mind that some parallel stream operations like <code>reduce</code> and <code>collect</code> need additional computations (combine operations) which isn&#39;t needed when executed sequentially.</p>

<p>Furthermore we&#39;ve learned that all parallel stream operations share the same JVM-wide common <code>ForkJoinPool</code>. So you probably want to avoid implementing slow blocking stream operations since that could potentially slow down other parts of your application which rely heavily on parallel streams.</p>

<h3 id="toc_10">That&#39;s it<a href="#thats-it" title="Permalink to this section">#</a></h3>

<p>My programming guide to Java 8 streams ends here. If you&#39;re interested in learning more about Java 8 streams, I recommend to you the <a href="http://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html#NonInterference">Stream Javadoc</a> package documentation. If you want to learn more about the underlying mechanisms, you probably want to read Martin Fowlers article about <a href="http://martinfowler.com/articles/collection-pipeline/">Collection Pipelines</a>.</p>

<p>If you&#39;re interested in JavaScript as well, you may want to have a look at <a href="https://github.com/winterbe/streamjs">Stream.js</a> - a JavaScript implementation of the Java 8 Streams API. You may also wanna read my <a href="/posts/2014/03/16/java-8-tutorial/">Java 8 Tutorial</a> and my <a href="/posts/2014/04/05/java8-nashorn-tutorial/">Java 8 Nashorn Tutorial</a>.</p>

<p>Hopefully this tutorial was helpful to you and you&#39;ve enjoyed reading it. The full source code of the tutorial samples is <a href="https://github.com/winterbe/java8-tutorial">hosted on GitHub</a>. Feel free to <a href="https://github.com/winterbe/java8-tutorial/fork">fork the repository</a> or send me your feedback via <a href="https://twitter.com/winterbe_">Twitter</a>.</p>

<p>Happy coding!</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Migrate Maven Projects to Java 11]]></title>
    <link href="http://panlw.github.io/15358753472382.html"/>
    <updated>2018-09-02T16:02:27+08:00</updated>
    <id>http://panlw.github.io/15358753472382.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://winterbe.com/posts/2018/08/29/migrate-maven-projects-to-java-11-jigsaw/">https://winterbe.com/posts/2018/08/29/migrate-maven-projects-to-java-11-jigsaw/</a></p>
</blockquote>

<p>So you want to migrate to Java 11 but your Maven project is still sitting on Java 8? You don&#39;t care much about the new <a href="https://www.oracle.com/corporate/features/understanding-java-9-modules.html">module system</a> (Jigsaw) introduced in Java 9, you just want your application to run on the latest JDK version? Then this guide is for you. It includes everything I&#39;ve learned while migrating our product to Java 11.</p>

<blockquote>
<p>As of 2019 Oracle Java 8 will no longer receive free security updates. So now is the time to migrate to <a href="http://jdk.java.net/11/">JDK 11</a>.</p>
</blockquote>

<h3 id="toc_0">Clean up your <code>pom.xml</code> files<a href="#clean-up-your-pom-xml-files" title="Permalink to this section">#</a></h3>

<p>The first thing you should do before even thinking about upgrading the Java version is to clean up your <code>pom.xml</code> files. If your project is a multi-module Maven project then it helps to establish a parent POM and maintain <code>dependencyManagement</code> und <code>pluginManagement</code> in this file. That way all your plugins and dependencies are defined in a single file and are not spread across multiple POM files what makes managing versions easier.</p>

<p>In order to migrate your project to the latest Java version 11 it&#39;s highly recommended to update as much plugins and dependencies to the latest stable version as possible. Many plugins such as the compiler plugin, surefire or failsafe are not compatible with Java 9 if you use older versions. Also a lot of libraries are incompatible without migrating to the latest version.</p>

<p>Make sure you have the versions plugin configured in your master POM:</p>

<pre><code>&lt;plugin&gt;
    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;
    &lt;artifactId&gt;versions-maven-plugin&lt;/artifactId&gt;
    &lt;version&gt;2.5&lt;/version&gt;
    &lt;configuration&gt;
        &lt;generateBackupPoms&gt;false&lt;/generateBackupPoms&gt;
    &lt;/configuration&gt;
&lt;/plugin&gt;

</code></pre>

<p>This plugin helps finding the latest plugin or dependency versions for your modules. Open up the terminal and execute this command to find the plugin versions you have to update:</p>

<pre><code>mvn versions:display-plugin-updates

</code></pre>

<p>You will see a list of plugins used in your project with newer versions available. Update all of those plugins to the lastest stable version. After you&#39;ve updated your plugin versions make sure that your project still compiles and runs properly.</p>

<blockquote>
<p>You can use <code>mvn -N ...</code> from your projects root directory to just check your parent POM in case of multi-module projects.</p>
</blockquote>

<h3 id="toc_1">Configure plugins for Java 11<a href="#configure-plugins-for-java-11" title="Permalink to this section">#</a></h3>

<p>The most important plugins for Java 11 are the compiler plugin, surefire (for unit-tests) and failsafe (for integration-tests).</p>

<p>In order to compile your project for Java 11 add the <code>release</code> configuration to the compiler plugin, a new compiler parameter to replace the <code>source</code> and <code>target</code> version parameters:</p>

<pre><code>&lt;plugin&gt;
    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
    &lt;version&gt;3.8.0&lt;/version&gt;
    &lt;configuration&gt;
        &lt;release&gt;11&lt;/release&gt;
    &lt;/configuration&gt;
&lt;/plugin&gt;

</code></pre>

<blockquote>
<p>Also don&#39;t forget to set your IDEs project SDK to same JDK version. In Intellij IDEA go to Module Settings -&gt; Project -&gt; SDK.</p>
</blockquote>

<p>For surefire and failsafe plugins we add an additional argument <code>--illegal-access=permit</code> to allow all reflection access for third party libraries:</p>

<pre><code>&lt;plugin&gt;
    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
    &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;
    &lt;version&gt;2.22.0&lt;/version&gt;
    &lt;configuration&gt;
        &lt;argLine&gt;
            --illegal-access=permit
        &lt;/argLine&gt;
    &lt;/configuration&gt;
&lt;/plugin&gt;
&lt;plugin&gt;
    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
    &lt;artifactId&gt;maven-failsafe-plugin&lt;/artifactId&gt;
    &lt;version&gt;2.22.0&lt;/version&gt;
    &lt;configuration&gt;
        &lt;argLine&gt;
            --illegal-access=permit
        &lt;/argLine&gt;
    &lt;/configuration&gt;
&lt;/plugin&gt;

</code></pre>

<p>This is only needed if your dependencies make heavy use of reflection. If you&#39;re unsure whether you need this you can add the <code>argLine</code> later if your tests run into trouble.</p>

<p>You&#39;ll see warnings like this when a library tries to illegally access classes via <code>setAccessible(true)</code>:</p>

<pre><code>WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.reflection.CachedClass
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release

</code></pre>

<blockquote>
<p>Keep in mind that later you probably also have to pass the <code>--illegal-access=permit</code> parameter when starting your application.</p>
</blockquote>

<h3 id="toc_2">Update dependencies<a href="#update-dependencies" title="Permalink to this section">#</a></h3>

<p>As mentioned before the best thing you can do is to migrate all your dependencies to the latest stable versions to make sure everything works fine with Java 11. While many older dependencies might work just fine there&#39;s a couple of dependencies where version updates are mandatory, e.g. all those various bytecode enhancement libaries such as <code>javassist</code>, <code>cglib</code>, <code>asm</code> or <code>byte-buddy</code>. Those libraries often come as transitive dependencies so make sure at least those libaries are up-to-date.</p>

<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.javassist&lt;/groupId&gt;
    &lt;artifactId&gt;javassist&lt;/artifactId&gt;
    &lt;version&gt;3.23.1-GA&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;cglib&lt;/groupId&gt;
    &lt;artifactId&gt;cglib-nodep&lt;/artifactId&gt;
    &lt;version&gt;3.2.7&lt;/version&gt;
&lt;/dependency&gt;

</code></pre>

<p>This command helps to find outdated dependency versions from your modules:</p>

<pre><code>mvn versions:display-dependency-updates

</code></pre>

<p>Update as much libaries as possible to the latest stable version. If there&#39;s some dependency that you can&#39;t update due to compatibility issues in your project than leave it as is. Chances are that it just runs fine with Java 11.</p>

<p>Now is a good time to compile your project with JDK 11 for the first time:</p>

<pre><code>mvn clean test-compile compile

</code></pre>

<blockquote>
<p>Hint: You can speed up multi-module Maven projects by using parallel builds, e.g. <code>mvn -T 4 compile</code> compiles all modules in parallel on 4 CPU cores.</p>
</blockquote>

<p>You will eventually face different compiler errors such as <code>ClassNotFoundException</code>. Every project is different so I cannot provide solutions for every problem you will face. The rest of this article describes solutions to various problems we had to solve in order to run our application with JDK 11.</p>

<h3 id="toc_3">Add missing modules<a href="#add-missing-modules" title="Permalink to this section">#</a></h3>

<p>With the introduction of the Java module system (Jigsaw) in Java 9 the Java standard libary has been divided into separate modules. While most classes are still available without any changes, some are not. You have to explicitely define which additional modules your application needs access to or you can just add those modules from the Maven central repository.</p>

<blockquote>
<p>The command <code>java --list-modules</code> lists all available modules.</p>
</blockquote>

<p>When migrating our web project to Java 11 we had to add <code>jaxb</code> and <code>javax.annotations</code> to prevent <code>ClassNotFoundException</code>. We&#39;ve added the following libaries as additional Maven dependencies to our POMs:</p>

<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;javax.annotation&lt;/groupId&gt;
    &lt;artifactId&gt;javax.annotation-api&lt;/artifactId&gt;
    &lt;version&gt;1.3.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt;
    &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt;
    &lt;version&gt;2.4.0-b180725.0427&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.glassfish.jaxb&lt;/groupId&gt;
    &lt;artifactId&gt;jaxb-runtime&lt;/artifactId&gt;
    &lt;version&gt;2.4.0-b180725.0644&lt;/version&gt;
&lt;/dependency&gt;

</code></pre>

<blockquote>
<p>Instead of adding those libaries via Maven we could utilize the <code>–add-modules</code> Java parameter to add additional JDK modules to the project.</p>
</blockquote>

<h3 id="toc_4">Fixing <code>sun.*</code> and <code>com.sun.*</code> imports<a href="#fixing-sun-and-com-sun-imports" title="Permalink to this section">#</a></h3>

<p>While some classes have been moved to additional Java modules other classes can no longer been used in user code, namely classes from <code>sun.*</code> packages and also some classes from <code>com.sun.*</code>. If you get compiler errors because your code links to classes from those packages you have to remove those imports from your code.</p>

<p>Here&#39;s a few things we had to fix in our project:</p>

<ul>
<li>  <code>sun.misc.BASE64Encoder</code>: This can simply be replaced by <code>java.util.Base64.getEncoder()</code> which is available since Java 8.</li>
<li>  <code>sun.reflect.generics.reflectiveObjects.ParameterizedTypeImpl</code>: This class has accidentally been used in our code base and can simply be replaced by the interface type <code>java.lang.reflect.ParameterizedType</code>.</li>
<li>  <code>sun.reflect.annotation.AnnotationParser</code>: We use this class to programmatically create annotation instances. The class is no longer accessible but can be replaced by <code>AnnotationFactory</code> from Hibernate Validator.</li>
<li>  <code>com.sun.org.apache.xml.internal.utils.DefaultErrorHandler</code>: We&#39;ve replaced this class with a custom implementation of the interface.</li>
</ul>

<h3 id="toc_5">Currency formats<a href="#currency-formats" title="Permalink to this section">#</a></h3>

<p>We&#39;ve encountered a curious case with number formats for locales such as <code>Locale.GERMANY</code> which let a bunch of our tests fail with a rather strange assertion error:</p>

<pre><code>java.lang.AssertionError:
Expected: is &quot;9,80 €&quot;
     but: was &quot;9,80 €&quot;

</code></pre>

<p>The underlying code uses <code>NumberFormat.getCurrencyInstance(Locale.GERMANY)</code> to format numbers into the german currency format. So what the heck is happening here?</p>

<p>Javas number formats have been modified to use <a href="https://en.wikipedia.org/wiki/Non-breaking_space">non-breaking spaces</a> instead of normal spaces between the number and the currency symbol. This change makes perfectly sense because it prevents line-breaks between the number and the currency symbol in various presentation formats. Changing the strings in our tests to use non-breaking spaces (use OPTION SPACE on Mac OSX keyboards) fixed this issue.</p>

<h3 id="toc_6">Servlet Container<a href="#servlet-container" title="Permalink to this section">#</a></h3>

<p>When running web applications with Apache Tomcat you need at least Apache Tomcat 7.0.85 or later. Otherwise Tomcat will not start on Java 9 and above and you would see the following error:</p>

<pre><code>/path/to/apache-tomcat-7.0.64/bin/catalina.sh run
-Djava.endorsed.dirs=/path/to/apache-tomcat-7.0.64/endorsed is not supported. Endorsed standards and standalone APIs
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.
in modular form will be supported via the concept of upgradeable modules.
Disconnected from server

</code></pre>

<p>Also don&#39;t forget to eventually add the additional startup parameter <code>--illegal-access=permit</code> to your servlet container.</p>

<h3 id="toc_7">That&#39;s all<a href="#thats-all" title="Permalink to this section">#</a></h3>

<p>I hope these tips are somewhat useful to you and helps you migrating your application from Java 8 to 11. If you like this guide please consider sharing the link with your followers. Also <a href="https://twitter.com/winterbe_">let me know on Twitter</a> if your migration was successful.</p>

<p>Good luck!</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zookeeper 总览]]></title>
    <link href="http://panlw.github.io/15356007721649.html"/>
    <updated>2018-08-30T11:46:12+08:00</updated>
    <id>http://panlw.github.io/15356007721649.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://juejin.im/post/5a3b542d6fb9a0452725c25f">https://juejin.im/post/5a3b542d6fb9a0452725c25f</a></p>

<p>翻译自 Zookeeper 官方网站 Release 3.4.11 版本</p>
</blockquote>

<h2 id="toc_0">Zookeeper</h2>

<ul>
<li>  <a href="#1">Zookeeper: 一个为分布式应用设计的<code>分布式协调服务</code></a>

<ul>
<li>  <a href="#1.1">Zookeeper 设计目标</a></li>
<li>  <a href="#1.2">Zookeeper<code>数据模型</code>和<code>层级命名空间</code></a></li>
<li>  <a href="#1.3">Zookeeper<code>默认节点</code>和<code>临时节点</code></a></li>
<li>  <a href="#1.4">Zookeeper<code>条件更新</code>和<code>监视</code>(watches)</a></li>
<li>  <a href="#1.5">Zookeeper<code>保证</code>(Guarantees)</a></li>
<li>  <a href="#1.6">Zookeeper<code>简单API</code></a></li>
<li>  <a href="#1.7">Zookeeper<code>实现原理</code></a></li>
<li>  <a href="#1.8">Zookeeper<code>使用</code></a></li>
<li>  <a href="#1.9">Zookeeper<code>性能</code></a></li>
<li>  <a href="#1.10">Zookeeper<code>可靠性</code></a></li>
<li>  <a href="#1.11">Zookeeper 项目</a></li>
</ul></li>
</ul>

<h3 id="toc_1"><a id="1">Zookeeper: 一个为分布式应用设计的<code>分布式协调服务</code></a></h3>

<p>ZooKeeper 是一款开源的<code>分布式应用</code>的<code>分布式协调服务</code>。它包含一个简单的<code>原语集</code>，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。Zookeeper 设计很容易进行编程，它使用一种类似于文件系统的目录树结构的数据模型，以 java 方式运行，有 java 和 c 的绑定 (binding)。</p>

<p><code>协调服务</code>是非常难以被正确实现的。他们特别容易产生诸如竞态条件、死锁等错误。ZooKeeper 背后的动机是为分布式应用程序减轻从零开始实现协调服务的难度。</p>

<h3 id="toc_2"><a id="1.1">设计目标</a></h3>

<h5 id="toc_3">Zookeeper 是非常简单的。</h5>

<p>ZooKeeper 允许分布式进程通过与标准文件系统类似组织的共享层级命名空间来相互协调。命名空间被称为<code>znode</code>的数据记录组成，用 ZooKeeper 的说法，这些记录和标准文件系统中的文件和目录非常相似。与典型的用于存储的文件系统不同，ZooKeeper 数据保存在内存中，这意味着 ZooKeeper 可以实现高吞吐量和低延迟。</p>

<p>Zookeeper 的实现着重于高性能、高可用性和严格的顺序访问。ZooKeeper 的性能方面意味着它可以用于大型分布式系统。可靠性方面使它不会造成单点故障。严格的排序意味着可以在客户端实现复杂的同步原语。</p>

<h5 id="toc_4">Zookeeper 是复制的（replicated）</h5>

<p>就像它协调的分布式进程一样，Zookeeper 自身也在被称为 “ensemble” 的一组主机之间进行复制。</p>

<p><img src="media/15356007721649/15356009470781.jpg" alt=""/></p>

<p>组成 Zookeeper 服务 (Service) 的每个服务器 (server) 之间都必须相互了解对方。他们维护一个内存状态图，以及一个持久存储的事务日志和快照。只要这些服务器 (servers) 中大多数是可用的，整个 ZooKeeper 服务就是可用的。</p>

<p>客户端 (client) 连接到任意一台 ZooKeeper 服务器。客户端维护一个 TCP 连接，通过它发送请求、获取响应、获取监视事件以及发送心跳。如果到服务器的 TCP 连接中断，客户端将连接到其他不同的服务器。</p>

<h5 id="toc_5">Zokeeper 是有顺序的</h5>

<p>ZooKeeper 使用反映所有 ZooKeeper 事务顺序的数字来标记每个更新。后续操作可以使用该次序来实现更高级别的抽象，例如同步原语。</p>

<h5 id="toc_6">ZooKeeper 是快速的</h5>

<p>在应对以 “读” 为主的负载时尤其地快速。ZooKeeper 应用程序在数千台机器上运行，并且在读取比写入更为普遍的情况下，性能表现最佳，比例约为 10：1。</p>

<h3 id="toc_7"><a id="1.2">Zookeeper 数据模型和层级命名空间</a></h3>

<p>ZooKeeper 提供的命名空间与标准文件系统非常相似。路径是由斜杠<code>/</code>分隔的一系列元素。 ZooKeeper 命名空间中的每个节点都由一个路径标识。<br/>
<img src="media/15356007721649/15356009665985.jpg" alt=""/></p>

<h3 id="toc_8"><a id="1.3">Zookeeper<code>默认节点</code>和<code>临时节点</code></a></h3>

<p>与标准文件系统不同的是，ZooKeeper 命名空间中的每个节点都可以拥有与其相关的数据以及子节点。这就像一个文件系统中可以存在一个文件或一个目录。ZooKeeper 被设计用来存储相关的协调数据，如状态信息、配置、位置信息等等，所以每个节点上存储的数据通常都很小，在字节 (byte) 到千字节 (kb) 范围内。我们使用术语 znode 来清楚地说明我们正在讨论 ZooKeeper 数据节点。</p>

<p>Znode 维护了一个状态 (<code>stat</code>) 结构，其中包含了表示数据改变、访问控制列表（ACL）改变的版本号、时间戳，可用于缓存校验、协调更新。每当一个 znode 的数据发生变化，版本号就会增加。例如，每当客户端检索数据时，客户端也会接收到相应数据的版本信息。</p>

<p>存储在命名空间中每个节点上的数据是以原子方式读取和写入的。读取一个 znode 将获得其全部的数据，而写入则替换其全部的数据。</p>

<p>ZooKeeper 也有临时节点的概念。当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。</p>

<h3 id="toc_9"><a id="1.4">Zookeeper<code>条件更新</code>和<code>监视</code>(watches)</a></h3>

<p>ZooKeeper 支持 “监视”(watches) 的概念。客户端可以在 znode 上设置一个监视 (watch)。当 znode 改变时，监视(watch) 将被触发并移除。当监视 (watch) 被触发时，当 “监视” 被触发时，客户端会收到一个描述了 znode 的变更的数据包。如果客户端和 Zookeeper 服务器之间的连接断开时，客户端将会收到一个本地通知。</p>

<h3 id="toc_10"><a id="1.5">Zookeeper<code>保证</code>(Guarantees)</a></h3>

<p>Zookeeper 非常地快速也非常简单。不过，由于它的目标是作为构建诸如 “同步” 这类更复杂服务的基础，它提供了一些的一组保证：</p>

<ul>
<li>  顺序一致性 - 来自客户端的更改请求将会按照它们的发送的顺序被应用。</li>
<li>  原子性 - 更改要么成功，要么失败，不会存在部分成功、部分失败的结果。</li>
<li>  单一系统映像 - 客户端会看到 Zookeeper 服务的相同的视图，而无论它们连到具体哪一个服务器上</li>
<li>  可靠性 - 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。</li>
<li>  及时性 - 客户端看到的系统视图在一定的时间范围内总是最新的。</li>
</ul>

<h3 id="toc_11"><a id="1.6">简单的 API</a></h3>

<p>ZooKeeper 的一个设计目标是提供一个非常简单的编程接口。 因此，它只支持这些操作：</p>

<ul>
<li><p>###### create</p>

<blockquote>
<p>在（命名空间）树的一个特定地址上创建一个节点。</p>
</blockquote></li>
<li><p>###### delete</p>

<blockquote>
<p>删除一个节点。</p>
</blockquote></li>
<li><p>###### exists</p>

<blockquote>
<p>判断某个路径下是否存在该节点。</p>
</blockquote></li>
<li><p>###### get data</p>

<blockquote>
<p>获取节点的数据。</p>
</blockquote></li>
<li><p>###### set data</p>

<blockquote>
<p>向节点写入数据。</p>
</blockquote></li>
<li><p>###### get children</p>

<blockquote>
<p>检索节点的子节点列表。</p>
</blockquote></li>
<li><p>###### sync</p>

<blockquote>
<p>等待数据传播完成。</p>
</blockquote></li>
</ul>

<h3 id="toc_12"><a id="1.7">Zookeeper<code>实现原理</code></a></h3>

<p><a href="https://link.juejin.im?target=http%3A%2F%2Fzookeeper.apache.org%2Fdoc%2Fr3.4.11%2FzookeeperOver.html%23fg_zkComponents">ZooKeeper Components</a> 显示了 ZooKeeper 服务的高级组件。除<code>Request Processor</code>外，构成 ZooKeeper 服务的每个服务器都复制每个组件的副本。</p>

<p><img src="media/15356007721649/15356009879352.jpg" alt=""/></p>

<p><code>replicated database</code>是一个内存数据库，它包含了整颗数据树。数据写入在应用到内存数据库之前，会先序列化到磁盘。</p>

<p>每一个 Zookeeper 服务器都向客户端提供服务，客户端连接到一个确切的 Zookeeper 服务器提交请求。读请求从服务器数据库的本地拷贝中获取。改变 Zookeeper 服务状态的请求、写入请求通过一个一致性协议进行处理。</p>

<p>作为协议的一部分，客户端的所有写入请求都被转发到一个单独的服务器，该服务器被称为 leader。而其余的服务器，被称为 follower，从 leader 接收消息提案（proposal）并对消息的交付取得一致。消息层维护 leader 失效时的更新替换以及 leader 和 follower 之间的同步。</p>

<p>Zookeeper 使用自定义的原子消息协议。由于消息层是原子的，Zookeeper 可以保证本地的复制品不会不一致。当 leader 收到一个写入请求时，它计算系统所处的状态以及何时应用写入请求，并将此转换为一个事务，包含新的状态。</p>

<h3 id="toc_13"><a id="1.8">使用</a></h3>

<p>Zookeeper 的编程接口特意地定义得很简单。然而，通过这些编程接口可以更高阶的操作，例如同步原语，成员分组，所有权，等等。</p>

<h3 id="toc_14"><a id="1.9">性能</a></h3>

<p>Zookeeper 被设计为高性能。但实际是否如此呢？在雅虎研发中心的 Zookeeper 开发团队的研究结果表明的确如此。（参见下图：Zookeeper 吞吐量随读写比的变化）。在 “读” 多于 “写” 的应用程序中尤其地高性能，因为 “写” 会导致在所有的服务器间同步状态。（“读”多于 “写” 是协调服务的典型场景。）</p>

<p>Zookeeper 吞吐量随读写比的变化</p>

<p><img src="media/15356007721649/15356010042046.jpg" alt=""/></p>

<p>图 “Zookeeper 吞吐量随读写比的变化” 是 Zookeeper3.2 版本运行于 Dual 2Gh Xeon + 2 个 15K RPM 的 SATA 硬盘驱动器的服务器上的结果。一个驱动器用作 Zookeeper 专用的日志设备。快照写到操作系统驱动器。写请求是 1K 数据的写入而读请求是 1K 的数据读取。“Servers” 标出了 Zookeeper Ensemble 的大小，即组成 Zookeeper 服务的服务器的数量。大约 30 台其它的服务器被用作模拟客户端。Zookeeper Ensemble 被配置为不允许客户端连接到 Leader 。</p>

<p>注：3.2 版本的读 / 写性能相对于 3.1 版本以前有最多达 2 倍的提升。</p>

<p>基准测试也表明了 Zookeeper 的可靠性。图 “错误发生的情况下的可靠性” 展示了 Zookeeper 是如何应对各种不同的失效的。图中标注的事件如下：</p>

<ol>
<li><p>一个 Follower 失效然后恢复。</p></li>
<li><p>另一个不同的 Follower 失效然后恢复。</p></li>
<li><p>Leader 失效。</p></li>
<li><p>两个 Follower 失效然后恢复。</p></li>
<li><p>另一个 Leader 失效。</p></li>
</ol>

<h3 id="toc_15"><a id="1.10">可靠性</a></h3>

<p><img src="media/15356007721649/15356010153963.jpg" alt=""/></p>

<p>从这张图中可以得到几点重要的结果。首先，如果 follower 失效并快速恢复，Zookeeper 能够维持高吞吐量，尽管存在失效。但也许更重要的是，leader 选举算法使系统足够快地恢复，避免了吞吐量的总体下降。从观察结果来看，Zookeeper 花了不到 200 毫秒的时间选举出了一个新的 leader。第三，只要 follower 恢复，Zookeeper 的吞吐量能够再次上升到刚开始处理请求时的水平。</p>

<h3 id="toc_16"><a id="1.11">关于 ZooKeeper 项目</a></h3>

<p>Zookeeper 已经被成功地用在许多工业级的应用。在雅虎，Zookeeper 被用作雅虎消息中间件的协调和失效恢复服务，该系统是一个高伸缩性的发布订阅系统，管理着成千上万的主题复制和数据分发。Zookeeper 还被用在雅虎爬虫的抓取服务上，用于管理失效恢复。许多雅虎的广告系统也用 Zookeeper 实现可靠的服务。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL]]></title>
    <link href="http://panlw.github.io/15353470248085.html"/>
    <updated>2018-08-27T13:17:04+08:00</updated>
    <id>http://panlw.github.io/15353470248085.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">JDBC Connect failed</h2>

<blockquote>
<p>Check VPN Global Mode</p>
</blockquote>

<h2 id="toc_1">Version 8+</h2>

<blockquote>
<p>&quot;Public Key Retrieval is not allowed&quot;</p>

<p>/usr/local/var/mysql/ca.pem</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Here are examples of everything new in ECMAScript 2016, 2017, and 2018]]></title>
    <link href="http://panlw.github.io/15352961449208.html"/>
    <updated>2018-08-26T23:09:04+08:00</updated>
    <id>http://panlw.github.io/15352961449208.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://medium.freecodecamp.org/here-are-examples-of-everything-new-in-ecmascript-2016-2017-and-2018-d52fa3b5a70e">https://medium.freecodecamp.org/here-are-examples-of-everything-new-in-ecmascript-2016-2017-and-2018-d52fa3b5a70e</a></p>
</blockquote>

<p><img src="https://cdn-images-1.medium.com/max/1000/1*Z-9unq6Am3vekNOa5fD1xg.png" alt=""/></p>

<p>It’s hard to keep track of what’s new in JavaScript (ECMAScript). And it’s even harder to find useful code examples.</p>

<p>So in this article, I’ll cover all 18 features that are listed in the <a href="https://github.com/tc39/proposals/blob/master/finished-proposals.md">TC39’s finished proposals</a> that were added in ES2016, ES2017, and ES2018 (final draft) and show them with useful examples.</p>

<blockquote>
<p>This is a pretty long post but should be an easy read. Think of this as “<strong>Netflix binge reading.”</strong> By the end of this, I promise that you’ll have a ton of knowledge about all these features.</p>
</blockquote>

<h4 id="toc_0"><strong>OK, let’s go over these one by one.</strong></h4>

<p><img src="https://cdn-images-1.medium.com/max/800/1*K09EWrqTcTwN9_dlhlzy6Q.png" alt=""/></p>

<h3 id="toc_1"><code>1\. Array.prototype.includes</code></h3>

<p><code>includes</code> is a simple instance method on the Array and helps to easily find if an item is in the Array (including <code>NaN</code> unlike <code>indexOf</code>).</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*OhhFTNabUEz8ZeI4vaCIJw.png" alt=""/>ECMAScript 2016 or ES7 — Array.prototype.includes()</p>

<blockquote>
<p>Trivia: the JavaScript spec people wanted to name it <code>contains</code> , but this was apparently already used by Mootools so they used <code>includes</code> .</p>
</blockquote>

<h4 id="toc_2"><code>2\.</code> Exponentiation <code>infix operator</code></h4>

<p>Math operations like addition and subtraction have infix operators like <code>+</code> and <code>-</code> , respectively. Similar to them, the <code>**</code> infix operator is commonly used for exponent operation. In ECMAScript 2016, the <code>**</code> was introduced instead of <code>Math.pow</code> .</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*c1k1vgBgGaam7XA8xAp49w.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*c1k1vgBgGaam7XA8xAp49w.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*c1k1vgBgGaam7XA8xAp49w.png" alt=""/>ECMAScript 2016 or ES7 — ** Exponent infix operator<img src="https://cdn-images-1.medium.com/freeze/max/30/1*fV_95TaY3ocgE8hlDhhv8w.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*fV_95TaY3ocgE8hlDhhv8w.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*fV_95TaY3ocgE8hlDhhv8w.png" alt=""/></p>

<h3 id="toc_3">1. Object.values()</h3>

<p><code>Object.values()</code> is a new function that’s similar to <code>Object.keys()</code> but returns all the values of the Object’s own properties excluding any value(s) in the prototypical chain.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*OkcC2Sozg0MKvkaqZWxmnw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*OkcC2Sozg0MKvkaqZWxmnw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*OkcC2Sozg0MKvkaqZWxmnw.png" alt=""/>ECMAScript 2017 (ES8)— Object.values()</p>

<h3 id="toc_4">2. Object.entries()</h3>

<p><code>Object.entries()</code> is related to <code>Object.keys</code> , but instead of returning just keys, it returns both keys and values in the array fashion. This makes it very simple to do things like using objects in loops or converting objects into Maps.</p>

<p><strong>Example 1:</strong></p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*23RYJzstZ7iMxKNYbfAAWg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*23RYJzstZ7iMxKNYbfAAWg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*23RYJzstZ7iMxKNYbfAAWg.png" alt=""/>ECMAScript 2017 (ES8) — Using Object.entries() in loops</p>

<p><strong>Example 2:</strong></p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*XAXiVkw2zKyBio4OX6DQoQ.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*XAXiVkw2zKyBio4OX6DQoQ.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*XAXiVkw2zKyBio4OX6DQoQ.png" alt=""/>ECMAScript 2017 (ES8) — Using Object.entries() to convert Object to Map</p>

<h3 id="toc_5">3. String padding</h3>

<p>Two instance methods were added to String — <code>String.prototype.padStart</code> and <code>String.prototype.padEnd</code> — that allow appending/prepending either an empty string or some other string to the start or the end of the original string.</p>

<pre>'someString'.padStart(numberOfCharcters [,stringForPadding]); </pre>

<pre>'5'.padStart(10) // '          5'
'5'.padStart(10, '=*') //'=*=*=*=*=5'</pre>

<pre>'5'.padEnd(10) // '5         '
'5'.padEnd(10, '=*') //'5=*=*=*=*='</pre>

<blockquote>
<p>This comes in handy when we want to align things in scenarios like pretty print display or terminal print.</p>
</blockquote>

<h4 id="toc_6">3.1 padStart example:</h4>

<p>In the below example, we have a list of numbers of varying lengths. We want to prepend “0” so that all the items have the same length of 10 digits for display purposes. We can use <code>padStart(10, &#39;0&#39;)</code> to easily achieve this.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*KLrT9Xmh43cIi2MFUmIfcw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*KLrT9Xmh43cIi2MFUmIfcw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*KLrT9Xmh43cIi2MFUmIfcw.png" alt=""/>ECMAScript 2017 — padStart example</p>

<h4 id="toc_7">3.2 padEnd example:</h4>

<p><code>padEnd</code> really comes in handy when we are printing multiple items of varying lengths and want to right-align them properly.</p>

<p>The example below is a good realistic example of how <code>padEnd</code> , <code>padStart</code> , and <code>Object.entries</code> all come together to produce a beautiful output.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*fLXPci_E_yXK9uSqLz-axQ.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*fLXPci_E_yXK9uSqLz-axQ.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*fLXPci_E_yXK9uSqLz-axQ.png" alt=""/>ECMAScript 2017 — padEnd, padStart and Object.Entries example</p>

<pre>const cars = {
  '🚙BMW': '10',
  '🚘Tesla': '5',
  '🚖Lamborghini': '0'
}</pre>

<pre>Object.entries(cars).map(([name, count]) => {
  //padEnd appends ' -' until the name becomes 20 characters
  //padStart prepends '0' until the count becomes 3 characters.
  console.log(`${name.padEnd(20, ' -')} Count: ${count.padStart(3, '0')}`)
});</pre>

<pre>//Prints..
// 🚙BMW - - - - - - -  Count: 010
// 🚘Tesla - - - - - -  Count: 005
// 🚖Lamborghini - - -  Count: 000</pre>

<h4 id="toc_8">3.3 ⚠️ padStart and padEnd on Emojis and other double-byte chars</h4>

<p>Emojis and other double-byte chars are represented using multiple bytes of unicode. So padStart and padEnd might not work as expected!⚠️</p>

<p>For example: Let’s say we are trying to pad the string <code>heart</code> to reach <code>10</code> characters with the ❤️ emoji. The result will look like below:</p>

<pre>//Notice that instead of 5 hearts, there are only 2 hearts and 1 heart that looks odd!
'heart'.padStart(10, "❤️"); // prints.. '❤️❤️❤heart'</pre>

<p>This is because ❤️ is 2 code points long (<code>&#39;\u2764\uFE0F&#39;</code> )! The word <code>heart</code> itself is 5 characters, so we only have a total of 5 chars left to pad. So what happens is that JS pads two hearts using <code>&#39;\u2764\uFE0F&#39;</code> and that produces ❤️❤️. For the last one it simply uses the first byte of the heart <code>\u2764</code> which produces ❤</p>

<p>So we end up with: <code>❤️❤️❤heart</code></p>

<blockquote>
<p>PS: You may use <a href="https://encoder.internetwache.org/#tab_uni">this link</a> to check out unicode char conversions.</p>
</blockquote>

<h3 id="toc_9">4. <code>Object.getOwnPropertyDescriptors</code></h3>

<p>This method returns all the details (including getter <code>get</code>and setter <code>set</code> methods) for all the properties of a given object. The main motivation to add this is to allow shallow copying / cloning an object into another objectthat also copies getter and setter functions as opposed to <code>Object.assign</code><strong> .</strong></p>

<p><strong>Object.assign shallow copies all the details except getter and setter functions of the original source object.</strong></p>

<p>The example below shows the difference between <code>Object.assign</code> and <code>Object.getOwnPropertyDescriptors</code> along with <code>Object.defineProperties</code> to copy an original object <code>Car</code> into a new object <code>ElectricCar</code> . You’ll see that by using <code>Object.getOwnPropertyDescriptors</code> ,<code>discount</code> getter and setter functions are also copied into the target object.</p>

<p>BEFORE…</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*7r4pk8hfx5VQ9-ERu--xCw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*7r4pk8hfx5VQ9-ERu--xCw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*7r4pk8hfx5VQ9-ERu--xCw.png" alt=""/>Before — Using Object.assign</p>

<p>AFTER…</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*gvlG4DfnkiOrlgPsQrjLfg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*gvlG4DfnkiOrlgPsQrjLfg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*gvlG4DfnkiOrlgPsQrjLfg.png" alt=""/>ECMAScript 2017 (ES8) — Object.getOwnPropertyDescriptors</p>

<pre>var Car = {
 name: 'BMW',
 price: 1000000,
 set discount(x) {
  this.d = x;
 },
 get discount() {
  return this.d;
 },
};</pre>

<pre>//Print details of Car object's 'discount' property
console.log(Object.getOwnPropertyDescriptor(Car, 'discount'));
//prints..
// { 
//   get: [Function: get],
//   set: [Function: set],
//   enumerable: true,
//   configurable: true
// }</pre>

<pre>//Copy Car's properties to ElectricCar using Object.assign
const ElectricCar = Object.assign({}, Car);</pre>

<pre>//Print details of ElectricCar object's 'discount' property
console.log(Object.getOwnPropertyDescriptor(ElectricCar, 'discount'));
//prints..
// { 
//   value: undefined,
//   writable: true,
//   enumerable: true,
//   configurable: true 

// }
//⚠️Notice that getters and setters are missing in ElectricCar object for 'discount' property !👎👎</pre>

<pre>//Copy Car's properties to ElectricCar2 using Object.defineProperties 
//and extract Car's properties using Object.getOwnPropertyDescriptors
const ElectricCar2 = Object.defineProperties({}, Object.getOwnPropertyDescriptors(Car));</pre>

<pre>//Print details of ElectricCar2 object's 'discount' property
console.log(Object.getOwnPropertyDescriptor(ElectricCar2, 'discount'));
//prints..
// { get: [Function: get],  👈🏼👈🏼👈🏼
//   set: [Function: set],  👈🏼👈🏼👈🏼
//   enumerable: true,
//   configurable: true 
// }
// Notice that getters and setters are present in the ElectricCar2 object for 'discount' property!</pre>

<h3 id="toc_10">5. <code>Add trailing commas in the function parameters</code></h3>

<p>This is a minor update that allows us to have trailing commas after the last function parameter. Why? To help with tools like git blame to ensure only new developers get blamed.</p>

<p>The below example shows the problem and the solution.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*-SKZCxQdf8Rk48SSaPtDGg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*-SKZCxQdf8Rk48SSaPtDGg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*-SKZCxQdf8Rk48SSaPtDGg.png" alt=""/>ECMAScript 2017 (ES 8) — Trailing comma in function paramameter</p>

<blockquote>
<p>Note: You can also call functions with trailing commas!</p>
</blockquote>

<h3 id="toc_11">6. Async/Await</h3>

<p>This, by far, is the most important and most useful feature if you ask me. Async functions allows us to not deal with callback hell and make the entire code look simple.</p>

<p>The <code>async</code> keyword tells the JavaScript compiler to treat the function differently. The compiler pauses whenever it reaches the <code>await</code> keyword within that function. It assumes that the expression after <code>await</code> returns a promise and waits until the promise is resolved or rejected before moving further.</p>

<p>In the example below, the <code>getAmount</code> function is calling two asynchronous functions <code>getUser</code> and <code>getBankBalance</code> . We can do this in promise, but using <code>async await</code> is more elegant and simple.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*L3FZ0onbBD4ay6UhZvPoMw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*L3FZ0onbBD4ay6UhZvPoMw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*L3FZ0onbBD4ay6UhZvPoMw.png" alt=""/>ECMAScript 2017 (ES 8) — Async Await basic example</p>

<h4 id="toc_12"><strong>6.1</strong> Async functions themselves return a Promise.</h4>

<p>If you are waiting for the result from an async function, you need to use Promise’s <code>then</code> syntax to capture its result.</p>

<p>In the following example, we want to log the result using <code>console.log</code> but not within the doubleAndAdd. So we want to wait and use <code>then</code> syntax to pass the result to <code>console.log</code> .</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*ylheY6gJawprWEVNL68mRQ.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*ylheY6gJawprWEVNL68mRQ.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*ylheY6gJawprWEVNL68mRQ.png" alt=""/>ECMAScript 2017 (ES 8) — Async Await themselves returns Promise</p>

<h4 id="toc_13"><strong>6.2 Calling async/await in parallel</strong></h4>

<p>In the previous example we are calling await twice, but each time we are waiting for one second (total 2 seconds). Instead we can parallelize it since <code>a</code> and <code>b</code> are not dependent on each other using <code>Promise.all</code>.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*VEF_Sq067Liq4lfTV8Xv0A.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*VEF_Sq067Liq4lfTV8Xv0A.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*VEF_Sq067Liq4lfTV8Xv0A.png" alt=""/>ECMAScript 2017 (ES 8) — Using Promise.all to parallelize async/await</p>

<h4 id="toc_14">6.3 Error handling async/await functions</h4>

<p>There are various ways to handle errors when using async await.</p>

<h4 id="toc_15"><strong>Option 1 — Use try catch within the function</strong></h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*iP84ax2TOt5dbaIjW7kzcw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*iP84ax2TOt5dbaIjW7kzcw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*iP84ax2TOt5dbaIjW7kzcw.png" alt=""/>ECMAScript 2017 — <strong>Use try catch within the async/await function</strong></p>

<pre>//Option 1 - Use try catch within the function
async function doubleAndAdd(a, b) {
 try {
  a = await doubleAfter1Sec(a);
  b = await doubleAfter1Sec(b);
 } catch (e) {
  return NaN; //return something
 }</pre>

<pre>return a + b;
}
//🚀Usage:
doubleAndAdd('one', 2).then(console.log); // NaN
doubleAndAdd(1, 2).then(console.log); // 6</pre>

<pre>function doubleAfter1Sec(param) {
 return new Promise((resolve, reject) => {
  setTimeout(function() {
   let val = param * 2;
   isNaN(val) ? reject(NaN) : resolve(val);
  }, 1000);
 });
}</pre>

<h4 id="toc_16"><strong>Option 2— Catch every await expression</strong></h4>

<p>Since every <code>await</code> expression returns a Promise, you can catch errors on each line as shown below.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*Bkls3dXMIRGKAwFN2r--qg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*Bkls3dXMIRGKAwFN2r--qg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*Bkls3dXMIRGKAwFN2r--qg.png" alt=""/>ECMAScript 2017 — <strong>Use try catch every await expression</strong></p>

<pre>//Option 2 - *Catch* errors on  every await line
//as each await expression is a Promise in itself
async function doubleAndAdd(a, b) {
 a = await doubleAfter1Sec(a).catch(e => console.log('"a" is NaN')); // 👈
 b = await doubleAfter1Sec(b).catch(e => console.log('"b" is NaN')); // 👈
 if (!a || !b) {
  return NaN;
 }
 return a + b;
}</pre>

<pre>//🚀Usage:
doubleAndAdd('one', 2).then(console.log); // NaN  and logs:  "a" is NaN
doubleAndAdd(1, 2).then(console.log); // 6</pre>

<pre>function doubleAfter1Sec(param) {
 return new Promise((resolve, reject) => {
  setTimeout(function() {
   let val = param * 2;
   isNaN(val) ? reject(NaN) : resolve(val);
  }, 1000);
 });
}</pre>

<h4 id="toc_17"><strong>Option 3 — Catch the entire async-await function</strong></h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*hhkv5ZBOUYViCL2UP0sv5Q.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*hhkv5ZBOUYViCL2UP0sv5Q.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*hhkv5ZBOUYViCL2UP0sv5Q.png" alt=""/>ECMAScript 2017 — <strong>Catch the entire async/await function at the end</strong></p>

<pre>//Option 3 - Dont do anything but handle outside the function
//since async / await returns a promise, we can catch the whole function's error
async function doubleAndAdd(a, b) {
 a = await doubleAfter1Sec(a);
 b = await doubleAfter1Sec(b);
 return a + b;
}</pre>

<pre>//🚀Usage:
doubleAndAdd('one', 2)
.then(console.log)
.catch(console.log); // 👈👈🏼<------- use "catch"</pre>

<pre>function doubleAfter1Sec(param) {
 return new Promise((resolve, reject) => {
  setTimeout(function() {
   let val = param * 2;
   isNaN(val) ? reject(NaN) : resolve(val);
  }, 1000);
 });
}</pre>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*X755b572fEcI0vK0fRKWkw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*X755b572fEcI0vK0fRKWkw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*X755b572fEcI0vK0fRKWkw.png" alt=""/></p>

<blockquote>
<p>ECMAScript is currently in final draft and will be out in June or July 2018. All the features covered below are in Stage-4 and will be part of ECMAScript 2018.</p>
</blockquote>

<h4 id="toc_18">1. <a href="https://github.com/tc39/ecmascript_sharedmem">Shared memory and atomics</a></h4>

<p>This is a huge, pretty advanced feature and is a core enhancement to JS engines.</p>

<p><strong>The main idea is to bring some sort of multi-threading feature to JavaScript so that JS developers can write high-performance, concurrent programs in the future by allowing to manage memory by themselves instead of letting JS engine manage memory.</strong></p>

<p>This is done by a new type of a global object called <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer">SharedArrayBuffer</a> that essentially stores data in a <strong>_shared_</strong> <strong>memory space</strong>. So this data can be shared between the main JS thread and web-worker threads.</p>

<p>Until now, if we want to share data between the main JS thread and web-workers, we had to copy the data and send it to the other thread using <code>postMessage</code> . Not anymore!</p>

<p>You simply use SharedArrayBuffer and the data is instantly accessible by both the main thread and multiple web-worker threads.</p>

<p>But sharing memory between threads can cause race conditions. To help avoid race conditions, the “<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Atomics">_Atomics_</a>” global object is introduced. <u>Atomics</u> provides various methods to lock the shared memory when a thread is using its data. It also provides methods to update such data in that shared memory safely.</p>

<blockquote>
<p>The recommendation is to use this feature via some library, but right now there are no libraries built on top of this feature.</p>
</blockquote>

<p>If you are interested, I recommend reading:</p>

<ol>
<li> <a href="http://lucasfcosta.com/2017/04/30/JavaScript-From-Workers-to-Shared-Memory.html">_From Workers to Shared Memor_</a>_y — _<a href="http://lucasfcosta.com/">_lucasfcosta_</a></li>
<li> <a href="https://hacks.mozilla.org/category/code-cartoons/a-cartoon-intro-to-sharedarraybuffers/">_A cartoon intro to SharedArrayBuffers_</a>_ — _<a href="https://medium.com/@linclark">_Lin Clark_</a></li>
<li> <a href="http://2ality.com/2017/01/shared-array-buffer.html">_Shared memory and atomics_</a>_ — _<a href="http://rauschma.de/">_Dr. Axel Rauschmayer_</a></li>
</ol>

<h4 id="toc_19">2. Tagged Template literal restriction removed</h4>

<p>First, we need to clarify what a “Tagged Template literal” is so we can understand this feature better.</p>

<p>In ES2015+, there is a feature called a tagged template literal that allows developers to customize how strings are interpolated. For example, in the standard way strings are interpolated like below…</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*4EizdrE9LlRZ5GXRq4G3Yw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*4EizdrE9LlRZ5GXRq4G3Yw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*4EizdrE9LlRZ5GXRq4G3Yw.png" alt=""/></p>

<p>In the tagged literal, you can write a function to receive the hardcoded parts of the string literal, for example <code>[ ‘Hello ‘, ‘!’ ]</code> , and the replacement variables, for example,<code>[ &#39;Raja&#39;]</code> , as parameters into a custom function (for example <code>greet</code> ), and return whatever you want from that custom function.</p>

<p>The below example shows that our custom “Tag” function <code>greet</code> appends time of the day like “Good Morning!” “Good afternoon,” and so on depending on the time of the day to the string literal and returns a custom string.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*PfeJ5R0h6SHx6SxSkPCLmg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*PfeJ5R0h6SHx6SxSkPCLmg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*PfeJ5R0h6SHx6SxSkPCLmg.png" alt=""/>Tag function example that shows custom string interpolation</p>

<pre>//A "Tag" function returns a custom string literal.
//In this example, greet calls timeGreet() to append Good //Morning/Afternoon/Evening depending on the time of the day.</pre>

<pre>function greet(hardCodedPartsArray, ...replacementPartsArray) {
 console.log(hardCodedPartsArray); //[ 'Hello ', '!' ]
 console.log(replacementPartsArray); //[ 'Raja' ]</pre>

<pre>let str = '';
 hardCodedPartsArray.forEach((string, i) => {
  if (i < replacementPartsArray.length) {
   str += `${string} ${replacementPartsArray[i] || ''}`;
  } else {
   str += `${string} ${timeGreet()}`; //<-- append Good morning/afternoon/evening here
  }
 });
 return str;
}</pre>

<pre>//🚀Usage:
const firstName = 'Raja';
const greetings = greet`Hello ${firstName}!`; //👈🏼<-- Tagged literal</pre>

<pre>console.log(greetings); //'Hello  Raja! Good Morning!' 🔥</pre>

<pre>function timeGreet() {
 const hr = new Date().getHours();
 return hr < 12
  ? 'Good Morning!'
  : hr < 18 ? 'Good Afternoon!' : 'Good Evening!';
}</pre>

<p>Now that we discussed what “Tagged” functions are, many people want to use this feature in different domains, like in Terminal for commands and HTTP requests for composing URIs, and so on.</p>

<h4 id="toc_20">⚠️The problem with Tagged String literal</h4>

<p>The problem is that ES2015 and ES2016 specs doesn’t allow using escape characters like “\u” (unicode), “\x”(hexadecimal) unless they look exactly like <code>\u00A9</code> or \u{2F804} or \xA9.</p>

<p>So if you have a Tagged function that internally uses some other domain’s rules (like Terminal’s rules), that may need to use <strong>\ubla123abla</strong> that doesn’t look like \u0049 or \u{@F804}, then you would get a syntax error.</p>

<p>In ES2018, the rules are relaxed to allow such seemingly invalid escape characters as long as the Tagged function returns the values in an object with a “cooked” property (where invalid characters are “undefined”), and then a “raw” property (with whatever you want).</p>

<pre><code>function myTagFunc(str) {  return { &quot;cooked&quot;: &quot;undefined&quot;, &quot;raw&quot;: str.raw[0] }} var str = myTagFunc `hi \
</code></pre>

<h3 id="toc_21">3. “dotall” flag for Regular expression</h3>

<p>Currently in RegEx, although the dot(“.”) is supposed to match a single character, it doesn’t match new line characters like <code>\n \r \f etc</code>.</p>

<p>For example:</p>

<pre>//Before
/first.second/.test('first\nsecond'); //false</pre>

<p>This enhancement makes it possible for the dot operator to match any single character. In order to ensure this doesn’t break anything, we need to use <code>\s</code> flag when we create the RegEx for this to work.</p>

<pre>//ECMAScript 2018
/first.second**/s**.test('first\nsecond'); **//true**   Notice: /s 👈🏼</pre>

<p>Here is the overall API from the <a href="https://github.com/tc39/proposal-regexp-dotall-flag">proposal</a> doc:</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*t5xegqe5su6XgRDcBObyDw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*t5xegqe5su6XgRDcBObyDw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*t5xegqe5su6XgRDcBObyDw.png" alt=""/>ECMAScript 2018 — Regex dotAll feature allows matching even \n via “.” via /s flag</p>

<h3 id="toc_22">4. RegExp Named Group Captures 🔥</h3>

<p>This enhancement brings a useful RegExp feature from other languages like Python, Java and so on called “Named Groups.” This features allows developers writing RegExp to provide names (identifiers) in the format<code>(?&lt;name&gt;...)</code> for different parts of the group in the RegExp. They can then use that name to grab whichever group they need with ease.</p>

<h4 id="toc_23">4.1 Basic Named group example</h4>

<p>In the below example, we are using <code>(?&lt;year&gt;) (?&lt;month&gt;) and (?&lt;day&gt;)</code> names to group different parts of the date RegEx. The resulting object will now contain a <code>groups</code> property with properties <code>year</code>, <code>month</code> , and <code>day</code> with corresponding values.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*1ORiZapMHp_SV5gvOVT2WA.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*1ORiZapMHp_SV5gvOVT2WA.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*1ORiZapMHp_SV5gvOVT2WA.png" alt=""/>ECMAScript 2018 — Regex named groups example</p>

<h4 id="toc_24"><strong>4.2 Using Named groups inside regex itself</strong></h4>

<p>We can use the <code>\k&lt;group name&gt;</code> format to back reference the group within the regex itself. The following example shows how it works.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*O6i-gXHBifD27qD73Sw7TA.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*O6i-gXHBifD27qD73Sw7TA.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*O6i-gXHBifD27qD73Sw7TA.png" alt=""/>ECMAScript 2018 — Regex named groups back referencing via \k<group name></p>

<h4 id="toc_25"><strong>4.3 Using named groups in String.prototype.replace</strong></h4>

<p>The named group feature is now baked into String’s <code>replace</code> instance method. So we can easily swap words in the string.</p>

<p>For example, change “firstName, lastName” to “lastName, firstName”.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*weBLy9CAXFnWNwUqcwNMAg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*weBLy9CAXFnWNwUqcwNMAg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*weBLy9CAXFnWNwUqcwNMAg.png" alt=""/>ECMAScript 2018 — Using RegEx’s named groups feature in replace function</p>

<h3 id="toc_26">5. Rest properties for Objects</h3>

<p>Rest operator <code>...</code> (three dots) allows us to extract Object properties that are not already extracted.</p>

<h4 id="toc_27"><strong>5.1 You can use rest to help extract only properties you want</strong></h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*Uh4-1F3aeoy5k3hq8nVlfQ.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*Uh4-1F3aeoy5k3hq8nVlfQ.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*Uh4-1F3aeoy5k3hq8nVlfQ.png" alt=""/>ECMAScript 2018 — Object destructuring via rest</p>

<h4 id="toc_28"><strong>5.2 Even better, you can remove unwanted items! 🔥🔥</strong></h4>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*43kFc4JJy8DSQiA_zQXZZA.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*43kFc4JJy8DSQiA_zQXZZA.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*43kFc4JJy8DSQiA_zQXZZA.png" alt=""/>ECMAScript 2018 — Object destructuring via rest</p>

<h3 id="toc_29">6. Spread properties for Objects</h3>

<p>Spread properties also look just like rest properties with three dots <code>...</code> but the difference is that you use spread to create (restructure) new objects.</p>

<blockquote>
<p>Tip: the spread operator is used in the right side of the equals sign. The rest are used in the left-side of the equals sign.</p>
</blockquote>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*QmSUhdHQiXaXL9vdE27Djg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*QmSUhdHQiXaXL9vdE27Djg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*QmSUhdHQiXaXL9vdE27Djg.png" alt=""/>ECMAScript 2018 — Object restructuring via spread</p>

<h3 id="toc_30">7. RegExp Lookbehind Assertions</h3>

<p>This is an enhancement to the RegEx that allows us to ensure some string exists immediately <em>_before</em>_ some other string.</p>

<p>You can now use a group <code>(?&lt;=…)</code> <u>(question mark, less than, equals)</u> to look behind for positive assertion.</p>

<p>Further, you can use <code>(?&lt;!…)</code> <u>(question mark, less than, exclamation)</u>, to look behind for a negative assertion. Essentially this will match as long as the -ve assertion passes.</p>

<p><strong>Positive Assertion:</strong> Let’s say we want to ensure that the <code>#</code> sign exists before the word <code>winning</code> (that is: <code>#winning</code>) and want the regex to return just the string “winning”. Here is how you’d write it.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*MJuEF0dePb_NE8DHFm0XNw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*MJuEF0dePb_NE8DHFm0XNw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*MJuEF0dePb_NE8DHFm0XNw.png" alt=""/>ECMAScript 2018 — <code>(?&lt;=…) for positive assertion</code></p>

<p><strong>Negative Assertion:</strong> Let’s say we want to extract numbers from lines that have € signs and not $ signs before those numbers.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*e1N-waOWBc3ykLRFCIzXSA.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*e1N-waOWBc3ykLRFCIzXSA.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*e1N-waOWBc3ykLRFCIzXSA.png" alt=""/>ECMAScript 2018 — (?&lt;!…) for negative assertions</p>

<h3 id="toc_31"><strong>8.</strong> <a href="https://github.com/tc39/proposal-regexp-unicode-property-escapes"><strong>RegExp Unicode Property Escapes</strong></a></h3>

<p>It was not easy to write RegEx to match various unicode characters. Things like <code>\w</code> , <code>\W</code> , <code>\d</code> etc only match English characters and numbers. But what about numbers in other languages like Hindi, Greek, and so on?</p>

<p>That’s where Unicode Property Escapes come in. <strong>It turns out Unicode adds metadata properties for each symbol (character) and uses it to group or characterize various symbols.</strong></p>

<p>For example, Unicode database groups all Hindi characters(हिन्दी) under a property called <code>Script</code> with value <code>Devanagari</code> and another property called <code>Script_Extensions</code> with the same value <code>Devanagari</code>. So we can search for <code>Script=Devanagari</code> and get all Hindi characters.</p>

<blockquote>
<p><a href="https://en.wikipedia.org/wiki/Devanagari_%28Unicode_block%29">Devanagari</a> can be used for various Indian languages like Marathi, Hindi, Sanskrit, and so on.</p>
</blockquote>

<p>Starting in ECMAScript 2018, we can use <code>\p</code> to escape characters along with <code>{Script=Devanagari}</code> to match all those Indian characters. <strong>That is, we can use:</strong> <code>**\p{Script=Devanagari}**</code> <strong>in the RegEx to match all Devanagari characters.</strong></p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*c-bRDN8WERPUYevc38jZMg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*c-bRDN8WERPUYevc38jZMg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*c-bRDN8WERPUYevc38jZMg.png" alt=""/>ECMAScript 2018 — showing \p</p>

<pre>//The following matches multiple hindi character
**/^\p{Script=Devanagari}+$/u.test('हिन्दी'); //true ** 
//PS:there are 3 hindi characters h</pre>

<p>Similarly, Unicode database groups all Greek characters under <code>Script_Extensions</code> (and <code>Script</code> ) property with the value <code>Greek</code> . So we can search for all Greek characters using <code>Script_Extensions=Greek</code> or <code>Script=Greek</code> .</p>

<p><strong>That is, we can use:</strong> <code>**\p{Script=Greek}**</code> <strong>in the RegEx to match all Greek characters.</strong></p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*DwP_VN4VUp7osFQC-I9OsQ.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*DwP_VN4VUp7osFQC-I9OsQ.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*DwP_VN4VUp7osFQC-I9OsQ.png" alt=""/>ECMAScript 2018 — showing \p</p>

<pre>//The following matches a single Greek character
**/\p{Script_Extensions=Greek}/u.test('π');** // true</pre>

<p>Further, the Unicode database stores various types of Emojis under the boolean properties <code>Emoji</code>, <code>Emoji_Component</code>, <code>Emoji_Presentation</code>, <code>Emoji_Modifier</code>, and <code>Emoji_Modifier_Base</code> with property values as <code>true</code>. So we can search for all Emojis by simply selecting <code>Emoji</code> to be true.</p>

<p><strong>That is, we can use:</strong> <code>**\p{Emoji}**</code><strong> ,</strong><code>**\Emoji_Modifier**</code> <strong>and so on to match various kinds of Emojis.</strong></p>

<p>The following example will make it all clear.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*DsQryeDlp8fAKBS8k_ohqw.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*DsQryeDlp8fAKBS8k_ohqw.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*DsQryeDlp8fAKBS8k_ohqw.png" alt=""/>ECMAScript 2018 — showing how \p can be used for various emojis</p>

<pre>//The following matches an Emoji character
/\p{Emoji}/u.test('❤️'); //true</pre>

<pre>//The following fails because yellow emojis don't need/have Emoji_Modifier!
/\p{Emoji}\p{Emoji_Modifier}/u.test('✌️'); //false</pre>

<pre>//The following matches an emoji character\p{Emoji} followed by \p{Emoji_Modifier}
/\p{Emoji}\p{Emoji_Modifier}/u.test('✌🏽'); //true</pre>

<pre>//Explaination:
//By default the victory emoji is yellow color.
//If we use a brown, black or other variations of the same emoji, they are considered
//as variations of the original Emoji and are represented using two unicode characters.
//One for the original emoji, followed by another unicode character for the color.
//
//So in the below example, although we only see a single brown victory emoji,
//it actually uses two unicode characters, one for the emoji and another
// for the brown color.
//
//In Unicode database, these colors have Emoji_Modifier property.
//So we need to use both \p{Emoji} and \p{Emoji_Modifier} to properly and
//completely match the brown emoji.
/\p{Emoji}\p{Emoji_Modifier}/u.test('✌🏽'); //true</pre>

<p><strong>Lastly, we can use capital &quot;P”(</strong><code>\P</code> <strong>) escape character instead of small p (</strong><code>\p</code> )<strong>, to negate the matches.</strong></p>

<p>References:</p>

<ol>
<li> <a href="https://mathiasbynens.be/notes/es-unicode-property-escapes">_ECMAScript 2018 Proposal_</a></li>
<li> <a href="https://mathiasbynens.be/notes/es-unicode-property-escapes">_https://mathiasbynens.be/notes/es-unicode-property-escapes_</a></li>
</ol>

<h3 id="toc_32">8. Promise.prototype.finally()</h3>

<p><code>finally()</code> is a new instance method that was added to Promise. The main idea is to allow running a callback after either <code>resolve</code> or <code>reject</code> to help clean things up. The <code>**finally**</code> <strong>callback is called without any value and is always executed no matter what.</strong></p>

<p>Let’s look at various cases.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*P1V6c1ncEjeCgtS6zzR0gg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*P1V6c1ncEjeCgtS6zzR0gg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*P1V6c1ncEjeCgtS6zzR0gg.png" alt=""/>ECMAScript 2018 — finally() in resolve case<img src="https://cdn-images-1.medium.com/freeze/max/30/1*tSbu3kZCkoGpXaWDuP6MPA.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*tSbu3kZCkoGpXaWDuP6MPA.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*tSbu3kZCkoGpXaWDuP6MPA.png" alt=""/>ECMAScript 2018 — finally() in reject case<img src="https://cdn-images-1.medium.com/freeze/max/30/1*kB6Ar5YJoAlwwhFqzMGBGg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*kB6Ar5YJoAlwwhFqzMGBGg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*kB6Ar5YJoAlwwhFqzMGBGg.png" alt=""/>ECMASCript 2018 — finally() in Error thrown from Promise case<img src="https://cdn-images-1.medium.com/freeze/max/30/1*wCcbabJsS8UbFclumSISqg.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*wCcbabJsS8UbFclumSISqg.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*wCcbabJsS8UbFclumSISqg.png" alt=""/>**ECMAScript 2018 — Error thrown from within <strong>catch</strong> case**</p>

<h3 id="toc_33">9. Asynchronous Iteration</h3>

<p>This is an <em>extremely</em> useful feature. Basically it allows us to create loops of async code with ease!</p>

<p>This feature adds a new <strong>“for-await-of”</strong> loop that allows us to call async functions that return promises (or Arrays with a bunch of promises) in a loop. The cool thing is that the loop waits for each Promise to resolve before doing to the next loop.</p>

<p><img src="https://cdn-images-1.medium.com/freeze/max/30/1*liLeNfWxZ3x1sqrVmRUdRQ.png?q=20" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*liLeNfWxZ3x1sqrVmRUdRQ.png" alt=""/><img src="https://cdn-images-1.medium.com/max/800/1*liLeNfWxZ3x1sqrVmRUdRQ.png" alt=""/>ECMAScript 2018 — Async Iterator via for-await-of</p>

<p>That’s pretty much it!</p>

<h4 id="toc_34">If this was useful, please click the clap 👏 button down below a few times to show your support! ⬇⬇⬇ 🙏🏼</h4>

<h3 id="toc_35">My Other Posts</h3>

<p><a href="https://medium.com/@rajaraodv/latest">_https://medium.com/@rajaraodv/latest_</a></p>

<h4 id="toc_36">Related ECMAScript 2015+ posts</h4>

<ol>
<li> <a href="https://medium.freecodecamp.org/check-out-these-useful-ecmascript-2015-es6-tips-and-tricks-6db105590377">_Check out these useful ECMAScript 2015 (ES6) tips and tricks_</a></li>
<li> <a href="https://medium.com/@rajaraodv/5-javascript-bad-parts-that-are-fixed-in-es6-c7c45d44fd81#.7e2s6cghy">_5 JavaScript “Bad” Parts That Are Fixed In ES6_</a></li>
<li><p><a href="https://medium.com/@rajaraodv/is-class-in-es6-the-new-bad-part-6c4e6fe1ee65#.4hqgpj2uv">_Is “Class” In ES6 The New “Bad” Part?_</a></p></li>
</ol>

<ul>
<li>  <a href="https://medium.freecodecamp.org/tagged/javascript?source=post">JavaScript</a></li>
<li>  <a href="https://medium.freecodecamp.org/tagged/tech?source=post">Tech</a></li>
<li>  <a href="https://medium.freecodecamp.org/tagged/programming?source=post">Programming</a></li>
<li>  <a href="https://medium.freecodecamp.org/tagged/startup?source=post">Startup</a></li>
<li>  <a href="https://medium.freecodecamp.org/tagged/web-development?source=post">Web Development</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 https://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=2653548297&idx=1&sn=71fc309da16f1ed2b3d8b0d847f730a0&chksm=813a7e91b64df78734a2d155e79bedab66ebd078aed5d6ab3f01eb1b1b2a1d957f7c3ca204d5&scene=21#wechat_redirect]]></title>
    <link href="http://panlw.github.io/15352960653784.html"/>
    <updated>2018-08-26T23:07:45+08:00</updated>
    <id>http://panlw.github.io/15352960653784.html</id>
    <content type="html"><![CDATA[
<p>导读：我们经常使用打车软件出行，也经常思考其架构设计。本文作者在所在国家也负责开发一款打车软件，并且开源了其中大部分代码，可以帮助我们更好了解网络约车软件的架构体系。本文由高可用架构翻译。</p>

<p><img src="http://mmbiz.qpic.cn/mmbiz_png/8XkvNnTiapOMnaWlypBttlyEyfP2FFJwMFfEjD6rrQsA0WwRZRO3qIAxXqlMnWvILWiadCNXYPEa33aJO5PsaLDQ/0?wx_fmt=png" alt=""/></p>

<p>各位读者好，本文将给大家分享我们如何通过内存存储实现地图动画车效果。 我们公司也运营了一个类似 Uber 的软件 Namba Taxi，我们需要在客户端主屏幕上显示动画车。 这篇文章是关于功能如何完整实现的文章，主要目的不是介绍 Go 语言。</p>

<h2 id="toc_0"><strong>开始</strong></h2>

<p>这个故事始于 2015 年，我们的移动开发人员开发一款软件，工作主题是为出租车司机提供打车服务。 在应用程序中，动画汽车看起来像下面的图中动画那样 [1] 。</p>

<p><img src="http://mmbiz.qpic.cn/mmbiz_png/8XkvNnTiapOMnaWlypBttlyEyfP2FFJwMxosd5hJ54PXZDDXnOFqibTIYtdsQGWtr4VTgYObn1zb2ULagtDvmMCg/0?wx_fmt=png" alt=""/></p>

<p>我们的第一个挑战是缺乏地图跟踪数据。我们每 15 秒获取一次位置数据。 我们不能简单减小上报间隔，因为当司机端程序上行数据时候，同时需要获取当前订单，下一个订单，以及一些警报功能（一个 SOS 按钮， 当司机按下它，其他司机就可以帮助他）。当我们减少更新间隔时，系统流量更大。 我们不确认我们是否能够扛住如此大的刷新。</p>

<h2 id="toc_1"><strong>实现的第一步</strong></h2>

<p>我们第一次的尝试比较简单：</p>

<ol>
<li><p>处理请求并保存坐标。</p></li>
<li><p>创建另一个请求并为汽车设置动画。</p></li>
</ol>

<p>显而易见，这样做存在一些问题，如大家在一些打车软件所见，我们不能正确地绘制汽车路线，汽车可能跑在田野，森林，湖泊和公寓上，用这种方法后效果看起来是这样的 [2]。</p>

<p><img src="http://mmbiz.qpic.cn/mmbiz_png/8XkvNnTiapOMnaWlypBttlyEyfP2FFJwMdWKnMmHpaANJJicc67qKbmkgTPExVVtAl0y9MOeW1bjbRBavJOakx4w/0?wx_fmt=gif" alt=""/></p>

<p>作为问题的解决方案，我们使用 OpenStreetMap Routeing Machine（OSRM）来规划线路并改进我们的算法，并使用相同的超时设置。</p>

<ol>
<li><p>发起请求。</p></li>
<li><p>获取坐标。</p></li>
<li><p>将保存的坐标发送到服务器。</p></li>
<li><p>通过 OSRM 构建路线。</p></li>
<li><p>返回数据到客户端。</p></li>
</ol>

<p>通过线路规划体系，现在似乎可以工作了，但我们又面临单向道路的问题</p>

<p><img src="http://mmbiz.qpic.cn/mmbiz_png/8XkvNnTiapOMnaWlypBttlyEyfP2FFJwMoo1cEvvjvZgAuZ35V80cBJRJxyqHyfIGvQmDxJzDfMgUS2xuzzbNZg/0?wx_fmt=png" alt=""/></p>

<p>例如，司机停留在红点的十字路口。 但他的设备位置准确性有问题，导致数据标记在十字路口的对面。 在客户端，我们获取这些坐标，保存并发送到后端，OSRM 建立一个合法的路线，并返回给应用程序。因为客户端移动得非常快，所以这种情况路线规划很可笑。<br/>
我们以一种朴素的方式解决了这个问题。 <strong>我们检查两点之间的最短距离，并且不建立距离小于 20 米的路线。</strong> 使用该算法经过几天的测试后，我们决定发布我们的应用程序并希望获取一些反馈。<br/>
尽管如此，我们的版本还存在一些问题，所以我们决定进行第二次迭代。</p>

<ol>
<li><p>第一是车费计算器，<strong>计算是在司机端（客户端）完成，这样避免发送无用的请求</strong>，可以节约很多服务端资源。 另一方面，为了安全等方面考虑，我们需要在服务器端复制数据并保存它。</p></li>
<li><p>此外，我们意识到每 15 秒一次上报太少，因为用户在屏幕打开后，15 秒后才会看到车在移动。</p></li>
<li><p>此外，我们在司机端的 GPS 模块有很多问题，这个可能跟司机的手机设备相关。</p></li>
<li><p>最后，我们想要在主屏幕上渲染动画车。</p></li>
</ol>

<h2 id="toc_2"><strong>还需要解决的问题</strong></h2>

<ol>
<li><p>从司机收集更多的数据</p></li>
<li><p>在主屏幕上显示动画车</p></li>
<li><p>在服务器端存储行车过程中计费数据</p></li>
<li><p>节约移动流量</p></li>
<li><p>每秒收集一次数据</p></li>
</ol>

<p>我想谈一谈有关节约移动流量带宽的问题。在我们国家，出租车收费非常便宜，我们像使用公共交通那样使用出租车。 例如，从城市的一边跑到另一边可能只需要 2 欧元，这就跟在巴黎坐地铁价格差不多。但另外一方面移动带宽成本还也很高，如果我们每秒节约 100 字节，那么我们将给为公司节省差不多 2000 美元。</p>

<h2 id="toc_3"><strong>数据追踪</strong></h2>

<ol>
<li><p>司机位置（纬度，经度）</p></li>
<li><p>司机当前的 session 信息，在登录时我们会给司机端提供 session id</p></li>
<li><p>订单信息（订单 ID 和车费）</p></li>
</ol>

<p>我们决定每一次数据上报应小于 100 字节。 我们寻找传输协议来解决这个问题</p>

<p>正如你可以看到，我们审视了以下几个协议：</p>

<ol>
<li><p>HTTP</p></li>
<li><p>WebSockets</p></li>
<li><p>TCP</p></li>
<li><p>UDP</p></li>
</ol>

<p><strong>对我们来说理想的选择是 UDP</strong>，因为：</p>

<ol>
<li><p>我们只发送数据报</p></li>
<li><p>我们不需要保证送达</p></li>
<li><p>极简主义</p></li>
<li><p>保存大量数据</p></li>
<li><p>只有 20 字节开销</p></li>
<li><p>在我们的国家的移动网络没有被阻止</p></li>
</ol>

<p>至于数据序列化，我们考察了：</p>

<ol>
<li><p>JSON</p></li>
<li><p>MsgPack</p></li>
<li><p>Protobuf</p></li>
</ol>

<p><strong>我们选择 ProtoBuf</strong>，因为它对小数据非常有效。</p>

<p><img src="http://mmbiz.qpic.cn/mmbiz_png/8XkvNnTiapOMnaWlypBttlyEyfP2FFJwMLibAuRGlVYtrciaab5sWnAvKNlqe2ia2EiawGkbC9UovDeibPfdU186oGrQ/0?wx_fmt=png" alt=""/></p>

<p>以看到最近的竞争对手是 PB 的三倍。（小编：可以参考 TimYang 的一条微博 [3] ）</p>

<h2 id="toc_4"><strong>每次上报总共的数据</strong></h2>

<ol>
<li><p>42 字节的业务数据</p></li>
<li><p>加上 20 字节的 IP 报头</p></li>
<li><p>得到每次上报 62 字节数据</p></li>
</ol>

<p>当我们获得数据时，我们考虑如何存储。</p>

<h2 id="toc_5"><strong>数据存储</strong></h2>

<p>我们需要存储这些数据：</p>

<ol>
<li><p>标识司机的会话信息 session id</p></li>
<li><p>车牌号</p></li>
<li><p>订单 ID 和计费信息</p></li>
<li><p>执行搜索的最后位置</p></li>
<li><p>N 次最后位置以规划路线</p></li>
</ol>

<h2 id="toc_6"><strong>使用的存储</strong></h2>

<ol>
<li><p>使用 Percona 存储所有数据。 我们存储司机，订单，计费等。</p></li>
<li><p>Redis 作为用于缓存。</p></li>
<li><p>Elasticsearch 用于地理编码</p></li>
</ol>

<p>如上所述，当有大量在线司机时候，使用这些存储来保存数据并不方便。 所以我们需要地理索引。</p>

<p>我们评估了两个地理索引：</p>

<ol>
<li><p>KD 树</p></li>
<li><p>R 树。</p></li>
</ol>

<p>我们对地理索引的要求：</p>

<ol>
<li><p>搜索 N 个最近的点。</p></li>
<li><p>我们需要一个平衡树，以在最糟糕的情况下提供最好的搜索</p></li>
</ol>

<h2 id="toc_7">KD 树<img src="http://mmbiz.qpic.cn/mmbiz_png/8XkvNnTiapOMnaWlypBttlyEyfP2FFJwMNpwaMWy5okg9EBiaHFXPRZuX6SwT3ceQKficI55o5bCebUcPNDgicySKw/0?wx_fmt=png" alt=""/></h2>

<p>KD 树并不适合我们的需要，因为它是不平衡的，只能搜索一个最近的点。 我们可以在 kd-tree 上实现 k-nearest 邻居，但是没必要重造轮子，因为 R-tree 已经解决了这个问题。</p>

<h2 id="toc_8">R - 树</h2>

<p><img src="http://mmbiz.qpic.cn/mmbiz_png/8XkvNnTiapOMnaWlypBttlyEyfP2FFJwMsYQQnUbcAwXMXR5drAE1gxHPEDeKnYfct9TgYtzyQjEnQxxicicPGicnw/0?wx_fmt=png" alt=""/></p>

<p>它看起来像这样。 我们可以执行搜索 N 个最近点，并且它是平衡树。 我们选择了这个。</p>

<p>您可以得到它的 Go 语言实现源码 [5]。</p>

<p>另外，我们需要一个过期机制，因为我们需要使司机的超时机制，比如司机端 900 秒没有响应则在服务器删除会话。 所以我们需要 LRU 数据结构来存储最后的位置。 同时因为我们只存储 N 个位置。 如果我们尝试添加数据时候，队列存储已满，我们则删除最少使用的那个条目。 </p>

<p>下面是我们的存储架构。</p>

<ol>
<li><p>我们将所有数据存储在内存中。</p></li>
<li><p><strong>我们使用 R-tree 执行搜索最近的司机</strong>。</p></li>
<li><p>此外，我们使用两个检索图，可以并按车牌号或 session 执行搜索</p></li>
</ol>

<h2 id="toc_9"><strong>我们打车软件最终算法</strong></h2>

<p>这里是后端的最终算法：</p>

<ol>
<li><p>使用 UDP 传输数据</p></li>
<li><p>尝试从存储获取司机</p></li>
<li><p>如果存储不存在 - 则从 Redis 获取司机</p></li>
<li><p>检查并验证数据</p></li>
<li><p>将司机保存到存储</p></li>
<li><p>如果不存在 - 初始化 LRU</p></li>
<li><p>更新 r-tree</p></li>
</ol>

<h2 id="toc_10"><strong>HTTP 接口</strong></h2>

<p>我们实现了这些接口：</p>

<ol>
<li><p>返回最近的司机；</p></li>
<li><p>从存储中删除司机（通过车牌号或 session id）</p></li>
<li><p>获取行程信息</p></li>
<li><p>获取司机信息</p></li>
</ol>

<h2 id="toc_11"><strong>结论</strong></h2>

<p>最后，我想给出我们在后端系统中总结的经验：</p>

<ol>
<li><p>UDP + Protobuf 以节省数据</p></li>
<li><p>内存存储</p></li>
<li><p>R 树获取最近的司机</p></li>
<li><p>LRU 缓存用于存储最后的 n 个位置</p></li>
<li><p>OSRM 用于地图匹配和定制路线</p>

<p><img src="http://mmbiz.qpic.cn/mmbiz_png/8XkvNnTiapOMnaWlypBttlyEyfP2FFJwM4mXrsdcMWvsrRnGLjT82TuFmG7CMibUeb7ONlhHxRscdWpTD34nImNg/0?wx_fmt=png" alt=""/></p></li>
</ol>

<p>您可以在 github [5] 上查看上面整个过程的源代码。现在功能还比较简单，但实现了文章中描述的许多功能。</p>

<p><strong>参考资源</strong></p>

<ol>
<li><p>GIF 动画下载：<a href="https://cdn-images-1.medium.com/max/1600/1*nI6cNApASR1mg6F5Sjgp7Q.gif">https://cdn-images-1.medium.com/max/1600/1*nI6cNApASR1mg6F5Sjgp7Q.gif</a></p></li>
<li><p><a href="https://cdn-images-1.medium.com/max/1600/1*KfGB1SARPoqOUtPtl4NNBg.gif">https://cdn-images-1.medium.com/max/1600/1*KfGB1SARPoqOUtPtl4NNBg.gif</a></p></li>
<li><p><a href="http://weibo.com/10503/24F1QpDmL">http://weibo.com/10503/24F1QpDmL</a></p></li>
<li><p><a href="https://github.com/dhconnelly/rtreego">https://github.com/dhconnelly/rtreego</a></p></li>
<li><p><a href="https://github.com/maddevsio/openfreecabs">https://github.com/maddevsio/openfreecabs</a></p></li>
<li><p>本文英文原文：<a href="https://blog.maddevs.io/how-we-built-a-backend-system-for-uber-like-map-with-animated-cars-on-it-using-go-29d5dcd517a#.npo2x5788">https://blog.maddevs.io/how-we-built-a-backend-system-for-uber-like-map-with-animated-cars-on-it-using-go-29d5dcd517a#.npo2x5788</a></p></li>
</ol>

<p><strong>推荐阅读</strong></p>

<ul>
<li><p><a href="http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&amp;mid=209153643&amp;idx=1&amp;sn=e0a64a8e7fcb8b43ceac85cc5782719f&amp;scene=21#wechat_redirect">Uber 容错设计与多机房容灾方案</a></p></li>
<li><p><a href="http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&amp;mid=2653547609&amp;idx=1&amp;sn=cbb55ee823ddec9d98ef1fa984e001f6&amp;scene=21#wechat_redirect">为什么 Uber 宣布从 Postgres 切换到 MySQL?</a></p></li>
<li><p><a href="http://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&amp;mid=2653547482&amp;idx=1&amp;sn=13675fae5e037d720a9e9fb4a4861afd&amp;scene=21#wechat_redirect">滴滴 passport 设计之道: 帐号体系高可用的 7 条经验 (含 PPT)</a></p></li>
</ul>

<p>本文由高可用架构翻译，转载请注明出处，技术原创及架构实践文章，欢迎通过公众号菜单「联系我们」进行投稿。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ES modules: A cartoon deep-dive]]></title>
    <link href="http://panlw.github.io/15352957865945.html"/>
    <updated>2018-08-26T23:03:06+08:00</updated>
    <id>http://panlw.github.io/15352957865945.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://hacks.mozilla.org/2018/03/es-modules-a-cartoon-deep-dive/">https://hacks.mozilla.org/2018/03/es-modules-a-cartoon-deep-dive/</a></p>
</blockquote>

<p>ES modules bring an official, standardized module system to JavaScript. It took a while to get here, though — nearly 10 years of standardization work.</p>

<p>But the wait is almost over. With the release of Firefox 60 in May (<a href="https://www.mozilla.org/en-US/firefox/developer/">currently in beta</a>), all major browsers will support ES modules, and the Node modules working group is currently working on adding ES module support to <a href="https://nodejs.org/en/">Node.js</a>. And <a href="https://www.youtube.com/watch?v=qR_b5gajwug">ES module integration for WebAssembly</a> is underway as well.</p>

<p>Many JavaScript developers know that ES modules have been controversial. But few actually understand how ES modules work.</p>

<p>Let’s take a look at what problem ES modules solve and how they are different from modules in other module systems.</p>

<h3 id="toc_0">What problem do modules solve?</h3>

<p>When you think about it, coding in JavaScript is all about managing variables. It’s all about assigning values to variables, or adding numbers to variables, or combining two variables together and putting them into another variable.</p>

<p><strong><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/01_variables.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/01_variables-500x178.png" alt=""/></a></strong></p>

<p>Because so much of your code is just about changing variables, how you organize these variables is going to have a big impact on how well you can code… and how well you can maintain that code.</p>

<p>Having just a few variables to think about at one time makes things easier. JavaScript has a way of helping you do this, called scope. Because of how scopes work in JavaScript, functions can’t access variables that are defined in other functions.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/02_module_scope_01.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/02_module_scope_01-500x292.png" alt=""/></a></p>

<p>This is good. It means that when you’re working on one function, you can just think about that one function. You don’t have to worry about what other functions might be doing to your variables.</p>

<p>It also has a downside, though. It does make it hard to share variables between different functions.</p>

<p>What if you do want to share your variable outside of a scope? A common way to handle this is to put it on a scope above you… for example, on the global scope.</p>

<p>You probably remember this from the jQuery days. Before you could load any jQuery plug-ins, you had to make sure that jQuery was in the global scope.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/02_module_scope_02.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/02_module_scope_02-500x450.png" alt=""/></a></p>

<p>This works, but they are some annoying problems that result.</p>

<p>First, all of your script tags need to be in the right order. Then you have to be careful to make sure that no one messes up that order.</p>

<p>If you do mess up that order, then in the middle of running, your app will throw an error. When the function goes looking for jQuery where it expects it — on the global — and doesn’t find it, it will throw an error and stop executing.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/02_module_scope_03.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/02_module_scope_03-500x450.png" alt=""/></a></p>

<p>This makes maintaining code tricky. It makes removing old code or script tags a game of roulette. You don’t know what might break. The dependencies between these different parts of your code are implicit. Any function can grab anything on the global, so you don’t know which functions depend on which scripts.</p>

<p>A second problem is that because these variables are on the global scope, every part of the code that’s inside of that global scope can change the variable. Malicious code can change that variable on purpose to make your code do something you didn’t mean for it to, or non-malicious code could just accidentally clobber your variable.</p>

<h3 id="toc_1">How do modules help?</h3>

<p>Modules give you a better way to organize these variables and functions. With modules, you group the variables and functions that make sense to go together.</p>

<p>This puts these functions and variables into a module scope. The module scope can be used to share variables between the functions in the module.</p>

<p>But unlike function scopes, module scopes have a way of making their variables available to other modules as well. They can say explicitly which of the variables, classes, or functions in the module should be available.</p>

<p>When something is made available to other modules, it’s called an export. Once you have an export, other modules can explicitly say that they depend on that variable, class or function.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/02_module_scope_04.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/02_module_scope_04-500x450.png" alt=""/></a></p>

<p>Because this is an explicit relationship, you can tell which modules will break if you remove another one.</p>

<p>Once you have the ability to export and import variables between modules, it makes it a lot easier to break up your code into small chunks that can work independently of each other. Then you can combine and recombine these chunks, kind of like Lego blocks, to create all different kinds of applications from the same set of modules.</p>

<p>Since modules are so useful, there have been multiple attempts to add module functionality to JavaScript. Today there are two module systems that are actively being used. CommonJS (CJS) is what Node.js has used historically. ESM (EcmaScript modules) is a newer system which has been added to the JavaScript specification. Browsers already support ES modules, and Node is adding support.</p>

<p>Let’s take an in-depth look at how this new module system works.</p>

<h3 id="toc_2">How ES modules work</h3>

<p>When you’re developing with modules, you build up a graph of dependencies. The connections between different dependencies come from any import statements that you use.</p>

<p>These import statements are how the browser or Node knows exactly what code it needs to load. You give it a file to use as an entry point to the graph. From there it just follows any of the import statements to find the rest of the code.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/04_import_graph.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/04_import_graph-500x291.png" alt=""/></a></p>

<p>But files themselves aren’t something that the browser can use. It needs to parse all of these files to turn them into data structures called Module Records. That way, it actually knows what’s going on in the file.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/05_module_record.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/05_module_record-500x287.png" alt=""/></a></p>

<p>After that, the module record needs to be turned into a module instance. An instance combines two things: the code and state.</p>

<p>The code is basically a set of instructions. It’s like a recipe for how to make something. But by itself, you can’t use the code to do anything. You need raw materials to use with those instructions.</p>

<p>What is state? State gives you those raw materials. State is the actual values of the variables at any point in time. Of course, these variables are just nicknames for the boxes in memory that hold the values.</p>

<p>So the module instance combines the code (the list of instructions) with the state (all the variables’ values).</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/06_module_instance.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/06_module_instance-500x372.png" alt=""/></a></p>

<p>What we need is a module instance for each module. The process of module loading is going from this entry point file to having a full graph of module instances.</p>

<p>For ES modules, this happens in three steps.</p>

<ol>
<li> Construction — find, download, and parse all of the files into module records.</li>
<li> Instantiation —find boxes in memory to place all of the exported values in (but don’t fill them in with values yet). Then make both exports and imports point to those boxes in memory. This is called linking.</li>
<li> Evaluation —run the code to fill in the boxes with the variables’ actual values.</li>
</ol>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/07_3_phases.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/07_3_phases-500x184.png" alt=""/></a></p>

<p>People talk about ES modules being asynchronous. You can think about it as asynchronous because the work is split into these three different phases — loading, instantiating, and evaluating — and those phases can be done separately.</p>

<p>This means the spec does introduce a kind of asynchrony that wasn’t there in CommonJS. I’ll explain more later, but in CJS a module and the dependencies below it are loaded, instantiated, and evaluated all at once, without any breaks in between.</p>

<p>However, the steps themselves are not necessarily asynchronous. They can be done in a synchronous way. It depends on what’s doing the loading. That’s because not everything is controlled by the ES module spec. There are actually two halves of the work, which are covered by different specs.</p>

<p>The <a href="https://tc39.github.io/ecma262/#sec-modules">ES module spec</a> says how you should parse files into module records, and how you should instantiate and evaluate that module. However, it doesn’t say how to get the files in the first place.</p>

<p>It’s the loader that fetches the files. And the loader is specified in a different specification. For browsers, that spec is the <a href="https://html.spec.whatwg.org/#fetch-a-module-script-tree">HTML spec</a>. But you can have different loaders based on what platform you are using.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/07_loader_vs_es.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/07_loader_vs_es-500x286.png" alt=""/></a></p>

<p>The loader also controls exactly how the modules are loaded. It calls the ES module methods — <code>ParseModule</code>, <code>Module.Instantiate</code>, and <code>Module.Evaluate</code>. It’s kind of like a puppeteer controlling the JS engine’s strings.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/08_loader_as_puppeteer.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/08_loader_as_puppeteer-500x330.png" alt=""/></a></p>

<p>Now let’s walk through each step in more detail.</p>

<h4 id="toc_3">Construction</h4>

<p>Three things happen for each module during the Construction phase.</p>

<ol>
<li> Figure out where to download the file containing the module from (aka module resolution)</li>
<li> Fetch the file (by downloading it from a URL or loading it from the file system)</li>
<li> Parse the file into a module record</li>
</ol>

<h4 id="toc_4">Finding the file and fetching it</h4>

<p>The loader will take care of finding the file and downloading it. First it needs to find the entry point file. In HTML, you tell the loader where to find it by using a script tag.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/08_script_entry.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/08_script_entry-500x188.png" alt=""/></a></p>

<p>But how does it find the next bunch of modules — the modules that <code>main.js</code> directly depends on?</p>

<p>This is where import statements come in. One part of the import statement is called the module specifier. It tells the loader where it can find each next module.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/09_module_specifier.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/09_module_specifier-500x105.png" alt=""/></a></p>

<p>One thing to note about module specifiers: they sometimes need to be handled differently between browsers and Node. Each host has its own way of interpreting the module specifier strings. To do this, it uses something called a module resolution algorithm, which differs between platforms. Currently, some module specifiers that work in Node won’t work in the browser, but there is <a href="https://github.com/domenic/package-name-maps">ongoing work to fix this</a>.</p>

<p>Until that’s fixed, browsers only accept URLs as module specifiers. They will load the module file from that URL. But that doesn’t happen for the whole graph at the same time. You don’t know what dependencies the module needs you to fetch until you’ve parsed the file… and you can’t parse the file until you fetched it.</p>

<p>This means that we have to go through the tree layer-by-layer, parsing one file, then figuring out its dependencies, and then finding and loading those dependencies.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/10_construction.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/10_construction-500x302.png" alt=""/></a></p>

<p>If the main thread were to wait for each of these files to download, a lot of other tasks would pile up in its queue.</p>

<p>That’s because when you’re working in a browser, the downloading part takes a long time.</p>

<p><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/11_latency-500x270.png" alt=""/>Based on <a href="https://twitter.com/srigi/status/917998817051541504">this chart</a>.</p>

<p>Blocking the main thread like this would make an app that uses modules too slow to use. This is one of the reasons that the ES module spec splits the algorithm into multiple phases. Splitting out construction into its own phase allows browsers to fetch files and build up their understanding of the module graph before getting down to the synchronous work of instantiating.</p>

<p>This approach—having the algorithm split up into phases—is one of the key differences between ES modules and CommonJS modules.</p>

<p>CommonJS can do things differently because loading files from the filesystem takes much less time than downloading across the Internet. This means Node can block the main thread while it loads the file. And since the file is already loaded, it makes sense to just instantiate and evaluate (which aren’t separate phases in CommonJS). This also means that you’re walking down the whole tree, loading, instantiating, and evaluating any dependencies before you return the module instance.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/12_cjs_require.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/12_cjs_require-500x298.png" alt=""/></a></p>

<p>The CommonJS approach has a few implications, and I will explain more about those later. But one thing that it means is that in Node with CommonJS modules, you can use variables in your module specifier. You are executing all of the code in this module (up to the <code>require</code> statement) before you look for the next module. That means the variable will have a value when you go to do module resolution.</p>

<p>But with ES modules, you’re building up this whole module graph beforehand… before you do any evaluation. This means you can’t have variables in your module specifiers, because those variables don’t have values yet.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/13_static_import.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/13_static_import-500x146.png" alt=""/></a></p>

<p>But sometimes it is really useful to use variables for module paths. For example, you might want to switch which module you load depending on what the code is doing or what environment it is running in.</p>

<p>To make this possible for ES modules, there’s a proposal called <a href="https://github.com/tc39/proposal-dynamic-import">dynamic import</a>. With it, you can use an import statement like <code>import(</code>${path}/foo.js<code>)</code>.</p>

<p>The way this works is that any file loaded using <code>import()</code> is handled as the entry point to a separate graph. The dynamically imported module starts a new graph, which is processed separately.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/14dynamic_import_graph.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/14dynamic_import_graph-500x389.png" alt=""/></a></p>

<p>One thing to note, though — any module that is in both of these graphs is going to share a module instance. This is because the loader caches module instances. For each module in a particular global scope, there will only be one module instance.</p>

<p>This means less work for the engine. For example, it means that the module file will only be fetched once even if multiple modules depend on it. (That’s one reason to cache modules. We’ll see another in the evaluation section.)</p>

<p>The loader manages this cache using something called a <a href="https://html.spec.whatwg.org/multipage/webappapis.html#module-map">module map</a>. Each global keeps track of its modules in a separate module map.</p>

<p>When the loader goes to fetch a URL, it puts that URL in the module map and makes a note that it’s currently fetching the file. Then it will send out the request and move on to start fetching the next file.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/15_module_map.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/15_module_map-500x170.png" alt=""/></a></p>

<p>What happens if another module depends on the same file? The loader will look up each URL in the module map. If it sees <code>fetching</code> in there, it will just move on to the next URL.</p>

<p>But the module map doesn’t just keep track of what files are being fetched. The module map also serves as a cache for the modules, as we’ll see next.</p>

<h4 id="toc_5">Parsing</h4>

<p>Now that we have fetched this file, we need to parse it into a module record. This helps the browser understand what the different parts of the module are.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/25_file_to_module_record.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/25_file_to_module_record-500x199.png" alt=""/></a></p>

<p>Once the module record is created, it is placed in the module map. This means that whenever it’s requested from here on out, the loader can pull it from that map.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/25_module_map.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/25_module_map-500x239.png" alt=""/></a></p>

<p>There is one detail in parsing that may seem trivial, but that actually has pretty big implications. All modules are parsed as if they had <code>&quot;use strict&quot;</code> at the top. There are also other slight differences. For example, the keyword <code>await</code> is reserved in a module’s top-level code, and the value of <code>this</code> is <code>undefined</code>.</p>

<p>This different way of parsing is called a “parse goal”. If you parse the same file but use different goals, you’ll end up with different results. So you want to know before you start parsing what kind of file you’re parsing — whether it’s a module or not.</p>

<p>In browsers this is pretty easy. You just put <code>type=&quot;module&quot;</code> on the script tag. This tells the browser that this file should be parsed as a module. And since only modules can be imported, the browser knows that any imports are modules, too.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/26_parse_goal.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/26_parse_goal-500x311.png" alt=""/></a></p>

<p>But in Node, you don’t use HTML tags, so you don’t have the option of using a <code>type</code> attribute. One way the community has tried to solve this is by using an <code>.mjs</code> extension. Using that extension tells Node, “this file is a module”. You’ll see people talking about this as the signal for the parse goal. The discussion is currently ongoing, so it’s unclear what signal the Node community will decide to use in the end.</p>

<p>Either way, the loader will determine whether to parse the file as a module or not. If it is a module and there are imports, it will then start the process over again until all of the files are fetched and parsed.</p>

<p>And we’re done! At the end of the loading process, you’ve gone from having just an entry point file to having a bunch of module records.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/27_construction.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/27_construction-500x406.png" alt=""/></a></p>

<p>The next step is to instantiate this module and link all of the instances together.</p>

<h4 id="toc_6">Instantiation</h4>

<p>Like I mentioned before, an instance combines code with state. That state lives in memory, so the instantiation step is all about wiring things up to memory.</p>

<p>First, the JS engine creates a module environment record. This manages the variables for the module record. Then it finds boxes in memory for all of the exports. The module environment record will keep track of which box in memory is associated with each export.</p>

<p>These boxes in memory won’t get their values yet. It’s only after evaluation that their actual values will be filled in. There is one caveat to this rule: any exported function declarations are initialized during this phase. This makes things easier for evaluation.</p>

<p>To instantiate the module graph, the engine will do what’s called a depth first post-order traversal. This means it will go down to the bottom of the graph — to the dependencies at the bottom that don’t depend on anything else — and set up their exports.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/30_live_bindings_01.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/30_live_bindings_01-500x206.png" alt=""/></a></p>

<p>The engine finishes wiring up all of the exports below a module — all of the exports that the module depends on. Then it comes back up a level to wire up the imports from that module.</p>

<p>Note that both the export and the import point to the same location in memory. Wiring up the exports first guarantees that all of the imports can be connected to matching exports.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/30_live_bindings_02.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/30_live_bindings_02-500x206.png" alt=""/></a></p>

<p>This is different from CommonJS modules. In CommonJS, the entire export object is copied on export. This means that any values (like numbers) that are exported are copies.</p>

<p>This means that if the exporting module changes that value later, the importing module doesn’t see that change.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/31_cjs_variable.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/31_cjs_variable-500x113.png" alt=""/></a></p>

<p>In contrast, ES modules use something called live bindings. Both modules point to the same location in memory. This means that when the exporting module changes a value, that change will show up in the importing module.</p>

<p>Modules that export values can change those values at any time, but importing modules cannot change the values of their imports. That being said, if a module imports an object, it can change property values that are on that object.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/30_live_bindings_04.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/30_live_bindings_04-500x206.png" alt=""/></a></p>

<p>The reason to have live bindings like this is then you can wire up all of the modules without running any code. This helps with evaluation when you have cyclic dependencies, as I’ll explain below.</p>

<p>So at the end of this step, we have all of the instances and the memory locations for the exported/imported variables wired up.</p>

<p>Now we can start evaluating the code and filling in those memory locations with their values.</p>

<h4 id="toc_7">Evaluation</h4>

<p>The final step is filling in these boxes in memory. The JS engine does this by executing the top-level code — the code that is outside of functions.</p>

<p>Besides just filling in these boxes in memory, evaluating the code can also trigger side effects. For example, a module might make a call to a server.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/40_top_level_code.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/40_top_level_code-500x146.png" alt=""/></a></p>

<p>Because of the potential for side effects, you only want to evaluate the module once. As opposed to the linking that happens in instantiation, which can be done multiple times with exactly the same result, evaluation can have different results depending on how many times you do it.</p>

<p>This is one reason to have the module map. The module map caches the module by canonical URL so that there is only one module record for each module. That ensures each module is only executed once. Just as with instantiation, this is done as a depth first post-order traversal.</p>

<p>What about those cycles that we talked about before?</p>

<p>In a cyclic dependency, you end up having a loop in the graph. Usually, this is a long loop. But to explain the problem, I’m going to use a contrived example with a short loop.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/41_cjs_cycle.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/41_cjs_cycle-500x224.png" alt=""/></a></p>

<p>Let’s look at how this would work with CommonJS modules. First, the main module would execute up to the require statement. Then it would go to load the counter module.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/41_cyclic_graph.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/41_cyclic_graph-500x281.png" alt=""/></a></p>

<p>The counter module would then try to access <code>message</code> from the export object. But since this hasn’t been evaluated in the main module yet, this will return undefined. The JS engine will allocate space in memory for the local variable and set the value to undefined.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/42_cjs_variable_2.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/42_cjs_variable_2-500x113.png" alt=""/></a></p>

<p>Evaluation continues down to the end of the counter module’s top level code. We want to see whether we’ll get the correct value for message eventually (after main.js is evaluated), so we set up a timeout. Then evaluation resumes on <code>main.js</code>.</p>

<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/43_cjs_cycle.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/43_cjs_cycle-500x224.png" alt=""/></a></p>

<p>The message variable will be initialized and added to memory. But since there’s no connection between the two, it will stay undefined in the required module.</p>

<p><strong><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/44_cjs_variable_2.png"><img src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/03/44_cjs_variable_2-500x216.png" alt=""/></a></strong></p>

<p>If the export were handled using live bindings, the counter module would see the correct value eventually. By the time the timeout runs, <code>main.js</code>’s evaluation would have completed and filled in the value.</p>

<p>Supporting these cycles is a big rationale behind the design of ES modules. It’s this three-phase design that makes them possible.</p>

<h3 id="toc_8">What’s the status of ES modules?</h3>

<p>With the release of Firefox 60 in early May, all major browsers will support ES modules by default. Node is also adding support, with a <a href="https://github.com/nodejs/modules">working group</a> dedicated to figuring out compatibility issues between CommonJS and ES modules.</p>

<p>This means that you’ll be able to use the script tag with <code>type=module</code>, and use imports and exports. However, more module features are yet to come. The <a href="https://github.com/tc39/proposal-dynamic-import">dynamic import proposal</a> is at Stage 3 in the specification process, as is <a href="https://github.com/tc39/proposal-import-meta">import.meta</a> which will help support Node.js use cases, and the <a href="https://github.com/domenic/package-name-maps">module resolution proposal</a> will also help smooth over differences between browsers and Node.js. So you can expect working with modules to get even better in the future.</p>

<h2 id="toc_9">Acknowledgements</h2>

<p>Thank you to everyone who gave feedback on this post, or whose writing or discussions informed it, including Axel Rauschmayer, Bradley Farias, Dave Herman, Domenic Denicola, Havi Hoffman, Jason Weathersby, JF Bastien, Jon Coppeard, Luke Wagner, Myles Borins, Till Schneidereit, Tobias Koppers, and Yehuda Katz, as well as the members of the WebAssembly community group, the Node modules working group, and TC39.</p>

<h2 id="toc_10">About <a href="http://code-cartoons.com">Lin Clark</a></h2>

<p>Lin is an engineer on the Mozilla Developer Relations team. She tinkers with JavaScript, WebAssembly, Rust, and Servo, and also draws code cartoons.</p>

<ul>
<li>  <a href="http://code-cartoons.com">code-cartoons.com</a></li>
<li>  <a href="http://twitter.com/linclark">@linclark</a></li>
</ul>

<p><a href="https://hacks.mozilla.org/author/lclarkmozilla-com/">More articles by Lin Clark…</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[13 Noteworthy Points from Google’s JavaScript Style Guide]]></title>
    <link href="http://panlw.github.io/15352953904391.html"/>
    <updated>2018-08-26T22:56:30+08:00</updated>
    <id>http://panlw.github.io/15352953904391.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://medium.freecodecamp.org/google-publishes-a-javascript-style-guide-here-are-some-key-lessons-1810b8ad050b">https://medium.freecodecamp.org/google-publishes-a-javascript-style-guide-here-are-some-key-lessons-1810b8ad050b</a></p>
</blockquote>

<p><img src="https://cdn-images-1.medium.com/max/2000/1*ouYvMzYuksK-IH1BPNKD0A.jpeg" alt=""/></p>

<p>For anyone who isn’t already familiar with it, <a href="https://google.github.io/styleguide/jsguide.html">Google puts out a style guide</a> for writing JavaScript that lays out (what Google believes to be) the best stylistic practices for writing clean, understandable code.</p>

<p>These are not hard and fast rules for writing valid JavaScript, only proscriptions for maintaining consistent and appealing style choices throughout your source files. This is particularly interesting for JavaScript, which is a flexible and forgiving language that allows for a wide variety of stylistic choices.</p>

<p>Google and <a href="https://github.com/airbnb/javascript">Airbnb</a> have two of the most popular style guides out there. I’d definitely recommend you check out both of them if you spend much time writing JS.</p>

<p>The following are thirteen of what I think are the most interesting and relevant rules from Google’s JS Style Guide.</p>

<p>They deal with everything from hotly contested issues (tabs versus spaces, and the controversial issue of how semicolons should be used), to a few more obscure specifications which surprised me. They will definitely change the way I write my JS going forward.</p>

<p>For each rule, I’ll give a summary of the specification, followed by a supporting quote from the style guide that describes the rule in detail. Where applicable, I’ll also provide an example of the style in practice, and contrast it with code that does not follow the rule.</p>

<h4 id="toc_0">Use spaces, not tabs</h4>

<blockquote>
<p>Aside from the line terminator sequence, the ASCII horizontal space character (0x20) is the only whitespace character that appears anywhere in a source file. This implies that… Tab characters are <strong>not</strong> used for indentation.</p>
</blockquote>

<p>The guide later specifies you should use two spaces (not four) for indentation.</p>

<pre>// bad
function foo() {
∙∙∙∙let name;
}
// bad
function bar() {
∙let name;
}
// good
function baz() {
∙∙let name;
}</pre>

<h4 id="toc_1">Semicolons ARE required</h4>

<blockquote>
<p>Every statement must be terminated with a semicolon. Relying on automatic semicolon insertion is forbidden.</p>
</blockquote>

<p>Although I can’t imagine why anyone is opposed to this idea, the consistent use of semicolons in JS is becoming the new ‘spaces versus tabs’ debate. Google’s coming out firmly here in the defence of the semicolon.</p>

<pre>// bad
let luke = {}
let leia = {}
[luke, leia].forEach(jedi => jedi.father = 'vader')</pre>

<pre>// good
let luke = {};
let leia = {};
[luke, leia].forEach((jedi) => {
  jedi.father = 'vader';
});</pre>

<h4 id="toc_2">Don’t use ES6 modules (yet)</h4>

<blockquote>
<p>Do not use ES6 modules yet (i.e. the <code>export</code> and <code>import</code> keywords), as their semantics are not yet finalized. Note that this policy will be revisited once the semantics are fully-standard.</p>
</blockquote>

<pre>// Don't do this kind of thing yet:</pre>

<pre><code>//------ lib.js ------
</code></pre>

<h4 id="toc_3">Horizontal alignment is discouraged (but not forbidden)</h4>

<blockquote>
<p>This practice is permitted, but it is <strong>generally discouraged</strong> by Google Style. It is not even required to <u>maintain</u> horizontal alignment in places where it was already used.</p>
</blockquote>

<p>Horizontal alignment is the practice of adding a variable number of additional spaces in your code, to make certain tokens appear directly below certain other tokens on previous lines.</p>

<pre>// bad
{
  tiny:   42,  
  longer: 435, 
};</pre>

<pre>// good
{
  tiny: 42, 
  longer: 435,
};</pre>

<h4 id="toc_4">Don’t use var anymore</h4>

<blockquote>
<p>Declare all local variables with either <code>_const_</code> or <code>_let_</code>. Use const by default, unless a variable needs to be reassigned. The <code>_var_</code> keyword must not be used.</p>
</blockquote>

<p>I still see people using <code>var</code> in code samples on StackOverflow and elsewhere. I can’t tell if there are people out there who will make a case for it, or if it’s just a case of old habits dying hard.</p>

<pre>// bad
var example = 42;</pre>

<pre>// good
let example = 42;</pre>

<h4 id="toc_5">Arrow functions are preferred</h4>

<blockquote>
<p>Arrow functions provide a concise syntax and fix a number of difficulties with <code>_this_</code>. Prefer arrow functions over the <code>_function_</code> keyword, particularly for nested functions</p>
</blockquote>

<p>I’ll be honest, I just thought that arrow functions were great because they were more concise and nicer to look at. Turns out they also serve a pretty important purpose.</p>

<pre>// bad
[1, 2, 3].map(function (x) {
  const y = x + 1;
  return x * y;
});
// good
[1, 2, 3].map((x) => {
  const y = x + 1;
  return x * y;
});</pre>

<h4 id="toc_6">Use template strings instead of concatenation</h4>

<blockquote>
<p>Use template strings (delimited with ```) over complex string concatenation, particularly if multiple string literals are involved. Template strings may span multiple lines.</p>
</blockquote>

<pre>// bad
function sayHi(name) {
  return 'How are you, ' + name + '?';
}
// bad
function sayHi(name) {
  return ['How are you, ', name, '?'].join();
}
// bad
function sayHi(name) {
  return `How are you, ${ name }?`;
}
// good
function sayHi(name) {
  return `How are you, ${name}?`;
}</pre>

<h4 id="toc_7"><strong>Don’t use line continuations for long strings</strong></h4>

<blockquote>
<p>Do not use <u>line continuations</u> (that is, ending a line inside a string literal with a backslash) in either ordinary or template string literals. Even though ES5 allows this, it can lead to tricky errors if any trailing whitespace comes after the slash, and is less obvious to readers.</p>
</blockquote>

<p>Interestingly enough, this is a rule that Google and Airbnb disagree on (here’s <a href="https://github.com/airbnb/javascript#strings--line-length">Airbnb’s spec</a>).</p>

<p>While Google recommends concatenating longer strings (as shown below) Airbnb’s style guide recommends essentially doing nothing, and allowing long strings to go on as long as they need to.</p>

<pre>// bad (sorry, this doesn't show up well on mobile)
const longString = 'This is a very long string that \
    far exceeds the 80 column limit. It unfortunately \
    contains long stretches of spaces due to how the \
    continued lines are indented.';</pre>

<pre>// good
const longString = 'This is a very long string that ' + 
    'far exceeds the 80 column limit. It does not contain ' + 
    'long stretches of spaces since the concatenated ' +
    'strings are cleaner.';</pre>

#### “for… of” is the preferred type of ‘for loop’

> With ES6, the language now has three different kinds of `for` loops. All may be used, though `for`-`of` loops should be preferred when possible.

This is a strange one if you ask me, but I thought I’d include it because it is pretty interesting that Google declares a preferred type of `for` loop.

I was always under the impression that `for... in` loops were better for objects, while `for... of` were better suited to arrays. A ‘right tool for the right job’ type situation.

While Google’s specification here doesn’t necessarily contradict that idea, it is still interesting to know they have a preference for this loop in particular.

#### Don’t use eval()

> Do not use `eval` or the `Function(...string)` constructor (except for code loaders). These features are potentially dangerous and simply do not work in CSP environments.

The [MDN page](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/eval) for `eval()` even has a section called “Don’t use eval!”

<pre>// bad
`let obj = { a: 20, b: 30 };
let propName = getPropName();  // returns "a" or "b"
eval( 'var result = obj.' + propName );`</pre>

<pre>// good
`let obj = { a: 20, b: 30 };
let propName = getPropName();  // returns "a" or "b"
let result = obj[ propName ];  //  obj[ "a" ] is the same as obj.a`</pre>

<h4 id="toc_8">Constants should be named in ALL_UPPERCASE separated by underscores</h4>

<blockquote>
<p>Constant names use <code>CONSTANT_CASE</code>: all uppercase letters, with words separated by underscores.</p>
</blockquote>

<p>If you’re absolutely sure that a variable shouldn’t change, you can indicate this by capitalizing the name of the constant. This makes the constant’s immutability obvious as it gets used throughout your code.</p>

<p>A notable exception to this rule is if the constant is function-scoped. In this case it should be written in camelCase.</p>

<pre>// bad
const number = 5;</pre>

<pre>// good
const NUMBER = 5;</pre>

<h4 id="toc_9">One variable per declaration</h4>

<blockquote>
<p>Every local variable declaration declares only one variable: declarations such as <code>let a = 1, b = 2;</code> are not used.</p>
</blockquote>

<pre>// bad
let a = 1, b = 2, c = 3;</pre>

<pre>// good
let a = 1;
let b = 2;
let c = 3;</pre>

<h4 id="toc_10">Use single quotes, not double quotes</h4>

<blockquote>
<p>Ordinary string literals are delimited with single quotes (<code>&#39;</code>), rather than double quotes (<code>&quot;</code>).</p>

<p>Tip: if a string contains a single quote character, consider using a template string to avoid having to escape the quote.</p>
</blockquote>

<pre>// bad
let directive = "No identification of self or mission."</pre>

<pre>// bad
let saying = `'Say it ain\u0027t so.';`</pre>

<pre>// good
let directive = 'No identification of self or mission.';</pre>

<pre>// good
let saying = `Say it ain't so`;</pre>

<h4 id="toc_11">A final note</h4>

<p>As I said in the beginning, these are not mandates. Google is just one of many tech giants, and these are just recommendations.</p>

<p>That said, it is interesting to look at the style recommendations that are put out by a company like Google, which employs a lot of brilliant people who spend a lot of time writing excellent code.</p>

<p>You can follow these rules if you want to follow the guidelines for ‘Google compliant source code’ — but, of course, plenty of people disagree, and you’re free to brush any or all of this off.</p>

<p>I personally think there are plenty of cases where Airbnb’s spec is more appealing than Google’s. No matter the stance you take on these particular rules, it is still important to keep stylistic consistency in mind when write any sort of code.</p>

<ul>
<li>  <a href="https://medium.freecodecamp.org/tagged/javascript?source=post">JavaScript</a></li>
<li>  <a href="https://medium.freecodecamp.org/tagged/google?source=post">Google</a></li>
<li>  <a href="https://medium.freecodecamp.org/tagged/web-development?source=post">Web Development</a></li>
<li>  <a href="https://medium.freecodecamp.org/tagged/programming?source=post">Programming</a></li>
<li>  <a href="https://medium.freecodecamp.org/tagged/tech?source=post">Tech</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[有赞统一日志平台初探]]></title>
    <link href="http://panlw.github.io/15352773081191.html"/>
    <updated>2018-08-26T17:55:08+08:00</updated>
    <id>http://panlw.github.io/15352773081191.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://tech.youzan.com/you-zan-tong-ri-zhi-ping-tai-chu-tan/">https://tech.youzan.com/you-zan-tong-ri-zhi-ping-tai-chu-tan/</a></p>
</blockquote>

<pre><code>【编者的话】从2015年初入职有赞以来，一直致力于后端服务开发，主要设计开发了监控系统Hawk，但这不是本次要分享的点。一个月前，负责日志平台Track的小伙伴寻求梦想出去创业了，有幸接手了日志平台，这对本人确实是个不小的挑战，也同样是个学习成长的机会。此次就借着梳理日志平台的机会，给大家分享一下有赞统一日志平台的架构设计。
</code></pre>

<h4 id="toc_0">一、引言</h4>

<p>自有赞成立以来，发展迅猛，业务增长很快，业务系统数量大，每天都会产生大量的系统日志和业务日志 (据统计，平均每秒产生日志 1.1 万条，峰值 1.5 万条，每天的日志量约 9 亿条，占用空间 2.4T 左右)。</p>

<p>在信息化时代，日志的价值是无穷的。为了对系统进行有效的监控、维护、优化、改进，都离不开对日志的收集和分析，而这些日志散落在各个服务器上，无论对运维同学、还是业务开发同学，抑或是数据部门的同学而言，查阅或分析日志是一大痛点，实时收集分布在不同节点或机器上的日志，供离线或在线查阅及分析来提升工作效率的需求异常迫切，在此背景下，于是有赞统一日志平台就应运而生了。</p>

<p>在互联网高速发展的今天，有那么多优秀的日志收集系统，诸如 Kafka、Flume、Scribe、Chukwa、ELK 等。对于如何选型在此不做讨论，而且本人才疏学浅，也未做深入调研和性能分析对比测试，还不够资格讨论。相信前人的选择是有其理由的，接下来我们来看看秉着 “短平快” 的互联网精神，构建的这套适合有赞业务系统的统一日志平台。</p>

<h4 id="toc_1">二、总体设计</h4>

<p>废话不多说，直接上总体架构图，如图 2-1 所示： <img src="http://7xtb4n.com1.z0.glb.clouddn.com/track-pic-2-1.png" alt=""/> 图 2-1 总体架构图</p>

<p>有赞统一日志系统，负责收集所有系统日志和业务日志，转化为流式数据，通过 flume 或 logstash 上传到日志中心 (kafka 集群)，然后供 Track、Storm、Spark 及其它系统实时分析处理日志，并将日志持久化存储到 HDFS 供离线数据分析处理，或写入 ElasticSearch 提供数据查询，或写入 Hawk 发起异常报警或提供指标监控查询。</p>

<h4 id="toc_2">三、模块分解</h4>

<p>从上面总体架构图中，我们可以看到整个日志平台架构分为四层，从左到右依次是日志接入层、日志中心、日志处理层、日志存储层。</p>

<h5 id="toc_3">3.1 日志接入层</h5>

<p>日志接入层主要有两种方式，方式 1 基于 rsyslog 和 logstash，方式 2 基于 flume-ng。</p>

<h6 id="toc_4">3.1.1</h6>

<p><img src="http://7xtb4n.com1.z0.glb.clouddn.com/track-pic-3-1.png" alt=""/> 图 3-1 日志接入方式 1</p>

<p>对于一些稳定的日志，比如系统日志或框架日志 (如 nginx 访问日志、phpfpm 异常日志等)，我们添加 nginx 配置，通过 rsyslog 写到本地目录 local0，然后 logstash 根据其配置，会将 local0 中的增量日志上传到日志中心对应的 topic 中，具体数据流图见图 3-1 所示：</p>

<h6 id="toc_5">3.1.2</h6>

<p>Flume NG 是一个分布式，高可用，可靠的系统，它能将不同的海量数据收集，移动并存储到一个数据存储系统中。轻量，配置简单，适用于各种日志收集，并支持 Failover 和负载均衡。并且它拥有非常丰富的组件。Flume NG 采用的是三层架构：Agent 层，Collector 层和 Store 层，每一层均可水平拓展。其中 Agent 包含 Source，Channel 和 Sink，三者组建了一个 Agent。三者的职责如下所示：<br/>
Source：用来消费（收集）数据源到 Channel 组件中，简单说就是搜集数据的入口。<br/>
Channel：中转临时存储，保存所有 Source 组件信息，其实就是个消息队列，可配置多个 Chanel。<br/>
Sink：从 Channel 中读取，读取成功后会删除 Channel 中的信息，简单说就是搜集数据的出口。</p>

<p>在有赞日志平台中，我们只用了 Agent 层。具体可以见图 3-2:</p>

<p><img src="http://7xtb4n.com1.z0.glb.clouddn.com/track-pic-3-2.png" alt=""/></p>

<p>图 3-2 日志接入方式 2</p>

<p>日志中心的 kafka 是根据 topic 存取数据的，所以需要在日志中加入 topic 字段。为了统一，我们对日志格式做了约定，格式如下:</p>

<pre><code>&lt;158&gt;yyyy-MM-dd HH:mm:ss host/ip level[pid]: topic=track.**** {&quot;type&quot;:&quot;error&quot;,&quot;tag&quot;:&quot;redis connection refused&quot;,&quot;platform&quot;:&quot;java/go/php&quot;,&quot;level&quot;:&quot;info/warn/error&quot;,&quot;app&quot;:&quot;appName&quot;,&quot;module&quot;:&quot;com.youzan.somemodule&quot;,&quot;detail&quot;:&quot;any things you want here&quot;}

</code></pre>

<p>对于 PHP Server，我们在 PHP 框架中封装了日志 SDK，PHP 开发的同学只需调用写日志接口，就可以将日志传到 Flume 中。同样的，对于 Java Server，也封装了日志 SDK(基于 logback 自定义了<code>TrackAppender</code>)，并集成在 Dubbox 框架中，业务开发的同学只需在其工程的 logback.xml 中添加相应的 appender 配置，指明应用名和日志 topic 即可将日志异步传到 Flume 中。对于其它应用或服务 (比如基于 Go、Node.JS、Python 等)，如果需要接入日志平台，只需按照以上日志格式组装日志，并将其上传到 Flume 即可。</p>

<p>细心的同学会发现，在图 3-2 中，我们用了<code>TrackSink</code>，这个是做什么的呢？虽然 Flume 自带丰富的组件，也包括 KafkaSink，但是为什么我们不用呢？考虑到自带的 KafkaSink 不能按我们需要的 topic 来分发数据，所以只能自定义实现了 Sink 来达到写不同 topic 日志到不同日志中心 topic 中去的目的。</p>

<p>另外，Flume 是通过 Supervisor 启动的，并且添加了监控报警，但是为了避免日志写失败，在 Flume 中，我们使用了 Failover 策略，假如写日志中心失败，则将日志写到本地，保证日志不丢失。</p>

<p>3.2 日志中心</p>

<p>美其名曰日志中心，但实际上只是日志中心缓存，我们只保存最近 24 小时的日志，需要持久化的日志都会刷入 HDFS。至于为什么选用 kafka 集群来构建日志中心，理由主要如下:</p>

<pre><code>  1、分布式架构，可支持水平扩展。
  2、高吞吐量，在普通的服务器上每秒钟也能处理几十万条消息(远高于我们的峰值1.5万条/秒)。
  3、消息持久化，按topic分区存储，支持可重复消费。
  4、日志系统不需要保证严格的消息准确性。
  5、数据在磁盘上的存取代价为O(1)。
  6、可根据broker配置定期删除过期数据。

</code></pre>

<p>3.3 日志处理层和日志存储层</p>

<p>日志处理层，是我们真正做事的地方；日志存储层，则是我们存放日志分析结果的地方。</p>

<p>基于日志中心，可做的事情有很多。只要我们对某 topic 日志感兴趣，那么便可以将该 topic 日志消费来满足我们的业务需求。我们可以：</p>

<pre><code>1、将日志聚合，根据业务不同，建立不同的索引，存入ElasticSearch提供查询。
2、发现异常日志时，发往监控中心，向对应的业务方发起报警，发现和预发问题的实时性提高了。
3、统计一些访问日志或调用日志等指标信息，发往监控中心来掌握相关调用趋势。
4、调用链开始做起来了，系统性能瓶颈一目了然了。
5、用户日志行为可分析了。

</code></pre>

<p>这里我们做了不少，但是需要做的还有更多，就不一一例举了。</p>

<h4 id="toc_6">四、遇到的问题和要做的事情</h4>

<p>突然接手如此规模的一个基础产品，遇到的问题还是比较多的:</p>

<pre><code>1、业务日志接入，每一次对接不仅需要开发日志消费模块，解析相应日志，建立相应的索引并写入elasticsearch，还需要开发对应定制的查询页面。由于自己本身对系统不熟悉，另外文档缺失，以及每一次对接的都是“新人”，还时不时可能会遇到各种千奇百怪的问题，需要排查定位并解决问题。这块急需解放，不然一个人真的忙不过来，针对该问题，接下来会抽象出日志消费和elasticsearch读写SDK，供业务接入方自己开发和维护。
2、对于各个组件(如logstash、flume、kafka、elasticsearch等)都未曾接触过的情况下，短时间接手这么一个新产品，需要学习的东西很多，压力还是很大的，但总算熬过来了。
3、缺失的开发测试环境，到写此文章时总算搭建起来了。
4、elasticsearch内存占用高，以及索引的管理与维护，还在优化和考虑中。
5、需要开发更加人性化且更易扩展和维护的运控平台供使用方查询日志。
6、日志收集到Flume增加支持UDP协议。
7、将存储层的HDFS移到日志中心，支持日志同时写入Kafka集群和HDFS集群。
8、是时候做点日志挖掘的事情了。

</code></pre>

<h4 id="toc_7">五、结语</h4>

<p>为什么做这次分享？</p>

<p>由于之前交接时间较短，实际只有 2 天，然后统一日志平台涉及的内容比较多，接手日志平台的这一个多月是痛苦的，然后找崔 (有赞 CTO) 吐槽了一下。结果崔知道我在梳理日志平台，就让我顺便写篇介绍有赞的日志架构的文章，帮助大家了解一下。怎奈我这人脸皮太薄，在对日志平台还不熟悉的情况下，竟然应承下来了，俗话说的好，死要面子活受罪。</p>

<p>最后，好像不做点广告都对不起人民大众, 热烈欢迎优秀程序员加我有赞大家庭，无论前端后端，只要想做事会做事就行。有意者请猛戳: <a href="http://job.youzan.com/" title="加入我们">加入我们</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL8 Authentication plugin Change]]></title>
    <link href="http://panlw.github.io/15348499248375.html"/>
    <updated>2018-08-21T19:12:04+08:00</updated>
    <id>http://panlw.github.io/15348499248375.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://samchu.logdown.com/posts/7425945-mysql8-authentication-plugin-change">http://samchu.logdown.com/posts/7425945-mysql8-authentication-plugin-change</a></p>

<p><img src="media/15348499248375/15348503868862.jpg" alt=""/></p>
</blockquote>

<p>這幾天 MySQL 出 8 的版本, 沒想到密碼儲存方式變更了, 頓時一堆人慘叫XD</p>

<p>因為 之前 MySQL 預設儲存密碼的方式是<code>mysql_native_password</code>, 但 8.0 之後 預設的儲存方式為<code>caching_sha2_password</code>, 說是又快又安全啦, 但讓人措手不及, 一堆 SQL 工具 (Navicat) 可能還來不及更新支援 就...</p>

<p>登入失敗!!</p>

<pre><code>Authentication plugin &#39;caching_sha2_password&#39; cannot be loaded: dlopen(/usr/local/mysql/lib/plugin/caching_sha2_password.so, 2): image not found
</code></pre>

<h2 id="toc_0">方法1 : 就升級上去吧, 變更 JDBC 連結方式</h2>

<ol>
<li>首先更新你的 JDBC 驅動 runtime &#39;mysql:mysql-connector-java:8.0.11&#39;</li>
<li>修改你的 driver-class-name , 因為 Loading class `com.mysql.jdbc.Driver&#39;. This is deprecated. , 請你換成新版的 com.mysql.cj.jdbc.Driver</li>
<li>JDBC URL 增加參數<code>allowPublicKeyRetrieval=true</code></li>
</ol>

<p>完成, 這樣你的 JDBC 就可以搭配使用上<code>caching_sha2_password</code>的機制了</p>

<h2 id="toc_1">方法2 : 我要最新版但是不要用新的密碼機制</h2>

<p>我是用 Docker 啦, 多個參數就可以正常使用了<code>--default-authentication-plugin=mysql_native_password</code></p>

<pre><code>docker run --name askask-mysql -e MYSQL_DATABASE=askask -e MYSQL_ROOT_PASSWORD=1qaz2wsx -p 3306:3306 -d mysql --default-authentication-plugin=mysql_native_password
</code></pre>

<p>收工</p>

<h2 id="toc_2">方法3 : 修改账户的密碼機制</h2>

<pre><code class="language-sql">CREATE DATABASE rep2 CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
CREATE USER &#39;dev&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;Dev.1234&#39;;
ALTER USER &#39;dev&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;password&#39;;
GRANT ALL PRIVILEGES ON rep2.* TO &#39;dev&#39;@&#39;%&#39;;
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[**The Path to Becoming a Software Architect**]]></title>
    <link href="http://panlw.github.io/15344302211672.html"/>
    <updated>2018-08-16T22:37:01+08:00</updated>
    <id>http://panlw.github.io/15344302211672.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://medium.com/@nvashanin/the-path-to-becoming-a-software-architect-de53f1cb310a">https://medium.com/@nvashanin/the-path-to-becoming-a-software-architect-de53f1cb310a</a></p>

<p><a href="https://medium.com/@nvashanin" title="Go to the profile of Nikolay Ashanin">Nikolay Ashanin</a> | Oct 1, 2017</p>

<p>Lead Software Engineer at EPAM Systems. Interested in software architecture and team management.</p>
</blockquote>

<p><img src="https://cdn-images-1.medium.com/max/800/1*JFdmWD8_X5gpCjNVaqILgQ.png" alt=""/>Image source: monumentvalleygame</p>

<p>Have you ever wondered what career opportunities a developer has? What directions are open, beyond what horizons to grow. And most importantly, where are developers beyond the age of 45? Is there a developer among your friends who is over 45? I personally know several developers beyond this age and many of them are hardcore programmers who even saw punch cards back in the day.</p>

<p><strong>There are several career paths a developer might take:</strong></p>

<p>● The first and obvious one is to <strong>grow in the area in which you are working</strong>. If you are a junior developer, then just grow to middle, then senior and lead roles.</p>

<p>● <strong>Transition to another technology stack</strong>. Actually, a big number of developers moved into the mobile area when iOS and Android OS gained ground.</p>

<p>● <strong>Grow into a manager role</strong>. As a developer, the greatest staffing issue I saw was the shortage of competent managers. Clever managers are expensive, hence they are scarce. If the manager has a technical background, that will allow him to be on the same wavelength with the developers.</p>

<p>● <strong>Become a software architect</strong>. This direction will be considered in this series of articles.</p>

<p>● <strong>Get out of IT</strong>. Sometimes this happens. It is never too late to do what you like to do.</p>

<h3 id="toc_0">Article series</h3>

<ol>
<li> <a href="https://medium.com/@nvashanin/the-path-to-becoming-a-software-architect-de53f1cb310a">The Path to Becoming a Software Architect</a></li>
<li> <a href="https://medium.com/@nvashanin/stakeholders-in-software-architecture-6d18f36250f9">Stakeholders in Software Architecture</a></li>
<li> <a href="https://medium.com/@nvashanin/types-of-software-architects-aa03e359d192">Types of Software Architects</a></li>
<li> <a href="https://medium.com/@nvashanin/quality-attributes-in-software-architecture-3844ea482732">Quality attributes in Software Architecture. Part I</a></li>
<li> TBD Quality attributes in Software Architecture. Part II</li>
<li> TBD Software Architect. Diagrams and documentation</li>
<li> <a href="https://medium.com/@nvashanin/certificates-in-software-architecture-6b18e0102fe7">Certificates in Software Architecture</a></li>
<li> <a href="https://medium.com/@nvashanin/books-in-software-architecture-6ad974e524ce">Books in Software Architecture</a></li>
<li> TBD Software Architect. Design vs Architecture</li>
</ol>

<h3 id="toc_1">Yes, This Was My Path</h3>

<p>In the past 8 years, I have worked with Java EE, then moved to iOS, and became a team lead. I managed various developer teams, including Android, and Web stacks. Created the architecture of the network layer for several services developed by the company, with sockets and REST API. I became acquainted with the managerial role and the prospect of growing in this direction while in the position of team lead for over two years. In my next role, my goal is to grow as a software architect.</p>

<p>For most developers, the function of the architect on the project is often unclear, so in this series of articles, I will try to find the answers to these related questions. Who is an architect, what is the scope of responsibilities, and how to grow in this direction and outline and action plan for myself and beginners wanting to move along this path.</p>

<h3 id="toc_2"><strong>Who Can Benefit from This?</strong></h3>

<p>This series of articles will help you if you belong to one of the following categories:</p>

<p>● <strong>IT developer or engineer</strong>. You are still growing as a developer, but you are looking ahead and planning your career. Even if the goals are initially vague, a person who consciously sets strategic goals will reach them much quicker than a person who does not plan where she is heading.</p>

<p>● <strong>Team leader, lead software engineer</strong>. You are at the highest stage of the software development discipline. To grow further, you have a choice to either learn one more stack of technologies, pursue a career outside software engineering, or to become a software architect.</p>

<p>● <strong>Software architect</strong>. You recently took this position, or have been working in this field for a long time. Perhaps one of the main qualities of such a specialist is the understanding that there are always areas that a person does not know and that the learning process is continuous.</p>

<p>● <strong>IT manager</strong>. Although you are a manager, you understand perfectly well that you should at least approximately understand what your subordinates or colleagues are doing. The acute problem of management is the technical incompetence of the manager in the field in which he or she is managing.</p>

<h3 id="toc_3"><strong>Who is an Architect?</strong></h3>

<p>Before moving on to more specific questions, it is necessary to define the software architect role and it responsibilities.</p>

<blockquote>
<p>A <strong>software architect</strong> is a software expert who makes high-level design choices and dictates technical standards, including software coding standards, tools, and platforms. The leading expert is referred to as the chief architect. (Wikipedia, The Free Encyclopedia, s.v. “Software architect”, <a href="https://en.wikipedia.org/wiki/Software_architect">https://en.wikipedia.org/wiki/Software_architect</a></p>
</blockquote>

<p>Like most high-level positions, there are no clear criteria that define this role. However, it is possible to define a number of responsibilities and qualities that contribute to the career of the architect.</p>

<p>First, let’s consider the <strong>characteristics of the architect</strong>:</p>

<p>● <strong>Communicability</strong>. Having talked with many software architects, I heard that it is one of the most important characteristic of this specialist. During the working day, they have to talk with customers in the language of business, managers of all levels, business analysts and developers. If you have a natural charisma and you know how to convince people, then this will be a huge plus, as it is very important to explain your actions correctly. Architects are laconic, eloquent and competent speakers. The software architects with whom I spoke have highly developed skills in communication and persuasion. Another reason why this characteristic is most important is that the architect in this role participates in most discussion making processes, and often compromises must be reach that are acceptable and beneficial for all involved parties.</p>

<p>● <strong>Broad and deep technical knowledge</strong>. This should be obvious since one cannot become a software architect with a medical background. In addition, the architect usually has knowledge in several technological stacks at a decent level, and should have a good understanding of a few other ones. The software architect should also be prepared to compose a large number of technical documentation, reports and diagrams.</p>

<p>● <strong>Responsibility</strong>. You should understand that architect decisions are usually the most expensive. Therefore, a person in this position should take the most responsible approach to his work and to the decisions made. If the developer’s error costs a couple days of work of one person, then the architect’s mistake can cost person-years on complex projects!</p>

<p>● <strong>Stress resistance</strong>. You will have to make decisions because in this role, you will be asked to do so and you will need response. You will be working with different people from different areas, and you will have to deal with rapidly changing demands or even with changing business environments. Therefore, it is necessary to be ready for stress and to look for some ways to escape negative emotions. Work is always more pleasant when it brings pleasure. So if you choose this role only for the money, then think again.</p>

<p>● <strong>Management skills</strong>. This includes both organizational and leadership skills. The ability to lead a team, which may be distributed and composed of very different specialists, is essential.</p>

<p>● <strong>Analytic skills</strong>. Even if a specialist has a wide erudition in technology, he has tried many things on his own or participated in projects of various types, this does not guarantee that he can easily change the style of thinking to architect. One of the most important tasks is the ability to represent an abstract problem in the form of some finite real object of the system, which developers are already evaluating, designing and developing. Great communications skills are essential to clearly represent the abstraction in the form of the final system to the members of the team and the customer. It will be necessary to clearly communicate to both business and development, what is still to be done.</p>

<p>If we talk about the responsibilities of the architect, then here is the perfect example from 19th century about bridge construction. At that time, the tests of the newly constructed bridge were the following: the key group of engineers, architects and workers stood under the bridge while the first vehicles were on it. Thus, they staked their lives upon the construction and the strength of the structure. So if there is a question — what is the responsibility of the software architect on the project? The answer is, he is responsible for everything.</p>

<p>If you give up loud and beautiful phrases, then the architect’s work includes:</p>

<p>● Identifying the stakeholders on the project.</p>

<p>● Identifying business requirements and requirements of the stakeholders on the project.</p>

<p>● Designing the entire system based on the received requirements.</p>

<p>● Choosing the system architecture and each individual component of this system at a high level.</p>

<p>● Choosing the technologies for the implementation of each component and connections between the components.</p>

<p>● Architectural review. Yes, yes, it exists.</p>

<p>● Code-review.</p>

<p>● Writing project documentation and its support.</p>

<p>● Creating unified development standards in the company.</p>

<p>● Controlling the architecture during the next iteration of the system release.</p>

<p>This is only a subset of the software architect’s responsibilities. The most important responsibility is complete technical support of the project from the moment of inception, through product release, to development of enhancements. And supporting the next releases. It will be necessary to switch a lot between different tasks during the working day.</p>

<h3 id="toc_4"><strong>How to Become a Software Architect?</strong></h3>

<p>To begin with, it is important to define milestone goals that lead to achieving your strategic goal of becoming a software architect. For me, such <strong>goals for the next six months</strong> are:</p>

<p>● <strong>Understand and try several technological stacks</strong>. My current knowledge is concentrated in the field of iOS. It is necessary to try Android, several server languages, to start python, and refresh Java EE skills. The architect is a full-stack developer, so it is important to have a broad technical knowledge.</p>

<p>● <strong>Reading literature</strong>. It is important to determine the most valuable books and articles that will help to grow in this direction. Usually the most effective way to find such literature is ask other professionals in this field for their recommendation. In one of the future articles, I plan to give you such a list of literature.</p>

<p>● <strong>Find a mentor</strong>. It is desirable to find a software architect at your current place of employment. It is always easier to get experience from a trained specialist than to start considering a certain area from scratch. It is important to be prepared to ask good questions from your mentor.</p>

<p>● <strong>Study courses/obtain certificates</strong>. There are many courses and certificates available, but only a few are worth their money, and the higher level courses cost a lot of money. Personally, I have attended the architectural courses of Luxoft (<a href="http://www.luxoft-training.com/it-course/ARC-001/">http://www.luxoft-training.com/it-course/ARC-001/</a>), which have proven to be a worthy investment. It is extremely important that the lecturer of the course be a professional in this field and be able to answer questions. As for certificates, before starting, it is best to understand whether there are authoritative certification systems for architects and whether it is worthwhile obtaining the certification. This point I will discuss in a future article of this series.</p>

<p>One of the most important parts is a clear and stable plan review. What has been done, what should be reviewed, and where to accelerate or which goal to remove as useless.</p>

<h3 id="toc_5">Check Your Readiness Level</h3>

<p>If you are interested in this introductory article from the series on how to become a software architect, or if you suddenly have thoughts to try this path, it is worth making sure that you really want it.</p>

<p>Firstly, people are afraid of everything new. A new position, new kind of stress, as opposed to the comfortable status quo. Of course, the choice is not always unambiguous and depends on how much you are willing to change something in your life. At the same time, it can depend not only on you, but also on the family, your financial commitments, parents and other factors.</p>

<p>Secondly, this path takes several years. The process of becoming a software architect does not happen overnight. As a team lead, I realized what to do and how to deal with stress only a year after I was appointed to an official position. At the same time six months before that, I performed it unofficially. One software architect I know said that he understood what his responsibilities are 18 months after he was promoted to this role. Such intervals of time are normal and you need to understand whether you are ready to move in this direction. Even if you do not have a stable plan ready, it is better to start taking small steps that move you ahead, rather than remaining in the same place.</p>

<p>Standing in the same place in IT is a synonym for stagnation and personal fetters in life.</p>

<ul>
<li>  <a href="https://medium.com/tag/software-development?source=post">Software Development</a></li>
<li>  <a href="https://medium.com/tag/software-architecture?source=post">Software Architecture</a></li>
<li>  <a href="https://medium.com/tag/software-engineering?source=post">Software Engineering</a></li>
<li>  <a href="https://medium.com/tag/management?source=post">Management</a></li>
<li>  <a href="https://medium.com/tag/software?source=post">Software</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[InnoDB并发如此高，原因竟然在这？]]></title>
    <link href="http://panlw.github.io/15342611126076.html"/>
    <updated>2018-08-14T23:38:32+08:00</updated>
    <id>http://panlw.github.io/15342611126076.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>原文地址 <a href="https://mp.weixin.qq.com/s/R3yuitWpHHGWxsUcE0qIRQ">https://mp.weixin.qq.com/s/R3yuitWpHHGWxsUcE0qIRQ</a></p>

<p>原创： 58沈剑  架构师之路  2018-08-14</p>
</blockquote>

<p>《<a href="http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651961431&amp;idx=1&amp;sn=4f46fbada3d99ca6cf74b305d06c1ac6&amp;chksm=bd2d0d8b8a5a849d8cb5a616c957abde7a6485cd2624372b84a5459eed081bd95429a09572f8&amp;scene=21#wechat_redirect">InnoDB 行锁，如何锁住一条不存在的记录？</a>》埋了一个坑，没想到评论反响剧烈，大家都希望深挖下去。原计划写写 InnoDB 的锁结束这个 case，既然呼声这么高，干脆全盘<strong>系统性</strong>的写写 InnoDB 的<strong>并发控制</strong>，<strong>锁</strong>，<strong>事务模型</strong>好了。</p>

<p>体系相对宏大，一篇肯定写不完，容我娓娓道来，通俗地说清楚来龙去脉。</p>

<p><strong>一、并发控制</strong></p>

<p><strong>为啥要进行并发控制？</strong></p>

<p>并发的任务对同一个临界资源进行操作，如果不采取措施，可能导致不一致，故必须进行<strong>并发控制</strong>（Concurrency Control）。</p>

<p><strong>技术上，通常如何进行并发控制？</strong></p>

<p>通过并发控制保证数据一致性的常见手段有：</p>

<ul>
<li><p>锁（Locking）</p></li>
<li><p>数据多版本（Multi Versioning）</p></li>
</ul>

<p><strong>二、锁</strong></p>

<p><strong>如何使用普通锁保证一致性？</strong></p>

<p>普通锁，被使用最多：</p>

<p>(1) 操作数据前，锁住，实施互斥，不允许其他的并发任务操作；</p>

<p>(2) 操作完成后，释放锁，让其他任务执行；</p>

<p>如此这般，来保证一致性。</p>

<p><strong>普通锁存在什么问题？</strong></p>

<p>简单的锁住太过粗暴，连 “读任务” 也无法并行，任务执行过程本质上是串行的。</p>

<p>于是出现了<strong>共享锁</strong>与<strong>排他锁</strong>：</p>

<ul>
<li><p>共享锁（<strong>S</strong>hare Locks，记为 S 锁），读取数据时加 S 锁</p></li>
<li><p>排他锁（e<strong>X</strong>clusive Locks，记为 X 锁），修改数据时加 X 锁</p></li>
</ul>

<p>共享锁与排他锁的玩法是：</p>

<ul>
<li><p>共享锁之间不互斥，简记为：读读可以并行</p></li>
<li><p>排他锁与任何锁互斥，简记为：写读，写写不可以并行</p></li>
</ul>

<p>可以看到，一旦写数据的任务没有完成，数据是不能被其他任务读取的，这对并发度有较大的影响。</p>

<p><u>画外音：对应到数据库，可以理解为，写事务没有提交，读相关数据的 select 也会被阻塞。</u></p>

<p><strong>有没有可能，进一步提高并发呢？</strong></p>

<p>即使写任务没有完成，其他读任务也可能并发，这就引出了数据多版本。</p>

<p><strong>三、数据多版本</strong></p>

<p>数据多版本是一种能够进一步提高并发的方法，它的<strong>核心原理</strong>是：</p>

<p>（1）写任务发生时，将数据克隆一份，以版本号区分；</p>

<p>（2）写任务操作新克隆的数据，直至提交；</p>

<p>（3）并发读任务可以继续读取旧版本的数据，不至于阻塞；</p>

<p><img src="https://mmbiz.qpic.cn/mmbiz_png/YrezxckhYOxqYZaEWwXRwibTg8vNtNIPG7Hfiat5wx6D353IIxWmOKJawOcJ84QFu2WYicElTUeTsy9Am0MQZpcyg/640?wx_fmt=png" alt=""/></p>

<p>如上图：</p>

<p>1. 最开始数据的版本是 V0；</p>

<p>2. T1 时刻发起了一个写任务，这是把数据 clone 了一份，进行修改，版本变为 V1，但任务还未完成；</p>

<p>3. T2 时刻并发了一个读任务，依然可以读 V0 版本的数据；</p>

<p>4. T3 时刻又并发了一个读任务，依然不会阻塞；</p>

<p>可以看到，数据多版本，通过 “读取旧版本数据” 能够极大提高任务的并发度。</p>

<p>提高并发的演进思路，就在如此：</p>

<ul>
<li><p><strong>普通锁</strong>，本质是串行执行</p></li>
<li><p><strong>读写锁</strong>，可以实现读读并发</p></li>
<li><p><strong>数据多版本</strong>，可以实现读写并发</p></li>
</ul>

<p><u>画外音：这个思路，比整篇文章的其他技术细节更重要，希望大家牢记。</u></p>

<p>好，对应到 InnoDB 上，具体是怎么玩的呢？</p>

<p><strong>四、redo, undo,</strong> <strong>回滚段</strong></p>

<p>在进一步介绍 InnoDB 如何使用 “读取旧版本数据” 极大提高任务的并发度之前，有必要先介绍下 redo 日志，undo 日志，回滚段（rollback segment）。</p>

<p><strong>为什么要有 redo</strong> <strong>日志？</strong></p>

<p>数据库事务提交后，必须将更新后的数据刷到磁盘上，以保证 ACID 特性。磁盘<strong>随机写</strong>性能较低，如果每次都刷盘，会极大影响数据库的吞吐量。</p>

<p>优化方式是，将修改行为先写到 redo 日志里（此时变成了<strong>顺序写</strong>），再定期将数据刷到磁盘上，这样能极大提高性能。</p>

<p><u>画外音：这里的架构设计方法是，<strong>随机写优化为顺序写</strong>，思路更重要。</u></p>

<p>假如某一时刻，数据库崩溃，还没来得及刷盘的数据，在数据库重启后，会重做 redo 日志里的内容，以保证已提交事务对数据产生的影响都刷到磁盘上。</p>

<p><strong>一句话</strong>，redo 日志用于保障，已提交事务的 ACID 特性。</p>

<p><strong>为什么要有 undo</strong> <strong>日志？</strong></p>

<p>数据库事务未提交时，会将事务修改数据的镜像（即修改前的旧版本）存放到 undo 日志里，当事务回滚时，或者数据库奔溃时，可以利用 undo 日志，即旧版本数据，撤销未提交事务对数据库产生的影响。</p>

<p><u>画外音：更细节的，</u></p>

<p><u>对于 <strong>insert 操作</strong>，undo 日志记录新数据的 PK(ROW</u>ID)，回滚时直接删除；_</p>

<p><u>对于 <strong>delete/update 操作</strong>，undo 日志记录旧数据 row，回滚时直接恢复；</u></p>

<p><u>他们分别存放在不同的 buffer 里。</u></p>

<p><strong>一句话</strong>，undo 日志用于保障，未提交事务不会对数据库的 ACID 特性产生影响。</p>

<p><strong>什么是回滚段？</strong></p>

<p>存储 undo 日志的地方，是回滚段。</p>

<p>undo 日志和回滚段和 InnoDB 的 MVCC 密切相关，这里举个例子展开说明一下。</p>

<p><strong>栗子</strong>：</p>

<p>t(id PK, name);</p>

<p>数据为：</p>

<p>1, shenjian</p>

<p>2, zhangsan</p>

<p>3, lisi</p>

<p><img src="https://mmbiz.qpic.cn/mmbiz_png/YrezxckhYOxqYZaEWwXRwibTg8vNtNIPGhicRJvTpNR0lzoZticJ8BLAWEAbMzC9pgZ0yYZ29IdWKekoqiaxuf6Neg/640?wx_fmt=png" alt=""/></p>

<p>此时没有事务未提交，故回滚段是空的。</p>

<p>接着启动了一个事务：</p>

<p>start trx;</p>

<p>delete (1, shenjian);</p>

<p>update set(3, lisi) to (3, xxx);</p>

<p>insert (4, wangwu);</p>

<p>并且事务处于未提交的状态。</p>

<p><img src="https://mmbiz.qpic.cn/mmbiz_png/YrezxckhYOxqYZaEWwXRwibTg8vNtNIPGLSOOJDKXmdHqkgdeXFibUI0bNhuQN0qb0E5BiaR00gwaS0IU7vzz0tSA/640?wx_fmt=png" alt=""/></p>

<p>可以看到：</p>

<p>(1) 被删除前的 (1, shenjian) 作为旧版本数据，进入了回滚段；</p>

<p>(2) 被修改前的 (3, lisi) 作为旧版本数据，进入了回滚段；</p>

<p>(3) 被插入的数据，PK(4) 进入了回滚段；</p>

<p>接下来，假如事务 rollback，此时可以通过回滚段里的 undo 日志回滚。</p>

<p><u>画外音：假设事务提交，回滚段里的 undo 日志可以删除。</u></p>

<p><img src="https://mmbiz.qpic.cn/mmbiz_png/YrezxckhYOxqYZaEWwXRwibTg8vNtNIPGMuEql2dsc2US7uwMaP9fBic9dPeod96CqwcaN6Qd75icNssicNHkaaMzw/640?wx_fmt=png" alt=""/></p>

<p>可以看到：</p>

<p>(1) 被删除的旧数据恢复了；</p>

<p>(2) 被修改的旧数据也恢复了；</p>

<p>(3) 被插入的数据，删除了；</p>

<p><img src="https://mmbiz.qpic.cn/mmbiz_png/YrezxckhYOxqYZaEWwXRwibTg8vNtNIPGry9tyIxsGfql43eEhWoYHg6ibS1S4th1dMjj6JKTwt8XWnIt0iaS71jw/640?wx_fmt=png" alt=""/></p>

<p>事务回滚成功，一切如故。</p>

<p><strong>四、InnoDB</strong> <strong>是基于多版本并发控制的存储引擎</strong></p>

<p>《<a href="http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651961428&amp;idx=1&amp;sn=31a9eb967941d888fbd4bb2112e9602b&amp;chksm=bd2d0d888a5a849e7ebaa7756a8bc1b3d4e2f493f3a76383fc80f7e9ce7657e4ed2f6c01777d&amp;scene=21#wechat_redirect">大数据量，高并发量的互联网业务，一定要使用 InnoDB</a>》提到，InnoDB 是高并发互联网场景最为推荐的存储引擎，根本原因，就是其<strong>多版本并发控制</strong>（Multi Version Concurrency Control, MVCC）。行锁，并发，事务回滚等多种特性都和 MVCC 相关。</p>

<p>MVCC 就是通过 “读取旧版本数据” 来降低并发事务的锁冲突，提高任务的并发度。</p>

<p><strong>核心问题：</strong></p>

<p><strong>旧版本数据存储在哪里？</strong></p>

<p><strong>存储旧版本数据，对 MySQL</strong> <strong>和 InnoDB</strong> <strong>原有架构是否有巨大冲击？</strong></p>

<p>通过上文 undo 日志和回滚段的铺垫，这两个问题就非常好回答了：</p>

<p>(1) 旧版本数据存储在回滚段里；</p>

<p>(2) 对 MySQL 和 InnoDB 原有架构体系冲击不大；</p>

<p>InnoDB 的内核，会对所有 row 数据增加三个内部属性：</p>

<p>(1)<strong>DB_TRX_ID</strong>，6 字节，记录每一行最近一次修改它的事务 ID；</p>

<p>(2)<strong>DB_ROLL_PTR</strong>，7 字节，记录指向回滚段 undo 日志的指针；</p>

<p>(3)<strong>DB_ROW_ID</strong>，6 字节，单调递增的行 ID；</p>

<p><strong>InnoDB</strong> <strong>为何能够做到这么高的并发？</strong></p>

<p>回滚段里的数据，其实是历史数据的快照（snapshot），这些数据是不会被修改，select 可以肆无忌惮的并发读取他们。</p>

<p><strong>快照读</strong>（Snapshot Read），这种<strong>一致性不加锁的读</strong>（Consistent Nonlocking Read），就是 InnoDB 并发如此之高的核心原因之一。</p>

<p>这里的<strong>一致性</strong>是指，事务读取到的数据，要么是事务开始前就已经存在的数据（当然，是其他已提交事务产生的），要么是事务自身插入或者修改的数据。</p>

<p><strong>什么样的 select</strong> <strong>是快照读？</strong></p>

<p>除非显示加锁，普通的 select 语句都是快照读，例如：</p>

<p>select * from t where id&gt;2;</p>

<p>这里的显示加锁，非快照读是指：</p>

<p>select * from t where id&gt;2 <strong>lock in share mode</strong>;</p>

<p>select * from t where id&gt;2 <strong>for update</strong>;</p>

<p>问题来了，这些显示加锁的读，是什么读？会加什么锁？和事务的隔离级别又有什么关系？</p>

<p>本节的内容已经够多了，且听下回分解。</p>

<p><strong>总结</strong></p>

<p>(1) 常见并发控制保证数据一致性的方法有<strong>锁</strong>，<strong>数据多版本</strong>；</p>

<p>(2) <strong>普通锁</strong>串行，<strong>读写锁</strong>读读并行，<strong>数据多版本</strong>读写并行；</p>

<p>(3)<strong>redo 日志</strong>保证已提交事务的 ACID 特性，设计思路是，通过顺序写替代随机写，提高并发；</p>

<p>(4)<strong>undo 日志</strong>用来回滚未提交的事务，它存储在回滚段里；</p>

<p>(5)InnoDB 是基于 <strong>MVCC</strong> 的存储引擎，它利用了存储在回滚段里的 undo 日志，即数据的旧版本，提高并发；</p>

<p>(6)InnoDB 之所以并发高，快照读不加锁；</p>

<p>(7)InnoDB 所有普通 select 都是快照读；</p>

<p><u>画外音：本文的知识点均基于 MySQL5.6。</u></p>

<p>希望大家有收获，下一篇继续深入 InnoDB 的<strong>锁</strong>。</p>

<p>希望通俗的技术文被更多人看到，求帮<strong>转</strong>。</p>

<p>相关文章：</p>

<p>《<a href="http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=2651961428&amp;idx=1&amp;sn=31a9eb967941d888fbd4bb2112e9602b&amp;chksm=bd2d0d888a5a849e7ebaa7756a8bc1b3d4e2f493f3a76383fc80f7e9ce7657e4ed2f6c01777d&amp;scene=21#wechat_redirect">InnoDB，5 项最佳实践，知其所以然？</a>》</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[来自Netflix的系统高可用建议]]></title>
    <link href="http://panlw.github.io/15342609315238.html"/>
    <updated>2018-08-14T23:35:31+08:00</updated>
    <id>http://panlw.github.io/15342609315238.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://www.infoq.com/cn/articles/tips-for-high-availability">http://www.infoq.com/cn/articles/tips-for-high-availability</a></p>
</blockquote>

<p>在过去四年中，Netflix 已从不到 5000 万用户增加到 1.25 亿用户。这种增长给我们带来了伸缩性方面的挑战，但实际上，我们已经设法在这段时间内提高了服务的整体可用性。在这个过程中，我们学到了很多东西，我们也更加明白该如何提升系统的可用性。但天下没有免费的午餐，这些经验来之不易：在出现问题时我们忙成一团，有时候还要处理用户事件。尽管我们还没有完全扫清所有的问题，我们的系统仍然还有很多可以改进的地方，但我们分享的这些经验都是从实战中总结出来的。希望你们能够从中收获点什么，以免在凌晨三点钟收到要你起床处理用户事件的电话。</p>

<p>在 Netflix，我们使用 Spinnaker 作为持续集成和交付的平台。这里讨论的很多最佳实践都已纳入到 Spinnaker 中，这些技巧和最佳实践具有通用性，将帮到任何想要提升系统可用性的人。</p>

<h2 id="toc_0">优先考虑区域部署而不是全球部署</h2>

<p>我们的目标是尽可能提供最佳的客户体验。因此，我们要限制系统变更的影响范围，对变更进行验证，然后将变更推给客户。更具体地说，我们一次只部署一个 AWS 区域，这为我们的生产部署提供了额外的安全保障。我们能够快速地转移受影响的客户流量，这也是我们最重要的四大补救手段之一。</p>

<p>我们还建议在每个区域部署之间对应用程序功能进行验证，并避免在目标区域的高峰时段进行部署。</p>

<p>在 Spinnaker 中，指定部署的目标区域非常简单。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/12111-1533721785047.png"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/12111-1533721785047.png" alt=""/></a>﻿</p>

<h2 id="toc_1">使用红黑部署策略进行生产部署</h2>

<p>在红黑（也称为蓝绿）部署中，新版本的应用程序（红色）在通过健康检查之后立即开始接收流量。在确定红色版本的健康状态之后，之前的（黑色）版本将被禁用，并且不会收到任何流量。如果要回滚，只需要启用以前的版本即可，非常简单。这种模型加快了我们的部署流程，并可以在出现问题时回滚到之前的状态。</p>

<p>要使用 Spinnaker 完成红黑部署，只需要在管道中指定策略（并可选择性地在策略中设置参数），Spinnaker 将负责完成部署。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/12612-1533721785745.png"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/12612-1533721785745.png" alt=""/></a>﻿</p>

<h2 id="toc_2">使用部署窗口</h2>

<p>每当你在部署新版本应用时，都要记住以下两点：首先，你（或你的同事）是否有监控部署，并在必要时进行补救？第二，如果出现了问题，你是否能够尽可能减小影响范围？</p>

<p>我们的流媒体流量遵循相对可预测的模式，大多数人会在晚上打开视频流。因此，我们建议选择工作时段和非高峰时段的部署窗口。</p>

<p>Spinnaker 为此提供了一个界面，让我们可以轻松地指定运行部署管道的日期和时间。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/413-1533721787411.jpeg"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/413-1533721787411.jpeg" alt=""/></a>﻿</p>

<h2 id="toc_3">确保不要在非工作时段或周末自动触发部署</h2>

<p>部署窗口也适用于自动触发的事件。在 Spinnaker 中，可以使用 cron 表达式作为管道触发器，这也可能是一个冒险的策略：有些 cron 表达式可能会在非工作时段或周末执行管道，但这不是我们所期望的。无论你使用哪一种自动化机制，都要确保任何自动触发的管道都可以在无人值守的模式下运行。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/8914-1533721784600.png"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/8914-1533721784600.png" alt=""/></a>﻿</p>

<h2 id="toc_4">启用 Chaos Monkey</h2>

<p>Chaos Monkey 由 Netflix 创建并开源，是我们混沌工程工具套件的一部分。Chaos Monkey 以不可预测的方式随机终止生产环境中的实例，以此来增强服务，让服务具备应对单实例故障的弹性能力。如果某些服务不具备弹性能力，Chaos Monkey 将会暴露出它们的漏洞，服务所有者就可以在这些漏洞演变成影响用户的事故之前修复它们。在 Netflix，生产环境中的所有服务都应该启用 Chaos Monkey，在 Chaos Monkey 终止应用程序实例时，服务所有者不应该检测到任何问题。</p>

<p>﻿﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/7415-1533721786316.png"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/7415-1533721786316.png" alt=""/></a></p>

<h2 id="toc_5">在将代码推送到生产环境之前使用各种测试和金丝雀分析来验证代码</h2>

<p>实现快速部署的关键是在部署之前自动验证新版本的软件。理想情况下，所有必要的测试套件都应该在没有人工干预的情况下运行。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/5616-1533721787677.png"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/5616-1533721787677.png" alt=""/></a>﻿</p>

<p>此外，我们建议使用金丝雀分析。金丝雀分析是一种通过实时流量来验证服务变更的有效方法。最近我们开源了内部工具 Kayenta，它可以轻松集成到 Spinnaker 中，并结合人工判断，成为放开所有生产流量之前的最后一道门槛。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/5217-1533721786866.png"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/5217-1533721786866.png" alt=""/></a>﻿</p>

<h2 id="toc_6">必要的人工干预</h2>

<p>尽可能使用自动化，但在必要的时候也需要人工干预。例如，在将新版本推向生产环境之前需要检查金丝雀运行的结果。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/4618-1533721785369.png"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/4618-1533721785369.png" alt=""/></a>﻿</p>

<h2 id="toc_7">在部署时尽可能只用已经测试过的东西</h2>

<p>既然你已经对新版本进行了大量的测试和验证，我们强烈建议你在进行生产环境部署时只用测试过的东西。对于我们来说，我们更倾向于从测试环境中复制经过验证的镜像，而不是重新构建新的镜像。</p>

<h2 id="toc_8">定期检查联系人设置</h2>

<p>有时候，为了确保应用程序的可用性，你所要做的其实很简单。如果你的应用程序会出问题，并且很可能会在某个时间点出问题，那么此时最重要的是找到能解决问题的人。因此，请定期检查你的联系人设置，这样可以确保在发生事故时能够迅速找到解决问题的人。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/3819-1533721783682.png"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/3819-1533721783682.png" alt=""/></a>﻿</p>

<p>Spinnaker 提供了一个 “Page application owner” 按钮，请确保这里配置的信息是最新的，这样就不会在发生问题时找错人。</p>

<h2 id="toc_9">知道如何快速回滚部署</h2>

<p>即使有可靠的测试、金丝雀和其他验证过程，将某些东西部署到生产环境中仍然会出现问题。也许这是一种由竞态条件导致的罕见错误，只会在达到一定规模时才发生。但无论是何种情况，最重要的是你要知道在必要时如何快速恢复到之前正常的状态。</p>

<p>在 Spinnaker 中，如果应用程序的新版本出现问题，可以通过 “Server Group” 下的 “Rollback” 选项进行回滚。回滚将启用你选择的 ASG（通常是之前的），并禁用发生故障的 ASG。Spinnaker 还支持创建可在发生管道故障时执行或通过手动触发的回滚管道。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/320-1533721786579.jpeg"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/320-1533721786579.jpeg" alt=""/></a>﻿</p>

<h2 id="toc_10">如果实例运行不正常，将部署视为失败</h2>

<p>多年来，有几次我们在部署成功后感觉状态不对，实例起来了，但不能正常处理流量。“成功” 的部署给我们造成了一种假象，当一个关键的服务运行不正常时，请求很快会堆积起来，有时会导致重试雪崩，造成各种各样的破坏。因此，当实例运行不正常时，要将部署视为失败。</p>

<p>Spinnaker 提供了一种灵活的方法用于关联实例的健康状况。当一个实例不健康时，Spinnaker 会将其标注出来，更重要的是，不健康的实例将收不到流量。如果 ASG 中的所有实例都不健康，Spinnaker 会将部署视为失败。Spinnaker 还用不同的颜色来标记实例的状态，如启动中、等待发现、不健康和健康，如下所示。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/8221-1533721786054.png"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/8221-1533721786054.png" alt=""/></a>﻿</p>

<h2 id="toc_11">在进行自动部署时，需要通知团队有关部署的情况</h2>

<p>让人们知道部署已成功进入生产环境，这对成功的运维来说至关重要。在出现问题时，需要知道发生了哪些变更以及这些变更是在什么时候发生的。因此，在进行自动部署时，需要通知团队，让他们密切关注服务的健康状况。在 Netflix，我们使用 Slack 发送通知。在 Spinnaker 中，管道可以在部署完成时通知相应的 Slack 频道。</p>

<p>﻿<a href="https://s3.amazonaws.com/infoq.content.live.0/articles/tips-for-high-availability/zh/resources/6422-1533721787145.png"><img src="https://res.infoq.com/articles/tips-for-high-availability/zh/resources/6422-1533721787145.png" alt=""/></a>﻿</p>

<h2 id="toc_12">自动化非典型部署，而不是进行一次性手动部署</h2>

<p>每个工程师都为非典型情况编写过一次性脚本。而当这类 “一次性” 情况再次发生时，团队的其他成员并不知道写脚本的那个工程师在脚本里都干了什么，因为脚本本来是打算运行一次就丢掉的！很多人都遇到过这种情况。</p>

<p>管道是自动执行一系列步骤的有效手段，即使有些步骤并不会每天都执行。例如，一个用于紧急推送的管道，它使用参数作为控制执行的条件（比如跳过部署窗口）。</p>

<p>不要忘记定期测试非关键场景的非典型（和典型）部署管道！</p>

<h2 id="toc_13">使用先决条件验证预期状态</h2>

<p>现如今，系统经常发生变化是常态。在 Netflix，我们的数百个微服务在不断发生变化。做出无根据的假设（比如假设其他系统的状态）是很危险的。我们现在使用先决条件来确保在部署新代码或进行其他变更时假设仍然有效。这对于长时间执行的管道（可能是因为人工判断或部署窗口造成延迟）来说尤为重要。我们可以在发生潜在的破坏性操作之前使用先决条件来验证预期的状态。</p>

<h2 id="toc_14">结论</h2>

<p>这篇文章总结了我们多年来在 Netflix 积累的各种技巧和最佳实践。我们的方法是尽可能围绕这些最佳实践构建工具。我们始终把提高服务可用性作为目标。在真正需要人工干预时，我们才会介入，否则就不插手。工程师的时间用在了那些可以提高可用性的任务上，而在不需要他们参与的情况下，他们可以专注其他事情。</p>

<p>英文原文：<a href="https://medium.com/@NetflixTechBlog/tips-for-high-availability-be0472f2599c">https://medium.com/@NetflixTechBlog/tips-for-high-availability-be0472f2599c</a></p>

<p><input type="hidden"></p>

<p>相关内容</p>

<h3 id="toc_15"><a href="http://www.infoq.com/cn/articles/how-netflix-does-failovers-7-minutes-flat?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_undefined_clk">Netflix 如何在 7 分钟内完成失效备援</a></h3>

<h3 id="toc_16"><a href="http://www.infoq.com/cn/articles/mysql-high-availability-at-github?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_undefined_clk">GitHub 的 MySQL 高可用性实践</a></h3>

<h3 id="toc_17"><a href="http://www.infoq.com/cn/articles/netflix-what-happens-when-you-press-play?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_undefined_clk">Netflix: 当你按下 “播放” 的时候发生了什么？</a></h3>

<h3 id="toc_18"><a href="http://www.infoq.com/cn/news/2018/05/netflix-zuul2?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_undefined_clk">Netflix 正式开源其 API 网关 Zuul 2</a></h3>

<h3 id="toc_19"><a href="http://www.infoq.com/cn/presentations/the-practice-of-open-source-distributed-monitoring-cat-system?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_undefined_clk">开源分布式监控 CAT 系统的高可用实践</a></h3>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[5 Reasons and 101 Bugfixes – Why You Should Use Hibernate 5.3]]></title>
    <link href="http://panlw.github.io/15342604876749.html"/>
    <updated>2018-08-14T23:28:07+08:00</updated>
    <id>http://panlw.github.io/15342604876749.html</id>
    <content type="html"><![CDATA[
<p>Hibernate 5.3 is available for a little more than 3 months now, and last week, the team released the <a href="http://in.relation.to/2018/07/24/hibernate-orm-533-final-out/">3rd maintenance release</a>. So, it’s about time to take a closer look at the new version.</p>

<p>In addition to more than 100 bug fixes, Hibernate 5.3 includes a few features and improvements that might motivate you to update your current project.</p>

<h2 id="toc_0">Improved Memory consumption</h2>

<p>Let’s start with probably the best reason to update to Hibernate 5.3: It consumes less memory than the previous versions.</p>

<p>The improvement was triggered by an interesting discussion in the <a href="https://discourse.hibernate.org/t/batch-fetch-style-recommendations/631">Hibernate forum</a>. A user reported that he tried to migrate his application from Hibernate 3.6 to 5.3. During the migration, he recognized that the memory consumption of Hibernate’s SessionFactory went up to 950MB.</p>

<p>The issue was caused by the size and number of <u>EntityLoader</u>s that Hibernate instantiated. It was fixed in 2 steps:</p>

<ol>
<li> <a href="https://hibernate.atlassian.net/browse/HHH-12556">HHH-12556</a> – Similar <u>EntityLoader</u>s now share some internal data structures. This reduced the memory consumption of the application by ~50%.
The fix was backported to Hibernate 5.2.18. So, if you’re using Hibernate 5.2 and don’t want to upgrade to 5.3, you should at least update to 5.2.18.</li>
<li> <a href="https://hibernate.atlassian.net/browse/HHH-12558">HHH-12558</a> – Hibernate supports a bunch of different lock modes with specific loaders. In the past, it instantiated all loaders eagerly. Hibernate 5.3 only instantiates the 2 most common ones and loads all others lazily.</li>
</ol>

<p>At the end of the discussion, the user who reported the issue wrote that the improved Hibernate version only used ~ 250MB. So, for his application, these two changes reduced the memory consumption by ~70%.</p>

<p>I obviously can’t promise that it will be equally effective for your project. However, the reported improvement is so enormous that you should at least give it a try.</p>

<h2 id="toc_1">JPA 2.2 compliance</h2>

<p>Hibernate 5.3.0 is the first version that’s fully compliant with JPA 2.2. However, because the support for all the interesting features was already added in Hibernate 5.0, 5.1 and 5.2, and I already wrote extensive tutorials about all of them, I will not dive any deeper into this topic.</p>

<p>If you’re not already familiar with JPA 2.2, you can read more about it in the following articles:</p>

<ul>
<li>  <a href="https://www.thoughts-on-java.org/map-date-time-api-jpa-2-2/">How To Map The Date And Time API with JPA 2.2</a></li>
<li>  <a href="https://www.thoughts-on-java.org/get-query-results-stream-hibernate-5/">How to get query results as a Stream with Hibernate 5.2</a> (please note that Hibernate now also offers the <u>getResultStream</u> method)</li>
<li>  <a href="https://www.thoughts-on-java.org/jpa-2-2s-new-stream-method-and-how-you-should-not-use-it/">JPA 2.2’s new getResultStream() method and how you should NOT use it</a></li>
<li>  <a href="https://www.thoughts-on-java.org/jpa-2-2-repeatable-annotations/">JPA 2.2 Introduces @Repeatable Annotations</a></li>
</ul>

<h2 id="toc_2">Small Improvements</h2>

<p>Learn more about primary keys<meta itemprop="thumbnailUrl" content="https://www.thoughts-on-java.org/wp-content/plugins/wp-youtube-lyte/lyteThumbs.php?origThumbUrl=%2F%2Fi.ytimg.com%2Fvi%2Fqn9SbW44rQ8%2Fmaxresdefault.jpg"><meta itemprop="embedURL" content="https://www.youtube.com/embed/qn9SbW44rQ8"><meta itemprop="uploadDate" content=""></p>

<p><img src="https://i.ytimg.com/vi/qn9SbW44rQ8/0.jpg" alt=""/><br/>
Watch this video on YouTube<meta itemprop="description" content="">](<a href="https://youtu.be/qn9SbW44rQ8">https://youtu.be/qn9SbW44rQ8</a>)</p>

<p><a href="https://youtu.be/qn9SbW44rQ8"></a><a href="http://bit.ly/2cUsid8">Follow me on YouTube</a> to not miss any new videos.</p>

<h3 id="toc_3">Implicit ID generator definitions</h3>

<p>If you <a href="https://www.thoughts-on-java.org/jpa-generate-primary-keys/">generate your primary key values</a>, you’re probably aware of Hibernate’s <u>@SequenceGenerator</u> and <u>@TableGenerator</u> annotations. You can use them to define which sequence or table Hibernate shall use to generate the primary key value.</p>

<p>Here is a typical example of a primary key mapping that tells Hibernate to use the database sequence <u>author</u>seq_ to generate the unique primary key values.</p>

<pre><code class="language-java">@Entity
public class Author {
 
    @Id
    @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = &quot;author_seq&quot;)
    @SequenceGenerator(name=&quot;author_seq&quot;, sequenceName = &quot;author_seq&quot;)
    private Long id;
 
    ...
}
</code></pre>

<p>The mapping definition consists of 2 parts:</p>

<ol>
<li> The <u>@GeneratedValue</u> annotation defines which generation strategy Hibernate shall use and references a custom generator.</li>
<li> The <u>@SquenceGenerator</u> annotation specifies the generator and tells Hibernate the name of the sequence you want to use.</li>
</ol>

<p>As you can see in the code snippet, I use the same name for the generator and the database sequence. That’s a pretty common and verbose mapping.</p>

<p>If your mapping looks the same, I have good news for you: You no longer need to define the generator if your database sequence or table has the same name as your <u>@SequenceGenerator</u> or <u>@TableGenerator</u>.</p>

<p>That enables me to shorten the previous mapping and to remove the <u>@SequenceGenerator</u> definition.</p>

<pre><code class="language-java">@Entity
public class Author {
 
    @Id
    @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = &quot;author_seq&quot;)
    private Long id;
 
    ...
}
</code></pre>

<h3 id="toc_4">Support for MySQL 8 SKIP LOCKED and NOWAIT</h3>

<p>MySQL 8.0.1 added the SKIP LOCKED and NOWAIT feature to provide different options to handle locked rows during read-operations. The MySQL Server team explained them in great detail on their blog: <a href="https://mysqlserverteam.com/mysql-8-0-1-using-skip-locked-and-nowait-to-handle-hot-rows/">MySQL 8.0.1: Using SKIP LOCKED and NOWAIT to handle hot rows.</a></p>

<p>Here’s a quick description of both features:</p>

<ul>
<li>  SKIP LOCKED enables you to perform a non-deterministic read that skips all locked rows. That means that locked rows are missing in your result set.</li>
<li>  If you require a deterministic read but don’t want to wait for the locks to be released, you can use the NOWAIT feature. It causes your query to fail immediately if any records in your result set are locked.</li>
</ul>

<p>The <u>MySQL8Dialect</u> included in Hibernate 5.3 supports both these features so that you can use them in your queries.</p>

<p>Learn more about AttributeConverter<meta itemprop="thumbnailUrl" content="https://www.thoughts-on-java.org/wp-content/plugins/wp-youtube-lyte/lyteThumbs.php?origThumbUrl=%2F%2Fi.ytimg.com%2Fvi%2FTIeeRif4ocg%2Fmaxresdefault.jpg"><meta itemprop="embedURL" content="https://www.youtube.com/embed/TIeeRif4ocg"><meta itemprop="uploadDate" content=""></p>

<p><img src="https://i.ytimg.com/vi/TIeeRif4ocg/0.jpg" alt=""/><br/>
Watch this video on YouTube<meta itemprop="description" content="">](<a href="https://youtu.be/TIeeRif4ocg">https://youtu.be/TIeeRif4ocg</a>)</p>

<p><a href="https://youtu.be/TIeeRif4ocg"></a><a href="http://bit.ly/2cUsid8">Follow me on YouTube</a> to not miss any new videos.</p>

<h3 id="toc_5">Apply AttributeConverter when calling a function</h3>

<p><a href="https://www.thoughts-on-java.org/jpa-21-how-to-implement-type-converter/">AttributeConverters</a> provide a standardized, easy way to define the mapping of a Java type. You can either use them to add support for unsupported classes or to customize the <a href="https://www.thoughts-on-java.org/jpa-21-type-converter-better-way-to/">mapping of an already supported Java type</a>.</p>

<p>The following code snippet shows an example from my <a href="https://www.thoughts-on-java.org/jpa-tips-map-duration-attribute/">JPA Tip: How to map a Duration attribute</a>. JPA 2.2 doesn’t provide a mapping for _java.time.Duration_ objects. If you want to map such an object, you can use this <u>AttributeConverter</u> to map it to a <u>Long</u>.</p>

<pre><code class="language-java">@Converter(autoApply = true)
public class DurationConverter implements AttributeConverter&lt;Duration, Long&gt; {
     
    Logger log = Logger.getLogger(DurationConverter.class.getSimpleName());
 
    @Override
    public Long convertToDatabaseColumn(Duration attribute) {
        log.info(&quot;Convert to Long&quot;);
        return attribute.toNanos();
    }
 
    @Override
    public Duration convertToEntityAttribute(Long duration) {
        log.info(&quot;Convert to Duration&quot;);
        return Duration.of(duration, ChronoUnit.NANOS);
    }
}
</code></pre>

<p>After you applied the AttributeConverter to an attribute or automatically applied them to all attributes of a specific type, it gets transparently used:</p>

<ul>
<li>  during all lifecycle state transitions,</li>
<li>  to map the result of a query and</li>
<li>  when used in path expressions in a <a href="http://JPQL">JPQL</a> or CriteriaQuery.</li>
</ul>

<p>However, for whatever reason, the usage of converted attribute values as function parameters is explicitly undefined.</p>

<p>Previous Hibernate versions didn’t convert the attribute value if you referenced it as a function parameter. This changed with Hibernate 5.3.2. It now converts the attribute value before it provides it as a function parameter.</p>

<h2 id="toc_6">Support for Java 9 and preparations for Java 11</h2>

<p>Beginning with Hibernate 5.3.0, all Hibernate modules specify a <a href="https://blog.codefx.org/java/java-module-system-tutorial/">Java 9 module</a> name following the pattern _org.hibernate.orm.${module-name}_, e.g., the hibernate-core module defines the name _org.hibernate.orm.core._</p>

<p>The Hibernate team also updated the dependencies, prepared the build process and run their test suite with the latest JDK 11 build. So, we can hope for a smooth transition to JDK11.</p>

<h2 id="toc_7">Conclusion</h2>

<p>Should you update to Hibernate 5.3?</p>

<p>You probably already know my answer. It’s a clear yes! Especially the improved memory consumption is a great reason to do the update.</p>

<p>However, please keep in mind that every update has its risks and that you obviously shouldn’t update any project dependency without testing it carefully.</p>

<p>So, what about you? Did you already update your application to use Hibernate 5.3 or will you update it in the near future?</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java 性能优化指南，及唯品会的实战]]></title>
    <link href="http://panlw.github.io/15340923334107.html"/>
    <updated>2018-08-13T00:45:33+08:00</updated>
    <id>http://panlw.github.io/15340923334107.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>原文出处： <a href="http://calvin1978.blogcn.com/articles/javatuning.html">江南白衣</a></p>
</blockquote>

<p>来了唯品会一年多，不少时间花在与服务化框架、业务应用的性能的缠斗上。</p>

<p>前几天正好趁着中生代社区的<a href="http://www.hdb.com/party/bajzu.html">十月十城技术沙龙</a>，把脑海中<strong>关于性能优化的记忆</strong>全部理了一遍…. 讲完回家，又本着认真严谨的态度再理了一遍，终于成为现在这份 <strong>66 页的 PPT</strong>。</p>

<p>各位客官，1.4 版的内容略有增减，超链接也已修好: <a href="http://files.blogcn.com/wp06/M00/00/ED/CpCCFVgRySAAAAAAAC42ozG7w4w912.pdf">《Java 性能优化指南 V1.4.pdf》</a></p>

<p><a href="http://files.blogcn.com/wp04/M00/08/02/CoFCGVgHnLkAAAAAAAETKzIbY-c369.jpg" title="幻灯片01"><img src="http://files.blogcn.com/wp04/M00/08/02/CoFCGVgHnLkAAAAAAAETKzIbY-c369.jpg" alt=""/></a></p>

<h3 id="toc_0">范围</h3>

<p>应用性能，受操作系统参数，三方类库选择，数据库查询，甚至压测工具如 JMeter 本身调优的影响。</p>

<p>本次分享只着重在三方面：</p>

<ul>
<li>  JVM 的调优</li>
<li>  代码的调优</li>
<li>  定位性能问题的工具</li>
</ul>

<p><a href="http://files.blogcn.com/wp06/M00/00/ED/CpCCFVgHnPMAAAAAAADXW3vnM8I951.jpg" title="幻灯片03"><img src="http://files.blogcn.com/wp06/M00/00/ED/CpCCFVgHnPMAAAAAAADXW3vnM8I951.jpg" alt=""/></a></p>

<p><a href="http://files.blogcn.com/wp02/M00/08/EF/CpAZrVgHnSkAAAAAAACnv2fHcK0833.jpg" title="幻灯片04"><img src="http://files.blogcn.com/wp02/M00/08/EF/CpAZrVgHnSkAAAAAAACnv2fHcK0833.jpg" alt=""/></a></p>

<h3 id="toc_1">基本原则</h3>

<p>网上如此多新旧不一的资料，这么多肆意传播亦真亦错的观点，怎么办呢？</p>

<ol>
<li> 多看一些靠谱的资料，问一些靠谱的人。</li>
<li> 怀疑一切，微基准测试一切，诚意推荐 JMH。</li>
<li> 看 JDK 代码，看一切代码。</li>
</ol>

<p><a href="http://files.blogcn.com/wp04/M00/00/D1/CpCCFVgHnewAAAAAAAC4WC08BEA045.jpg" title="幻灯片06"><img src="http://files.blogcn.com/wp04/M00/00/D1/CpCCFVgHnewAAAAAAAC4WC08BEA045.jpg" alt=""/></a></p>

<p><a href="http://files.blogcn.com/wp06/M00/04/D0/CoFCGVgHnjEAAAAAAADZwUFf8O8583.jpg" title="幻灯片07"><img src="http://files.blogcn.com/wp06/M00/04/D0/CoFCGVgHnjEAAAAAAADZwUFf8O8583.jpg" alt=""/></a></p>

<p><a href="http://files.blogcn.com/wp02/M00/08/EF/CpAZrVgHnokAAAAAAACCHhzO17w957.jpg" title="幻灯片08"><img src="http://files.blogcn.com/wp02/M00/08/EF/CpAZrVgHnokAAAAAAACCHhzO17w957.jpg" alt=""/></a></p>

<p><a href="http://files.blogcn.com/wp04/M00/08/02/CoFCGVgHn6YAAAAAAADGggFLBi0755.jpg" title="幻灯片09"><img src="http://files.blogcn.com/wp04/M00/08/02/CoFCGVgHn6YAAAAAAADGggFLBi0755.jpg" alt=""/></a></p>

<h3 id="toc_2">JVM 优化</h3>

<p>首先，JIT 入门知识；然后，JVM 参数的简介；再然后，最头痛的 GC 问题的处理。</p>

<p><a href="http://files.blogcn.com/wp06/M00/00/ED/CpCCFVgHoB4AAAAAAACR8THhKLc792.jpg" title="幻灯片21"><img src="http://files.blogcn.com/wp06/M00/00/ED/CpCCFVgHoB4AAAAAAACR8THhKLc792.jpg" alt=""/></a></p>

<p><a href="http://files.blogcn.com/wp06/M00/00/ED/CpCCFVgHqVoAAAAAAADQAgCkMkE356.jpg" title="幻灯片30"><img src="http://files.blogcn.com/wp06/M00/00/ED/CpCCFVgHqVoAAAAAAADQAgCkMkE356.jpg" alt=""/></a></p>

<h3 id="toc_3">代码优化</h3>

<p>代码优化，两大方向一是面向 GC 的编程，二是并发与锁，然后再来聊聊其他。</p>

<p><a href="http://files.blogcn.com/wp02/M00/08/EF/CpAZrVgHoGwAAAAAAADk5iKpsPw033.jpg" title="幻灯片34"><img src="http://files.blogcn.com/wp02/M00/08/EF/CpAZrVgHoGwAAAAAAADk5iKpsPw033.jpg" alt=""/></a></p>

<h3 id="toc_4">问题定位工具集</h3>

<p>黑盒调优是最不可靠的，推荐线下用 JMC，线上用 Btrace 定位问题。</p>

<p><a href="http://files.blogcn.com/wp04/M00/00/D1/CpCCFVgHoZMAAAAAAAC3Llc-Yyw623.jpg" title="幻灯片51"><img src="http://files.blogcn.com/wp04/M00/00/D1/CpCCFVgHoZMAAAAAAAC3Llc-Yyw623.jpg" alt=""/></a></p>

<h3 id="toc_5">特别鸣谢</h3>

<p>感谢 R 大 ， 日常三更半夜跨洋热心解答各种 JVM 问题。</p>

<p>感谢 Chembo(国钦)，对 PPT 的美化。</p>

<h3 id="toc_6">完整 PPT 下载</h3>

<p><a href="http://files.blogcn.com/wp06/M00/00/ED/CpCCFVgRySAAAAAAAC42ozG7w4w912.pdf">《Java 性能优化指南 V1.4.pdf》</a>, by 江南白衣, 超链接修正版。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[干货 | 余额宝大规模服务化的技术创新]]></title>
    <link href="http://panlw.github.io/15340916506798.html"/>
    <updated>2018-08-13T00:34:10+08:00</updated>
    <id>http://panlw.github.io/15340916506798.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/41646747">https://zhuanlan.zhihu.com/p/41646747</a> 一个不太可爱的女孩子</p>

<p>本文作者：李鑫，天弘基金移动平台部任技术总监兼首架，主要负责天弘移动直销平台的整体技术架构和技术团队管理。<br/>
在此之前，在华为的中间件技术团队，任六级技术专家，主导了多款华为软件的云计算产品的规划、设计、构建及落地工作，包括 APaaS、ASPaaS、服务治理平台、分布式服务调测框架等几款产品；更早之前，在当当网的运作产品中心做技术负责人，主要负责电商中后台的仓储、物流、客服等系统的重构优化及技术管理工作。</p>

<p>个人从业十多年，做过很多技术方向，也是从项目版本研发慢慢到中间件研发，再到平台研发，涉及的技术领域比较多。在并行计算、大规模分布式服务及治理、中间件云化及服务化（PaaS）、APM 监控、基础开发平台、数据集成等领域都有些技术积累，如果大家在这些领域有疑问或好的建议，欢迎加我的微信号共同探讨。</p>
</blockquote>

<p><img src="https://pic3.zhimg.com/v2-448a9367fbd6d700321a85583097d054_r.jpg" alt=""/></p>

<p>七月初，李鑫在 ArchSummit 深圳大会上做了题为《余额宝大规模服务化的技术创新》的分享，现场反响热烈。现将 PPT 和讲稿整理出来，分享给大家，希望能给大家一些启发，也欢迎留言讨论。</p>

<p><img src="https://pic2.zhimg.com/80/v2-fa07d74992a0f5f565dbfd12a5391aa5_hd.jpg" alt=""/></p>

<p>分享分为三部分：</p>

<ul>
<li>  余额宝的整体架构变迁历史；</li>
<li>  讲一讲我们是如何进行基金实时销售平台及大数据平台的服务化改造的；</li>
<li>  “服务化” 对我们运维及研发模式的影响及我们的应对策略；</li>
</ul>

<p>余额宝的整体架构变迁历史</p>

<p><img src="https://pic4.zhimg.com/80/v2-bc3a8986b6158bf772dd6b2e711a40e2_hd.jpg" alt=""/></p>

<p>余额宝本质上是一支货币基金，它的背后是天弘的增利宝基金。由于和支付宝的关系，它既是理财产品，又是支付产品，理财和支付的双重属性，再加上互联网产品所特有的极简的用户体验，让余额宝一经推出，迅速成为了 “爆款”，短短五年内获得了一个惊人的发展。可以毫不夸张的说，余额宝的出现，开启了中国的全民理财时代！</p>

<p><img src="https://pic2.zhimg.com/80/v2-d99a3a7f381fc64de0f3d43c07146cea_hd.jpg" alt=""/></p>

<p>为了适应业务的爆炸式增长，5 年来余额宝的技术架构做了 4 次大的变更，每次技术变更的背后，都承载了天弘技术团队对系统规模、可扩展性及升级成本的综合考量和平衡之道。</p>

<p><img src="https://pic4.zhimg.com/80/v2-02129e0f6899ad2c991f93f0383154b2_hd.jpg" alt=""/></p>

<p><strong>余额宝上线之初，解决的是 “从无到有” 的问题。</strong><br/>
当时没有其它类似的互联网金融产品可以做参考，我们采用了传统的典型企业级金融架构。由于采用的是自建 IDC 机房的方式，我们用硬件负载均衡设备将交易请求接入进来，前端是由两台 weblogic 构成的小型的前置处理集群，请求被稍做处理之后，即被送到后端由金正的基金交易中间件构建的集群做业务处理，其中 KCXP 和 KCBP 是金证公司的消息中间件和业务中间件，业务数据存储采用的是两台 Oracle 数据库服务器构建的一主一备的小集群，这个是线上库，同时，还有一个同样架构的历史库服务。硬件方面采用的都是小型机设备，数据备份则采用 EMC 的产品。</p>

<p>这是典型的 IOE 架构，全套的商用软硬件配置，成本很高。架构体系虽然很多环节都采用了集群的方式，但更多的是使用主备模式，而不是负载均衡的分布式模式，因此系统的单点资源负载压力较大，尤其是数据库，基本上就是单库模式（另一个库是备库），扩展性较差。<br/>
当时的系统容量设计上限是能支持千万级用户，传统基金销售模式是走代销机构的方式，投资基金用户也多以理财为目的。所以每天可能处理的帐户开户也就是几万到几十万的规模。由于余额宝对接是支付宝，支付宝的用户规模达到千万级，这是设计产品时对需求的定位。按照预估，这个设计容量怎么都能扛个几年。结果，我们低估了余额宝的热度，上线短短 10 天左右，新开户数已经突破 100W 了，按这个速度，3 个月左右数据库容量上线就要被突破。事实也确实如此，我们的客户量三个月就达到一千万，余额宝一期系统的生命周期只有三个月！</p>

<p><img src="https://pic2.zhimg.com/80/v2-5816971a16e8e2b907617e72c69a7da4_hd.jpg" alt=""/></p>

<p>所以一期系统一上线，团队就不得不开始考虑扩容，计划将容量扩充 30~50 倍，计算规模也同步增加。如果还是采用一期系统的纯商用软硬件的模式进行横向扩展的话，成本要达到 1~2 个亿，这样的成本对于当时天弘这样一家小型基金公司而言，是不可负担之重！因此，在阿里的建议下，我们决定整体上云。</p>

<p>当时做出这个决定的压力还是非常大的，因为当时没有任何一家金融公司和基金公司这么玩，我们成了第一个吃螃蟹的人。但在巨大的成本压力之下，我们走出了这一步，这就是余额宝 2.0！</p>

<p>余额宝 2.0 的架构中用阿里云上的软负载均衡 SLB 替换了硬件负载均衡；用阿里云上的虚拟计算单元 ECS 替换小型机成为前置服务及中间件服务的服务器；用阿里云的 web 服务替换了前置服务器上的 weblogic。</p>

<p>最大的一个变化是数据库层面，原来的 Oracle 单库被替换成了阿里云上的一个 50 个节点的 RDS 集群，实际上就是进行了分库分表的拆分，经过测算，需要使用 50 组业务节点，但在拆分时，考虑到扩展性，并未简单地拆分成 50 份，而是根据用户帐号 ID 作为分片主键将核心业务表拆分成 1000 份，然后每个节点处理 20 份数据（物理子表）。这样做的好处是将来如果系统遇到瓶颈，需要扩容时，不需要对拆分算法进行修改，而且数据平均迁移时只需要以库为级别进行，从而避免了拆表。</p>

<p>上云后，不仅数据库总容量有了几十倍的提升，交易处理效率也从一期的 120W 笔 / 小时提升到了近 2000W 笔 / 小时；最大清算时间从之前的 7 个多小时降低到了不到 2 个小时；而总成本，才增加了不到 1 倍。所以，上云对我们系统整体效率的提升和成本的降低有非常明显的作用。</p>

<p><img src="https://pic4.zhimg.com/80/v2-6413443e5520ec8dfcae02e4bc97e5bd_hd.jpg" alt=""/></p>

<p>余额宝 2.0 的架构稳定运行了近 3 年，中间经历了几次小的升级优化，有力支撑了这个过程中的各种业务创新，但也在支撑业务快速发展中埋下了一些 “坑”。</p>

<p>2016 年，我们决定对系统进行一次大升级。这次升级的主要基调就是 “业务逻辑重构，优化清算流程”，这就是余额宝 3.0！</p>

<p>这一阶段的业务逻辑复杂度要远远高于 3 年前，因此 3.0 的架构中，计算单元比 2.0 有了明显的扩充。由于数据库前期预留的 buffer 比较大，并没有成为本阶段的瓶颈，依然维持了 50 个节点的规模。</p>

<p>这次升级之后，总体计算能力有了较大幅度的提高。处理效率比起 2.0 的时候增长了 2 倍多，也支撑了 2016 年春节期间日交易 4 亿多笔的峰值。但是，清算时间比 2.0 时期有较大增长，这成了系统的一个 “隐患”。</p>

<p><img src="https://pic1.zhimg.com/80/v2-ffb278a398ee7a6d383025d3e579863f_hd.jpg" alt=""/></p>

<p>2017 年，为了配合支付宝拓宽线下支付场景，并将业务推广覆盖到三、四线城市，同时，也要解决清算时间过长的隐患，我们规划了余额宝 4.0 的升级。</p>

<p>这一阶段的系统规模已经很大了，如果还是按 3.0 的架构进行横向扩充的话，成本将呈线性增长。经过综合考量，决定在升级前，先优化单节点的处理性能，提高效率及负载后再扩容，以降低总体的升级成本。</p>

<p>因此，这次升级首先将直销和代销业务合二为一，同一台计算单元既处理直销业务，也处理代销业务，提高了单点的处理效率。在此基础上，再进行扩容，将计算单元从 340 节点扩充到 480 节点，数据库扩容 4 倍。通过这两步优化及扩充动作，最终系统的容量及计算能力均有了 4~8 倍的提高，这套新的架构支撑我们平稳度过了 2017 年双十一及春节的交易高峰。</p>

<p>看到这里，大家可能会有疑问：一般在系统服务化改造中，服务是会被拆的越来越细，为什么我们反其道而行，反而对服务进行了整合？这是因为，余额宝发展到现在，业务模式已经比较成熟，通过细粒度的服务模态来保证可扩展性的需求已经不是那么强烈；另一方面，系统规模庞大，扩容的成本成为重点考虑因素；综合这两方面的考量，适当增加单点的复杂度，可以降低整体成本。</p>

<p><img src="https://pic4.zhimg.com/80/v2-49d8eaa19b1a017f36edd9ae65199acb_hd.jpg" alt=""/></p>

<p>目前，针对余额宝这单只基金已经建立起了一套完整的技术生态体系，它的核心是余额宝的产品、帐号、交易、清算等模块，在结合实时调用和文件交互两套接口的基础上，构建了电商大数据的分析体系及一系列辅助支撑系统。同时，余额宝系统和其它第三方系统也有大量的交互，包括支付宝、监管、直代销渠道等等。</p>

<p>我们是如何进行基金实时销售平台及大数据平台的服务化改造的<br/>
余额宝系统的建设直接锻炼了天弘的技术团队，让我们明白了大型互联网应用是一个什么样的玩法，这也直接推动了天弘自有的基金直销平台的服务化改造。接下来，我将从基金实时交易平台及大数据平台的服务化改造这两方面来对此分别做详细介绍。</p>

<p><img src="https://pic1.zhimg.com/80/v2-f2286374d36cbd661878e12ee089f9de_hd.jpg" alt=""/></p>

<p><strong>在开始这块的内容之前，先简单的给大家介绍一下基金公司的业务。</strong><br/>
基金公司最主要的就是 “买卖” 基金，我们从直销和代销渠道把交易请求 “接” 进来，在我们的核心交易系统进行申购、认购、定投、赎回、转换等等操作，这个过程里，会涉及与支付渠道、银行等一系列的交付；同时，还有大量的清结算和 TA 清算，这个过程里，还要和银证监会、中登等一系列监管机构有数据上的交互。聚拢过来的巨量的资金会被统一管控、并投入到股市、债市、货币市场等投资市场去赚钱收益。围绕这个业务还有相应的投研、基金产品管理、风控、客服等中后台的业务支持。<br/>
以上，就是基金公司的日常业务模式。</p>

<p><img src="https://pic2.zhimg.com/80/v2-d4ef2511eaa39b96914d43002786fcab_hd.jpg" alt=""/></p>

<p>在天弘早期的基金销售系统的建设中，其实没有什么服务化的概念，当时的模式是有什么类型的业务，就针对这种业务单独开发一套独立的销售及清结算系统。由于业务量普遍不大，这些系统往往采用单体架构模式，不考虑横向扩展性。经过多年的发展和积累，内部多套直销及代销交易系统并存，系统间帐号没有打通，用户的资产数据无法统一，用户体验差；另一方面，各系统间功能重复的现象严重，不仅重复占用软硬件资源，版本的控制也很麻烦。<br/>
这种状况甚至在我们整体迁移到云上之后还存在了很长的一段时间，所以，<strong>所谓的 “服务化”，并不是仅仅上云那么简单，它更多的还是涉及到架构思维的转变。</strong></p>

<p><img src="https://pic1.zhimg.com/80/v2-f23511243bdad6525dd807da0e29b059_hd.jpg" alt=""/></p>

<p>痛定思痛之后，我们决定将这些系统中通用的能力，包括用户账户、交易、支付、资产、结算等抽取出来，以独立服务的形式对外提供通用服务。这样，原来的业务系统更多的充当了一个交易大厅的角色，可以做的更轻，扩展也就更容易了。用户的交易请求通过安全网关层被统一接入进来，我们目前使用了两套网关，一套是 SLB，另外一套是移动网关。整套平台都是在阿里云及蚂蚁金融云的 I 层及 P 层能力基础之上构建的，我们在它们的基础之上还构建了相应的日志监控、服务治理、APM、运维管控等一系列能力。</p>

<p>以上，就是我们目前实时交易平台的整体服务化的架构。</p>

<p><img src="https://pic1.zhimg.com/80/v2-4eb0d4d090cc40b5e6bf09278b050c95_hd.jpg" alt=""/></p>

<p>数据分析也是金融公司的一项重要工作，我们的大数据平台会从实时线上业务系统、清结算系统、运营活动、web 及 APP 的用户埋点中采集各个维度的数据，并以 ODS（操作型数据）汇总到数据仓库中，再根据预先定义的数据模型，抽取出相应的主数据。在此基础之上，基于用户、运营、资产、交易、风控等主题来构建多层次的数据集市。有了这个数据集市之后，我们就可以以服务的形式，在数据上做一层服务化的封装，在其上进行数据的应用。一类应用是数据的离线分析，包括留存分析、保有分析、营销分析等等；另一类应用是将这些重度汇总数据应用在实时业务之中，尤其是营销活动之中。我们在这些数据集市上，构建了一些高级运营活动，包括基于用户综合资产构建的理财竞赛，如 “弘运榜”、“年度账单”、“理财达人” 等等；另外，我们还基于这些不同维度的数据，搞了一个衡量用户综合理财能力的指标体系，即“财商指数”。</p>

<p>我们这套能力是基于阿里云上的大数据加工及分析能力来构建的，利用了阿里云的 MaxCompute、DTS、QuickBI 等一系列能力。在大数据平台的能力构建上，我们遵循如下模式：首先进行数据模型的规划；有了模型之后利用 ETL 进行数据的抽取、转换及清洗；接着再利用一系列的规则对数据质量进行监控；将格的数据共享出去，供其他方应用；另外，定期进行数据资产评估，基于评估结果不断的对模型进行优化调整。这样，就形成了对数据的闭环操作。</p>

<p><strong>在这里，要重点强调的是数据质量监控。</strong>对于离线分析，数据的精度及实时性普遍要求不高；但对于二次使用的汇总数据，则有很高的精度要求和实时性要求，比如用于用户竞赛排行并有奖励的一些运营活动，由于每笔交易记录都与钱挂钩，用户对准确性很敏感，稍有不慎就会引发大规模的客诉，因此我们在自构建的规则引擎基础上，利用数百条预先定义的规则，对数据进行抽样或者全量的检测，一旦检测到异常，则会自动触发人工订正或者自动化数据订正的任务。</p>

<p><img src="https://pic2.zhimg.com/80/v2-485378d5ee7e8316cd128b96ce0c0b68_hd.jpg" alt=""/></p>

<p>我们目前使用的服务化的底层框架是蚂蚁金融云提供的 SOFARPC。SOFARPC 提供了相对简便的服务暴露及服务接入的方式。如上图所示，它可以基于 Spring 的扩展标签机制，把一个 Spring 的 bean 实例以特定的协议暴露为远程服务，也可以以接口的形式把一个远程服务接入进来，同时，它还提供了链式过滤器的机制，对所有的服务调用请求进行一个串行式的处理，我们也可以通过它来实现一些自定义的服务管控策略，包括服务 Mock，线上数据采集等能力。</p>

<p><img src="https://pic4.zhimg.com/80/v2-425203cfc2fd880b46e9e9848f3ff95e_hd.jpg" alt=""/></p>

<p>单有分布式服务框架，还不足以保证服务化的平稳落地。企业服务化之路要走的顺畅，一定是要两条腿走路的，一条腿是分布式服务框架，另一条腿是服务治理，只有两条腿都健壮，路才能走的顺畅。阿里云结合它线上的资源编排和资源调度能力，为 SOFARPC 提供了相对完善的服务生命周期管理的能力，能够实现诸如服务上线、下线，扩容、缩容等操作。同时，蚂蚁还提供了一个叫 Guardian 的组件，通过它可以实现对线上服务的熔断限流的自动保护机制，类似 Netflix 提供的 Hystrix 组件，大家有兴趣可以去了解一下。</p>

<p><img src="https://pic4.zhimg.com/80/v2-ecf0fe4b534d372dc36043fc9e913ba5_hd.jpg" alt=""/></p>

<p>我所在的移动开发部门，采用了蚂蚁的移动开发平台 mPaaS 框架，mPaaS 是类似 OSGi 的一套模块化的插件管理框架，APP 应用需要的各种基础能力都可以以插件的形式集成进来，它提供的服务远程调用能力就是基于 SOFARPC。我们看一下上面的这个图，mpaaS 提供了统一的服务网关，可以实现对服务端的 SOFA 服务的远程调用能力；同时，它还提供了日志网关和消息网关，可以实现对 APP 上的埋点信息的采集服务及消息的推送服务。通过 mPaaS 这套框架，我们可以相对方便的实现移动应用的开发工作。</p>

<p>以上就是目前我们基金实时销售平台的整体服务化的一个状况，接下来，我们再介绍一下服务化对我们研发和运维的影响。</p>

<p><img src="https://pic1.zhimg.com/80/v2-6b965f3bb1d5779437aa9d4bd751a8f8_hd.jpg" alt=""/></p>

<p>“服务化” 对我们运维及研发模式的影响及我们的应对策略<br/>
服务化的本质就是一个 “拆” 字，原来的单体应用被拆成了大大小小的应用集群和服务集群，并被分散到网络的各个节点，由不同的团队负责，每个团队各管一段。在这个背景下，运维和研发都会遭遇一系列新的问题和挑战，包括故障的定界定位、调用关系的梳理、集群环境下的调试及分布式环境下的事务一致性的保障等等。</p>

<p>接下来就来看看，我们是如何破解这些困局的。</p>

<p><img src="https://pic4.zhimg.com/80/v2-53adc1cb5473ec83cb8ab8e1ee178c47_hd.jpg" alt=""/></p>

<p><strong>【只有更高效的收集线上服务的日志，才能更好的对服务进行监控和管控】</strong><br/>
传统的日志收集一般采用诸如 log4j 这类的日志组件进行日志的落盘，再通过 logstash 或者 flume 这类的日志采集组件进行落盘日志的增量收集，通过这种方式进行日志采集存在大量的磁盘 IO。对于线上服务器来说，最大的性能瓶颈就是磁盘 IO，尤其是在高并发和高负载环境下，磁盘 IO 对系统性能的影响会被成倍放大。我们的测试显示，在整个系统负载被打满的前提下，日志采集所产生的整体性能消耗占了总资源的 40% 左右。</p>

<p>为了降低系统资源占用，同时更高效的采集服务日志，我们开发了无磁盘 IO 的日志采集方式。具体流程是：采用类似 Spring AOP 的方式，对服务的请求进行挡截，采集服务的调用延时、服务状态等信息；同时，根据自定义的配置，抓取特定的入参和出参数据，所有这些信息都会被封装到一个消息对象之中，并扔到一个内存消息队列之中进行缓存；与此同时，有独立的线程对这些消息进行预处理（如果需要的话），预处理结果也会被压入内存消息队列中再次进行缓存；最后，由独立的发送线程将这些内存消息队列中的原始日志或者预处理数据发送到远程的日志手机端。</p>

<p>在日志的收集端，接进来的日志统一被扔到内存消息队列中缓存，再被分散到不同时间片段对应的二级消息队列中，由独立的分析器实例集合进行分析和落盘存储，通过这种纯内存 + 全异步的处理方式，我们就可以最大限度的避免资源锁的竞争，并榨取服务器的性能，从而实现对日志的高效的处理。</p>

<p>通过这套体系，在不堵塞的情况下，任何一个服务节点的故障，在 1~2 秒之内就能被我们的分析器捕捉到。</p>

<p><img src="https://pic4.zhimg.com/80/v2-43b32c2fb751fef1fb7ec0c1d3be9af5_hd.jpg" alt=""/></p>

<p>如果把分布式服务框架比作是 “咖啡” 的话，那应用性能管理中的调用链监控及分析就是 “奶昔” 了，咖啡和奶昔是什么，是绝配！</p>

<p>调用链比常规的日志收集方式更关注日志之间的关系，它通过一个统一的 traceId 把不同服务节点上的日志聚合在一起，来完整描述一个请求的调用过程，通过这个调用链路，我们可以发现服务的性能瓶颈在哪里、埋点的缺失情况、网络的质量等等一系列信息，通过调用链的聚合，还可以获取到服务集群的负载和健康度等更复杂的信息。</p>

<p>调用链能够有效解决分布式环境下的监控需求，但在使用调用链的过程中，也要平衡全采集还是抽样采集、自动插码埋点还是手动埋点、实时统计还是预统计等等这些问题，如何权衡，需要根据自身的特点及技术实力来做决策。今天由于时间关系，不在这里展开了，如果有感兴趣的同学，可以关注我在大会后两天的深度培训《微服务治理的探索与实践》。</p>

<p><img src="https://pic1.zhimg.com/80/v2-010c471293822c6edf53598a35e63545_hd.jpg" alt=""/></p>

<p>我们前面说了，企业服务化落地要两条 “腿” 走路，一条是服务框架，另外一条就是服务治理，服务化之路要走的顺畅，一定是两条腿都健壮。</p>

<p>通过几年的努力，我们已经初步构建了服务化的治理体系，能够覆盖到服务监控和服务管控的大部分需求，其中管控的大部分能力是依托于蚂蚁金融云的能力来构建的，而监控这部分能力则是在 SOFARPC 的基础上，通过整合常规日志体系及 APM 监控的能力来综合获取的。<br/>
服务监控这块，我们从各个服务节点抽取服务调用延时、调用状态、调用异常等信息，并汇总到日志中心进行综合统计，得到各类的监控报表和监控大盘。通过错误信息，我们可以进行线上的故障定位定界；通过调用量的各级汇总，我们可以获取线上实时 “水位”，进而进行客观的容量规划；通过调用延时和错误率，我们可以推断线上服务的健康度；在这些数据的基础上，基于时间维度，还可以获取到服务随时间的质量演进情况，这样的话，我们对整个服务集群就能有一个全面而实时的了解，并在此基础上，做出正确的管控决策。</p>

<p>通过服务管控，可以将服务生命周期管理的调度指令下发到发布系统，进行服务的上线、下线、扩容、缩容等操作，另外限流、降级、调整负载的指令则会直接下发到各个服务节点中，由服务框架的 SDK 进行相应的调整动作。</p>

<p>这样，通过服务的监控（左边）和服务的管控（右边），就形成了针对服务治理的一个闭环的操作。</p>

<p><img src="https://pic4.zhimg.com/80/v2-44b14c158d5433d1b6d3bdac49166903_hd.jpg" alt=""/></p>

<p>在服务化的过程中，研发遇到的第一个困难，一定是调试。原来单体应用中的服务被拆分到不同团队，并部署在不同的服务器上，而本地只有一个服务接口。这时候要做调试，要么做 P2P 直连，要么做 Mock 。采用传统的 Mock 手段，要写一堆的 Mock 语句，比如用 mockito，就要写一堆的 when…..thenReturn…. 的语句，耦合度非常的高。</p>

<p>我们是利用分布式服务框架提供的过滤器机制，开发了一个 Mock 过滤器，并通过 Mock 数据文件来详细定义要被 Mock 的服务的名称、入参及出参。这样，当请求过来的时候，将服务名及入参和 Mock 数据中的定义进行比对，结果吻合，则直接将 Mock 数据文件中的出参反序列化后作为服务的调用结果直接返回，同时远程调用的所有后续操作被终止。这样，就通过 Mock 数据模拟了一个真实的远程服务。</p>

<p>Mock 过滤器的启用可以通过配置文件来实现 “开关控制”，可以只在开发和测试环境启用，生产环境关闭。</p>

<p>通过这种方式来构建服务的 Mock 能力，我们就不需要写一堆的 Mock 代码了，而且整个过程对业务逻辑来说完全无感知，完全把 Mock 能力下沉到底层的服务框架。</p>

<p><img src="https://pic4.zhimg.com/80/v2-83de9c9141a351da2a3119e50308ffce_hd.jpg" alt=""/></p>

<p>通过这种方式构建的分布式服务的 Mock 能力，除了 Mock 过滤器，最核心的就是 Mock 数据的构建。<br/>
<strong>Mock 数据的质量直接决定了调测的质量！</strong><br/>
说起 Mock 数据，它所做的无非就是匹配哪个服务、输入的参数是什么，输出的结果又是什么。但实际的情况往往更复杂，你不可能通过静态数据去构建一个所谓的 “当前时间” 吧！因此，Mock 数据除了支持静态输入输出数据的比对，还需要支持动态匹配模式，也就是支持脚本匹配，我们所构建的服务 Mock 框架，支持在 Mock 数据中同时使用 bsh 和 groovy 这两种脚本。另外，一个服务集群中，往往会存在同一服务的不同版本，因此要真实模拟现实情况的话，Mock 数据也必须有版本的概念。</p>

<p>除了以上两种匹配模式，我们针对实际情况，还开发了第三种 Mock 模式，就是可以针对一个真实请求，部分修改它的回参来模拟出一个第三方的结果，这种方式在参数量非常多的情况下非常有用。</p>

<p>所以，要构建好一个 Mock 数据是需要投入不少工作量的，那么谁来做这个事情呢？这实际上牵涉到管理规范了。我们的规定是，服务谁提供，就由谁来构建这个 mock 数据，服务调用方可以在这个基础上做修改或者替换。但这还不够，由于服务会非常多，因此，对 Mock 数据的管理一定要体系化和工程化。<strong>我的建议是，可以采用独立的项目工程对 Mock 数据进行独立的管理和发布。</strong></p>

<p>目前，我们针对前端和服务端都开发了完整的 Mock 能力，可以让开发人员在基本 “无感” 的状态下进行本地化的功能调测，同时提供一些自研的小工具来自动生成 Mock 文件，以降低构建 Mock 的难度和人力投入。</p>

<p>为了有效降低制作 Mock 文件的成本，我们还基于服务框架的过滤器机制开发了 “在线数据抓取过滤器”，它可以将指定的服务请求的入参和返回结果都抓取下来，并直接写成 Mock 数据文件。通过抓取方式获得的 Mock 数据文件，<strong>往往有更好的数据质量</strong>，毕竟反映的是更加真实的业务场景。当然了，这里还有一个合规性的问题，对线上数据的抓取是种敏感行为，大部分公司这么干都会很谨慎，一般都要做好数据脱敏的处理工作。对于我们，目前只在测试环境中进行数据抓取操作。</p>

<p><img src="https://pic1.zhimg.com/80/v2-0d2850203e49e03b0be9e89235823248_hd.jpg" alt=""/></p>

<p>事务的一致性和可用性问题是分布式环境下 “老生常谈” 的问题了，相信大家也或多或少遇到过这类问题。针对分布式事务，我们采取了 3 级应对的策略。</p>

<p>首先，在分库分表操作中，我们会坚持 “实体组” 优先的策略，尽量按照统一的 “片键” 进行分库分表操作，比如说，如果统一按 “用户账户 ID” 作为分库分表键的话，那么用户相关的交易、资产、支付等相关信息都会落到同一个物理库实例之中，这样的话，针对此用户的相关操作，本地事务就可以生效，从而避免了分布式事务的使用。因为对于任何分布式事务而言，不管做不做资源锁定，为了有效保障事务状态，都需要额外的资源处理消耗。</p>

<p>另外，我们还提供了自研的支持多级事务的 TCC 服务，以应对不可避免的分布式事务需求。采用 TCC 的原因最主要还是在于相对其它资源管理器而言，它相对简单，我们不用关注资源层面，只需要关注服务接口即可。<br/>
上面的第二张图是 TCC 的典型架构模式图，相信只要研究过 TCC 的同学们一定看过这张图，第三张则是我们自研的 TCC 的一个更详细的交互架构图，能体现更多技术细节，希望能对大家有所参考借鉴。<br/>
总的来说，从我个人的理解而言，自己实现一个 TCC 框架（独立服务）并不麻烦，最核心的是要解决两大核心问题，一个是参与事务的业务数据的缓存和回放问题，我们在做 TRY 操作的时候，就需要将事务数据缓存起来，可以存到数据库中，当框架做 Confirm 和 Cancel 操作时，再用缓存的事务数据去运行特定的服务逻辑，所以，这就要求在 TRY、Confirm 和 Cancel 的方法构造上要有一定的约束，也就是相互之间要能够识别哪些入参是事务数据；另一个是父子事务的事务 ID 的传递问题，我们通过分布式服务框架的 “非业务传参” 来解决这个问题，一旦某一个事务构建了一个事务 ID，这个事务 ID 就会被放置到环境上下文之中，并随着 RPC 调用传递到远程服务，远程服务如果侦测到上下文中已经存在事务 ID 了，则就不再构建新的事务 ID，这样的话，父子事务之间就通过同一个事务 ID 关联在一起。<br/>
最后，最终一致性的保障一定是 “对账、对账、对账”，这是最传统，也是最可靠的最后一道防线，这也是金融公司的基础能力，这里我就不展开详细说了。</p>

<p><img src="https://pic2.zhimg.com/80/v2-b70c0af13fbc3a1e8019e0aaf8dbb0f8_hd.jpg" alt=""/></p>

<p>服务化之后，每个团队负责一部分的服务，经常一个业务会涉及多个团队之间的协同配合，如何让团队内部、团队之间的协作更高效，天弘内部也做了不同的尝试，从综合效果来说，敏捷模式会更适合一些。<br/>
以我们移动平台团队举例，我们目前采用两周一迭代、固定发版的模式，同时每个迭代之内，采用 “火车发布模式”，实行班车制，准点发车，这样的话，其它协作部门在很早之前就能大概知道我们的一个发布计划，产品方面也大概知道要把需求放入哪个迭代之中。这样，能够有效减轻部门间的沟通成本。在每期工作量评估的时候，我们一般会预留一些工作量 buffer，以应对一些临时性需求，这类需求不受版本约束，按需发布。如果这个迭代周期内没有这类紧急需求的话，我们会从 backlog 中捞一些架构优化的需求来填补这些 buffer。</p>

<p>对每个迭代而言，最不可控的就是 UI 的设计了，UI 的设计过程中，感性化的因素会更多一些，可能会反复修改多次，不像程序代码那么明确。所以，我们一般不将 UI 设计纳入迭代之中，而是将其作为需求的一部分，在每个迭代开始之前的工作量评估中，要求必须提供完整的 UI 物料，否则不予评估工作量，此需求也不会被纳入迭代之中。<br/>
要保证敏捷模式平稳推进，还需要一套与之匹配的 DevOps 研发工具体系去支撑它。这方面蚂蚁金融云有相对完善的研发管理工具体系，但我们目前暂时没有使用，毕竟团队规模不一样。我们团队目前规模还比较小，因此还是采用业界最通用的一些开源的产品（包括 Jekins、Jira、Wiki 等）来整合构建我们自己的 DevOps 的工具链，但我们会在我们的研发 Pipeline 中通过脚本来整合金融云的一系列能力，包括包上传、发布能等一系列 IaaS 的能力。这样，就将云下的研发和云上的发布能力整合在了一起。同时，我们会收集 DevOps 工具链中各个环节的数据，并通过自研的精益看板来进行各个维度的数据汇总统计和呈现，从而实现对研发的推进状况及质量的严格把控。</p>

<p><img src="https://pic3.zhimg.com/80/v2-87efc79672b19d697a03793aa134e1f6_hd.jpg" alt=""/></p>

<p>总结<br/>
以上就是本次分享的主要内容，前面我们已经介绍了，我们很多服务化的能力都是在蚂蚁金融云的 I 层和 P 层能力基础之上构建起来的，蚂蚁目前已经将它的云原生架构引擎 —— SOFA 中间件进行逐步开源，尤其是我之前介绍的 SOFARPC，各位同学如果感兴趣的话，可以关注本公众号了解。</p>

<p><img src="https://pic4.zhimg.com/80/v2-6cd70446d9f8bc3be06edb1fcd87e57b_hd.jpg" alt=""/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Git实用技巧和命令]]></title>
    <link href="http://panlw.github.io/15340911901321.html"/>
    <updated>2018-08-13T00:26:30+08:00</updated>
    <id>http://panlw.github.io/15340911901321.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://www.ctolib.com/topics-133950.html">https://www.ctolib.com/topics-133950.html</a></p>

<p>原文链接：<a href="https://thecuriousdev.org/useful-git-tips-commands/">https://thecuriousdev.org/useful-git-tips-commands/</a></p>
</blockquote>

<pre><code>作者 | viktor
译者 | 金灵杰
</code></pre>

<p>Git 是一个非常强大的工具，它包含丰富的工具用以维护项目。本文介绍了一些 Git 日常使用过程中的实用技巧和命令，希望这些内容能够对大家有所帮助。</p>

<h2 id="toc_0">Git diff</h2>

<p>通常情况下，我们会在自己的独立分支中完成需求开发，此时就会有需求将自己的分支和其他分支进行对比。这个功能可以通过</p>

<pre>git diff branch1 branch</pre>

<p>命令来实现。</p>

<p>如果希望对比暂存区和当前的 HEAD，那么使用</p>

<pre>git diff --cached</pre>

<p>命令会非常方便。普通的 git diff 命令默认对比的是没有加到索引中的文件。</p>

<p>恢复暂存区</p>

<p>如果已经将一些文件添加到暂存区后又后悔了，Git 提供了多个命令来实现这个功能，具体需要根据当时情况而定。</p>

<pre>git rm path/to/file --cached</pre>

<p>这个命令将文件从暂存区索引中删除，但是仍然会将文件保留在工作目录。这比直接使用</p>

<pre>git rm file -f</pre>

<p>完全删除文件会安全一点。</p>

<h2 id="toc_1">Git reset</h2>

<p>如果希望恢复一些已经提交的改动，我们可以使用</p>

<pre>git reset</pre>

<p>这个命令可以完成许多不同的行为，因此需要按照实际场景进行使用。</p>

<p>如果希望去除所有修改，包括索引中的内容和工作目录中的修改，那么可以使用</p>

<pre>git reset --hard</pre>

<p>如果仅仅是希望重置索引，那么可以使用</p>

<pre>git reset --mixed</pre>

<p>这也是 git reset 命令的默认行为。混合的重置会保留当前工作目录中的改动。最后，如果仅仅希望修改分支的 HEAD，可以通过</p>

<pre>git reset --soft</pre>

<p>来实现。</p>

<p>当运行 git reset 命令的时候，我们可以指定多个目标文件作为参数传入。当然可以通过</p>

<pre>git reset --hard COMMIT_ID</pre>

<p>恢复到指定的提交版本。</p>

<h2 id="toc_2">Git stash</h2>

<p>大家应该对 git stash 命令并不陌生，它可以通过 git stash pop 命令方便的将之前的改动恢复回来。然而，如果工作目录中有未追踪的文件，默认情况下是不会将其存入临时储藏区的。为了能够临时保存未追踪的文件，可以使用</p>

<pre>git stash --include-untracked</pre>

<p>另外一个非常有用的命令是</p>

<pre>git stash list</pre>

<p>它能列出临时储藏区中的内容。</p>

<h2 id="toc_3">历史记录</h2>

<p>Git 自带了非常强大的工具来查看项目以及特定文件的变更情况。我个人非常喜欢用其中的一个命令：</p>

<pre>git log --graph --decorate --oneline</pre>

<p>它可以用于展示经过修饰的提交历史。这个命令非常冗长，因此我建议可以为它创建一个别名（这可能是所有技巧中最有用的，因为许多命令都比较难记）。git log 命令可以显示 HEAD、所有提交的 ID 以及分支信息。有了这些信息之后，我们可以使用</p>

<pre>git show COMMIT_ID/HEAD/BRANCH</pre>

<p>来显示更详细的信息。</p>

<p>有的时候我们需要了解谁对一个文件做了哪些改动，这正是</p>

<pre>git blame path/to/file</pre>

<p>这个命令所提供的功能。</p>

<p>之前提到过 git diff 命令，它也是一个查看历史的工具。例如，如果需要对比当前 HEAD 和前两个提交，可以使用</p>

<pre>git diff HEAD HEAD~2</pre>

<p>为了能够展示每个提交中更详细的更新信息，可以使用</p>

<pre>git log --patch</pre>

<p>如果只想要看包含关键字 “apple” 的提交，使用</p>

<pre>git log --grep apples --oneline</pre>

<p>要查看历史提交记录中两个点之间的提交历史，我们可以用</p>

<pre>git log HEAD~5..HEAD^ --oneline</pre>

<p>对于分支可以使用</p>

<pre>git log branch_name..master --oneline</pre>

<h2 id="toc_4">修复错误提交</h2>

<p>注意：以下一些命令会修改提交历史，使用前请确保了解后再执行。</p>

<p>当提交出错时，我们可能会希望能够修改提交历史。我不建议修改已经推送到远程仓库的提交历史（即使 git 允许这样做），但是对于本地仓库的提交历史，我个人认为还是可以修改的。通过</p>

<pre>git commit --amend</pre>

<p>可以删除前一次提交，并创建一个新的提交记录以替代之前的提交。</p>

<p>另一个我很喜欢的 git 使用技巧是交互式变基 (rebase）。它可以用来编辑提交信息，或者将多个提交压缩成一个提交，这也是我最喜欢的一个功能。为了在远程仓库 origin 的 master 分支之后的所有提交上执行交互式变基，可以使用</p>

<pre>git rebase -i origin/master</pre>

<p>这个命令会显示提交列表和可执行操作的详细描述。例如以下操作将会把多个提交压缩成一个：</p>

<pre>1 pick 80f2a48 Add feature X
2 squash 2c74ea2 Add junit tests for feature X
3 squash 4k81nm5 Bugfix for feature X</pre>

<p>最终的结果会是生成一个提交消息为 “Add feature X” 的提交。</p>

<p>如果需要恢复一个有问题的提交，我们可以使用</p>

<pre>git revert COMMIT_ID</pre>

<p>该命令会创建一个新的提交，让当前项目状态恢复到指定提交之前。</p>

<p>如果我们在修复问题时出现了误操作，例如不小心删除了不应该删除的文件。我们还是可以从版本库中恢复回来，因为 git 保存了所有修改的版本，包括被移除的提交。 git reflog 命令就是用来实现这个功能的。</p>

<h2 id="toc_5">挑拣提交（cherry-pick）</h2>

<p>假设我们和同事在各自单独的分支上进行开发，同事有一个重要的提交我们也想应用到自己的分支上来，但是不需要对方分支的其他提交。这时我们可以使用</p>

<pre>git cherry-pick COMMIT_ID</pre>

<h2 id="toc_6">后记   </h2>

<p>以上都是我最喜欢的 git 实用技巧。希望你也能从中学到一些新知识。这些都是我在日常使用中发现的非常有用的命令，它们对我的日常工作非常有用。如果你也有类似常用的 git 实用技巧或者常用命令，可以分享出来大家一起交流。</p>

]]></content>
  </entry>
  
</feed>
