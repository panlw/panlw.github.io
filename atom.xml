<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Junkman]]></title>
  <link href="http://panlw.github.io/atom.xml" rel="self"/>
  <link href="http://panlw.github.io/"/>
  <updated>2018-06-29T17:34:21+08:00</updated>
  <id>http://panlw.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[Introduction to Testing with Spock and Groovy]]></title>
    <link href="http://panlw.github.io/15337171704262.html"/>
    <updated>2018-08-08T16:32:50+08:00</updated>
    <id>http://panlw.github.io/15337171704262.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://www.baeldung.com/groovy-spock">https://www.baeldung.com/groovy-spock</a></p>

<p>Last modified: March 2, 2018</p>
</blockquote>

<h2 id="toc_0"><strong>1. Introduction</strong></h2>

<p>In this article, we’ll take a look at <a href="http://spockframework.org/">Spock</a>, a <a href="http://groovy-lang.org/">Groovy</a> testing framework. Mainly, Spock aims to be a more powerful alternative to the traditional JUnit stack, by leveraging Groovy features.</p>

<p>Groovy is a JVM-based language which seamlessly integrates with Java. On top of interoperability, it offers additional language concepts such as being a dynamic, having optional types and meta-programming.</p>

<p>By making use of Groovy, Spock introduces new and expressive ways of testing our Java applications, which simply aren’t possible in ordinary Java code. We’ll explore some of Spock’s high-level concepts during this article, with some practical step by step examples.</p>

<h2 id="toc_1"><strong>2. Maven Dependency</strong></h2>

<p>Before we get started, let’s add our <a href="http://search.maven.org/#search%7Cga%7C1%7C%20(g%3A%22org.spockframework%22%20AND%20a%3A%22spock-core%22)%20OR%20(g%3A%22org.codehaus.groovy%22%20AND%20a%3A%22groovy-all%22)">Maven dependencies</a>:</p>

<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.spockframework&lt;/groupId&gt;
    &lt;artifactId&gt;spock-core&lt;/artifactId&gt;
    &lt;version&gt;1.0-groovy-2.4&lt;/version&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt;
    &lt;artifactId&gt;groovy-all&lt;/artifactId&gt;
    &lt;version&gt;2.4.7&lt;/version&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre>

<p>We’ve added both Spock and Groovy as we would any standard library. However, as Groovy is a new JVM language, we need to include the <u>gmavenplus</u> plugin in order to be able to compile and run it:</p>

<pre><code class="language-xml">&lt;plugin&gt;
    &lt;groupId&gt;org.codehaus.gmavenplus&lt;/groupId&gt;
    &lt;artifactId&gt;gmavenplus-plugin&lt;/artifactId&gt;
    &lt;version&gt;1.5&lt;/version&gt;
    &lt;executions&gt;
        &lt;execution&gt;
            &lt;goals&gt;
                &lt;goal&gt;compile&lt;/goal&gt;
                &lt;goal&gt;testCompile&lt;/goal&gt;
            &lt;/goals&gt;
        &lt;/execution&gt;
     &lt;/executions&gt;
&lt;/plugin&gt;
</code></pre>

<p>Now we are ready to write our first Spock test, which will be written in Groovy code. Note that we are using Groovy and Spock only for testing purposes and this is why those dependencies are test-scoped.</p>

<h2 id="toc_2"><strong>3. Structure of a Spock Test</strong></h2>

<h3 id="toc_3"><strong>3.1. Specifications and Features</strong></h3>

<p>As we are writing our tests in Groovy, we need to add them to the <u>src/test/groovy</u> directory, instead of <u>src/test/java.</u> Let’s create our first test in this directory, naming it <u>Specification.groovy:</u></p>

<pre><code class="language-java">class FirstSpecification extends Specification {

}
</code></pre>

<p>Note that we are extending the <u>Specification</u> interface. Each Spock class must extend this in order to make the framework available to it. It’s doing so that allows us to implement our first <u>feature:</u></p>

<pre><code class="language-groovy">def &quot;one plus one should equal two&quot;() {
  expect:
  1 + 1 == 2
}
</code></pre>

<p>Before explaining the code, it’s also worth noting that in Spock, what we refer to as a <u>feature</u> is somewhat synonymous to what we see as a <u>test</u> in JUnit. So <strong>whenever we refer to a <u>feature</u> we are actually referring to a <u>test.</u></strong></p>

<p>Now, let’s analyze our <u>feature</u>. In doing so, we should immediately be able to see some differences between it and Java.</p>

<p>The first difference is that the feature method name is written as an ordinary string. In JUnit, we would have had a method name which uses camelcase or underscores to separate the words, which would not have been as expressive or human readable.</p>

<p>The next is that our test code lives in an <u>expect</u> block. We will cover blocks in more detail shortly, but essentially they are a logical way of splitting up the different steps of our tests.</p>

<p>Finally, we realize that there are no assertions. That’s because the assertion is implicit, passing when our statement equals <u>true</u> and failing when it equals <u>false</u>. Again, we’ll cover assertions in more details shortly.</p>

<h3 id="toc_4"><strong>3.2. Blocks</strong></h3>

<p>Sometimes when writing JUnit a test, we might notice there isn’t an expressive way of breaking it up into parts. For example, if we were following behavior driven development, we might end up denoting the <u>given when then</u> parts using comments:</p>

<pre><code class="language-java">@Test
public void givenTwoAndTwo_whenAdding_thenResultIsFour() {
   // Given
   int first = 2;
   int second = 4;
 
   // When
   int result = 2 + 2;
 
   // Then
   assertTrue(result == 4)
}
</code></pre>

<p>Spock addresses this problem with blocks. <strong>Blocks are a Spock native way of breaking up the phases of our test using labels.</strong> They give us labels for <u>given when then</u> and more:</p>

<ol>
<li> <u>Setup</u> (Aliased by Given) – Here we perform any setup needed before a test is run. This is an implicit block, with code not in any block at all becoming part of it</li>
<li> <u>When</u> – This is where we provide a <u>stimulus</u> to what is under test. In other words, where we invoke our method under test</li>
<li> <u>Then</u> – This is where the assertions belong. In Spock, these are evaluated as plain boolean assertions, which will be covered later</li>
<li> <u>Expect</u> – This is a way of performing our <u>stimulus</u> and <u>assertion</u> within the same block. Depending on what we find more expressive, we may or may not choose to use this block</li>
<li> <u>Cleanup</u> – Here we tear down any test dependency resources which would otherwise be left behind. For example, we might want to remove any files from the file system or remove test data written to a database</li>
</ol>

<p>Let’s try implementing our test again, this time making full use of blocks:</p>

<pre><code class="language-groovy">def &quot;two plus two should equal four&quot;() {
    given:
        int left = 2
        int right = 2
 
    when:
        int result = left + right
 
    then:
        result == 4
}
</code></pre>

<p>As we can see, blocks help our test become more readable.</p>

<h3 id="toc_5"><strong>3.3. Leveraging Groovy Features for Assertions</strong></h3>

<p><strong>Within the <u>then</u> and <u>expect</u> blocks, assertions are implicit</strong>.</p>

<p>Mostly, every statement is evaluated and then fails if it is not <u>true</u>. When coupling this with various Groovy features, it does a good job of removing the need for an assertion library. Let’s try a <a href="https://docs.oracle.com/javase/8/docs/api/java/util/List.html">_list_</a> assertion to demonstrate this:</p>

<pre><code class="language-groovy">def &quot;Should be able to remove from list&quot;() {
    given:
        def list = [1, 2, 3, 4]
 
    when:
        list.remove(0)
 
    then:
        list == [2, 3, 4]
}
</code></pre>

<p>While we’re only touching briefly on Groovy in this article, it’s worth explaining what is happening here.</p>

<p>First, Groovy gives us simpler ways of creating lists. We can just able to declare our elements with square brackets, and internally a <u>list</u> will be instantiated.</p>

<p>Secondly, as Groovy is dynamic, we can use <u>def</u> which just means we aren’t declaring a type for our variables.</p>

<p>Finally, in the context of simplifying our test, the most useful feature demonstrated is operator overloading. This means that internally, rather than making a reference comparison like in Java, the <u>equals()</u> method will be invoked to compare the two lists.</p>

<p>It’s also worth demonstrating what happens when our test fails. Let’s make it break and then view what’s output to the console:</p>

<pre><code class="language-log">Condition not satisfied:
 
list == [1, 3, 4]
|    |
|    false
[2, 3, 4]
 &lt;Click to see difference&gt;
 
at FirstSpecification.Should be able to remove from list(FirstSpecification.groovy:30)
</code></pre>

<p>While all that’s going on is calling <u>equals()</u> on two lists, Spock is intelligent enough to perform a breakdown of the failing assertion, giving us useful information for debugging.</p>

<h3 id="toc_6"><strong>3.4. Asserting Exceptions</strong></h3>

<p>Spock also provides us with an expressive way of checking for exceptions. In JUnit, some our options might be using a <u>try-catch</u> block, declare <u>expected</u> at the top of our test, or making use of a third party library. Spock’s native assertions come with a way of dealing with exceptions out of the box:</p>

<pre><code class="language-groovy">def &quot;Should get an index out of bounds when removing a non-existent item&quot;() {
    given:
        def list = [1, 2, 3, 4]
  
    when:
        list.remove(20)
 
    then:
        thrown(IndexOutOfBoundsException)
        list.size() == 4
}
</code></pre>

<p>Here, we’ve not had to introduce an additional library. Another advantage is that the <u>thrown()</u> method will assert the type of the exception, but not halt execution of the test.</p>

<h2 id="toc_7"><strong>4. Data Driven Testing</strong></h2>

<h3 id="toc_8"><strong>4.1. What is a Data Driven Testing?</strong></h3>

<p>Essentially, <strong>data driven testing is when we test the same behavior multiple times with different parameters and assertions</strong>. A classic example of this would be testing a mathematical operation such as squaring a number. Depending on the various permutations of operands, the result will be different. In Java, the term we may be more familiar with is parameterized testing.</p>

<h3 id="toc_9"><strong>4.2. Implementing a Parameterized Test in Java</strong></h3>

<p>For some context, it’s worth implementing a parameterized test using JUnit:</p>

<pre><code class="language-java">@RunWith(Parameterized.class)
public class FibonacciTest {
    @Parameters
    public static Collection&lt;Object[]&gt; data() {
        return Arrays.asList(new Object[][] {     
          { 1, 1 }, { 2, 4 }, { 3, 9 }  
        });
    }
 
    private int input;
 
    private int expected;
 
    public ToThePowerOfTwo(int input, int expected) {
        this.input = input;
        this.expected = expected;
    }
 
    @Test
    public void test() {
        assertEquals(fExpected, Math.pow(3, 2));
    }
}
</code></pre>

<p>As we can see there’s quite a lot of verbosity, and the code isn’t very readable. We’ve had to create a two-dimensional object array that lives outside of the test, and even a wrapper object for injecting the various test values.</p>

<h3 id="toc_10"><strong>4.3. Using Datatables in Spock</strong></h3>

<p>One easy win for Spock when compared to JUnit is how it cleanly it implements parameterized tests. Again, in Spock, this is known as <strong>Data Driven Testing.</strong> Now, let’s implement the same test again, only this time we’ll use Spock with <strong>Data Tables</strong>, which provides a far more convenient way of performing a parameterized test:</p>

<pre><code class="language-groovy">def &quot;numbers to the power of two&quot;(int a, int b, int c) {
  expect:
      Math.pow(a, b) == c
 
  where:
      a | b | c
      1 | 2 | 1
      2 | 2 | 4
      3 | 2 | 9
}  
</code></pre>

<p>As we can see, we just have a straightforward and expressive Data table containing all our parameters.</p>

<p>Also, it belongs where it should do, alongside the test, and there is no boilerplate. The test is expressive, with a human-readable name, and pure <u>expect</u> and <u>where</u> block to break up the logical sections.</p>

<h3 id="toc_11"><strong>4.4. When a Datatable Fails</strong></h3>

<p>It’s also worth seeing what happens when our test fails:</p>

<pre><code class="language-log">Condition not satisfied:
 
Math.pow(a, b) == c
     |   |  |  |  |
     4.0 2  2  |  1
               false
 
Expected :1
 
Actual   :4.0
</code></pre>

<p>Again, Spock gives us a very informative error message. We can see exactly what row of our Datatable caused a failure and why.</p>

<h2 id="toc_12"><strong>5. Mocking</strong></h2>

<h3 id="toc_13"><strong>5.1. What is Mocking?</strong></h3>

<p>Mocking is a way of changing the behavior of a class which our service under test collaborates with. It’s a helpful way of being able to test business logic in isolation of its dependencies.</p>

<p>A classic example of this would be replacing a class which makes a network call with something which simply pretends to. For a more in-depth explanation, it’s worth reading <a href="/mockito-vs-easymock-vs-jmockit">this article</a>.</p>

<h3 id="toc_14"><strong>5.2. Mocking using Spock</strong></h3>

<p>Spock has it’s own mocking framework, making use of interesting concepts brought to the JVM by Groovy. First, let’s instantiate a <u>Mock:</u></p>

<pre><code class="language-java">PaymentGateway paymentGateway = Mock()
</code></pre>

<p>In this case, the type of our mock is inferred by the variable type. As Groovy is a dynamic language, we can also provide a type argument, allow us to not have to assign our mock to any particular type:</p>

<pre><code class="language-groovy">def paymentGateway = Mock(PaymentGateway)
</code></pre>

<p>Now, whenever we call a method on our <u>PaymentGateway</u> mock_,_ a default response will be given, without a real instance being invoked:</p>

<pre><code class="language-groovy">when:
    def result = paymentGateway.makePayment(12.99)
 
then:
    result == false
</code></pre>

<p>The term for this is <u>lenient mocking</u>. This means that mock methods which have not been defined will return sensible defaults, as opposed to throwing an exception. This is by design in Spock, in order to make mocks and thus tests less brittle.</p>

<h3 id="toc_15"><strong>5.3. Stubbing Method calls on <u>Mocks</u></strong></h3>

<p>We can also configure methods called on our mock to respond in a certain way to different arguments. Let’s try getting our <u>PaymentGateway</u> mock to return <u>true</u> when we make a payment of <u>20:</u></p>

<pre><code class="language-groovy">given:
    paymentGateway.makePayment(20) &gt;&gt; true
 
when:
    def result = paymentGateway.makePayment(20)
 
then:
    result == true
</code></pre>

<p>What’s interesting here, is how Spock makes use of Groovy’s operator overloading in order to stub method calls. With Java, we have to call real methods, which arguably means that the resulting code is more verbose and potentially less expressive.</p>

<p>Now, let’s try a few more types of stubbing.</p>

<p>If we stopped caring about our method argument and always wanted to return <u>true,</u> we could just use an underscore:</p>

<pre><code class="language-groovy">paymentGateway.makePayment(_) &gt;&gt; true
</code></pre>

<p>If we wanted to alternate between different responses, we could provide a list, for which each element will be returned in sequence:</p>

<pre><code class="language-groovy">paymentGateway.makePayment(_) &gt;&gt;&gt; [true, true, false, true]
</code></pre>

<p>There are more possibilities, and these may be covered in a more advanced future article on mocking.</p>

<h3 id="toc_16"><strong>5.4. Verification</strong></h3>

<p>Another thing we might want to do with mocks is assert that various methods were called on them with expected parameters. In other words, we ought to verify interactions with our mocks.</p>

<p>A typical use case for verification would be if a method on our mock had a <u>void</u> return type. In this case, by there being no result for us to operate on, there’s no inferred behavior for us to test via the method under test. Generally, if something was returned, then the method under test could operate on it, and it’s the result of that operation would be what we assert.</p>

<p>Let’s try verifying that a method with a void return type is called:</p>

<pre><code class="language-groovy">def &quot;Should verify notify was called&quot;() {
    given:
        def notifier = Mock(Notifier)
 
    when:
        notifier.notify(&#39;foo&#39;)
 
    then:
        1 * notifier.notify(&#39;foo&#39;)
}
</code></pre>

<p>Spock is leveraging Groovy operator overloading again. By multiplying our mocks method call by one, we are saying how many times we expect it to have been called.</p>

<p>If our method had not been called at all or alternatively had not been called as many times as we specified, then our test would have failed to give us an informative Spock error message. Let’s prove this by expecting it to have been called twice:</p>

<pre><code class="language-groovy">2 * notifier.notify(&#39;foo&#39;)
</code></pre>

<p>Following this, let’s see what the error message looks like. We’ll that as usual; it’s quite informative:</p>

<pre><code class="language-log">Too few invocations for:
 
2 * notifier.notify(&#39;foo&#39;)   (1 invocation)
</code></pre>

<p>Just like stubbing, we can also perform looser verification matching. If we didn’t care what our method parameter was, we could use an underscore:</p>

<pre><code class="language-groovy">2 * notifier.notify(_)
</code></pre>

<p>Or if we wanted to make sure it wasn’t called with a particular argument, we could use the not operator:</p>

<pre><code class="language-groovy">2 * notifier.notify(!&#39;foo&#39;)
</code></pre>

<p>Again, there are more possibilities, which may be covered in a future more advanced article.</p>

<h2 id="toc_17"><strong>6. Conclusion</strong></h2>

<p>In this article, we’ve given a quick slice through testing with Spock.</p>

<p>We’ve demonstrated how, by leveraging Groovy, we can make our tests more expressive than the typical JUnit stack. We’ve explained the structure of <u>specifications</u> and <u>features</u>.</p>

<p>And we’ve shown how easy it is to perform data-driven testing, and also how mocking and assertions are easy via native Spock functionality.</p>

<p>The implementation of these examples can be found <a href="https://github.com/eugenp/tutorials/tree/master/testing-modules/groovy-spock">over on GitHub</a>. This is a Maven-based project, so should be easy to run as is.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[10 Excellent Ways to Secure Your Spring Boot Application]]></title>
    <link href="http://panlw.github.io/15336595358049.html"/>
    <updated>2018-08-08T00:32:15+08:00</updated>
    <id>http://panlw.github.io/15336595358049.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://developer.okta.com/blog/2018/07/30/10-ways-to-secure-spring-boot">https://developer.okta.com/blog/2018/07/30/10-ways-to-secure-spring-boot</a></p>
</blockquote>

<p>Spring Boot has dramatically simplified the development of Spring applications. Its autoconfiguration and starter dependencies reduce the amount of code and configuration you need to begin an app. If you were used to Spring and lots of XML back in the day, Spring Boot is a breath of fresh air.</p>

<p>Spring Boot was first released in 2014, and a lot has changed since then. Much like code quality and testing, security has become a concern in developers minds. If you’re a developer and you’re not concerned about security, chances are you think you should be. This post aims to educate you on steps you can take to create a more secure Spring Boot application.</p>

<p>I collaborated on this post with <a href="https://twitter.com/sjmaple">Simon Maple</a>, fellow Java Champion and Director of Developer Relations at Snyk. We both work for companies in the security industry, love Java, and want to help developers create more secure applications. We figured writing this post would be a fun way to give back to the community. If you have additional suggestions from the ones we’ve listed, please add them in the comments!</p>

<h2 id="toc_0"><a href="#1-use-https-in-production">1. Use HTTPS in Production</a></h2>

<p>Transport Layer Security (TLS) is the official name for HTTPS. You might’ve heard it called SSL (Secure Sockets Layer). SSL is the deprecated name. TLS is a cryptographic protocol that provides secure communication over a computer network. Its primary goal is to ensure privacy and data integrity between computer applications.</p>

<p>TLS/SSL certificates used to be expensive, and HTTPS was considered slow. Machines have become much faster, solving the performance problem, and <a href="https://letsencrypt.org/">Let’s Encrypt</a> provides free TLS certificates. These two developments have changed the game and caused TLS to become mainstream.</p>

<p>As of July 24, 2018, Google Chrome <a href="https://www.wired.com/story/google-chrome-https-not-secure-label/">now labels HTTP sites as “not secure”</a>. While this has created a fair amount of controversy in the web community, it’s here to stay. Troy Hunt, a well-known security researcher, has created a <a href="https://www.troyhunt.com/why-no-https-heres-the-worlds-largest-websites-not-redirecting-insecure-requests/">Why No HTTPS?</a> site that tracks large websites not using HTTPS. You might not be developing the next major website, but why limit yourself?!</p>

<p>Generating and renewing Let’s Encrypt TLS certificates can be automated. Since they’re free, there’s no reason not to do it! <a href="https://dzone.com/articles/spring-boot-secured-by-lets-encrypt">Spring Boot Secured By Let’s Encrypt</a> is a useful guide on how to do this.</p>

<p>To force HTTPS in your Spring Boot app, you can extend <code>WebSecurityConfigurerAdapter</code> and require a secure connection.</p>

<pre><code class="language-java">@Configuration
public class SecurityConfiguration extends WebSecurityConfigurerAdapter {

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        http.requiresChannel().requiresSecure();
    }
}

</code></pre>

<p>This configuration will also force HTTPS in development, which can be a pain because you have to use a self-signed certificate. If you’re using Heroku, Cloud Foundry, or other cloud providers, a more logical configuration is to look for the <code>X-Forwarded-Proto</code> header.</p>

<pre><code class="language-java">@Configuration
public class SecurityConfiguration extends WebSecurityConfigurerAdapter {

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        http.requiresChannel()
            .requestMatchers(r -&gt; r.getHeader(&quot;X-Forwarded-Proto&quot;) != null)
            .requiresSecure();
    }
}

</code></pre>

<p>Cloud providers can greatly simplify TLS certificates. <a href="https://aws.amazon.com/certificate-manager/">Amazon Certificate Manager</a> is exactly like Let’s Encrypt except it’s built into all of the AWS products/services by default. It lets you provision 100% free SSL certs and handles automatic renewal, etc., with literally zero effort/config. Heroku has <a href="https://devcenter.heroku.com/articles/automated-certificate-management">Automated Certificate Management</a> too.</p>

<p>Another important thing to do is to use HTTP Strict Transport Security (HSTS). HSTS is a web security policy mechanism that protects websites against protocol downgrade attacks and cookie hijacking. The server communicates the HSTS Policy to the browser with a response header field named <code>Strict-Transport-Security</code>. Spring Security sends this header by default to avoid the unnecessary HTTP hop in the beginning.</p>

<h2 id="toc_1"><a href="#2-check-your-dependencies-with-snyk">2. Check Your Dependencies with Snyk</a></h2>

<p>There’s a good chance you don’t know how many direct dependencies your application uses. It’s extremely likely you don’t know how many transitive dependencies your application uses. This is often true, despite dependencies making up the majority of your overall application. Attackers target open source dependencies more and more, as their reuse provides many victims for a malicious hacker. It’s important to ensure there are no known vulnerabilities in the entire dependency tree of your application.</p>

<p><a href="http://snyk.io">Snyk</a> tests your application build artifacts, flagging those dependencies that have known vulnerabilities. It provides you with a list of vulnerabilities that exist in the packages you’re using in your application as a dashboard.</p>

<p><img src="media/15336595358049/15336596928659.png" alt=""/></p>

<p>Additionally, it will suggest upgrade versions or provide patches to remediate your security issues, via a pull request against your source code repository. Snyk also protects your environment, by ensuring that any future pull requests raised on your repository are automatically tested (via webhooks) to make sure they do not introduce new known vulnerabilities.</p>

<p>New vulnerabilities are found in existing projects and libraries every day, so it’s important to also monitor and protect your production deployments. Snyk takes snapshots and monitors your deployment so that when new vulnerabilities are found, you can automatically be notified via your preferred channel, JIRA, slack or email as well as have pull requests created to offer upgrades and patches to the new vulnerabilities.</p>

<p>Snyk is available via a web UI as well as a CLI, so you can easily integrate it with your CI environment, and configure it to break your build when vulnerabilities exist with a severity beyond your set threshold.</p>

<p>You can use <a href="https://snyk.io/signup">Snyk for free</a> for open source projects or for private projects with a limited number of monthly tests.</p>

<h2 id="toc_2"><a href="#3-upgrade-to-latest-releases">3. Upgrade To Latest Releases</a></h2>

<p>There are various reasons to regularly upgrade the dependencies in your application. Security is one of the most important reasons that will give you the motivation to upgrade. The <a href="http://start.spring.io">start.spring.io</a> starter page uses the most recent versions of Spring packages as well as dependencies, where possible.</p>

<blockquote>
<p>“I find looking for vulnerabilities in your dependencies may help motivate people to upgrade. However, there is plenty of evidence that not all CVEs are even reported. Generally, I find the ideal (perhaps not practical) solution is to be on latest and greatest.” — <a href="https://twitter.com/rob_winch">Rob Winch</a></p>
</blockquote>

<p>Infrastructure upgrades are often less disruptive than dependency upgrades, as library authors vary in their sensitivity to backward compatibility and behavior changes between releases. That being said, you have three options when you find a security vulnerability in your configuration: Upgrade, Patch or Ignore.</p>

<p>Upgrades are the safest, in terms of the overall health of your application after you make any necessary changes to your app to make use of the newer version.</p>

<p>Patches to a vulnerable project eliminate the vulnerability from the package, but typically leaves you will a configuration which might not be as well tested. There will be fewer code changes to your library as the patch will only be changing vulnerable code, so your chances of breaking backward compatibility or introducing behavior changes are reduced. Third party security companies such as Snyk handcraft patches for many vulnerabilities so that if it’s not possible to upgrade to a newer version of a library you can still use an older version with a patch.</p>

<p>Ignoring a vulnerability is, of course, an option, but not a good one. Perhaps you know of a vulnerability, but do not believe it is directly exploitable. Keep in mind that it might not be in your application flow today, but at some point, a developer might add additional code that uses a vulnerable path.</p>

<h2 id="toc_3"><a href="#4-enable-csrf-protection">4. Enable CSRF Protection</a></h2>

<p><a href="https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)">Cross-Site Request Forgery</a> is an attack that forces a user to execute unwanted actions in an application they’re currently logged into. If the user is a normal user, a successful attack can involve state-changing requests like transferring funds or changing their email address. If the user has elevated permissions, a CSRF attack can compromise the entire application.</p>

<p>Spring Security has <a href="https://docs.spring.io/spring-security/site/docs/current/reference/html/csrf.html">excellent CSRF support</a> that’s on by default. If you’re using Spring MVC’s <code>&lt;form:form&gt;</code> tag or Thymeleaf and <code>@EnableWebSecurity</code>, the CSRF token will automatically be added as a hidden input field.</p>

<p>If you’re using a JavaScript framework like Angular or React, you will need to configure the <code>CookieCsrfTokenRepository</code> so JavaScript can read the cookie.</p>

<pre><code class="language-java">@EnableWebSecurity
public class WebSecurityConfig extends WebSecurityConfigurerAdapter {

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        http
            .csrf()
                .csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());
    }
}

</code></pre>

<p>If you’re using Angular, this is all you need to do. If you’re using React, you’ll need to <a href="/blog/2018/07/19/simple-crud-react-and-spring-boot#modify-react-handle-csrf-and-be-identity-aware">read the <code>XSRF-TOKEN</code> cookie and send it back as an <code>X-XSRF-TOKEN</code> header</a>.</p>

<p>Spring Security automatically adds a <code>secure</code> flag to the <code>XSRF-TOKEN</code> cookie when the request happens over HTTPS. Spring Security doesn’t use the <code>SameSite=strict</code> flag for CSRF cookies, but it does when using Spring Session or WebFlux session handling. It makes sense for session cookies since it’s being used to identify the user. It doesn’t provide much value for CSRF cookies since the CSRF token needs to be in the request too.</p>

<h2 id="toc_4"><a href="#5-use-a-content-security-policy-to-prevent-xss-attacks">5. Use a Content Security Policy to Prevent XSS Attacks</a></h2>

<p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">Content Security Policy</a> (CSP) is an added layer of security that helps mitigate <a href="https://www.owasp.org/index.php/Cross-site_Scripting_(XSS)">XSS (cross-site scripting)</a> and data injection attacks. To enable it, you need to configure your app to return a <code>Content-Security-Policy</code> header. You can also use a <code>&lt;meta http-equiv=&quot;Content-Security-Policy&quot;&gt;</code> tag in your HTML page.</p>

<p>Spring security provides a number of <a href="https://docs.spring.io/spring-security/site/docs/current/reference/html/headers.html">security headers by default</a>:</p>

<pre><code class="language-txt">Cache-Control: no-cache, no-store, max-age=0, must-revalidate
Pragma: no-cache
Expires: 0
X-Content-Type-Options: nosniff
Strict-Transport-Security: max-age=31536000 ; includeSubDomains
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block

</code></pre>

<p>Spring Security <u>does not add</u> a CSP by default. You can enable the CSP header in your Spring Boot app using the configuration below.</p>

<pre><code class="language-java">@EnableWebSecurity
public class WebSecurityConfig extends WebSecurityConfigurerAdapter {

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        http.headers()
            .contentSecurityPolicy(&quot;script-src &#39;self&#39; https://trustedscripts.example.com; object-src https://trustedplugins.example.com; report-uri /csp-report-endpoint/&quot;);
    }
}

</code></pre>

<p>CSP is a good defense to prevent XSS attacks. Keep in mind that opening up your CSP to allow for a CDN often allows many very old and vulnerable JavaScript libraries to be accessed. This means using a CDN often means that you are no longer adding much value to the security of your application.</p>

<p>You can test your CSP headers are working with <a href="https://securityheaders.com">securityheaders.com</a>.</p>

<h2 id="toc_5"><a href="#6-use-openid-connect-for-authentication">6. Use OpenID Connect for Authentication</a></h2>

<p>OAuth 2.0 is the industry-standard protocol for authorization. It uses <strong>scopes</strong> to define permissions about what actions an authorized user can perform. However, OAuth 2.0 is not an authentication protocol and provides no information about the authenticated user.</p>

<p>OpenID Connect (OIDC) is an OAuth 2.0 extension that provides user information. It adds an ID token in addition to an access token, as well as a <code>/userinfo</code> endpoint that you can get additional information from. It also adds an endpoint discovery feature and dynamic client registration.</p>

<p>The diagram below shows how OIDC works for authentication.</p>

<p><img src="media/15336595358049/15336596117553.png" alt=""/></p>

<p>If you use OIDC for authentication, you won’t have to worry about storing users, passwords, or authenticating users. Instead, you’ll use an Identity Provider (IdP) to do this for you. Your IdP might even offer security add-ons like multi-factor authentication (MFA).</p>

<p>To see how to use OIDC in your Spring Boot application, see <a href="/blog/2017/12/18/spring-security-5-oidc">Get Started with Spring Security 5.0 and OIDC</a>. To summarize how to use it, you need to add a few dependencies to your project, then configure a few properties in your <code>application.yml</code> file.</p>

<pre><code class="language-yml">spring:
  security:
    oauth2:
      client:
        registration:
          okta:
            client-id: {clientId}
            client-secret: {clientSecret}
            scope: openid email profile
        provider:
          okta:
            issuer-uri: https://{yourOktaDomain}/oauth2/default

</code></pre>

<p><strong>NOTE:</strong> Using <code>issuer-uri</code> is only supported in Spring Security 5.1, which is under active development and scheduled for release in September 2018.</p>

<p>You can set up your own OIDC Server using an open source system like <a href="https://www.keycloak.org/">Keycloak</a>. If you’d rather not maintain your own server in production, you can use Okta’s Developer APIs. Sign up today for a free account and get 1000 active users per month at <a href="https://developer.okta.com/signup/">developer.okta.com/signup</a>!</p>

<p>If you want to play with OAuth 2.0, OIDC, and the different flows it allows, see <a href="https://www.oauth.com/playground/">https://www.oauth.com/playground</a>. This site does not require you to create an account, but it does use Okta’s Developer APIs under the covers.</p>

<h2 id="toc_6"><a href="#7-managing-passwords-use-password-hashing">7. Managing Passwords? Use Password Hashing!</a></h2>

<p>Storing passwords in plain text is one of the worst things you can do for the security of your app. Luckily, Spring Security doesn’t allow plain text passwords by default. It also ships with a <a href="https://docs.spring.io/spring-security/site/docs/current/reference/html/crypto.html">crypto module</a> you can use for symmetric encryption, key generation, and password hashing (a.k.a., password encoding).</p>

<p><code>PasswordEncoder</code> is the main interface for password hashing in Spring Security and looks as follows:</p>

<pre><code class="language-java">public interface PasswordEncoder {
    String encode(String rawPassword);
    boolean matches(String rawPassword, String encodedPassword);
}

</code></pre>

<p>Spring Security provides several implementations, the most popular being <code>BCryptPasswordEncoder</code> and <code>Pbkdf2PasswordEncoder</code>.</p>

<p>For managing passwords in general, we recommend using either SCrypt or Argon2. SCrypt is old now (been around a while), and has an extra complexity factor that BCrypt doesn’t, making it exponentially more difficult/expensive to brute force. It’s written by a famous cryptographer/security guy (<a href="https://twitter.com/cperciva">Colin Percival</a>) and has great libraries in just about every programming language. SCrypt is also endorsed by <a href="https://latacora.singles/2018/04/03/cryptographic-right-answers.html">Latacora</a>.</p>

<p>From <a href="https://twitter.com/rdegges">Randall Degges</a>, a cryptography expert on the Okta Developer Relations team:</p>

<blockquote>
<p>Argon2 is relatively new (a few years old now), but has been widely audited/reviewed and was the result of a cryptographic hashing challenge that many organizations took part in over the course of several years. It’s without a doubt the “strongest” hashing algorithm of them all adds another layer of complexity that scrypt doesn’t, which makes it exponentially more expensive/difficult to brute force compared to scrypt. Argon2 is awesome, and I’ve used it with great success in several languages, but if you’re worried about being too bleeding-edge scrypt is a safe bet, and not controversial.</p>
</blockquote>

<p>From <a href="https://twitter.com/rob_winch">Rob Winch</a>, Spring Security Lead:</p>

<blockquote>
<p>“I like BCrypt, but the general advice is one-way adaptive hashes. Some users may need to use PBKDF2 for compliance reasons. There is a <a href="https://github.com/spring-projects/spring-security/issues/5354">ticket logged</a> for Argon2 support, but there are not any Apache 2 native Java implementations that I have found (if you know of any, please let me know!). Instead, the libraries rely on a binary that they delegate to which isn’t ideal from my perspective. We are on the fence about waiting vs. leveraging one of the implementations that delegate to a binary.”</p>
</blockquote>

<p>For those that want to use SCrypt, there is support in Spring Security through Bouncy Castle in <a href="https://docs.spring.io/spring-security/site/docs/current/reference/htmlsingle/#pe-scpe"><code>SCryptPasswordEncoder</code></a>. Spring Security 5.1 (est. late September 2018) will ship with a <a href="https://github.com/spring-projects/spring-security/issues/2778">UserDetailsPasswordService API</a> that allows you to upgrade your password storage.</p>

<h2 id="toc_7"><a href="#8-store-secrets-securely">8. Store Secrets Securely</a></h2>

<p>Sensitive information such as passwords, access tokens, etc., should be handled with care. You cannot leave these around, pass them in plain text, or be predictable if keeping them in your local storage. As (GitHub) <a href="https://github.com/search?q=removed+password&amp;type=Commits">history has proved</a> time and time again, developers do not think carefully enough about how they store their secrets.</p>

<p>Of course, you could and should encrypt your sensitive data, such as a password. Now that your password is safe, you have a new secret, your decryption key! What are you going to do with this new secret? Maybe store it locally? Perhaps in another location, somewhere you think an attacker would struggle to find it. This doesn’t fix the problem; it just defers it. Without putting a proper process in place, you only make it slightly harder for a hacker to unlock your secrets.</p>

<p>A good practice is to store secrets in a vault that can be used to store, provide access to, and even generate credentials to services that your application may use. <a href="https://www.vaultproject.io/">Vault by HashiCorp</a> makes storing secrets trivial, as well as offering a number of additional services. Vault can be configured so that no one person can access all data, providing no single point of control. The root key Vault uses changes regularly and is only stored in memory. There’s a master switch that when triggered will seal your vault, stopping it from sharing secrets if an issue occurs. Vault uses tokens that are assigned to policies that can scope particular users, services, or applications. You can also integrate with common authentication mechanisms such as LDAP to obtain tokens.</p>

<p>In addition to the golden-path view where no issues exists, Vault also helps with the scenario that exists when you have been hacked. At this point it’s important to revoke single or multiple secrets, perhaps by a specific user, or of a specific type. Vault offers an automated way to do this quickly when the time comes.</p>

<p>If this interests you, be sure to invest some time looking at the <a href="http://projects.spring.io/spring-vault/">Spring Vault</a> which adds an abstraction over the HashiCorp Vault, providing Spring annotation based access for clients, allowing them to access, store, and revoke secrets without getting lost in the infrastructure. The following code snippet shows how easy it is to extract a password from the Spring Vault using an annotation.</p>

<pre><code class="language-java">@Value(&quot;${password}&quot;)
String password;

</code></pre>

<h2 id="toc_8"><a href="#9-test-your-app-with-owasps-zap">9. Test Your App with OWASP’s ZAP</a></h2>

<p>The <a href="https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project">OWASP ZAP</a> security tool is a proxy that performs penetration testing against your live application at runtime. It’s a popular (over 4k stars) free, open source project that is hosted on <a href="https://github.com/zaproxy/zaproxy">GitHub</a>.</p>

<p>Two approaches OWASP ZAP uses to find vulnerabilities are Spider and Active Scan. The Spider tool starts with a seed of URLs, which it will access and parse through each response, identifying hyperlinks and adding them to a list. It will then access these newly found URLs and recursively continue, creating a map of URLs for your web application. The Active Scan tool will automatically test your selected targets against a list of potential vulnerabilities. It provides you with a report that shows where your web application is exploitable, with details about the vulnerability.</p>

<h2 id="toc_9"><a href="#10-have-your-security-team-do-a-code-review">10. Have Your Security Team do a Code Review</a></h2>

<p>Code reviews are essential for any high performing software development team. At Okta, all of our production code and official open source projects are required to go through an analysis from our expert security team. You might not have security experts at your company, but if you’re dealing with sensitive data, maybe you should!</p>

<h2 id="toc_10"><a href="#dont-allow-your-lack-of-security-to-be-disturbing">Don’t Allow Your Lack of Security to be Disturbing</a></h2>

<p>Okta has some great t-shirts that say “I find your lack of security disturbing”. We love to hear the sound of latex gloves being put on as we wear them when traveling through airports. Don’t be the type of developer that lacks security in their Spring Boot apps!</p>

<p>To learn more about Spring Boot and security in your applications, check out the following tutorials and articles:</p>

<ul>
<li>  <a href="/blog/2017/12/18/spring-security-5-oidc">Get Started with Spring Security 5.0 and OIDC</a></li>
<li>  <a href="/blog/2018/07/19/simple-crud-react-and-spring-boot">Use React and Spring Boot to Build a Simple CRUD App</a></li>
<li>  <a href="/blog/2017/10/13/okta-groups-spring-security">Add Role-Based Access Control to Your App with Spring Security and Thymeleaf</a></li>
<li>  <a href="https://www.okta.com/security-blog/2018/05/security-and-the-api-journey/">Security and the API Journey</a></li>
<li>  <a href="https://devcenter.heroku.com/articles/preparing-a-spring-boot-app-for-production-on-heroku">Preparing a Spring Boot App for Production on Heroku</a></li>
</ul>

<p>If you like this article and want to see more like it, follow <a href="https://twitter.com/oktadev">@oktadev on Twitter</a>, or <a href="https://www.facebook.com/oktadevelopers/">on Facebook</a>. And as always, we’d love to hear from you in the comments below.</p>

<p><script type="text/javascript">var disqus_title = &quot;10 Excellent Ways to Secure Your Spring Boot Application&quot;; var disqus_url = &#39;<a href="https://developer.okta.com/blog/2018/07/30/10-ways-to-secure-spring-boot">https://developer.okta.com/blog/2018/07/30/10-ways-to-secure-spring-boot</a>&#39;; (function () { var dsq = document.createElement(&#39;script&#39;); dsq.async = true; dsq.type = &#39;text/javascript&#39;; dsq.src = &#39;//oktadevblog.disqus.com/embed.js&#39;; (document.getElementsByTagName(&#39;head&#39;)[0] || document.getElementsByTagName(&#39;body&#39;)[0]).appendChild(dsq); })();</script> Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus</a>.</article></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First MicroProfile.io application using Java Module System]]></title>
    <link href="http://panlw.github.io/15336592302916.html"/>
    <updated>2018-08-08T00:27:10+08:00</updated>
    <id>http://panlw.github.io/15336592302916.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Embrace the JPMS power with MicroProfile.io applications</h2>

<h3 id="toc_1">Update</h3>

<p>Sample application migrated to use JDK 11.</p>

<h3 id="toc_2">MicroProfile.io</h3>

<p><a href="https://microprofile.io/">Eclipse MicroProfile</a> project is growing fast, it has a lot of supporters and compatible implementations.</p>

<p>I see it as a new way to package enterprise Java Enterprise applications that already leverage of existing Java Specifications (JSRs) and want to be compatible with different platforms, specially ready for running in Cloud.</p>

<p>It also aims to reduce the gap between community feedback and release of new features.</p>

<p>I would like to mention that in addition of well know MicroProfile implementations like Payara Micro, WildFly Swarm, TomEE and Websphere Liberty, there&#39;s also Hammock, which I&#39;ll use in this post.</p>

<p><a href="https://hammock-project.github.io/">Hammock</a> is an open-source project that allows the creation of CDI based microservices using Microprofile.io specification and additional starter modules such as JPA (Hibernate/EclipseLink/OpenJPA), Security (JWT, Keycloak), Messaging (Artemis/RabbitMQ) or your own starter module, just like Spring Boot does, but in a CDI way.</p>

<p>Currently in development version 2.2 supports most of MicroProfile.io 1.3 capabilities.</p>

<h3 id="toc_3">First MicroProfile.io JPMS application</h3>

<p>There&#39;re few ways to start using Hammock, the easiest one is to add the following maven dependency.</p>

<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;ws.ament.hammock&lt;/groupId&gt;
    &lt;artifactId&gt;dist-microprofile&lt;/artifactId&gt;
    &lt;version&gt;${hammock.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<p>Personally, as I want to ensure my application dependencies are thin I prefer to use the DIY way, adding each module individually (CDI, REST, JSON), so I can choose which implementation of CDI, REST and JSON I’ll use.</p>

<p>It also helps us to fix JPMS comparability issues that I found during the implementation of (my) first MicroProfile.io JPMS application (I have not heard of any other on the internet).</p>

<p>As usual, I already explained in previous post <a href="https://medium.com/criciumadev/java-10-migration-5d853f5b5f7e"><strong>Upgrade to Java 10 now! Why not?</strong></a> in which I only add module-info.java and deal with application dependencies to start using module system.</p>

<h4 id="toc_4">The problem</h4>

<p>Java Module System (JPMS) is still recent and thirdparty libraries and frameworks are trying to catch up to support modularization, so we will need a few tweaks, like preventing two JARs with the same package names conflicts in the classpath (that was already a hidden problem, because you know, API changes and first class on classpath wins).</p>

<p>With JPMS, it prevents two modules (or automatic modules) to export the same package.</p>

<h4 id="toc_5">Solution</h4>

<p>The sample application is a basic Hello World JAX-RS resource using JSON-B.</p>

<pre><code class="language-java">package hammock.jpms;

import javax.enterprise.context.RequestScoped;
import javax.ws.rs.*;

@Path(&quot;/hello&quot;)
@RequestScoped
public class HelloResource {

    @GET
    public Person hello() {
        Person person = new Person();
        person.setName(&quot;Leonardo&quot;);
        return person;
    }
}
</code></pre>

<p>With the following module descriptor:</p>

<pre><code class="language-java">open module hammock.jpms {

    requires cdi.api;
    requires hammock.core;
    requires java.json.bind;
    requires java.ws.rs;
    requires java.xml;
    requires jdk.unsupported;
    requires org.apache.logging.log4j;

}
</code></pre>

<p>View the <a href="https://github.com/panga/hammock-jpms/blob/master/pom.xml">Maven project descriptor (pom.xml)</a> to see the dependencies and plugins declarations.</p>

<h3 id="toc_6">Results</h3>

<p>The total size of this example application is around <code>12mb</code> and the startup time of the whole application is around <code>1s</code> in my machine.</p>

<p>Also the maximum memory usage (RSS) of the JVM was <code>133mb</code> in my tests.</p>

<p><u>Note: The maximum heap size used in tests was -Xmx128m.</u></p>

<h3 id="toc_7">Put Things Together using JLink and Docker</h3>

<p>Following the same approach of previous post <a href="https://medium.com/criciumadev/create-a-cloud-native-image-using-java-modules-a670be616b29"><strong>Create a Cloud Native Image using Java Modules</strong></a> I can create a minimal JVM to run the application and generate a Docker image.</p>

<pre><code class="language-Dockerfile">FROM panga/openjdk-alpine:11-jdk as builder

RUN jlink \
    --add-modules java.logging,java.xml,java.naming,java.management,jdk.unsupported \
    --verbose \
    --strip-debug \
    --compress 2 \
    --no-header-files \
    --no-man-pages \
    --output /opt/jre-minimal

FROM alpine:3.8

COPY --from=builder /opt/jre-minimal /opt/jre-minimal

ENV LANG=C.UTF-8 \
    PATH=${PATH}:/opt/jre-minimal/bin

ADD modules /opt/app/modules
ADD patch/java.beans /opt/app/patch/java.beans

ARG JVM_OPTS
ENV JVM_OPTS=${JVM_OPTS}

CMD java ${JVM_OPTS} \
    --patch-module java.base=/opt/app/patch/java.beans \
    --add-exports java.base/java.beans=johnzon.mapper \
    --add-exports java.base/java.beans=org.apache.logging.log4j.core \
    --module-path /opt/app/modules \
    --module hammock.jpms
</code></pre>

<p>The resulting was an amazing <code>54.3mb</code> Docker image with only minimal JRE and application modules.</p>

<p>If you look carefully, you will notice that a <code>patch-module</code> was added in the command line in order to <strong>hack</strong> JPMS and remove <code>java.desktop</code> module dependency. We really don&#39;t need Swing/AWT classes here!</p>

<p>I was only able to achieve that using my new pet project <a href="https://github.com/panga/lite-beans">LiteBeans</a>, a <u>java.beans</u> package patch and alternative API implementation used to remove <u>java.desktop</u> module requirement on JDK 9 and up.</p>

<p><a href="https://github.com/panga/lite-beans" title="https://github.com/panga/lite-beans"><strong>panga/lite-beans</strong><br/>
<u>lite-beans - LiteBeans is implementation of the java.beans package based on the Apache Harmony project</u>github.com</a><a href="https://github.com/panga/lite-beans"></a></p>

<h3 id="toc_8">Conclusion</h3>

<p>The CDI is the new glue and Docker the new hammer.</p>

<p>Finally, you can find the source in this repository: <a href="https://github.com/panga/hammock-jpms">panga/hammock-jpms</a></p>

<p>Also the instructions to build and run are available in the <a href="https://github.com/panga/hammock-jpms/blob/master/README.md">README</a>.</p>

<p><a href="https://github.com/panga/hammock-jpms" title="https://github.com/panga/hammock-jpms"><strong>panga/hammock-jpms</strong><br/>
<u>hammock-jpms - Hammock MicroProfile (CDI + JAXRS + JSON) HelloWorld using Java Module System (JPMS)</u>github.com</a><a href="https://github.com/panga/hammock-jpms"></a></section></p>

<ul>
<li>  <a href="https://medium.com/tag/java?source=post">Java</a></li>
<li>  <a href="https://medium.com/tag/microprofile?source=post">Microprofile</a></li>
<li>  <a href="https://medium.com/tag/jdk10?source=post">Jdk10</a></li>
<li>  <a href="https://medium.com/tag/java10?source=post">Java10</a></li>
<li>  <a href="https://medium.com/tag/jigsaw?source=post">Jigsaw</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jenkins 的 Pipeline 脚本在美团餐饮 SaaS 中的实践]]></title>
    <link href="http://panlw.github.io/15332186142588.html"/>
    <updated>2018-08-02T22:03:34+08:00</updated>
    <id>http://panlw.github.io/15332186142588.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://tech.meituan.com/erp_cd_jenkins_pipeline.html">https://tech.meituan.com/erp_cd_jenkins_pipeline.html</a></p>

<p>张杰 王浩 ·2018-08-02 20:39</p>
</blockquote>

<h2 id="toc_0">一、背景</h2>

<p>在日常开发中，我们经常会有发布需求，而且还会遇到各种环境，比如：线上环境（Online），模拟环境（Staging），开发环境（Dev）等。最简单的就是手动构建、上传服务器，但这种方式太过于繁琐，使用持续集成可以完美地解决这个问题，推荐了解一下 <a href="https://jenkins.io/">Jenkins</a>。<br/>
Jenkins 构建也有很多种方式，现在使用比较多的是自由风格的软件项目（Jenkins 构建的一种方式，会结合 SCM 和构建系统来构建你的项目，甚至可以构建软件以外的系统）的方式。针对单个项目的简单构建，这种方式已经足够了，但是针对多个类似且又存在差异的项目，就难以满足要求，否则就需要大量的 job 来支持，这就存在，一个小的变动，就需要修改很多个 job 的情况，难以维护。我们团队之前就存在这样的问题。</p>

<p>目前，我们团队主要负责开发和维护多个 Android 项目，而且每个项目都需要构建，每个构建流程非常类似但又存在一定的差异。比如构建的流程大概如下：</p>

<ul>
<li>  克隆代码；</li>
<li>  静态代码检查（可选）；</li>
<li>  单元测试（可选）；</li>
<li>  编译打包 APK 或者热补丁；</li>
<li>  APK 分析，获取版本号（VersionCode），包的 Hash 值（apkhash）等；</li>
<li>  加固；</li>
<li>  上传测试分发平台；</li>
<li>  存档（可选）；</li>
<li>  触发自动化测试（可选）；</li>
<li>  通知负责人构建结果等。</li>
</ul>

<p>整个流程大体上是相同的，但是又存在一些差异。比如有的构建可以没有单元测试，有的构建不用触发自动化测试，而且构建结果通知的负责人也不同。如果使用自由风格软件项目的普通构建，每个项目都要建立一个 job 来处理流程（可能会调用其他 job）。</p>

<p>这种处理方式原本也是可以的，但是必须考虑到，可能会有新的流程接入（比如二次签名），构建流程也可能存在 Bug 等多种问题。无论哪种情况，一旦修改主构建流程，每个项目的 job 都需要修改和测试，就必然会浪费大量的时间。针对这种情况，我们使用了 Pipeline 的构建方式来解决。</p>

<p>当然，如果有项目集成了 React Native，还需要构建 JsBundle。在 Native 修改以后，JsBundle 不一定会有更新，如果是构建 Native 的时候一起构建 JsBundle，就会造成很多资源浪费。并且直接把 JsBundle 这类大文件放在 Native 的 Git 仓库里，也不是特别合适。</p>

<p>本文是分享一种<code>Pipeline</code>的使用经验，来解决这类问题。</p>

<h2 id="toc_1">二、Pipeline 的介绍</h2>

<p>Pipeline 也就是构建流水线，对于程序员来说，最好的解释是：使用代码来控制项目的构建、测试、部署等。使用它的好处有很多，包括但不限于：</p>

<ul>
<li>  使用 Pipeline 可以非常灵活的控制整个构建过程；</li>
<li>  可以清楚的知道每个构建阶段使用的时间，方便构建的优化；</li>
<li>  构建出错，使用 stageView 可以快速定位出错的阶段；</li>
<li>  一个 job 可以搞定整个构建，方便管理和维护等。</li>
</ul>

<p><strong>Stage View</strong></p>

<p><img src="media/15332186142588/15332187874743.png" alt=""/></p>

<h2 id="toc_2">三、使用 Pipeline 构建</h2>

<p>新建一个 Pipeline 项目，写入 Pipeline 的构建脚本，就像下面这样:</p>

<p><img src="media/15332186142588/15332187981437.png" alt=""/></p>

<p>对于单个项目来说，使用这样的 Pipeline 来构建能够满足绝大部分需求，但是这样做也有很多缺陷，包括：</p>

<ul>
<li>  多个项目的 Pipeline 打包脚本不能公用，导致一个项目写一份脚本，维护比较麻烦。一个变动，需要修改多个 job 的脚本；</li>
<li>  多个人维护构建 job 的时候，可能会覆盖彼此的代码；</li>
<li>  修改脚本失败以后，无法回滚到上个版本；</li>
<li>  无法进行构建脚本的版本管理，老版本发修复版本需要构建，可能和现在用的 job 版本已经不一样了，等等。</li>
</ul>

<h2 id="toc_3">四、把 Pipeline 当代码写</h2>

<p>既然存在缺陷，我们就要找更好的方式，其实 Jenkins 提供了一个更优雅的管理 Pipeline 脚本的方式，在配置项目 Pipeline 的时候，选择<code>Pipeline script from SCM</code>，就像下面这样：</p>

<p><img src="media/15332186142588/15332188225715.png" alt=""/></p>

<p>这样，Jenkins 在启动 job 的时候，首先会去仓库里面拉取脚本，然后再运行这个脚本。在脚本里面，我们规定的构建方式和流程，就会按部就班地执行。构建的脚本，可以实现多人维护，还可以 Review，避免出错。 以上就算搭建好了一个基础，而针对多个项目时，还有一些事情要做，不可能完全一样，以下是构建的结构图：</p>

<p><img src="media/15332186142588/15332188392351.png" alt=""/></p>

<p>如此以来，我们的构建数据来源分为三部分：job UI 界面、仓库的通用 Pipeline 脚本、项目下的特殊配置，我们分别来看一下：</p>

<h3 id="toc_4">job UI 界面（参数化构建）</h3>

<p>在配置 job 的时候，选择参数化构建过程，传入项目仓库地址、分支、构建通知人等等。还可以增加更多的参数 ，这些参数的特点是，可能需要经常修改，比如灵活选择构建的代码分支。</p>

<p><img src="media/15332186142588/15332188481073.png" alt=""/></p>

<h3 id="toc_5">项目配置</h3>

<p>在项目工程里面，放入针对这个项目的配置，一般是一个项目固定，不经常修改的参数，比如项目名字，如下图：</p>

<p><img src="media/15332186142588/15332188580960.png" alt=""/></p>

<h3 id="toc_6">注入构建信息</h3>

<p>QA 提一个 Bug，我们需要确定，这是哪次的构建，或者要知道 commitId，从而方便进行定位。因此在构建时，可以把构建信息注入到 APK 之中。</p>

<ol>
<li> 把属性注入到<code>gradle.properties</code></li>
</ol>

<pre><code class="language-properties"># 应用的后端环境
APP_ENV=Beta
# CI 打包的编号，方便确定测试的版本，不通过 CI 打包，默认是 0
CI_BUILD_NUMBER=0
# CI 打包的时间，方便确定测试的版本，不通过 CI 打包，默认是 0
CI_BUILD_TIMESTAMP=0
</code></pre>

<ol>
<li> 在 build.gradle 里设置 buildConfigField</li>
</ol>

<pre><code class="language-groovy">#使用的是 gradle.properties 里面注入的值
buildConfigField &quot;String&quot;, &quot;APP_ENV&quot;, &quot;\&quot;${APP_ENV}\&quot;&quot;
buildConfigField &quot;String&quot;, &quot;CI_BUILD_NUMBER&quot;, &quot;\&quot;${CI_BUILD_NUMBER}\&quot;&quot;
buildConfigField &quot;String&quot;, &quot;CI_BUILD_TIMESTAMP&quot;, &quot;\&quot;${CI_BUILD_TIMESTAMP}\&quot;&quot;
buildConfigField &quot;String&quot;, &quot;GIT_COMMIT_ID&quot;, &quot;\&quot;${getCommitId()}\&quot;&quot;

// 获取当前 Git commitId
String getCommitId() {
    try {
        def commitId = &#39;git rev-parse HEAD&#39;.execute().text.trim()
        return commitId;
    } catch (Exception e) {
        e.printStackTrace();
    }
}
</code></pre>

<p>3. 显示构建信息<br/>
在App里，找个合适的位置，比如开发者选项里面，把刚才的信息显示出来。QA提Bug时，要求他们把这个信息一起带上</p>

<pre><code class="language-java">mCIIdtv.setText(String.format(&quot;CI 构建号:%s&quot;, BuildConfig.CI_BUILD_NUMBER));
mCITimetv.setText(String.format(&quot;CI 构建时间:%s&quot;, BuildConfig.CI_BUILD_TIMESTAMP));
mCommitIdtv.setText(String.format(&quot;Git CommitId:%s&quot;, BuildConfig.GIT_COMMIT_ID));
</code></pre>

<h3 id="toc_7">仓库的通用 Pipeline 脚本</h3>

<p>通用脚本是抽象出来的构建过程，遇到和项目有关的都需要定义成变量，再从变量里进行读取，不要在通用脚本里写死。</p>

<pre><code class="language-jenkinsfile">node {
    try{
        stage(&#39;检出代码&#39;){//从git仓库中检出代码
            git branch: &quot;${BRANCH}&quot;,credentialsId: &#39;xxxxx-xxxx-xxxx-xxxx-xxxxxxx&#39;, url: &quot;${REPO_URL}&quot;
               loadProjectConfig();
          }
           stage(&#39;编译&#39;){
               //这里是构建，你可以调用job入参或者项目配置的参数，比如：
               echo &quot;项目名字 ${APP_CHINESE_NAME}&quot;
               //可以判断
               if (Boolean.valueOf(&quot;${IS_USE_CODE_CHECK}&quot;)) {
                   echo &quot;需要静态代码检查&quot;
               } else {
                   echo &quot;不需要静态代码检查&quot;
               }

           }
           stage(&#39;存档&#39;){//这个演示的Android的项目，实际使用中，请根据自己的产物确定
               def apk = getShEchoResult (&quot;find ./lineup/build/outputs/apk -name &#39;*.apk&#39;&quot;)
               def artifactsDir=&quot;artifacts&quot;//存放产物的文件夹
            sh &quot;mkdir ${artifactsDir}&quot;
               sh &quot;mv ${apk} ${artifactsDir}&quot;
               archiveArtifacts &quot;${artifactsDir}/*&quot;
           }
           stage(&#39;通知负责人&#39;){
               emailext body: &quot;构建项目:${BUILD_URL}\r\n构建完成&quot;, subject: &#39;构建结果通知【成功】&#39;, to: &quot;${EMAIL}&quot;
           }
    } catch (e) {
        emailext body: &quot;构建项目:${BUILD_URL}\r\n构建失败，\r\n错误消息：${e.toString()}&quot;, subject: &#39;构建结果通知【失败】&#39;, to: &quot;${EMAIL}&quot;
    } finally{
        // 清空工作空间
        cleanWs notFailBuild: true
    }

}

// 获取 shell 命令输出内容
def getShEchoResult(cmd) {
    def getShEchoResultCmd = &quot;ECHO_RESULT=`${cmd}`\necho \${ECHO_RESULT}&quot;
    return sh (
        script: getShEchoResultCmd,
        returnStdout: true
    ).trim()
}

//加载项目里面的配置文件
def loadProjectConfig(){
    def jenkinsConfigFile=&quot;./jenkins.groovy&quot;
    if (fileExists(&quot;${jenkinsConfigFile}&quot;)) {
        load &quot;${jenkinsConfigFile}&quot;
        echo &quot;找到打包参数文件${jenkinsConfigFile}，加载成功&quot;
    } else {
        echo &quot;${jenkinsConfigFile}不存在,请在项目${jenkinsConfigFile}里面配置打包参数&quot;
        sh &quot;exit 1&quot;
    }
}
</code></pre>

<p>轻轻的点两下<code>Build with Parameters</code> -&gt; <code>开始构建</code>，然后等几分钟的时间，就能够收到邮件。</p>

<p><img src="media/15332186142588/15332189738099.png" alt=""/></p>

<h2 id="toc_8">五、其他构建结构</h2>

<p>以上，仅仅是针对我们当前遇到问题的一种不错的解决方案，可能并不完全适用于所有场景，但是可以根据上面的结构进行调整，比如：</p>

<ul>
<li>  根据 stage 拆分出不同的 Pipeline 脚本，这样方便 CI 的维护，一个或者几个人维护构建中的一个 stage；</li>
<li>  把构建过程中的 stage 做成普通的<code>自由风格的软件项目</code>的 job，把它们作为基础服务，在 Pipeline 中调用这些基础服务等。</li>
</ul>

<h2 id="toc_9">六、当遇上 React Native</h2>

<p>当项目引入了 React Native 以后，因为技术栈的原因，React Native 的页面是由前端团队开发，但容器和原生组件是 Android 团队维护，构建流程也发生了一些变化。</p>

<h3 id="toc_10">方案对比</h3>

<table>
<thead>
<tr>
<th>方案</th>
<th>说明</th>
<th>缺点</th>
<th>优点</th>
</tr>
</thead>

<tbody>
<tr>
<td>手动拷贝</td>
<td>等 JsBundle 构建好了，再手动把构建完成的产物，拷贝到 Native 工程里面</td>
<td>1. 每次手动操作，比较麻烦，效率低，容易出错</td>
<td></td>
</tr>
</tbody>
</table>

<p>2. 涉及到跨端合作，每次要去前端团队主动拿 JsBundle<br/>
3. Git 不适合管理大文件和二进制文件 | 简单粗暴 |<br/>
| 使用 submodule 保存构建好的 JsBundle | 直接把 JsBundle 放在 Native 仓库的一个 submodule 里面，由前端团队主动更新，每次更新 Native 的时候，直接就拿到了最新的 JsBundle | 1. 简单无开发成本<br/>
2. 不方便单独控制 JsBundle 的版本<br/>
3. Git 不适合管理大文件和二进制文件 | 前端团队可以主动更新 JsBundle |<br/>
| 使用 submodule 管理 JsBundle 的源码 | 直接把 JsBundle 的源码放在 Native 仓库的一个 submodule 里面，由前端团队开发更新，每次构建 Native 的时候，先构构建 JsBundle | 1. 不方便单独控制 JsBundle 的版本<br/>
2. 即使 JsBundle 无更新，也需要构建，构建速度慢，浪费资源 | 方便灵活 |<br/>
| 分开构建，产物存档 | JsBundle 和 Native 分开构建，构建完了的 JsBundle 分版本存档，Native 构建的时候，直接去下载构建好了的 JsBundle 版本 | 1. 通过配置管理 JsBundle，解放 Git<br/>
2. 方便 Jenkins 构建的时候，动态配置需要的 JsBundle 版本 | 1. 需要花费时间建立流程<br/>
2. 需要开发 Gradle 的 JsBundle 下载插件 |</p>

<p>前端团队开发页面，构建后生成 JsBundle，Android 团队拿到前端构建的 JsBundle，一起打包生成最终的产物。 在我们开发过程中，JsBundle 修改以后，不一定需要修改 Native，Native 构建的时候，也不一定每次都需要重新构建 JsBundle。并且这两个部分由两个团队负责，各自独立发版，构建的时候也应该独立构建，不应该融合到一起。</p>

<p>综合对比，我们选择了使用分开构建的方式来实现。</p>

<h3 id="toc_11">分开构建</h3>

<p>因为需要分开发布版本，所以 JsBundle 的构建和 Native 的构建要分开，使用两个不同的 job 来完成，这样也方便两个团队自行操作，避免相互影响。 JsBundle 的构建，也可以参考上文提到的 Pipeline 的构建方式来做，这里不再赘述。<br/>
在独立构建以后，怎么才能组合到一起呢？我们是这样思考的：JsBundle 构建以后，分版本的储存在一个地方，供 Native 在构建时下载需要版本的 JsBundle，大致的流程如下：</p>

<p><img src="media/15332186142588/15332189883865.png" alt=""/></p>

<p>这个流程有两个核心，一个是构建的 JsBundle 归档存储，一个是在 Native 构建时去下载。</p>

<h3 id="toc_12">JsBundle 归档存储</h3>

<table>
<thead>
<tr>
<th>方案</th>
<th>缺点</th>
<th>优点</th>
</tr>
</thead>

<tbody>
<tr>
<td>直接存档在 Jenkins 上面</td>
<td>1. JsBundle 不能汇总浏览</td>
<td></td>
</tr>
</tbody>
</table>

<p>2. Jenkins 很多人可能要下载，命名带有版本号，时间，分支等，命名不统一，不方便构建下载地址<br/>
3. 下载 Jenkins 上面的产物需要登陆授权，比较麻烦 | 1. 实现简单，一句代码就搞定，成本低 |<br/>
| 自己构建一个存储服务 | 1. 工程大，开发成本高<br/>
2. 维护起来麻烦 | 可扩展，灵活性高 |<br/>
| MSS<br/>
(美团存储服务) | 无 | 1. 储存空间大<br/>
2. 可靠性高，配合 CDN 下载速度快<br/>
3. 维护成本低， 价格便宜 |</p>

<p>这里我们选择了 MSS。 上传文件到 MSS，可以使用<code>s3cmd</code>，但毕竟不是每个 Slave 上面都有安装，通用性不强。为了保证稳定可靠，这里基于 <a href="https://github.com/meituan/mssapi_java">MSS 的 SDK</a> 写个小工具即可，比较简单，几行代码就可以搞定。</p>

<pre><code class="language-java">private static String TenantId = &quot;mss_TenantId==&quot;;
private static AmazonS3 s3Client;

public static void main(String[] args) throws IOException {
    if (args == null || args.length != 3) {
        System.out.println(&quot;请依次输入：inputFile、bucketName、objectName&quot;);
        return;
    }
    s3Client = AmazonS3ClientProvider.CreateAmazonS3Conn();
    uploadObject(args[0], args[1], args[2]);
}

public static void uploadObject(String inputFile, String bucketName, String objectName) {
    try {
        File file = new File(inputFile);
        if (!file.exists()) {
            System.out.println(&quot;文件不存在：&quot; + file.getPath());
            return;
        }
        s3Client.putObject(new PutObjectRequest(bucketName, objectName, file));
        System.out.printf(&quot;上传%s到MSS成功: %s/v1/%s/%s/%se&quot;, inputFile, AmazonS3ClientProvider.url, TenantId, bucketName, objectName);
    } catch (AmazonServiceException ase) {
        System.out.println(&quot;Caught an AmazonServiceException, which &quot; +
                &quot;means your request made it &quot; +
                &quot;to Amazon S3, but was rejected with an error response&quot; +
                &quot; for some reason.&quot;);
        System.out.println(&quot;Error Message:    &quot; + ase.getMessage());
        System.out.println(&quot;HTTP Status Code: &quot; + ase.getStatusCode());
        System.out.println(&quot;AWS Error Code:   &quot; + ase.getErrorCode());
        System.out.println(&quot;Error Type:       &quot; + ase.getErrorType());
        System.out.println(&quot;Request ID:       &quot; + ase.getRequestId());
    } catch (AmazonClientException ace) {
        System.out.println(&quot;Caught an AmazonClientException, which &quot; +
                &quot;means the client encountered &quot; +
                &quot;an internal error while trying to &quot; +
                &quot;communicate with S3, &quot; +
                &quot;such as not being able to access the network.&quot;);
        System.out.println(&quot;Error Message: &quot; + ace.getMessage());
    }
}
</code></pre>

<p>我们直接在 Pipeline 里构建完成后，调用这个工具就可以了。<br/>
当然，JsBundle 也分类型，在调试的时候可能随时需要更新，这些 JsBundle 不需要永久保存，一段时间后就可以删除了。在删除时，可以参考 <a href="https://www.mtyun.com/doc/sdk/mss-sdk/java/sheng-ming-zhu-qi-guan-li">MSS 生命周期管理</a>。所以，我们在构建 JsBundle 的 job 里，添加一个参数来区分。</p>

<pre><code class="language-jenkinsfile">//根据TYPE，上传到不同的bucket里面
def bucket = &quot;rn-bundle-prod&quot;
if (&quot;${TYPE}&quot; == &quot;dev&quot;) {
    bucket = &quot;rn-bundle-dev&quot; //有生命周期管理，一段时间后自动删除
}
echo &quot;开始JsBundle上传到MSS&quot;
//jar地址需要替换成你自己的
sh &quot;curl -s -S -L  http://s3plus.sankuai.com/v1/mss_xxxxx==/rn-bundle-prod/rn.bundle.upload-0.0.1.jar -o upload.jar&quot;
sh &quot;java -jar upload.jar ${archiveZip} ${bucket} ${PROJECT}/${targetZip}&quot;
echo &quot;上传JsBundle到MSS:${archiveZip}&quot;

</code></pre>

<h3 id="toc_13">Native 构建时 JsBundle 的下载</h3>

<p>为了实现构建时能够自动下载，我们写了一个 Gradle 的插件。<br/>
首先要在 build.gradle 里面配置插件依赖：</p>

<pre><code class="language-gradle">classpath &#39;com.zjiecode:rn-bundle-gradle-plugin:0.0.1&#39;
</code></pre>

<p>在需要的 Module 应用插件：</p>

<pre><code class="language-gradle">apply plugin: &#39;mt-rn-bundle-download&#39;
</code></pre>

<p>在 build.gradle 里面配置 JsBundle 的信息：</p>

<pre><code class="language-jenkinsfile">RNDownloadConfig {
    //远程文件目录,因为有多种类型，所以这里可以填多个。
    paths = [
            &#39;http://msstest-corp.sankuai.com/v1/mss_xxxx==/rn-bundle-dev/xxx/&#39;,
            &#39;http://msstest-corp.sankuai.com/v1/mss_xxxx==/rn-bundle-prod/xxx/&#39;
    ]
    version  = &quot;1&quot;//版本号，这里使用的是打包JsBundle的BUILD_NUMBER
    fileName = &#39;xxxx.android.bundle-%s.zip&#39; //远程文件的文件名,%s会用上面的version来填充
    outFile  = &#39;xxxx/src/main/assets/JsBundle/xxxx.android.bundle.zip&#39; // 下载后的存储路径，相对于项目根目录
}

</code></pre>

<p>插件会在 package 的 task 前面，插入一个下载的 task，task 读取上面的配置信息，在打包阶段检查是否已经存在这个版本的 JsBundle。如果不存在，就会去归档的 JsBundle 里，下载我们需要的 JsBundle。 当然，这里的 version 可以使用上文介绍的<code>注入构建信息</code>的方式，通过 job 参数的方式进行注入。这样在 Jenkins 构建 Native 时，就可以动态地填写需要 JsBundle 的版本了。<br/>
这个 Gradle 插件，我们已经放到到了 github 仓库，你可以基于此修改，当然，也欢迎 PR。<br/>
<a href="https://github.com/zjiecode/rn-bundle-gradle-plugin">https://github.com/zjiecode/rn-bundle-gradle-plugin</a></p>

<h2 id="toc_14">六、总结</h2>

<p>我们把一个构建分成了好几个部分，带来的好处如下：</p>

<ul>
<li>  核心构建过程，只需要维护一份，减轻维护工作；</li>
<li>  方便多个人维护构建 CI，避免 Pipeline 代码被覆盖；</li>
<li>  方便构建 job 的版本管理，比如要修复某个已经发布的版本，可以很方便切换到发布版本时候用的 Pipeline 脚本版本；</li>
<li>  每个项目，配置也比较灵活，如果项目配置不够灵活，可以尝试定义更多的变量；</li>
<li>  构建过程可视化，方便针对性优化和错误定位等。</li>
</ul>

<p>当然，Pipeline 也存在一些弊端，比如：</p>

<ul>
<li>  语法不够友好，但好在 Jenkins 提供了一个比较强大的帮助工具（Pipeline Syntax）；</li>
<li>  代码测试繁琐，没有本地运行环境，每次测试都需要提交运行一个 job，等等。</li>
</ul>

<p>当项目集成了 React Native 时，配合 Pipeline，我们可以把 JsBundle 的构建产物上传到 MSS 归档。在构建 Native 的时候 ，可以动态地下载。</p>

<h2 id="toc_15">七、作者</h2>

<ul>
<li>张杰，美团点评高级 Android 工程师，2017 年加入餐饮平台成都研发中心，主要负责餐饮平台 B 端应用开发。</li>
<li>王浩，美团点评高级 Android 工程师，2017 年加入餐饮平台成都研发中心，主要负责餐饮平台 B 端应用开发。</li>
</ul>

<h2 id="toc_16">八、招聘广告</h2>

<p>本文作者来自美团成都研发中心（是的，我们在成都建研发中心啦）。我们在成都有众多后端、前端和测试的岗位正在招人，欢迎大家投递简历：<a href="mailto:songyanwei@meituan.com">songyanwei@meituan.com</a>。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于ZooKeeper的分布式锁和队列]]></title>
    <link href="http://panlw.github.io/15331749691571.html"/>
    <updated>2018-08-02T09:56:09+08:00</updated>
    <id>http://panlw.github.io/15331749691571.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://www.cnblogs.com/luxiaoxun/p/4889764.html">http://www.cnblogs.com/luxiaoxun/p/4889764.html</a></p>
</blockquote>

<p>在分布式系统中，往往需要一些分布式同步原语来做一些协同工作，<a href="http://www.cnblogs.com/luxiaoxun/p/4887452.html">上一篇</a>文章介绍了 Zookeeper 的基本原理，本文介绍下基于 Zookeeper 的 Lock 和 Queue 的实现，主要代码都来自 Zookeeper 的官方 recipe。</p>

<h3 id="toc_0">锁（Lock）</h3>

<p>完全分布式锁是全局同步的，这意味着在任何时刻没有两个客户端会同时认为它们都拥有相同的锁，使用 Zookeeper 可以实现分布式锁，需要首先定义一个锁节点（lock root node）。</p>

<p>需要获得锁的客户端按照以下步骤来获取锁：</p>

<ol>
<li> 保证锁节点（lock root node）这个父根节点的存在，这个节点是每个要获取 lock 客户端共用的，这个节点是 PERSISTENT 的。</li>
<li><p>第一次需要创建本客户端要获取 lock 的节点，调用 create( )，并设置 节点为 EPHEMERAL_SEQUENTIAL 类型，表示该节点为临时的和顺序的。如果获取锁的节点挂掉，则该节点自动失效，可以让其他节点获取锁。</p></li>
<li><p>在父锁节点（lock root node）上调用 getChildren() ，不需要设置监视标志。 (为了避免 “羊群效应”).</p></li>
<li><p>按照 Fair 竞争的原则，将步骤 3 中的子节点（要获取锁的节点）按照节点顺序的大小做排序，取出编号最小的一个节点做为 lock 的 owner，判断自己的节点 id<br/>
是否就为 owner id，如果是则返回，lock 成功。如果不是则调用 exists( ) 监听比自己小的前一位的 id，关注它锁释放的操作（也就是 exist watch）。</p></li>
<li><p>如果第 4 步监听 exist 的 watch 被触发，则继续按 4 中的原则判断自己是否能获取到 lock。</p></li>
</ol>

<p>释放锁：需要释放锁的客户端只需要删除在第 2 步中创建的节点即可。</p>

<p>注意事项：</p>

<p>一个节点的删除只会导致一个客户端被唤醒，因为每个节点只被一个客户端 watch，这避免了 “羊群效应”。</p>

<p>一个分布式 lock 的实现：</p>

<pre><code class="language-java">package org.apache.zookeeper.recipes.lock;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.apache.zookeeper.KeeperException;
import org.apache.zookeeper.WatchedEvent;
import org.apache.zookeeper.Watcher;
import static org.apache.zookeeper.CreateMode.EPHEMERAL_SEQUENTIAL;
import org.apache.zookeeper.ZooKeeper;
import org.apache.zookeeper.data.ACL;
import org.apache.zookeeper.data.Stat;

import java.util.List;
import java.util.SortedSet;
import java.util.TreeSet;

/**
 * A &lt;a href=&quot;package.html&quot;&gt;protocol to implement an exclusive
 *  write lock or to elect a leader&lt;/a&gt;. &lt;p/&gt; You invoke {@link #lock()} to 
 *  start the process of grabbing the lock; you may get the lock then or it may be 
 *  some time later. &lt;p/&gt; You can register a listener so that you are invoked 
 *  when you get the lock; otherwise you can ask if you have the lock
 *  by calling {@link #isOwner()}
 *
 */
public class WriteLock extends ProtocolSupport {
    private static final Logger LOG = LoggerFactory.getLogger(WriteLock.class);

    private final String dir;
    private String id;
    private ZNodeName idName;
    private String ownerId;
    private String lastChildId;
    private byte[] data = {0x12, 0x34};
    private LockListener callback;
    private LockZooKeeperOperation zop;

    /**
     * zookeeper contructor for writelock
     * @param zookeeper zookeeper client instance
     * @param dir the parent path you want to use for locking
     * @param acls the acls that you want to use for all the paths, 
     * if null world read/write is used.
     */
    public WriteLock(ZooKeeper zookeeper, String dir, List&lt;ACL&gt; acl) {
        super(zookeeper);
        this.dir = dir;
        if (acl != null) {
            setAcl(acl);
        }
        this.zop = new LockZooKeeperOperation();
    }

    /**
     * zookeeper contructor for writelock with callback
     * @param zookeeper the zookeeper client instance
     * @param dir the parent path you want to use for locking
     * @param acl the acls that you want to use for all the paths
     * @param callback the call back instance
     */
    public WriteLock(ZooKeeper zookeeper, String dir, List&lt;ACL&gt; acl, 
            LockListener callback) {
        this(zookeeper, dir, acl);
        this.callback = callback;
    }

    /**
     * return the current locklistener
     * @return the locklistener
     */
    public LockListener getLockListener() {
        return this.callback;
    }

    /**
     * register a different call back listener
     * @param callback the call back instance
     */
    public void setLockListener(LockListener callback) {
        this.callback = callback;
    }

    /**
     * Removes the lock or associated znode if 
     * you no longer require the lock. this also 
     * removes your request in the queue for locking
     * in case you do not already hold the lock.
     * @throws RuntimeException throws a runtime exception
     * if it cannot connect to zookeeper.
     */
    public synchronized void unlock() throws RuntimeException {

        if (!isClosed() &amp;&amp; id != null) {
            // we don&#39;t need to retry this operation in the case of failure
            // as ZK will remove ephemeral files and we don&#39;t wanna hang
            // this process when closing if we cannot reconnect to ZK
            try {
                ZooKeeperOperation zopdel = new ZooKeeperOperation() {
                    public boolean execute() throws KeeperException,
                        InterruptedException {
                        zookeeper.delete(id, -1);   
                        return Boolean.TRUE;
                    }
                };
                zopdel.execute();
            } catch (InterruptedException e) {
                LOG.warn(&quot;Caught: &quot; + e, e);
                //set that we have been interrupted.
               Thread.currentThread().interrupt();
            } catch (KeeperException.NoNodeException e) {
                // do nothing
            } catch (KeeperException e) {
                LOG.warn(&quot;Caught: &quot; + e, e);
                throw (RuntimeException) new RuntimeException(e.getMessage()).
                    initCause(e);
            }
            finally {
                if (callback != null) {
                    callback.lockReleased();
                }
                id = null;
            }
        }
    }

    /** 
     * the watcher called on  
     * getting watch while watching 
     * my predecessor
     */
    private class LockWatcher implements Watcher {
        public void process(WatchedEvent event) {
            // lets either become the leader or watch the new/updated node
            LOG.debug(&quot;Watcher fired on path: &quot; + event.getPath() + &quot; state: &quot; + 
                    event.getState() + &quot; type &quot; + event.getType());
            try {
                lock();
            } catch (Exception e) {
                LOG.warn(&quot;Failed to acquire lock: &quot; + e, e);
            }
        }
    }

    /**
     * a zoookeeper operation that is mainly responsible
     * for all the magic required for locking.
     */
    private  class LockZooKeeperOperation implements ZooKeeperOperation {

        /** find if we have been created earler if not create our node
         * 
         * @param prefix the prefix node
         * @param zookeeper teh zookeeper client
         * @param dir the dir paretn
         * @throws KeeperException
         * @throws InterruptedException
         */
        private void findPrefixInChildren(String prefix, ZooKeeper zookeeper, String dir) 
            throws KeeperException, InterruptedException {
            List&lt;String&gt; names = zookeeper.getChildren(dir, false);
            for (String name : names) {
                if (name.startsWith(prefix)) {
                    id = dir + &quot;/&quot; + name;
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(&quot;Found id created last time: &quot; + id);
                    }
                    break;
                }
            }
            if (id == null) {
                id = zookeeper.create(dir + &quot;/&quot; + prefix, data, 
                        getAcl(), EPHEMERAL_SEQUENTIAL);

                if (LOG.isDebugEnabled()) {
                    LOG.debug(&quot;Created id: &quot; + id);
                }
            }

        }

        /**
         * the command that is run and retried for actually 
         * obtaining the lock
         * @return if the command was successful or not
         */
        public boolean execute() throws KeeperException, InterruptedException {
            do {
                if (id == null) {
                    long sessionId = zookeeper.getSessionId();
                    String prefix = &quot;x-&quot; + sessionId + &quot;-&quot;;
                    // lets try look up the current ID if we failed 
                    // in the middle of creating the znode
                    findPrefixInChildren(prefix, zookeeper, dir);
                    idName = new ZNodeName(id);
                }
                if (id != null) {
                    List&lt;String&gt; names = zookeeper.getChildren(dir, false);
                    if (names.isEmpty()) {
                        LOG.warn(&quot;No children in: &quot; + dir + &quot; when we&#39;ve just &quot; +
                        &quot;created one! Lets recreate it...&quot;);
                        // lets force the recreation of the id
                        id = null;
                    } else {
                        // lets sort them explicitly (though they do seem to come back in order ususally :)
                        SortedSet&lt;ZNodeName&gt; sortedNames = new TreeSet&lt;ZNodeName&gt;();
                        for (String name : names) {
                            sortedNames.add(new ZNodeName(dir + &quot;/&quot; + name));
                        }
                        ownerId = sortedNames.first().getName();
                        SortedSet&lt;ZNodeName&gt; lessThanMe = sortedNames.headSet(idName);
                        if (!lessThanMe.isEmpty()) {
                            ZNodeName lastChildName = lessThanMe.last();
                            lastChildId = lastChildName.getName();
                            if (LOG.isDebugEnabled()) {
                                LOG.debug(&quot;watching less than me node: &quot; + lastChildId);
                            }
                            Stat stat = zookeeper.exists(lastChildId, new LockWatcher());
                            if (stat != null) {
                                return Boolean.FALSE;
                            } else {
                                LOG.warn(&quot;Could not find the&quot; +
                                        &quot; stats for less than me: &quot; + lastChildName.getName());
                            }
                        } else {
                            if (isOwner()) {
                                if (callback != null) {
                                    callback.lockAcquired();
                                }
                                return Boolean.TRUE;
                            }
                        }
                    }
                }
            }
            while (id == null);
            return Boolean.FALSE;
        }
    };

    /**
     * Attempts to acquire the exclusive write lock returning whether or not it was
     * acquired. Note that the exclusive lock may be acquired some time later after
     * this method has been invoked due to the current lock owner going away.
     */
    public synchronized boolean lock() throws KeeperException, InterruptedException {
        if (isClosed()) {
            return false;
        }
        ensurePathExists(dir);

        return (Boolean) retryOperation(zop);
    }

    /**
     * return the parent dir for lock
     * @return the parent dir used for locks.
     */
    public String getDir() {
        return dir;
    }

    /**
     * Returns true if this node is the owner of the
     *  lock (or the leader)
     */
    public boolean isOwner() {
        return id != null &amp;&amp; ownerId != null &amp;&amp; id.equals(ownerId);
    }

    /**
     * return the id for this lock
     * @return the id for this lock
     */
    public String getId() {
       return this.id;
    }
}
</code></pre>

<p>注意这里的 lock，可能会失败，会尝试多次，每次失败后会 Sleep 一段时间。</p>

<p>PS：官方的代码有个小 bug，id 和 ownerId 应该都是全路径，即 id = dir + &quot;/&quot; + name; 原代码在 findPrefixInChildren 里有问题。</p>

<p>用于辅助节点大小顺序排序的类：</p>

<pre><code class="language-java">package org.apache.zookeeper.recipes.lock;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * Represents an ephemeral znode name which has an ordered sequence number and
 * can be sorted in order
 * 
 */
class ZNodeName implements Comparable&lt;ZNodeName&gt; {
    private final String name;
    private String prefix;
    private int sequence = -1;
    private static final Logger LOG = LoggerFactory.getLogger(ZNodeName.class);

    public ZNodeName(String name) {
        if (name == null) {
            throw new NullPointerException(&quot;id cannot be null&quot;);
        }
        this.name = name;
        this.prefix = name;
        int idx = name.lastIndexOf(&#39;-&#39;);
        if (idx &gt;= 0) {
            this.prefix = name.substring(0, idx);
            try {
                this.sequence = Integer.parseInt(name.substring(idx + 1));
                // If an exception occurred we misdetected a sequence suffix,
                // so return -1.
            } catch (NumberFormatException e) {
                LOG.info(&quot;Number format exception for &quot; + idx, e);
            } catch (ArrayIndexOutOfBoundsException e) {
                LOG.info(&quot;Array out of bounds for &quot; + idx, e);
            }
        }
    }

    @Override
    public String toString() {
        return name.toString();
    }

    @Override
    public boolean equals(Object o) {
        if (this == o)
            return true;
        if (o == null || getClass() != o.getClass())
            return false;

        ZNodeName sequence = (ZNodeName) o;

        if (!name.equals(sequence.name))
            return false;

        return true;
    }

    @Override
    public int hashCode() {
        return name.hashCode() + 37;
    }

    public int compareTo(ZNodeName that) {
        int s1 = this.sequence;
        int s2 = that.sequence;
        if (s1 == -1 &amp;&amp; s2 == -1) {
            return this.name.compareTo(that.name);
        }
        if (s1 == -1) {
            return -1;
        } else if (s2 == -1) {
            return 1;
        } else {
            return s1 - s2;
        }
    }

    /**
     * Returns the name of the znode
     */
    public String getName() {
        return name;
    }

    /**
     * Returns the sequence number
     */
    public int getZNodeName() {
        return sequence;
    }

    /**
     * Returns the text prefix before the sequence number
     */
    public String getPrefix() {
        return prefix;
    }
}
</code></pre>

<p>PS：这个 ZNodeName 类是被我修改过的，官方的代码比较有问题，官方的先用了节点路径的前缀 prefix 比较，再去比较 sequence 序号是不对的，这样会导致 sessionid 小的总是能拿到锁。应该直接比较全局有序的 sequence 序号，小的先拿到锁，先到先得。</p>

<p>Zookeeper 统一操作 ZooKeeperOperation 接口：</p>

<pre><code class="language-java">public interface ZooKeeperOperation {

    /**
     * Performs the operation - which may be involved multiple times if the connection
     * to ZooKeeper closes during this operation
     *
     * @return the result of the operation or null
     * @throws KeeperException
     * @throws InterruptedException
     */
    public boolean execute() throws KeeperException, InterruptedException;
}
</code></pre>

<p>因为 Zookeeper 的操作会失败，这个类封装了多次尝试：</p>

<pre><code class="language-java">/**
 *
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the &quot;License&quot;); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.zookeeper.recipes.lock;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.apache.zookeeper.CreateMode;
import org.apache.zookeeper.KeeperException;
import org.apache.zookeeper.ZooDefs;
import org.apache.zookeeper.ZooKeeper;
import org.apache.zookeeper.data.ACL;
import org.apache.zookeeper.data.Stat;
import org.apache.zookeeper.recipes.lock.ZooKeeperOperation;

import java.util.List;
import java.util.concurrent.atomic.AtomicBoolean;

/**
 * A base class for protocol implementations which provides a number of higher 
 * level helper methods for working with ZooKeeper along with retrying synchronous
 *  operations if the connection to ZooKeeper closes such as 
 *  {@link #retryOperation(ZooKeeperOperation)}
 *
 */
class ProtocolSupport {
    private static final Logger LOG = LoggerFactory.getLogger(ProtocolSupport.class);

    protected final ZooKeeper zookeeper;
    private AtomicBoolean closed = new AtomicBoolean(false);
    private long retryDelay = 500L;
    private int retryCount = 10;
    private List&lt;ACL&gt; acl = ZooDefs.Ids.OPEN_ACL_UNSAFE;

    public ProtocolSupport(ZooKeeper zookeeper) {
        this.zookeeper = zookeeper;
    }

    /**
     * Closes this strategy and releases any ZooKeeper resources; but keeps the
     *  ZooKeeper instance open
     */
    public void close() {
        if (closed.compareAndSet(false, true)) {
            doClose();
        }
    }

    /**
     * return zookeeper client instance
     * @return zookeeper client instance
     */
    public ZooKeeper getZookeeper() {
        return zookeeper;
    }

    /**
     * return the acl its using
     * @return the acl.
     */
    public List&lt;ACL&gt; getAcl() {
        return acl;
    }

    /**
     * set the acl 
     * @param acl the acl to set to
     */
    public void setAcl(List&lt;ACL&gt; acl) {
        this.acl = acl;
    }

    /**
     * get the retry delay in milliseconds
     * @return the retry delay
     */
    public long getRetryDelay() {
        return retryDelay;
    }

    /**
     * Sets the time waited between retry delays
     * @param retryDelay the retry delay
     */
    public void setRetryDelay(long retryDelay) {
        this.retryDelay = retryDelay;
    }

    /**
     * Allow derived classes to perform 
     * some custom closing operations to release resources
     */
    protected void doClose() {
    }

    /**
     * Perform the given operation, retrying if the connection fails
     * @return object. it needs to be cast to the callee&#39;s expected 
     * return type.
     */
    protected Object retryOperation(ZooKeeperOperation operation) 
        throws KeeperException, InterruptedException {
        KeeperException exception = null;
        for (int i = 0; i &lt; retryCount; i++) {
            try {
                return operation.execute();
            } catch (KeeperException.SessionExpiredException e) {
                LOG.warn(&quot;Session expired for: &quot; + zookeeper + &quot; so reconnecting due to: &quot; + e, e);
                throw e;
            } catch (KeeperException.ConnectionLossException e) {
                if (exception == null) {
                    exception = e;
                }
                LOG.debug(&quot;Attempt &quot; + i + &quot; failed with connection loss so &quot; +
                        &quot;attempting to reconnect: &quot; + e, e);
                retryDelay(i);
            }
        }
        throw exception;
    }

    /**
     * Ensures that the given path exists with no data, the current
     * ACL and no flags
     * @param path
     */
    protected void ensurePathExists(String path) {
        ensureExists(path, null, acl, CreateMode.PERSISTENT);
    }

    /**
     * Ensures that the given path exists with the given data, ACL and flags
     * @param path
     * @param acl
     * @param flags
     */
    protected void ensureExists(final String path, final byte[] data,
            final List&lt;ACL&gt; acl, final CreateMode flags) {
        try {
            retryOperation(new ZooKeeperOperation() {
                public boolean execute() throws KeeperException, InterruptedException {
                    Stat stat = zookeeper.exists(path, false);
                    if (stat != null) {
                        return true;
                    }
                    zookeeper.create(path, data, acl, flags);
                    return true;
                }
            });
        } catch (KeeperException e) {
            LOG.warn(&quot;Caught: &quot; + e, e);
        } catch (InterruptedException e) {
            LOG.warn(&quot;Caught: &quot; + e, e);
        }
    }

    /**
     * Returns true if this protocol has been closed
     * @return true if this protocol is closed
     */
    protected boolean isClosed() {
        return closed.get();
    }

    /**
     * Performs a retry delay if this is not the first attempt
     * @param attemptCount the number of the attempts performed so far
     */
    protected void retryDelay(int attemptCount) {
        if (attemptCount &gt; 0) {
            try {
                Thread.sleep(attemptCount * retryDelay);
            } catch (InterruptedException e) {
                LOG.debug(&quot;Failed to sleep: &quot; + e, e);
            }
        }
    }
}
</code></pre>

<p>这个类是本客户端获取到 lock 和释放 lock 的时候触发操作的接口：</p>

<pre><code class="language-java">public interface LockListener {
    /**
     * call back called when the lock 
     * is acquired
     */
    public void lockAcquired();

    /**
     * call back called when the lock is 
     * released.
     */
    public void lockReleased();
}
</code></pre>

<h3 id="toc_1">队列（Queue）</h3>

<p>分布式队列是通用的数据结构，为了在 Zookeeper 中实现分布式队列，首先需要指定一个 Znode 节点作为队列节点（queue node）， 各个分布式客户端通过调用 create() 函数向队列中放入数据，调用 create() 时节点路径名带 &quot;qn-&quot; 结尾，并设置顺序（_sequence_）节点标志。 由于设置了节点的顺序标志，新的路径名具有以下字符串模式：&quot;_path-to-queue-node_/qn-X&quot;，X 是唯一自增号。需要从队列中获取数据 / 移除数据的客户端首先调用 getChildren() 函数，有数据则获取（获取数据后可以删除也可以不删），没有则在队列节点（queue node）上将 _watch_ 设置为 true，等待触发并处理最小序号的节点（即从序号最小的节点中取数据）。</p>

<p>实现步骤基本如下：</p>

<p>前提：需要一个队列 root 节点 dir</p>

<p>入队：使用 create() 创建节点，将共享数据 data 放在该节点上，节点类型为 PERSISTENT_SEQUENTIAL，永久顺序性的（也可以设置为临时的，看需求）。</p>

<p>出队：因为队列可能为空，2 种方式处理：一种如果为空则 wait 等待，一种返回异常。</p>

<p>等待方式：这里使用了 CountDownLatch 的等待和 Watcher 的通知机制，使用了 TreeMap 的排序获取节点顺序最小的数据（FIFO）。</p>

<p>抛出异常：getChildren() 获取队列数据时，如果 size==0 则抛出异常。</p>

<p>一个分布式 Queue 的实现，详细代码：</p>

<pre><code class="language-java">package org.apache.zookeeper.recipes.queue;

import java.util.List;
import java.util.NoSuchElementException;
import java.util.TreeMap;
import java.util.concurrent.CountDownLatch;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.apache.zookeeper.CreateMode;
import org.apache.zookeeper.KeeperException;
import org.apache.zookeeper.WatchedEvent;
import org.apache.zookeeper.Watcher;
import org.apache.zookeeper.ZooDefs;
import org.apache.zookeeper.ZooKeeper;
import org.apache.zookeeper.data.ACL;
import org.apache.zookeeper.data.Stat;

/**
 * 
 * A &lt;a href=&quot;package.html&quot;&gt;protocol to implement a distributed queue&lt;/a&gt;.
 * 
 */
public class DistributedQueue {
    private static final Logger LOG = LoggerFactory.getLogger(DistributedQueue.class);

    private final String dir;

    private ZooKeeper zookeeper;
    private List&lt;ACL&gt; acl = ZooDefs.Ids.OPEN_ACL_UNSAFE;

    private final String prefix = &quot;qn-&quot;;

    public DistributedQueue(ZooKeeper zookeeper, String dir, List&lt;ACL&gt; acl){
        this.dir = dir;

        if(acl != null){
            this.acl = acl;
        }
        this.zookeeper = zookeeper;

        //Add root dir first if not exists
        if (zookeeper != null) {
            try {
                Stat s = zookeeper.exists(dir, false);
                if (s == null) {
                    zookeeper.create(dir, new byte[0], acl, CreateMode.PERSISTENT);
                }
            } catch (KeeperException e) {
                LOG.error(e.toString());
            } catch (InterruptedException e) {
                LOG.error(e.toString());
            }
        }
    }

    /**
     * Returns a Map of the children, ordered by id.
     * @param watcher optional watcher on getChildren() operation.
     * @return map from id to child name for all children
     */
    private TreeMap&lt;Long,String&gt; orderedChildren(Watcher watcher) throws KeeperException, InterruptedException {
        TreeMap&lt;Long,String&gt; orderedChildren = new TreeMap&lt;Long,String&gt;();

        List&lt;String&gt; childNames = null;
        try{
            childNames = zookeeper.getChildren(dir, watcher);
        }catch (KeeperException.NoNodeException e){
            throw e;
        }

        for(String childName : childNames){
            try{
                //Check format
                if(!childName.regionMatches(0, prefix, 0, prefix.length())){
                    LOG.warn(&quot;Found child node with improper name: &quot; + childName);
                    continue;
                }
                String suffix = childName.substring(prefix.length());
                Long childId = new Long(suffix);
                orderedChildren.put(childId,childName);
            }catch(NumberFormatException e){
                LOG.warn(&quot;Found child node with improper format : &quot; + childName + &quot; &quot; + e,e);
            }
        }

        return orderedChildren;
    }

    /**
     * Find the smallest child node.
     * @return The name of the smallest child node.
     */
    private String smallestChildName() throws KeeperException, InterruptedException {
        long minId = Long.MAX_VALUE;
        String minName = &quot;&quot;;

        List&lt;String&gt; childNames = null;

        try{
            childNames = zookeeper.getChildren(dir, false);
        }catch(KeeperException.NoNodeException e){
            LOG.warn(&quot;Caught: &quot; +e,e);
            return null;
        }

        for(String childName : childNames){
            try{
                //Check format
                if(!childName.regionMatches(0, prefix, 0, prefix.length())){
                    LOG.warn(&quot;Found child node with improper name: &quot; + childName);
                    continue;
                }
                String suffix = childName.substring(prefix.length());
                long childId = Long.parseLong(suffix);
                if(childId &lt; minId){
                    minId = childId;
                    minName = childName;
                }
            }catch(NumberFormatException e){
                LOG.warn(&quot;Found child node with improper format : &quot; + childName + &quot; &quot; + e,e);
            }
        }

        if(minId &lt; Long.MAX_VALUE){
            return minName;
        }else{
            return null;
        }
    }

    /**
     * Return the head of the queue without modifying the queue.
     * @return the data at the head of the queue.
     * @throws NoSuchElementException
     * @throws KeeperException
     * @throws InterruptedException
     */
    public byte[] element() throws NoSuchElementException, KeeperException, InterruptedException {
        TreeMap&lt;Long,String&gt; orderedChildren;

        // element, take, and remove follow the same pattern.
        // We want to return the child node with the smallest sequence number.
        // Since other clients are remove()ing and take()ing nodes concurrently, 
        // the child with the smallest sequence number in orderedChildren might be gone by the time we check.
        // We don&#39;t call getChildren again until we have tried the rest of the nodes in sequence order.
        while(true){
            try{
                orderedChildren = orderedChildren(null);
            }catch(KeeperException.NoNodeException e){
                throw new NoSuchElementException();
            }
            if(orderedChildren.size() == 0 ) throw new NoSuchElementException();

            for(String headNode : orderedChildren.values()){
                if(headNode != null){
                    try{
                        return zookeeper.getData(dir+&quot;/&quot;+headNode, false, null);
                    }catch(KeeperException.NoNodeException e){
                        //Another client removed the node first, try next
                    }
                }
            }

        }
    }

    /**
     * Attempts to remove the head of the queue and return it.
     * @return The former head of the queue
     * @throws NoSuchElementException
     * @throws KeeperException
     * @throws InterruptedException
     */
    public byte[] remove() throws NoSuchElementException, KeeperException, InterruptedException {
        TreeMap&lt;Long,String&gt; orderedChildren;
        // Same as for element.  Should refactor this.
        while(true){
            try{
                orderedChildren = orderedChildren(null);
            }catch(KeeperException.NoNodeException e){
                throw new NoSuchElementException();
            }
            if(orderedChildren.size() == 0) throw new NoSuchElementException();

            for(String headNode : orderedChildren.values()){
                String path = dir +&quot;/&quot;+headNode;
                try{
                    byte[] data = zookeeper.getData(path, false, null);
                    zookeeper.delete(path, -1);
                    return data;
                }catch(KeeperException.NoNodeException e){
                    // Another client deleted the node first.
                }
            }
        }
    }

    private class LatchChildWatcher implements Watcher {

        CountDownLatch latch;

        public LatchChildWatcher(){
            latch = new CountDownLatch(1);
        }

        public void process(WatchedEvent event){
            LOG.debug(&quot;Watcher fired on path: &quot; + event.getPath() + &quot; state: &quot; + 
                    event.getState() + &quot; type &quot; + event.getType());
            latch.countDown();
        }
        public void await() throws InterruptedException {
            latch.await();
        }
    }

    /**
     * Removes the head of the queue and returns it, blocks until it succeeds.
     * @return The former head of the queue
     * @throws NoSuchElementException
     * @throws KeeperException
     * @throws InterruptedException
     */
    public byte[] take() throws KeeperException, InterruptedException {
        TreeMap&lt;Long,String&gt; orderedChildren;
        // Same as for element.  Should refactor this.
        while(true){
            LatchChildWatcher childWatcher = new LatchChildWatcher();
            try{
                orderedChildren = orderedChildren(childWatcher);
            }catch(KeeperException.NoNodeException e){
                zookeeper.create(dir, new byte[0], acl, CreateMode.PERSISTENT);
                continue;
            }
            if(orderedChildren.size() == 0){
                childWatcher.await();
                continue;
            }

            for(String headNode : orderedChildren.values()){
                String path = dir +&quot;/&quot;+headNode;
                try{
                    byte[] data = zookeeper.getData(path, false, null);
                    zookeeper.delete(path, -1);
                    return data;
                }catch(KeeperException.NoNodeException e){
                    // Another client deleted the node first.
                }
            }
        }
    }

    /**
     * Inserts data into queue.
     * @param data
     * @return true if data was successfully added
     */
    public boolean offer(byte[] data) throws KeeperException, InterruptedException{
        for(;;){
            try{
                zookeeper.create(dir+&quot;/&quot;+prefix, data, acl, CreateMode.PERSISTENT_SEQUENTIAL);
                return true;
            }catch(KeeperException.NoNodeException e){
                zookeeper.create(dir, new byte[0], acl, CreateMode.PERSISTENT);
            }
        }
    }

    /**
     * Returns the data at the first element of the queue, or null if the queue is empty.
     * @return data at the first element of the queue, or null.
     * @throws KeeperException
     * @throws InterruptedException
     */
    public byte[] peek() throws KeeperException, InterruptedException{
        try{
            return element();
        }catch(NoSuchElementException e){
            return null;
        }
    }

    /**
     * Attempts to remove the head of the queue and return it. Returns null if the queue is empty.
     * @return Head of the queue or null.
     * @throws KeeperException
     * @throws InterruptedException
     */
    public byte[] poll() throws KeeperException, InterruptedException {
        try{
            return remove();
        }catch(NoSuchElementException e){
            return null;
        }
    }
}
</code></pre>

<p><strong>Apache Curator</strong></p>

<p>Curator 是一个封装 Zookeeper 操作的库，使用这个库的好处是 Curator 帮你管理和 Zookeeper 的连接，当连接有问题时会自动重试（retry）。</p>

<pre><code class="language-java">RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3)
CuratorFramework client = CuratorFrameworkFactory.newClient(zookeeperConnectionString, retryPolicy);
client.start();
</code></pre>

<p>Curator 已经封装了一些常用的 Recipes</p>

<h4 id="toc_2">Distributed Lock</h4>

<pre><code class="language-java">InterProcessMutex lock = new InterProcessMutex(client, lockPath);
if ( lock.acquire(maxWait, waitUnit) ) 
{
    try 
    {
        // do some work inside of the critical section here
    }
    finally
    {
        lock.release();
    }
}
</code></pre>

<h4 id="toc_3">Leader Election</h4>

<pre><code class="language-java">LeaderSelectorListener listener = new LeaderSelectorListenerAdapter()
{
    public void takeLeadership(CuratorFramework client) throws Exception
    {
        // this callback will get called when you are the leader
        // do whatever leader work you need to and only exit
        // this method when you want to relinquish leadership
    }
}

LeaderSelector selector = new LeaderSelector(client, path, listener);
selector.autoRequeue();  // not required, but this is behavior that you will probably expect
selector.start();
</code></pre>

<h2 id="toc_4">参考</h2>

<ul>
<li><a href="http://zookeeper.apache.org/doc/trunk/recipes.html">http://zookeeper.apache.org/doc/trunk/recipes.html</a></li>
<li><a href="http://curator.apache.org/curator-recipes/index.html">http://curator.apache.org/curator-recipes/index.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ZooKeeper基本原理]]></title>
    <link href="http://panlw.github.io/15331745470579.html"/>
    <updated>2018-08-02T09:49:07+08:00</updated>
    <id>http://panlw.github.io/15331745470579.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://www.cnblogs.com/luxiaoxun/p/4887452.html">https://www.cnblogs.com/luxiaoxun/p/4887452.html</a></p>

<p>作者：<a href="http://www.cnblogs.com/luxiaoxun/">阿凡卢</a></p>

<p>出处：<a href="http://www.cnblogs.com/luxiaoxun/">http://www.cnblogs.com/luxiaoxun/</a></p>
</blockquote>

<p><strong>ZooKeeper</strong> <strong>简介</strong></p>

<p>ZooKeeper 是一个开放源码的分布式应用程序协调服务，它包含一个简单的原语集，分布式应用程序可以基于它实现同步服务，配置维护和命名服务等。</p>

<p><img src="https://images2015.cnblogs.com/blog/434101/201510/434101-20151019093350567-692728278.jpg" alt=""/></p>

<p><strong>ZooKeeper 设计目的</strong></p>

<p>1. 最终一致性：client 不论连接到哪个 Server，展示给它都是同一个视图，这是 zookeeper 最重要的性能。</p>

<p>2. 可靠性：具有简单、健壮、良好的性能，如果消息 m 被到一台服务器接受，那么它将被所有的服务器接受。</p>

<p>3. 实时性：Zookeeper 保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper 不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用 sync() 接口。</p>

<p>4. 等待无关（wait-free）：慢的或者失效的 client 不得干预快速的 client 的请求，使得每个 client 都能有效的等待。</p>

<p>5. 原子性：更新只能成功或者失败，没有中间状态。</p>

<p>6. 顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息 a 在消息 b 前发布，则在所有 Server 上消息 a 都将在消息 b 前被发布；偏序是指如果一个消息 b 在消息 a 后被同一个发送者发布，a 必将排在 b 前面。</p>

<p><strong>ZooKeeper</strong> <strong>数据模型</strong></p>

<p>Zookeeper 会维护一个具有层次关系的数据结构，它非常类似于一个标准的文件系统，如图所示：</p>

<p><img src="https://images2015.cnblogs.com/blog/434101/201510/434101-20151017140829960-1863595007.jpg" alt=""/></p>

<p>Zookeeper 这种数据结构有如下这些特点：</p>

<p>1）每个子目录项如 NameService 都被称作为 znode，这个 znode 是被它所在的路径唯一标识，如 Server1 这个 znode 的标识为 / NameService/Server1。</p>

<p>2）znode 可以有子节点目录，并且每个 znode 可以存储数据，注意 EPHEMERAL（临时的）类型的目录节点不能有子节点目录。</p>

<p>3）znode 是有版本的（version），每个 znode 中存储的数据可以有多个版本，也就是一个访问路径中可以存储多份数据，version 号自动增加。</p>

<p>4）znode 的类型：</p>

<ul>
<li>  <strong>_Persistent _</strong>节点，一旦被创建，便不会意外丢失，即使服务器全部重启也依然存在。每个 Persist 节点即可包含数据，也可包含子节点。</li>
<li><p><strong>_Ephemeral _</strong>节点，在创建它的客户端与服务器间的 Session 结束时自动被删除。服务器重启会导致 Session 结束，因此 Ephemeral 类型的 znode 此时也会自动删除。</p></li>
<li><p><strong>_Non-sequence _</strong>节点，多个客户端同时创建同一 Non-sequence 节点时，只有一个可创建成功，其它匀失败。并且创建出的节点名称与创建时指定的节点名完全一样。</p></li>
<li><p><strong>_Sequence _</strong>节点，创建出的节点名在指定的名称之后带有 10 位 10 进制数的序号。多个客户端创建同一名称的节点时，都能创建成功，只是序号不同。</p></li>
</ul>

<p>5）znode 可以被监控，包括这个目录节点中存储的数据的修改，子节点目录的变化等，一旦变化可以通知设置监控的客户端，这个是 Zookeeper 的核心特性，Zookeeper 的很多功能都是基于这个特性实现的。</p>

<p>6）ZXID：每次对 Zookeeper 的状态的改变都会产生一个 zxid（ZooKeeper Transaction Id），zxid 是全局有序的，如果 zxid1 小于 zxid2，则 zxid1 在 zxid2 之前发生。</p>

<p><strong>ZooKeeper Session</strong></p>

<p>Client 和 Zookeeper 集群建立连接，整个 session 状态变化如图所示：</p>

<p><img src="https://images2015.cnblogs.com/blog/434101/201510/434101-20151017140903647-942632156.jpg" alt=""/></p>

<p>如果 Client 因为 Timeout 和 Zookeeper Server 失去连接，client 处在 CONNECTING 状态，会自动尝试再去连接 Server，如果在 session 有效期内再次成功连接到某个 Server，则回到 CONNECTED 状态。</p>

<p>注意：如果因为网络状态不好，client 和 Server 失去联系，client 会停留在当前状态，会尝试主动再次连接 Zookeeper Server。client 不能宣称自己的 session expired，session expired 是由 Zookeeper Server 来决定的，client 可以选择自己主动关闭 session。</p>

<p><strong>ZooKeeper Watch</strong></p>

<p>Zookeeper watch 是一种监听通知机制。Zookeeper 所有的读操作 getData(), getChildren() 和 exists() 都可以设置监视 (watch)，监视事件可以理解为一次性的触发器，官方定义如下： a watch event is one-time trigger, sent to the client that set the watch, whichoccurs when the data for which the watch was set changes。Watch 的三个关键点：</p>

<p>*（一次性触发）One-time trigger</p>

<p>当设置监视的数据发生改变时，该监视事件会被发送到客户端，例如，如果客户端调用了 getData(&quot;/znode1&quot;, true) 并且稍后 /znode1 节点上的数据发生了改变或者被删除了，客户端将会获取到 /znode1 发生变化的监视事件，而如果 /znode1 再一次发生了变化，除非客户端再次对 / znode1 设置监视，否则客户端不会收到事件通知。</p>

<p>*（发送至客户端）Sent to the client</p>

<p>Zookeeper 客户端和服务端是通过 socket 进行通信的，由于网络存在故障，所以监视事件很有可能不会成功地到达客户端，监视事件是异步发送至监视者的，Zookeeper 本身提供了顺序保证 (ordering guarantee)：即客户端只有首先看到了监视事件后，才会感知到它所设置监视的 znode 发生了变化 (a client will never see a change for which it has set a watch until it first sees the watch event)。网络延迟或者其他因素可能导致不同的客户端在不同的时刻感知某一监视事件，但是不同的客户端所看到的一切具有一致的顺序。</p>

<p>*（被设置 watch 的数据）The data for which the watch was set</p>

<p>这意味着 znode 节点本身具有不同的改变方式。你也可以想象 Zookeeper 维护了两条监视链表：数据监视和子节点监视 (data watches and child watches) getData() 和 exists() 设置数据监视，getChildren()设置子节点监视。或者你也可以想象 Zookeeper 设置的不同监视返回不同的数据，getData() 和 exists() 返回 znode 节点的相关信息，而 getChildren() 返回子节点列表。因此，setData() 会触发设置在某一节点上所设置的数据监视（假定数据设置成功），而一次成功的 create() 操作则会出发当前节点上所设置的数据监视以及父节点的子节点监视。一次成功的 delete 操作将会触发当前节点的数据监视和子节点监视事件，同时也会触发该节点父节点的 child watch。</p>

<p>Zookeeper 中的监视是轻量级的，因此容易设置、维护和分发。当客户端与 Zookeeper 服务器失去联系时，客户端并不会收到监视事件的通知，只有当客户端重新连接后，若在必要的情况下，以前注册的监视会重新被注册并触发，对于开发人员来说这通常是透明的。只有一种情况会导致监视事件的丢失，即：通过 exists() 设置了某个 znode 节点的监视，但是如果某个客户端在此 znode 节点被创建和删除的时间间隔内与 zookeeper 服务器失去了联系，该客户端即使稍后重新连接 zookeeper 服务器后也得不到事件通知。</p>

<p><strong>Consistency Guarantees</strong></p>

<p>Zookeeper 是一个高效的、可扩展的服务，read 和 write 操作都被设计为快速的，read 比 write 操作更快。</p>

<p>顺序一致性（Sequential Consistency）：从一个客户端来的更新请求会被顺序执行。</p>

<p>原子性（Atomicity）：更新要么成功要么失败，没有部分成功的情况。</p>

<p>唯一的系统镜像（Single System Image）：无论客户端连接到哪个 Server，看到系统镜像是一致的。</p>

<p>可靠性（Reliability）：更新一旦有效，持续有效，直到被覆盖。</p>

<p>时间线（Timeliness）：保证在一定的时间内各个客户端看到的系统信息是一致的。</p>

<p><strong>ZooKeeper</strong> <strong>的工作原理</strong></p>

<p>在 zookeeper 的集群中，各个节点共有下面 3 种角色和 4 种状态：</p>

<ul>
<li>  角色：leader,follower,observer</li>
<li>  状态：leading,following,observing,looking</li>
</ul>

<p>Zookeeper 的核心是原子广播，这个机制保证了各个 Server 之间的同步。实现这个机制的协议叫做 Zab 协议（ZooKeeper Atomic Broadcast protocol）。Zab 协议有两种模式，它们分别是恢复模式（Recovery 选主）和广播模式（Broadcast 同步）。当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态。</p>

<p>为了保证事务的顺序一致性，zookeeper 采用了递增的事务 id 号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了 zxid。实现中 zxid 是一个 64 位的数字，它高 32 位是 epoch 用来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个新的 epoch，标识当前属于那个 leader 的统治时期。低 32 位用于递增计数。</p>

<p>每个 Server 在工作过程中有 4 种状态：</p>

<p>LOOKING：当前 Server 不知道 leader 是谁，正在搜寻。</p>

<p>LEADING：当前 Server 即为选举出来的 leader。</p>

<p>FOLLOWING：leader 已经选举出来，当前 Server 与之同步。</p>

<p>OBSERVING：observer 的行为在大多数情况下与 follower 完全一致，但是他们不参加选举和投票，而仅仅接受 (observing) 选举和投票的结果。</p>

<p><strong>Leader Election</strong></p>

<p>当 leader 崩溃或者 leader 失去大多数的 follower，这时候 zk 进入恢复模式，恢复模式需要重新选举出一个新的 leader，让所有的 Server 都恢复到一个正确的状态。Zk 的选举算法有两种：一种是基于 basic paxos 实现的，另外一种是基于 fast paxos 算法实现的。系统默认的选举算法为 fast paxos。先介绍 basic paxos 流程：</p>

<p>1. 选举线程由当前 Server 发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的 Server；</p>

<p>2. 选举线程首先向所有 Server 发起一次询问（包括自己）；</p>

<p>3. 选举线程收到回复后，验证是否是自己发起的询问（验证 zxid 是否一致），然后获取对方的 id（myid），并存储到当前询问对象列表中，最后获取对方提议的 leader 相关信息（id,zxid），并将这些信息存储到当次选举的投票记录表中；</p>

<p>4. 收到所有 Server 回复以后，就计算出 zxid 最大的那个 Server，并将这个 Server 相关信息设置成下一次要投票的 Server；</p>

<p>5. 线程将当前 zxid 最大的 Server 设置为当前 Server 要推荐的 Leader，如果此时获胜的 Server 获得 n/2 + 1 的 Server 票数，设置当前推荐的 leader 为获胜的 Server，将根据获胜的 Server 相关信息设置自己的状态，否则，继续这个过程，直到 leader 被选举出来。</p>

<p>通过流程分析我们可以得出：要使 Leader 获得多数 Server 的支持，则 Server 总数必须是奇数 2n+1，且存活的 Server 的数目不得少于 n+1.</p>

<p>每个 Server 启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的 server 还会从磁盘快照中恢复数据和会话信息，zk 会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。</p>

<p>fast paxos 流程是在选举过程中，某 Server 首先向所有 Server 提议自己要成为 leader，当其它 Server 收到提议以后，解决 epoch 和 zxid 的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出 Leader。</p>

<p><strong>Leader</strong> <strong>工作流程</strong></p>

<p>Leader 主要有三个功能：</p>

<p>1. 恢复数据；</p>

<p>2. 维持与 follower 的心跳，接收 follower 请求并判断 follower 的请求消息类型；</p>

<p>3.follower 的消息类型主要有 PING 消息、REQUEST 消息、ACK 消息、REVALIDATE 消息，根据不同的消息类型，进行不同的处理。</p>

<p>PING 消息是指 follower 的心跳信息；REQUEST 消息是 follower 发送的提议信息，包括写请求及同步请求；</p>

<p>ACK 消息是 follower 的对提议的回复，超过半数的 follower 通过，则 commit 该提议；</p>

<p>REVALIDATE 消息是用来延长 SESSION 有效时间。</p>

<p><strong>Follower</strong> <strong>工作流程</strong></p>

<p>Follower 主要有四个功能：</p>

<p>1. 向 Leader 发送请求（PING 消息、REQUEST 消息、ACK 消息、REVALIDATE 消息）；</p>

<p>2. 接收 Leader 消息并进行处理；</p>

<p>3. 接收 Client 的请求，如果为写请求，发送给 Leader 进行投票；</p>

<p>4. 返回 Client 结果。</p>

<p>Follower 的消息循环处理如下几种来自 Leader 的消息：</p>

<p>1.PING 消息：心跳消息</p>

<p>2.PROPOSAL 消息：Leader 发起的提案，要求 Follower 投票</p>

<p>3.COMMIT 消息：服务器端最新一次提案的信息</p>

<p>4.UPTODATE 消息：表明同步完成</p>

<p>5.REVALIDATE 消息：根据 Leader 的 REVALIDATE 结果，关闭待 revalidate 的 session 还是允许其接受消息</p>

<p>6.SYNC 消息：返回 SYNC 结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。</p>

<p><strong>Zab: Broadcasting State Updates</strong></p>

<p>Zookeeper Server 接收到一次 request，如果是 follower，会转发给 leader，Leader 执行请求并通过 Transaction 的形式广播这次执行。Zookeeper 集群如何决定一个 Transaction 是否被 commit 执行？通过 “两段提交协议”（a two-phase commit）：</p>

<ol>
<li> Leader 给所有的 follower 发送一个 PROPOSAL 消息。</li>
<li> 一个 follower 接收到这次 PROPOSAL 消息，写到磁盘，发送给 leader 一个 ACK 消息，告知已经收到。</li>
<li> 当 Leader 收到法定人数（quorum）的 follower 的 ACK 时候，发送 commit 消息执行。</li>
</ol>

<p>Zab 协议保证：</p>

<ul>
<li>  1）  如果 leader 以 T1 和 T2 的顺序广播，那么所有的 Server 必须先执行 T1，再执行 T2。</li>
<li>  2）  如果任意一个 Server 以 T1、T2 的顺序 commit 执行，其他所有的 Server 也必须以 T1、T2 的顺序执行。</li>
</ul>

<p>“两段提交协议” 最大的问题是如果 Leader 发送了 PROPOSAL 消息后 crash 或暂时失去连接，会导致整个集群处在一种不确定的状态（follower 不知道该放弃这次提交还是执行提交）。Zookeeper 这时会选出新的 leader，请求处理也会移到新的 leader 上，不同的 leader 由不同的 epoch 标识。切换 Leader 时，需要解决下面两个问题：</p>

<p>1. Never forget delivered messages</p>

<p>Leader 在 COMMIT 投递到任何一台 follower 之前 crash，只有它自己 commit 了。新 Leader 必须保证这个事务也必须 commit。</p>

<p>2. Let go of messages that are skipped</p>

<p>Leader 产生某个 proposal，但是在 crash 之前，没有 follower 看到这个 proposal。该 server 恢复时，必须丢弃这个 proposal。</p>

<p>Zookeeper 会尽量保证不会同时有 2 个活动的 Leader，因为 2 个不同的 Leader 会导致集群处在一种不一致的状态，所以 Zab 协议同时保证：</p>

<ul>
<li>  1）  在新的 leader 广播 Transaction 之前，先前 Leader commit 的 Transaction 都会先执行。</li>
<li>  2）  在任意时刻，都不会有 2 个 Server 同时有法定人数（quorum）的支持者。</li>
</ul>

<p>这里的 quorum 是一半以上的 Server 数目，确切的说是有投票权力的 Server（不包括 Observer）。</p>

<p>总结：简单介绍了 Zookeeper 的基本原理，数据模型，Session，Watch 机制，一致性保证，Leader Election，Leader 和 Follower 的工作流程和 Zab 协议。</p>

<p>参考：</p>

<ul>
<li>《ZooKeeper—Distributed Process Coordination》 by FlavioJunqueira and Benjamin Reed</li>
<li><a href="http://zookeeper.apache.org/doc/current/zookeeperOver.html">http://zookeeper.apache.org/doc/current/zookeeperOver.html</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/index.html">http://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/index.html</a></li>
<li><a href="https://my.oschina.net/pingpangkuangmo/blog/778927">《ZooKeeper 的一致性算法赏析》</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elm architecture with React + Redux + Redux-loop]]></title>
    <link href="http://panlw.github.io/15331089375454.html"/>
    <updated>2018-08-01T15:35:37+08:00</updated>
    <id>http://panlw.github.io/15331089375454.html</id>
    <content type="html"><![CDATA[
<p><a href="https://smallbusinessforum.co/elm-architecture-with-react-redux-redux-loop-645a67070b1a">https://smallbusinessforum.co/elm-architecture-with-react-redux-redux-loop-645a67070b1a</a></p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*Or0o-_dFsZe1ahMAC2yLZQ.png" alt=""/></p>

<p>When I started learning React I have beed so confused with Flux architecture. I understand problem which Flux trying to solve, but i don’t have a clue how to do it properly.</p>

<p>After playing with <a href="https://github.com/facebook/flux">Facebook Flux implementation</a> it was good for me but i wanted to write less boilerplate code with different stores. I made my own implementation of stores with connection to dispatcher updates, but it still wasn’t looks perfect.</p>

<p>After while i discovered this great <a href="https://youtu.be/xsSnOQynTHs">presentation</a> by Dan Abramav</p>

<p>I were so excited about single atom of state and how Redux transparent looks Redux flow. It was so easy for development and I started my next project on work with React + Redux.</p>

<p>As for many developers one question wasn’t clear enough with this tools.</p>

<blockquote>
<p>How to solve side effects like http requests</p>
</blockquote>

<h3 id="toc_0">Elm</h3>

<p>I were plunged into background of Redux and found <a href="http://elm-lang.org/">Elm</a>. After learning some basics I understand that it is what I’m looking for. But Elm looks so hardcore for production development and I just made a few simple projects at home.</p>

<p><a href="https://github.com/evancz/elm-architecture-tutorial/blob/master/examples/05-http.elm">This code</a> demonstrate how easy Elm deal with side effects and extracts them from main business logic, like it never exists in your application.</p>

<p><img src="https://cdn-images-1.medium.com/max/800/1*Rfkexz95FuEZ8j4Ruv-Z8g.png" alt=""/></p>

<p>The <code>update</code> function now returns more than just a new model. It returns a new model and some commands you want to run. These commands are all going to produce <code>Msg</code> values that will get fed right back into our <code>update</code> function.</p>

<p>There is a <code>subscriptions</code> function. This function lets you declare any event sources you need to subscribe to given the current model. Just like with <code>Html Msg</code> and <code>Cmd Msg</code>, these subscriptions will produce <code>Msg</code> values that get fed right back into our <code>update</code> function.</p>

<p>One crucial detail here is that commands and subscriptions are <u>data</u>. When you create a command, you do not actually <u>do</u> it. Same with commands in real life. Point is, commands and subscriptions are data. You hand them to Elm to actually run them, giving Elm a chance to log all of this information.</p>

<p>This application flow looks so easy and transparent that i started to search similar way in React+Redux ecosystem.</p>

<p>Many methods for handling effects in Redux, especially those implemented with action-creators, incorrectly teach the user that asynchronous effects are fundamentally different from synchronous state transitions. This separation encourages divergent and increasingly specific means of processing particular types effects. Instead, we should focus on making our reducers powerful enough to handle asynchronous effects as well as synchronous state transitions.</p>

<h3 id="toc_1">Redux-thunk</h3>

<p>Redux Thunk <a href="https://github.com/gaearon/redux-thunk">middleware</a> allows you to write action creators that return a function instead of an action. The thunk can be used to delay the dispatch of an action, or to dispatch only if a certain condition is met. The inner function receives the store methods <code>dispatch</code> and <code>getState</code> as parameters.</p>

<p>Problem of thunk that inside this function you could do any what you want and never handle whats going wrong. You don’t have description of effects which need to be run.</p>

<h3 id="toc_2">Redux-saga</h3>

<p>Next thing that I found was <a href="https://github.com/redux-saga/redux-saga">Redux-saga</a>. It helps you to separate side-effects from your application, but made it more complex because actions now used in another parts of your application where you keep your sagas. So I not been satisfied at all and continue searching.</p>

<p><code>redux-saga</code> is a library that aims to make side effects (i.e. asynchronous things like data fetching and impure things like accessing the browser cache) in React/Redux applications easier and better.</p>

<p>The mental model is that a saga is like a separate thread in your application that’s solely responsible for side effects. <code>redux-saga</code> is a redux middleware, which means this thread can be started, paused and cancelled from the main application with normal redux actions, it has access to the full redux application state and it can dispatch redux actions as well.</p>

<h3 id="toc_3">Redux-loop</h3>

<p>Final catch was the best I found not popular library <a href="https://github.com/redux-loop/redux-loop">Redux-loop</a>. It solve side-effect problem in a way that I prefer.</p>

<p>After every state update it next effects needed to be run described in your state. The values returned from the reducer when scheduling an effect with redux-loop only <u>describe</u> the effect. Calling the reducer will not cause the effect to run. The value returned by the reducer is just an object that the store knows how to interpret when it is enhanced by redux-loop. You can safely call a reducer in your tests without worrying about waiting for effects to finish and what they will do to your environment.</p>

<p>With <code>redux-loop</code>, the reducer doesn&#39;t just decide what happens <u>now</u> due to a particular action, it decides what happens <u>next</u>. All of the behavior of your application can be traced through one place, and that behavior can be easily broken apart and composed back together. This is one of the most powerful features of the <a href="https://guide.elm-lang.org/architecture/">Elm architecture</a>, and with <code>redux-loop</code> it is a feature of Redux as well.</p>

<p>When I started my product <a href="https://recomea.com">Recomea</a> redux-loop become my best friend to handle side-effects.</p>

<pre><code class="language-js">...
case SIGN_IN_FACEBOOK:
  return loop(        
   state,        
   Effects.promise(         
    facebookSigninEffect,       
   )      
);
...
</code></pre>

<p>With reducers like this all my components become more clear and I forgot about horrible redux-thunk.</p>

<ul>
<li>  <a href="https://smallbusinessforum.co/tagged/redux?source=post">Redux</a></li>
<li>  <a href="https://smallbusinessforum.co/tagged/react?source=post">React</a></li>
<li>  <a href="https://smallbusinessforum.co/tagged/elm?source=post">Elm</a></li>
<li>  <a href="https://smallbusinessforum.co/tagged/javascript?source=post">JavaScript</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Streams：一个新的 Redis 通用数据结构]]></title>
    <link href="http://panlw.github.io/15329286072253.html"/>
    <updated>2018-07-30T13:30:07+08:00</updated>
    <id>http://panlw.github.io/15329286072253.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://linux.cn/article-9879-1.html">https://linux.cn/article-9879-1.html</a><br/>
via: <a href="http://antirez.com/news/114">http://antirez.com/news/114</a><br/>
作者：<a href="http://antirez.com/">antirez</a> 译者：<a href="https://github.com/qhwdw">qhwdw</a> 校对：<a href="https://github.com/wxy">wxy</a>, <a href="https://github.com/pityonline">pityonline</a></p>
</blockquote>

<p>直到几个月以前，对于我来说，在消息传递的环境中，<ruby>流 <rt>streams</rt></ruby> 只是一个有趣且相对简单的概念。这个概念在 Kafka 流行之后，我主要研究它们在 Disque 案例中的应用，Disque 是一个消息队列，它将在 Redis 4.2 中被转换为 Redis 的一个模块。后来我决定让 Disque 都用 AP 消息（LCTT 译注：参见 <a href="https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86">CAP 定理</a>），也就是说，它将在不需要客户端过多参与的情况下实现容错和可用性，这样一来，我更加确定地认为流的概念在那种情况下并不适用。</p>

<p>然而在那时 Redis 有个问题，那就是缺省情况下导出数据结构并不轻松。它在 Redis <ruby>列表 <rt>list</rt></ruby>、<ruby>有序集 <rt>sorted list</rt></ruby>、<ruby>发布 / 订阅 <rt>Pub/Sub</rt></ruby> 功能之间有某些缺陷。你可以权衡使用这些工具对一系列消息或事件建模。</p>

<p>有序集是内存消耗大户，那自然就不能对投递的相同消息进行一次又一次的建模，客户端不能阻塞新消息。因为有序集并不是一个序列化的数据结构，它是一个元素可以根据它们量的变化而移动的集合：所以它不像时序性的数据那样。</p>

<p>列表有另外的问题，它在某些特定的用例中会产生类似的适用性问题：你无法浏览列表中间的内容，因为在那种情况下，访问时间是线性的。此外，没有任何指定输出的功能，列表上的阻塞操作仅为单个客户端提供单个元素。列表中没有固定的元素标识，也就是说，不能指定从哪个元素开始给我提供内容。</p>

<p>对于一对多的工作任务，有发布 / 订阅机制，它在大多数情况下是非常好的，但是，对于某些不想 <ruby>“即发即弃”<rt>fire-and-forget</rt></ruby> 的东西：保留一个历史是很重要的，不只是因为是断开之后会重新获得消息，也因为某些如时序性的消息列表，用范围查询浏览是非常重要的：比如在这 10 秒范围内温度读数是多少？</p>

<p>我试图解决上述问题，我想规划一个通用的有序集合，并列入一个独特的、更灵活的数据结构，然而，我的设计尝试最终以生成一个比当前的数据结构更加矫揉造作的结果而告终。Redis 有个好处，它的数据结构导出更像自然的计算机科学的数据结构，而不是 “Salvatore 发明的 API”。因此，我最终停止了我的尝试，并且说，“ok，这是我们目前能提供的”，或许我会为发布 / 订阅增加一些历史信息，或者为列表访问增加一些更灵活的方式。然而，每次在会议上有用户对我说 “你如何在 Redis 中模拟时间系列” 或者类似的问题时，我的脸就绿了。</p>

<p><a id="3_3022" class="target-fix ext" rel="external nofollow" target="_blank"></a></p>

<h3 id="toc_0">起源</h3>

<p>在 Redis 4.0 中引入模块之后，用户开始考虑他们自己怎么去修复这些问题。其中一个用户 Timothy Downs 通过 IRC 和我说道：</p>

<pre><code>&lt;forkfork&gt; 我计划给这个模块增加一个事务日志式的数据类型 —— 这意味着大量的订阅者可以在不导致 redis 内存激增的情况下做一些像发布/订阅那样的事情
&lt;forkfork&gt; 订阅者持有他们在消息队列中的位置，而不是让 Redis 必须维护每个消费者的位置和为每个订阅者复制消息
</code></pre>

<p>他的思路启发了我。我想了几天，并且意识到这可能是我们马上同时解决上面所有问题的契机。我需要去重新构思 “日志” 的概念是什么。日志是个基本的编程元素，每个人都使用过它，因为它只是简单地以追加模式打开一个文件，并以一定的格式写入数据。然而 Redis 数据结构必须是抽象的。它们在内存中，并且我们使用内存并不是因为我们懒，而是因为使用一些指针，我们可以概念化数据结构并把它们抽象，以使它们摆脱明确的限制。例如，一般来说日志有几个问题：偏移不是逻辑化的，而是真实的字节偏移，如果你想要与条目插入的时间相关的逻辑偏移应该怎么办？我们有范围查询可用。同样，日志通常很难进行垃圾回收：在一个只能进行追加操作的数据结构中怎么去删除旧的元素？好吧，在我们理想的日志中，我们只需要说，我想要数字最大的那个条目，而旧的元素一个也不要，等等。</p>

<p>当我从 Timothy 的想法中受到启发，去尝试着写一个规范的时候，我使用了 Redis 集群中的 radix 树去实现，优化了它内部的某些部分。这为实现一个有效利用空间的日志提供了基础，而且仍然有可能在<ruby>对数时间 <rt>logarithmic time</rt></ruby> 内访问范围。同时，我开始去读关于 Kafka 的流相关的内容以获得另外的灵感，它也非常适合我的设计，最后借鉴了 Kafka <ruby>消费组 <rt>consumer groups</rt></ruby> 的概念，并且再次针对 Redis 进行优化，以适用于 Redis 在内存中使用的情况。然而，该规范仅停留在纸面上，在一段时间后我几乎把它从头到尾重写了一遍，以便将我与别人讨论的所得到的许多建议一起增加到 Redis 升级中。我希望 Redis 流能成为对于时间序列有用的特性，而不仅是一个常见的事件和消息类的应用程序。</p>

<h3 id="toc_1">让我们写一些代码吧</h3>

<p>从 Redis 大会回来后，整个夏天我都在实现一个叫 listpack 的库。这个库是 <code>ziplist.c</code> 的继任者，那是一个表示在单个分配中的字符串元素列表的数据结构。它是一个非常特殊的序列化格式，其特点在于也能够以逆序（从右到左）解析：以便在各种用例中替代 ziplists。</p>

<p>结合 radix 树和 listpacks 的特性，它可以很容易地去构建一个空间高效的日志，并且还是可索引的，这意味着允许通过 ID 和时间进行随机访问。自从这些就绪后，我开始去写一些代码以实现流数据结构。我还在完成这个实现，不管怎样，现在在 Github 上的 Redis 的 streams 分支里它已经可以跑起来了。我并没有声称那个 API 是 100% 的最终版本，但是，这有两个有意思的事实：一，在那时只有消费群组是缺失的，加上一些不太重要的操作流的命令，但是，所有的大的方面都已经实现了。二，一旦各个方面比较稳定了之后，我决定大概用两个月的时间将所有的流的特性<ruby>向后移植 <rt>backport</rt></ruby> 到 4.0 分支。这意味着 Redis 用户想要使用流，不用等待 Redis 4.2 发布，它们在生产环境马上就可用了。这是可能的，因为作为一个新的数据结构，几乎所有的代码改变都出现在新的代码里面。除了阻塞列表操作之外：该代码被重构了，我们对于流和列表阻塞操作共享了相同的代码，而极大地简化了 Redis 内部实现。</p>

<h3 id="toc_2">教程：欢迎使用 Redis 的 streams</h3>

<p>在某些方面，你可以认为流是 Redis 列表的一个增强版本。流元素不再是一个单一的字符串，而是一个<ruby>字段 <rt>field</rt></ruby> 和<ruby>值 <rt>value</rt></ruby> 组成的对象。范围查询更适用而且更快。在流中，每个条目都有一个 ID，它是一个逻辑偏移量。不同的客户端可以<ruby>阻塞等待 <rt>blocking-wait</rt></ruby> 比指定的 ID 更大的元素。Redis 流的一个基本的命令是 <code>XADD</code>。是的，所有的 Redis 流命令都是以一个 <code>X</code> 为前缀的。</p>

<pre><code>&gt; XADD mystream * sensor-id 1234 temperature 10.5
1506871964177.0
</code></pre>

<p>这个 <code>XADD</code> 命令将追加指定的条目作为一个指定的流 —— “mystream” 的新元素。上面示例中的这个条目有两个字段：<code>sensor-id</code> 和 <code>temperature</code>，每个条目在同一个流中可以有不同的字段。使用相同的字段名可以更好地利用内存。有意思的是，字段的排序是可以保证顺序的。<code>XADD</code> 仅返回插入的条目的 ID，因为在第三个参数中是星号（<code>*</code>），表示由命令自动生成 ID。通常这样做就够了，但是也可以去强制指定一个 ID，这种情况用于复制这个命令到<ruby>从服务器 <rt>slave server</rt></ruby> 和 <ruby>AOF<rt>append-only file</rt></ruby> 文件。</p>

<p>这个 ID 是由两部分组成的：一个毫秒时间和一个序列号。<code>1506871964177</code> 是毫秒时间，它只是一个毫秒级的 UNIX 时间戳。圆点（<code>.</code>）后面的数字 <code>0</code> 是一个序号，它是为了区分相同毫秒数的条目增加上去的。这两个数字都是 64 位的无符号整数。这意味着，我们可以在流中增加所有想要的条目，即使是在同一毫秒中。ID 的毫秒部分使用 Redis 服务器的当前本地时间生成的 ID 和流中的最后一个条目 ID 两者间的最大的一个。因此，举例来说，即使是计算机时间回跳，这个 ID 仍然是增加的。在某些情况下，你可以认为流条目的 ID 是完整的 128 位数字。然而，事实上它们与被添加到的实例的本地时间有关，这意味着我们可以在毫秒级的精度的范围随意查询。</p>

<p>正如你想的那样，快速添加两个条目后，结果是仅一个序号递增了。我们可以用一个 <code>MULTI</code>/<code>EXEC</code> 块来简单模拟 “快速插入”：</p>

<pre><code>&gt; MULTI
OK
&gt; XADD mystream * foo 10
QUEUED
&gt; XADD mystream * bar 20
QUEUED
&gt; EXEC
1) 1506872463535.0
2) 1506872463535.1
</code></pre>

<p>在上面的示例中，也展示了无需指定任何初始<ruby>模式 <rt>schema</rt></ruby> 的情况下，对不同的条目使用不同的字段。会发生什么呢？就像前面提到的一样，只有每个块（它通常包含 50-150 个消息内容）的第一个消息被使用。并且，相同字段的连续条目都使用了一个标志进行了压缩，这个标志表示与 “它们与这个块中的第一个条目的字段相同”。因此，使用相同字段的连续消息可以节省许多内存，即使是字段集随着时间发生缓慢变化的情况下也很节省内存。</p>

<p>为了从流中检索数据，这里有两种方法：范围查询，它是通过 <code>XRANGE</code> 命令实现的；<ruby>流播 <rt>streaming</rt></ruby>，它是通过 <code>XREAD</code> 命令实现的。<code>XRANGE</code> 命令仅取得包括从开始到停止范围内的全部条目。因此，举例来说，如果我知道它的 ID，我可以使用如下的命名取得单个条目：</p>

<pre><code>&gt; XRANGE mystream 1506871964177.0 1506871964177.0
1) 1) 1506871964177.0
   2) 1) &quot;sensor-id&quot;
      2) &quot;1234&quot;
      3) &quot;temperature&quot;
      4) &quot;10.5&quot;
</code></pre>

<p>不管怎样，你都可以使用指定的开始符号 <code>-</code> 和停止符号 <code>+</code> 表示最小和最大的 ID。为了限制返回条目的数量，也可以使用 <code>COUNT</code> 选项。下面是一个更复杂的 <code>XRANGE</code> 示例：</p>

<pre><code>&gt; XRANGE mystream - + COUNT 2
1) 1) 1506871964177.0
   2) 1) &quot;sensor-id&quot;
      2) &quot;1234&quot;
      3) &quot;temperature&quot;
      4) &quot;10.5&quot;
2) 1) 1506872463535.0
   2) 1) &quot;foo&quot;
      2) &quot;10&quot;
</code></pre>

<p>这里我们讲的是 ID 的范围，然后，为了取得在一个给定时间范围内的特定范围的元素，你可以使用 <code>XRANGE</code>，因为 ID 的 “序号” 部分可以省略。因此，你可以只指定“毫秒” 时间即可，下面的命令的意思是：“从 UNIX 时间 1506872463 开始给我 10 个条目”：</p>

<pre><code>127.0.0.1:6379&gt; XRANGE mystream 1506872463000 + COUNT 10
1) 1) 1506872463535.0
   2) 1) &quot;foo&quot;
      2) &quot;10&quot;
2) 1) 1506872463535.1
   2) 1) &quot;bar&quot;
      2) &quot;20&quot;
</code></pre>

<p>关于 <code>XRANGE</code> 需要注意的最重要的事情是，假设我们在回复中收到 ID，随后连续的 ID 只是增加了序号部分，所以可以使用 <code>XRANGE</code> 遍历整个流，接收每个调用的指定个数的元素。Redis 中的<code>*SCAN</code> 系列命令允许迭代 Redis 数据结构，尽管事实上它们不是为迭代设计的，但这样可以避免再犯相同的错误。</p>

<h3 id="toc_3">使用 XREAD 处理流播：阻塞新的数据</h3>

<p>当我们想通过 ID 或时间去访问流中的一个范围或者是通过 ID 去获取单个元素时，使用 <code>XRANGE</code> 是非常完美的。然而，在使用流的案例中，当数据到达时，它必须由不同的客户端来消费时，这就不是一个很好的解决方案，这需要某种形式的<ruby>汇聚池 <rt>pooling</rt></ruby>。（对于 <u>某些</u> 应用程序来说，这可能是个好主意，因为它们仅是偶尔连接查询的）</p>

<p><code>XREAD</code> 命令是为读取设计的，在同一个时间，从多个流中仅指定我们从该流中得到的最后条目的 ID。此外，如果没有数据可用，我们可以要求阻塞，当数据到达时，就解除阻塞。类似于阻塞列表操作产生的效果，但是这里并没有消费从流中得到的数据，并且多个客户端可以同时访问同一份数据。</p>

<p>这里有一个典型的 <code>XREAD</code> 调用示例：</p>

<pre><code>&gt; XREAD BLOCK 5000 STREAMS mystream otherstream $ $
</code></pre>

<p>它的意思是：从 <code>mystream</code> 和 <code>otherstream</code> 取得数据。如果没有数据可用，阻塞客户端 5000 毫秒。在 <code>STREAMS</code> 选项之后指定我们想要监听的关键字，最后的是指定想要监听的 ID，指定的 ID 为 <code>$</code> 的意思是：假设我现在需要流中的所有元素，因此，只需要从下一个到达的元素开始给我。</p>

<p>如果我从另一个客户端发送这样的命令：</p>

<pre><code>&gt; XADD otherstream * message “Hi There”
</code></pre>

<p>在 <code>XREAD</code> 侧会出现什么情况呢？</p>

<pre><code>1) 1) &quot;otherstream&quot;
   2) 1) 1) 1506935385635.0
         2) 1) &quot;message&quot;
            2) &quot;Hi There&quot;
</code></pre>

<p>与收到的数据一起，我们也得到了数据的关键字。在下次调用中，我们将使用接收到的最新消息的 ID：</p>

<pre><code>&gt; XREAD BLOCK 5000 STREAMS mystream otherstream $ 1506935385635.0
</code></pre>

<p>依次类推。然而需要注意的是使用方式，客户端有可能在一个非常大的延迟之后再次连接（因为它处理消息需要时间，或者其它什么原因）。在这种情况下，期间会有很多消息堆积，为了确保客户端不被消息淹没，以及服务器不会因为给单个客户端提供大量消息而浪费太多的时间，使用 <code>XREAD</code> 的 <code>COUNT</code> 选项是非常明智的。</p>

<h3 id="toc_4">流封顶</h3>

<p>目前看起来还不错…… 然而，有些时候，流需要删除一些旧的消息。幸运的是，这可以使用 <code>XADD</code> 命令的 <code>MAXLEN</code> 选项去做：</p>

<pre><code>&gt; XADD mystream MAXLEN 1000000 * field1 value1 field2 value2
</code></pre>

<p>它是基本意思是，如果在流中添加新元素后发现消息数量超过了 <code>1000000</code> 个，那么就删除旧的消息，以便于元素总量重新回到 <code>1000000</code> 以内。它很像是在列表中使用的 <code>RPUSH</code> + <code>LTRIM</code>，但是，这次我们是使用了一个内置机制去完成的。然而，需要注意的是，上面的意思是每次我们增加一个新的消息时，我们还需要另外的工作去从流中删除旧的消息。这将消耗一些 CPU 资源，所以在计算 <code>MAXLEN</code> 之前，尽可能使用 <code>~</code> 符号，以表明我们不要求非常 <u>精确</u> 的 1000000 个消息，就是稍微多一些也不是大问题：</p>

<pre><code>&gt; XADD mystream MAXLEN ~ 1000000 * foo bar
</code></pre>

<p>这种方式的 XADD 仅当它可以删除整个节点的时候才会删除消息。相比普通的 <code>XADD</code>，这种方式几乎可以自由地对流进行封顶。</p>

<h3 id="toc_5">消费组（开发中）</h3>

<p>这是第一个 Redis 中尚未实现而在开发中的特性。灵感也是来自 Kafka，尽管在这里是以不同的方式实现的。重点是使用了 <code>XREAD</code>，客户端也可以增加一个 <code>GROUP &lt;name&gt;</code> 选项。相同组的所有客户端将自动得到 <u>不同的</u> 消息。当然，同一个流可以被多个组读取。在这种情况下，所有的组将收到流中到达的消息的相同副本。但是，在每个组内，消息是不会重复的。</p>

<p>当指定组时，能够指定一个 <code>RETRY &lt;milliseconds&gt;</code> 选项去扩展组：在这种情况下，如果消息没有通过 <code>XACK</code> 进行确认，它将在指定的毫秒数后进行再次投递。这将为消息投递提供更佳的可靠性，这种情况下，客户端没有私有的方法将消息标记为已处理。这一部分也正在开发中。</p>

<h3 id="toc_6">内存使用和节省加载时间</h3>

<p>因为用来建模 Redis 流的设计，内存使用率是非常低的。这取决于它们的字段、值的数量和长度，对于简单的消息，每使用 100MB 内存可以有几百万条消息。此外，该格式设想为需要极少的序列化：listpack 块以 radix 树节点方式存储，在磁盘上和内存中都以相同方式表示的，因此它们可以很轻松地存储和读取。例如，Redis 可以在 0.3 秒内从 RDB 文件中读取 500 万个条目。这使流的复制和持久存储非常高效。</p>

<p>我还计划允许从条目中间进行部分删除。现在仅实现了一部分，策略是在条目在标记中标识条目为已删除，并且，当已删除条目占全部条目的比例达到指定值时，这个块将被回收重写，如果需要，它将被连到相邻的另一个块上，以避免碎片化。</p>

<h3 id="toc_7">关于最终发布时间的结论</h3>

<p>Redis 的流特性将包含在年底前（LCTT 译注：本文原文发布于 2017 年 10 月）推出的 Redis 4.0 系列的稳定版中。我认为这个通用的数据结构将为 Redis 提供一个巨大的补丁，以用于解决很多现在很难以解决的情况：那意味着你（之前）需要创造性地 “滥用” 当前提供的数据结构去解决那些问题。一个非常重要的使用场景是时间序列，但是，我觉得对于其它场景来说，通过 <code>TREAD</code> 来流播消息将是非常有趣的，因为对于那些需要更高可靠性的应用程序，可以使用发布 / 订阅模式来替换 “即用即弃”，还有其它全新的使用场景。现在，如果你想在有问题环境中评估这个新数据结构，可以更新 GitHub 上的 streams 分支开始试用。欢迎向我们报告所有的 bug。:-)</p>

<p>如果你喜欢观看视频的方式，这里有一个现场演示：<a href="https://www.youtube.com/watch?v=ELDzy9lCFHQ">https://www.youtube.com/watch?v=ELDzy9lCFHQ</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Guide to Java 9 Modularity]]></title>
    <link href="http://panlw.github.io/15327632423477.html"/>
    <updated>2018-07-28T15:34:02+08:00</updated>
    <id>http://panlw.github.io/15327632423477.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://www.baeldung.com/java-9-modularity">http://www.baeldung.com/java-9-modularity</a></p>
</blockquote>

<h2 id="toc_0"><strong>1. Overview</strong></h2>

<p>Java 9 introduces a new level of abstraction above packages, formally known as the Java Platform Module System (JPMS), or “Modules” for short.</p>

<p>In this tutorial, we’ll go through the new system and discuss its various aspects.</p>

<p>We’ll also build a simple project to demonstrate all concepts we’ll be learning in this guide.</p>

<h2 id="toc_1"><strong>2. What’s a Module?</strong></h2>

<p>First of all, we need to understand what a module is before we can understand how to use them.</p>

<p><strong>A Module is a group of closely related packages and resources along with a new module descriptor file.</strong></p>

<p>In other words, it’s a “package of Java Packages” abstraction that allows us to make our code even more reusable.</p>

<h3 id="toc_2"><strong>2.1. Packages</strong></h3>

<p>The packages inside a module are identical to the Java packages we’ve been using since the inception of Java.</p>

<p>When we create a module, <strong>we organize the code internally in packages just like we previously did with any other project.</strong></p>

<p>Aside from organizing our code, packages are used to determine what code is publicly accessible outside of the module. We’ll spend more time talking about this later in the article.</p>

<h3 id="toc_3"><strong>2.2. Resources</strong></h3>

<p><strong>Each module is responsible for its resources, like media or configuration files.</strong></p>

<p>Previously we’d put all resources into the root level of our project and manually manage which resources belonged to different parts of the application.</p>

<p>With modules, we can ship required images and XML files with the module that needs it, making our projects much easier to manage.</p>

<h3 id="toc_4"><strong>2.3. Module Descriptor</strong></h3>

<p>When we create a module, we include a descriptor file that defines several aspects of our new module:</p>

<ul>
<li>  <strong>Name</strong> – the name of our module</li>
<li>  <strong>Dependencies</strong> – a list of other modules that this module depends on</li>
<li>  <strong>Public Packages</strong> – a list of all packages we want accessible from outside the module</li>
<li>  <strong>Services Offered</strong> – we can provide service implementations that can be consumed by other modules</li>
<li>  <strong>Services Consumed</strong> – allows the current module to be a consumer of a service</li>
<li>  <strong>Reflection Permissions</strong> – explicitly allows other classes to use reflection to access the private members of a package</li>
</ul>

<p>The module naming rules are similar to how we name packages (dots are allowed, dashes are not). It’s very common to do either project-style (my.module) or Reverse-DNS (_com.baeldung.mymodule_) style names. We’ll use project-style in this guide.</p>

<p><strong>We need to list all packages we want to be public because by default all packages are module private.</strong></p>

<p>The same is true for reflection. By default, we cannot use reflection on classes we import from another module.</p>

<p>Later in the article, we’ll look at examples of how to use the module descriptor file.</p>

<h3 id="toc_5"><strong>2.4. Module Types</strong></h3>

<p>There are four types of modules in the new module system:</p>

<ul>
<li>  <strong>System Modules</strong>– These are the modules listed when we run the _list-modules_ command above. They include the Java SE and JDK modules.</li>
<li>  <strong>Application Modules</strong> – These modules are what we usually want to build when we decide to use Modules. They are named and defined in the compiled _module-info.class_ file included in the assembled JAR.</li>
<li>  <strong>Automatic Modules</strong> – We can include unofficial modules by adding existing JAR files to the module path. The name of the module will be derived from the name of the JAR. Automatic modules will have full read access to every other module loaded by the path.</li>
<li>  <strong>Unnamed Module</strong> – When a class or JAR is loaded onto the classpath, but not the module path, it’s automatically added to the unnamed module. It’s a catch-all module to maintain backward compatibility with previously-written Java code.</li>
</ul>

<h3 id="toc_6"><strong>2.5. Distribution</strong></h3>

<p>Modules can be distributed one of two ways: as a JAR file or as an “exploded” compiled project. This, of course, is the same as any other Java project so it should come as no surprise.</p>

<p>We can create multi-module projects comprised of a “main application” and several library modules.</p>

<p><strong>We have to be careful though because we can only have one module per JAR file.</strong></p>

<p>When we set up our build file, we need to make sure to bundle each module in our project as a separate jar.</p>

<h2 id="toc_7"><strong>3. Default Modules</strong></h2>

<p>When we install Java 9, we can see that the JDK now has a new structure.</p>

<p>They have taken all the original packages and moved them into the new module system.</p>

<p>We can see what these modules are by typing into the command line:</p>

<pre><code class="language-sh">java --list-modules
</code></pre>

<p>These modules are split into four major groups: _java, javafx, jdk, _and _Oracle_.</p>

<p><u>java</u> modules are the implementation classes for the core SE Language Specification.</p>

<p><u>javafx</u> modules are the FX UI libraries.</p>

<p><strong>Anything needed by the JDK itself is kept in the _jdk_ modules.</strong></p>

<p>And finally, <strong>anything that is Oracle-specific is in the _oracle_ modules.</strong></p>

<h2 id="toc_8"><strong>4. Module Declarations</strong></h2>

<p><strong>To set up a module, we need to put a special file at the root of our packages named _module-info.java_.</strong></p>

<p>This file is known as the module descriptor and contains all of the data needed to build and use our new module.</p>

<p>We construct the module with a declaration whose body is either empty or made up of module directives:</p>

<pre><code class="language-java">module myModuleName {
    // all directives are optional
}
</code></pre>

<p>We start the module declaration with the <u>module</u> keyword, and we follow that with the name of the module.</p>

<p>The module will work with this declaration, but we’ll commonly need more information.</p>

<p>That is where the module directives come in.</p>

<h3 id="toc_9"><strong>4.1. Requires</strong></h3>

<p>Our first directive is _requires_. This module directive allows us to declare module dependencies:</p>

<pre><code class="language-java">module my.module {
    requires module.name;
}
</code></pre>

<p>Now, _my.module_ has <strong>both a runtime and a compile-time dependency</strong> on <u>module.name</u>.</p>

<p>And all public types exported from a dependency are accessible by our module when we use this directive.</p>

<h3 id="toc_10"><strong>4.2. Requires Static</strong></h3>

<p>Sometimes we write code that references another module, but that users of our library will never want to use.</p>

<p>For instance, we might write a utility function that pretty-prints our internal state when another logging module is present. But, not every consumer of our library will want this functionality, and they don’t want to include an extra logging library.</p>

<p>In these cases, we want to use an optional dependency. By using the _requires static_ directive, we create a compile-time-only dependency:</p>

<pre><code class="language-java">module my.module {
    requires static module.name;
}
</code></pre>

<h3 id="toc_11"><strong>4.3. Requires Transitive</strong></h3>

<p>We commonly work with libraries to make our lives easier.</p>

<p>But, we need to make sure that any module that brings in our code will also bring in these extra ‘transitive’ dependencies or they won’t work.</p>

<p>Luckily, we can use the _requires transitive_ directive to force any downstream consumers also to read our required dependencies:</p>

<pre><code class="language-java">module my.module {
    requires transitive module.name;
}
</code></pre>

<p>Now, when a developer <u>requires my.module</u>, they won’t also have also to say _requires module.name_ for our module to still work.</p>

<h3 id="toc_12"><strong>4.4. Exports</strong></h3>

<p><strong>By default, a module doesn’t expose any of its API to other modules.</strong> This _strong encapsulation_ was one of the key motivators for creating the module system in the first place.</p>

<p>Our code is significantly more secure, but now we need to explicitly open our API up to the world if we want it to be usable.</p>

<p><strong>We use the _exports_ directive to expose all public members of the named package:</strong></p>

<pre><code class="language-java">module my.module {
    exports com.my.package.name;
}
</code></pre>

<p>Now, when someone does _requires my.module_, they will have access to the public types in our _com.my.package.name_ package, but not any other package.</p>

<h3 id="toc_13"><strong>4.5. Exports … To</strong></h3>

<p><strong>We can use _exports…to_ to open up our public classes to the world.</strong></p>

<p>But, what if we don’t want the entire world to access our API?</p>

<p><strong>We can restrict which modules have access to our APIs using the _exports…to_ directive.</strong></p>

<p>Similar to the _exports_ directive, we declare a package as exported. But, we also list which modules we are allowing to import this package as a <u>requires</u>. Let’s see what this looks like:</p>

<pre><code class="language-java">module my.module {
    export com.my.package.name to com.specific.package;
}
</code></pre>

<h3 id="toc_14"><strong>4.6. Uses</strong></h3>

<p>A _service_ is an implementation of a specific interface or abstract class that can be _consumed_ by other classes.</p>

<p><strong>We designate the services our module consumes with the _uses_ directive.</strong></p>

<p>Note that <strong>the class name we _use_ is either the interface or abstract class of the service, not the implementation class</strong>:</p>

<pre><code class="language-java">module my.module {
    uses class.name;
}
</code></pre>

<p>We should note here that there’s a difference between a _requires_ directive and the _uses_ directive.</p>

<p>We might <u>require</u> a module that provides a service we want to consume, but that service implements an interface from one of its transitive dependencies.</p>

<p>Instead of forcing our module to require _all_ transitive dependencies just in case, we use the _uses_ directive to add the required interface to the module path.</p>

<h3 id="toc_15"><strong>4.7. Provides … With</strong></h3>

<p><strong>A module can also be a _service provider_ that other modules can consume.</strong></p>

<p>The first part of the directive is the _provides_ keyword. Here is where we put the interface or abstract class name.</p>

<p>Next, we have the _with_ directive where we provide the implementation class name that either <u>implements</u> the interface or _extends_ the abstract class.</p>

<p>Here’s what it looks like put together:</p>

<pre><code class="language-java">module my.module {
    provides MyInterface with MyInterfaceImpl;
}
</code></pre>

<h3 id="toc_16"><strong>4.8. Open</strong></h3>

<p>We mentioned earlier that encapsulation was a driving motivator for the design of this module system.</p>

<p>Before Java 9, it was possible to use reflection to examine every type and member in a package, even the _private_ ones. Nothing was truly encapsulated, which can open up all kinds of problems for developers of the libraries.</p>

<p>Because Java 9 enforces _strong encapsulation_, <strong>we now have to explicitly grant permission for other modules to reflect on our classes.</strong></p>

<p>If we want to continue to allow full reflection as older versions of Java did, we can simply _open_ the entire module up:</p>

<pre><code class="language-java">open module my.module {
}
</code></pre>

<h3 id="toc_17"><strong>4.9. Opens</strong></h3>

<p>If we need to allow reflection of private types, but we don’t want all of our code exposed, <strong>we can use the _opens_ directive to expose specific packages.</strong></p>

<p>But remember, this will open the package up to the entire world, so make sure that is what you want:</p>

<pre><code class="language-java">module my.module {
  opens com.my.package;
}
</code></pre>

<h3 id="toc_18"><strong>4.10. Opens … To</strong></h3>

<p>Okay, so reflection is great sometimes, but we still want as much security as we can get from _encapsulation_. <strong>We can selectively open our packages to a pre-approved list of modules, in this case, using the _opens…to_ directive</strong>:</p>

<pre><code class="language-java">module my.module {
    opens com.my.package to moduleOne, moduleTwo, etc.;
}
</code></pre>

<h2 id="toc_19"><strong>5. Command Line Options</strong></h2>

<p>By now, support for Java 9 modules has been added to Maven and Gradle, so you won’t need to do a lot of manual building of your projects. However, it’s still valuable to know _how_ to use the module system from the command line.</p>

<p>We’ll be using the command line for our full example down below to help solidify how the entire system works in our minds.</p>

<ul>
<li>  <u><strong>module-path</strong></u> <strong>–</strong>We use the _–module-path_ option to specify the module path. This is a list of one or more directories that contain your modules.</li>
<li>  <u><strong>add-reads</strong></u> – Instead of relying on the module declaration file, we can use the command line equivalent of the _requires_ directive; _–add-reads_.</li>
<li>  <u><strong>add-exports</strong></u> <strong>–</strong>Command line replacement for the <u>exports</u> directive.</li>
<li>  <u><strong>add-opens</strong></u> <u>–</u>Replace the _open_ clause in the module declaration file.</li>
<li>  <u><strong>add-modules</strong></u> <u>–</u>Adds the list of modules into the default set of modules</li>
<li>  <u><strong>list-modules</strong></u> <u>–</u>Prints a list of all modules and their version strings</li>
<li>  <u><strong>patch-module</strong></u> – Add or override classes in a modules</li>
<li>  <u><strong>illegal-access=permit|warn|deny</strong></u> – Either relax strong encapsulation by showing a single global warning, shows every warning, or fails with errors. The default is _permit_.</li>
</ul>

<h2 id="toc_20"><strong>6. Visibility</strong></h2>

<p>We should spend a little time talking about the visibility of our code.</p>

<p><strong>A lot of libraries depend on reflection to work their magic</strong> (JUnit and Spring come to mind).</p>

<p>By default in Java 9, we will _only_ have access to public classes, methods, and fields in our exported packages. Even if we use reflection to get access to non-public members and call _setAccessible(true), _we won’t be able to access these members.</p>

<p>We can use the _open_, _opens_, and _opens…to_ options to grant runtime-only access for reflection. Note, <strong>this is runtime-only!</strong></p>

<p>We won’t be able to compile against private types, and we should never need to anyway.</p>

<p>If we must have access to a module for reflection, and we’re not the owner of that module (i.e., we can’t use the _opens…to_ directive), then it’s possible to use the command line _–add-opens_ option to allow own modules reflection access to the locked down module at runtime.</p>

<p>The only caveat here’s that you need to have access to the command line arguments that are used to run a module for this to work.</p>

<h2 id="toc_21"><strong>7. Putting It All Together</strong></h2>

<p>Now that we know what a module is and how to use them let’s go ahead and build a simple project to demonstrate all the concepts we just learned.</p>

<p>To keep things simple, we won’t be using Maven or Gradle. Instead, we’ll rely on the command line tools to build our modules.</p>

<h3 id="toc_22"><strong>7.1. Setting Up Our Project</strong></h3>

<p>First, we need to set up our project structure. We’ll create several directories to organize our files.</p>

<p>Start by creating the project folder:</p>

<pre><code class="language-sh">mkdir module-project
cd module-project
</code></pre>

<p>This is the base of our whole project, so add files in here such as Maven or Gradle build files, other source directories, and resources.</p>

<p>We also put a directory to hold all our project specific modules.</p>

<p>Next, we create a module directory:</p>

<pre><code class="language-sh">mkdir simple-modules
</code></pre>

<p>Here’s what our project structure will look like:</p>

<pre><code class="language-txt">module-project
|- // src if we use the default package
|- // build files also go at this level
|- simple-modules
  |- hello.modules
    |- com
      |- baeldung
        |- modules
          |- hello
  |- main.app
    |- com
      |- baeldung
        |- modules
          |- main
</code></pre>

<h3 id="toc_23"><strong>7.2. Our First Module</strong></h3>

<p>Now that we have the basic structure in place, let’s add our first module.</p>

<p>Under the _simple-modules _directory, create a new directory called _hello.modules_.</p>

<p><strong>We can name this anything we want but follow package naming rules</strong> (i.e., periods to separate words, etc.). We can even use the name of our main package as the module name if we want, but usually, we want to stick to the same name we would use to create a JAR of this module.</p>

<p>Under our new module, we can create the packages we want. In our case, we are going to create one package structure:</p>

<pre><code>com.baeldung.modules.hello
</code></pre>

<p>Next, create a new class called _HelloModules.java_ in this package. We will keep the code simple:</p>

<pre><code class="language-java">package com.baeldung.modules.hello;
 
public class HelloModules {
    public static void doSomething() {
        System.out.println(&quot;Hello, Modules!&quot;);
    }
}
</code></pre>

<p>And finally, in the _hello.modules_ root directory, add in our module descriptor; _module-info.java_:</p>

<pre><code class="language-java">module hello.modules {
    exports com.baeldung.modules.hello;
}
</code></pre>

<p>To keep this example simple, all we are doing is exporting all public members of the _com.baeldung.modules.hello _package.</p>

<h3 id="toc_24"><strong>7.3. Our Second Module</strong></h3>

<p>Our first module is great, but it doesn’t do anything.</p>

<p>We can create a second module that uses it now.</p>

<p>Under our _simple-modules_ directory, create another module directory called _main.app_. We are going to start with the module descriptor this time:</p>

<pre><code class="language-java">module main.app {
    requires hello.modules;
}
</code></pre>

<p>We don’t need to expose anything to the outside world. Instead, all we need to do is depend on our first module, so we have access to the public classes it exports.</p>

<p>Now we can create an application that uses it.</p>

<p>Create a new package structure: _com.baeldung.modules.main_.</p>

<p>Now, create a new class file called _MainApp.java._</p>

<pre><code class="language-java">package com.baeldung.modules.main;
 
import com.baeldung.modules.hello.HelloModules;
 
public class MainApp {
    public static void main(String[] args) {
        HelloModules.doSomething();
    }
}
</code></pre>

<p>And that is all the code we need to demonstrate modules. Our next step is to build and run this code from the command line.</p>

<h3 id="toc_25"><strong>7.4. Building Our Modules</strong></h3>

<p>To build our project, we can create a simple bash script and place it at the root of our project.</p>

<p>Create a file called _compile-simple-modules.sh_:</p>

<pre><code class="language-sh">#!/usr/bin/env bash
javac -d outDir --module-source-path simple-modules $(find simple-modules -name &quot;*.java&quot;)
</code></pre>

<p>There are two parts to this command, the _javac_ and _find_ commands.</p>

<p>The _find_ command is simply outputting a list of all ._java_ files under our simple-modules directory. We can then feed that list directly into the Java compiler.</p>

<p>The only thing we have to do differently than the older versions of Java is to provide a _module-source-path_ parameter to inform the compiler that it’s building modules.</p>

<p>Once we run this command, we will have an _outDir_ folder with two compiled modules inside.</p>

<h3 id="toc_26"><strong>7.5. Running Our Code</strong></h3>

<p>And now we can finally run our code to verify modules are working correctly.</p>

<p>Create another file in the root of the project: _run-simple-module-app.sh_.</p>

<pre><code class="language-sh">#!/usr/bin/env bash
java --module-path outDir -m main.app/com.baeldung.modules.main.MainApp
</code></pre>

<p>To run a module, we must provide at least the _module-path_ and the main class. If all works, you should see:</p>

<pre><code class="language-sh">$ ./run-simple-module-app.sh 
Hello, Modules!
</code></pre>

<h3 id="toc_27"><strong>7.6. Adding a Service</strong></h3>

<p>Now that we have a basic understanding of how to build a module, let’s make it a little more complicated.</p>

<p>We’re going to see how to use the _provides…with_ and _uses_ directives.</p>

<p>Start by defining a new file in the _hello.modules_ module named _HelloInterface__.java_:</p>

<pre><code class="language-java">public interface HelloInterface {
    void sayHello();
}
</code></pre>

<p>To make things easy, we’re going to implement this interface with our existing _HelloModules.java_ class:</p>

<pre><code class="language-java">public class HelloModules implements HelloInterface {
    public static void doSomething() {
        System.out.println(&quot;Hello, Modules!&quot;);
    }
 
    public void sayHello() {
        System.out.println(&quot;Hello!&quot;);
    }
}
</code></pre>

<p>That is all we need to do to create a _service_.</p>

<p>Now, we need to tell the world that our module provides this service.</p>

<p>Add the following to our _module-info.java_:</p>

<pre><code>provides com.baeldung.modules.hello.HelloInterface with com.baeldung.modules.hello.HelloModules;
</code></pre>

<p>As we can see, we declare the interface and which class implements it.</p>

<p>Next, we need to consume this _service_. In our _main.app_ module, let’s add the following to our _module-info.java_:</p>

<pre><code class="language-java">uses com.baeldung.modules.hello.HelloInterface;
</code></pre>

<p>Finally, in our main method we can use this service like this:</p>

<pre><code class="language-java">HelloModules module = new HelloModules();
module.sayHello();
</code></pre>

<p>Compile and run:</p>

<pre><code class="language-sh">$ ./run-simple-module-app.sh 
Hello, Modules!
Hello!
</code></pre>

<p>We use these directives to be much more explicit about how our code is to be used.</p>

<p>We could put the interface into a private package while exposing the implementation in a public package.</p>

<p>This makes our code much more secure with very little extra overhead.</p>

<p>Go ahead and try out some of the other directives to learn more about modules and how they work.</p>

<h2 id="toc_28"><strong>8. Conclusion</strong></h2>

<p>In this extensive guide, we focused on and covered the basics of the new Java 9 Module system.</p>

<p>We started by talking about what a module is.</p>

<p>Next, we talked about how to discover which modules are included in the JDK.</p>

<p>We also covered the module declaration file in detail.</p>

<p>We rounded out the theory by talking about the various command line arguments we’ll need to build our modules.</p>

<p>Finally, we put all our previous knowledge into practice and created a simple application built on top of the module system.</p>

<p>To see this code and more, be sure to <a href="https://github.com/eugenp/tutorials/tree/master/core-java-9">check it out over on Github</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dapper，大规模分布式系统的跟踪系统]]></title>
    <link href="http://panlw.github.io/15327611910129.html"/>
    <updated>2018-07-28T14:59:51+08:00</updated>
    <id>http://panlw.github.io/15327611910129.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://bigbully.github.io/Dapper-translation/">https://bigbully.github.io/Dapper-translation/</a></p>
</blockquote>

<pre><code>作者：Benjamin H. Sigelman, Luiz Andr´e Barroso, Mike Burrows, Pat Stephenson, Manoj Plakal, Donald Beaver, Saul Jaspan, Chandan Shanbhag
</code></pre>

<h3 id="toc_0">概述</h3>

<p>当代的互联网的服务，通常都是用复杂的、大规模分布式集群来实现的。互联网应用构建在不同的软件模块集上，这些软件模块，有可能是由不同的团队开发、可能使用不同的编程语言来实现、有可能布在了几千台服务器，横跨多个不同的数据中心。因此，就需要一些可以帮助理解系统行为、用于分析性能问题的工具。</p>

<p>Dapper--Google 生产环境下的分布式跟踪系统，应运而生。那么我们就来介绍一个大规模集群的跟踪系统，它是如何满足一个低损耗、应用透明的、大范围部署这三个需求的。当然 Dapper 设计之初，参考了一些其他分布式系统的理念，尤其是 Magpie 和 X-Trace，但是我们之所以能成功应用在生产环境上，还需要一些画龙点睛之笔，例如采样率的使用以及把代码植入限制在一小部分公共库的改造上。</p>

<p>自从 Dapper 发展成为一流的监控系统之后，给其他应用的开发者和运维团队帮了大忙，所以我们今天才发表这篇论文，来汇报一下这两年来，Dapper 是怎么构建和部署的。Dapper 最初只是作为一个自给自足的监控工具起步的，但最终进化成一个监控平台，这个监控平台促生出多种多样的监控工具，有些甚至已经不是由 Dapper 团队开发的了。下面我们会介绍一些使用 Dapper 搭建的分析工具，分享一下这些工具在 google 内部使用的统计数据，展现一些使用场景，最后会讨论一下我们迄今为止从 Dapper 收获了些什么。</p>

<h3 id="toc_1">1. 介绍</h3>

<p>我们开发 Dapper 是为了收集更多的复杂分布式系统的行为信息，然后呈现给 Google 的开发者们。这样的分布式系统有一个特殊的好处，因为那些大规模的低端服务器，作为互联网服务的载体，是一个特殊的经济划算的平台。想要在这个上下文中理解分布式系统的行为，就需要监控那些横跨了不同的应用、不同的服务器之间的关联动作。</p>

<p>下面举一个跟搜索相关的例子，这个例子阐述了 Dapper 可以应对哪些挑战。比如一个前段服务可能对上百台查询服务器发起了一个 Web 查询，每一个查询都有自己的 Index。这个查询可能会被发送到多个的子系统，这些子系统分别用来处理广告、进行拼写检查或是查找一些像图片、视频或新闻这样的特殊结果。根据每个子系统的查询结果进行筛选，得到最终结果，最后汇总到页面上。我们把这种搜索模型称为 “全局搜索”（universal search）。总的来说，这一次全局搜索有可能调用上千台服务器，涉及各种服务。而且，用户对搜索的耗时是很敏感的，而任何一个子系统的低效都导致导致最终的搜索耗时。如果一个工程师只能知道这个查询耗时不正常，但是他无从知晓这个问题到底是由哪个服务调用造成的，或者为什么这个调用性能差强人意。首先，这个工程师可能无法准确的定位到这次全局搜索是调用了哪些服务，因为新的服务、乃至服务上的某个片段，都有可能在任何时间上过线或修改过，有可能是面向用户功能，也有可能是一些例如针对性能或安全认证方面的功能改进。其次，你不能苛求这个工程师对所有参与这次全局搜索的服务都了如指掌，每一个服务都有可能是由不同的团队开发或维护的。再次，这些暴露出来的服务或服务器有可能同时还被其他客户端使用着，所以这次全局搜索的性能问题甚至有可能是由其他应用造成的。举个例子，一个后台服务可能要应付各种各样的请求类型，而一个使用效率很高的存储系统，比如 Bigtable，有可能正被反复读写着，因为上面跑着各种各样的应用。</p>

<p>上面这个案例中我们可以看到，对 Dapper 我们只有两点要求：无所不在的部署，持续的监控。无所不在的重要性不言而喻，因为在使用跟踪系统的进行监控时，即便只有一小部分没被监控到，那么人们对这个系统是不是值得信任都会产生巨大的质疑。另外，监控应该是 7x24 小时的，毕竟，系统异常或是那些重要的系统行为有可能出现过一次，就很难甚至不太可能重现。那么，根据这两个明确的需求，我们可以直接推出三个具体的设计目标：</p>

<p>1. 低消耗：跟踪系统对在线服务的影响应该做到足够小。在一些高度优化过的服务，即使一点点损耗也会很容易察觉到，而且有可能迫使在线服务的部署团队不得不将跟踪系统关停。</p>

<p>2. 应用级的透明：对于应用的程序员来说，是不需要知道有跟踪系统这回事的。如果一个跟踪系统想生效，就必须需要依赖应用的开发者主动配合，那么这个跟踪系统也太脆弱了，往往由于跟踪系统在应用中植入代码的 bug 或疏忽导致应用出问题，这样才是无法满足对跟踪系统 “无所不在的部署” 这个需求。面对当下想 Google 这样的快节奏的开发环境来说，尤其重要。</p>

<p>3. 延展性：Google 至少在未来几年的服务和集群的规模，监控系统都应该能完全把控住。</p>

<p>一个额外的设计目标是为跟踪数据产生之后，进行分析的速度要快，理想情况是数据存入跟踪仓库后一分钟内就能统计出来。尽管跟踪系统对一小时前的旧数据进行统计也是相当有价值的，但如果跟踪系统能提供足够快的信息反馈，就可以对生产环境下的异常状况做出快速反应。</p>

<p>做到真正的应用级别的透明，这应该是当下面临的最挑战性的设计目标，我们把核心跟踪代码做的很轻巧，然后把它植入到那些无所不在的公共组件种，比如线程调用、控制流以及 RPC 库。使用自适应的采样率可以使跟踪系统变得可伸缩，并降低性能损耗，这些内容将在第 4.4 节中提及。结果展示的相关系统也需要包含一些用来收集跟踪数据的代码，用来图形化的工具，以及用来分析大规模跟踪数据的库和 API。虽然单独使用 Dapper 有时就足够让开发人员查明异常的来源，但是 Dapper 的初衷不是要取代所有其他监控的工具。我们发现，Dapper 的数据往往侧重性能方面的调查，所以其他监控工具也有他们各自的用处。</p>

<h2 id="toc_2">1.1 文献的总结</h2>

<p>分布式系统跟踪工具的设计空间已经被一些优秀文章探索过了，其中的 Pinpoint[9]、Magpie[3] 和 X-Trace[12] 和 Dapper 最为相近。这些系统在其发展过程的早期倾向于写入研究报告中，即便他们还没来得及清楚地评估系统当中一些设计的重要性。相比之下，由于 Dapper 已经在大规模生产环境中摸爬滚打了多年，经过这么多生产环境的验证之后，我们认为这篇论文最适合重点阐述在部署 Dapper 的过程中我们有那些收获，我们的设计思想是如何决定的，以及以什么样的方式实现它才会最有用。Dappe 作为一个平台，承载基于 Dapper 开发的性能分析工具，以及 Dapper 自身的监测工具，它的价值在于我们可以在回顾评估中找出一些意想不到的结果。</p>

<p>虽然 Dapper 在许多高阶的设计思想上吸取了 Pinpoint 和 Magpie 的研究成果，但在分布式跟踪这个领域中，Dapper 的实现包含了许多新的贡献。例如，我们想实现低损耗的话，特别是在高度优化的而且趋于极端延迟敏感的 Web 服务中，采样率是很必要的。或许更令人惊讶的是，我们发现即便是 1/1000 的采样率，对于跟踪数据的通用使用层面上，也可以提供足够多的信息。</p>

<p>我们的系统的另一个重要的特征，就是我们能实现的应用级的透明。我们的组件对应用的侵入被先限制在足够低的水平上，即使想 Google 网页搜索这么大规模的分布式系统，也可以直接进行跟踪而无需加入额外的标注 (Annotation)。虽然由于我们的部署系统有幸是一定程度的同质化的，所以更容易做到对应用层的透明这点，但是我们证明了这是实现这种程度的透明性的充分条件。</p>

<h2 id="toc_3">2. Dapper 的分布式跟踪</h2>

<p><img src="media/15327611910129/15327613033809.jpg" alt=""/></p>

<p>图 1：这个路径由用户的 X 请求发起，穿过一个简单的服务系统。用字母标识的节点代表分布式系统中的不同处理过程。</p>

<p>分布式服务的跟踪系统需要记录在一次特定的请求后系统中完成的所有工作的信息。举个例子，图 1 展现的是一个和 5 台服务器相关的一个服务，包括：前端（A），两个中间层（B 和 C），以及两个后端（D 和 E）。当一个用户（这个用例的发起人）发起一个请求时，首先到达前端，然后发送两个 RPC 到服务器 B 和 C。B 会马上做出反应，但是 C 需要和后端的 D 和 E 交互之后再返还给 A，由 A 来响应最初的请求。对于这样一个请求，简单实用的分布式跟踪的实现，就是为服务器上每一次你发送和接收动作来收集跟踪标识符 (message identifiers) 和时间戳(timestamped events)。</p>

<p>为了将所有记录条目与一个给定的发起者（例如，图 1 中的 RequestX）关联上并记录所有信息，现在有两种解决方案，黑盒 (black-box) 和基于标注 (annotation-based) 的监控方案。黑盒方案 [1，15，2] 假定需要跟踪的除了上述信息之外没有额外的信息，这样使用统计回归技术来推断两者之间的关系。基于标注的方案 [3，12，9，16] 依赖于应用程序或中间件明确地标记一个全局 ID，从而连接每一条记录和发起者的请求。虽然黑盒方案比标注方案更轻便，他们需要更多的数据，以获得足够的精度，因为他们依赖于统计推论。基于标注的方案最主要的缺点是，很明显，需要代码植入。在我们的生产环境中，因为所有的应用程序都使用相同的线程模型，控制流和 RPC 系统，我们发现，可以把代码植入限制在一个很小的通用组件库中，从而实现了监测系统的应用对开发人员是有效地透明。</p>

<p>我们倾向于认为，Dapper 的跟踪架构像是内嵌在 RPC 调用的树形结构。然而，我们的核心数据模型不只局限于我们的特定的 RPC 框架，我们还能跟踪其他行为，例如 Gmail 的 SMTP 会话，外界的 HTTP 请求，和外部对 SQL 服务器的查询等。从形式上看，我们的 Dapper 跟踪模型使用的树形结构，Span 以及 Annotation。</p>

<h2 id="toc_4">2.1 跟踪树和 span</h2>

<p>在 Dapper 跟踪树结构中，树节点是整个架构的基本单元，而每一个节点又是对 span 的引用。节点之间的连线表示的 span 和它的父 span 直接的关系。虽然 span 在日志文件中只是简单的代表 span 的开始和结束时间，他们在整个树形结构中却是相对独立的，任何 RPC 相关的时间数据、零个或多个特定应用程序的 Annotation 的相关内容会在 2.3 节中讨论。</p>

<p><img src="media/15327611910129/15327613158760.jpg" alt=""/></p>

<p>图 2：5 个 span 在 Dapper 跟踪树种短暂的关联关系</p>

<p>在图 2 中说明了 span 在一个大的跟踪过程中是什么样的。Dapper 记录了 span 名称，以及每个 span 的 ID 和父 ID，以重建在一次追踪过程中不同 span 之间的关系。如果一个 span 没有父 ID 被称为 root span。所有 span 都挂在一个特定的跟踪上，也共用一个跟踪 id（在图中未示出）。所有这些 ID 用全局唯一的 64 位整数标示。在一个典型的 Dapper 跟踪中，我们希望为每一个 RPC 对应到一个单一的 span 上，而且每一个额外的组件层都对应一个跟踪树型结构的层级。<br/>
<img src="media/15327611910129/15327613285085.jpg" alt=""/></p>

<p>图 3：在图 2 中所示的一个单独的 span 的细节图</p>

<p>图 3 给出了一个更详细的典型的 Dapper 跟踪 span 的记录点的视图。在图 2 中这种某个 span 表述了两个 “Helper.Call” 的 RPC(分别为 server 端和 client 端)。span 的开始时间和结束时间，以及任何 RPC 的时间信息都通过 Dapper 在 RPC 组件库的植入记录下来。如果应用程序开发者选择在跟踪中增加他们自己的注释（如图中 “foo” 的注释）(业务数据)，这些信息也会和其他 span 信息一样记录下来。</p>

<p>记住，任何一个 span 可以包含来自不同的主机信息，这些也要记录下来。事实上，每一个 RPC span 可以包含客户端和服务器两个过程的注释，使得链接两个主机的 span 会成为模型中所说的 span。由于客户端和服务器上的时间戳来自不同的主机，我们必须考虑到时间偏差。在我们的分析工具，我们利用了这个事实：RPC 客户端发送一个请求之后，服务器端才能接收到，对于响应也是一样的（服务器先响应，然后客户端才能接收到这个响应）。这样一来，服务器端的 RPC 就有一个时间戳的一个上限和下限。</p>

<h2 id="toc_5">2.2 植入点</h2>

<p>Dapper 可以以对应用开发者近乎零浸入的成本对分布式控制路径进行跟踪，几乎完全依赖于基于少量通用组件库的改造。如下：</p>

<ul>
<li>  当一个线程在处理跟踪控制路径的过程中，Dapper 把这次跟踪的上下文的在 ThreadLocal 中进行存储。追踪上下文是一个小而且容易复制的容器，其中承载了 Scan 的属性比如跟踪 ID 和 span ID。</li>
<li>  当计算过程是延迟调用的或是异步的，大多数 Google 开发者通过线程池或其他执行器，使用一个通用的控制流库来回调。Dapper 确保所有这样的回调可以存储这次跟踪的上下文，而当回调函数被触发时，这次跟踪的上下文会与适当的线程关联上。在这种方式下，Dapper 可以使用 trace ID 和 span ID 来辅助构建异步调用的路径。</li>
<li>  几乎所有的 Google 的进程间通信是建立在一个用 C++ 和 Java 开发的 RPC 框架上。我们把跟踪植入该框架来定义 RPC 中所有的 span。span 的 ID 和跟踪的 ID 会从客户端发送到服务端。像那样的基于 RPC 的系统被广泛使用在 Google 中，这是一个重要的植入点。当那些非 RPC 通信框架发展成熟并找到了自己的用户群之后，我们会计划对 RPC 通信框架进行植入。</li>
</ul>

<p>Dapper 的跟踪数据是独立于语言的，很多在生产环境中的跟踪结合了用 C++ 和 Java 写的进程的数据。在 3.2 节中，我们讨论应用程序的透明度时我们会把这些理论的是如何实践的进行讨论。</p>

<h2 id="toc_6">2.3 Annotation</h2>

<p><img src="media/15327611910129/15327613415889.jpg" alt=""/></p>

<p>上述植入点足够推导出复杂的分布式系统的跟踪细节，使得 Dapper 的核心功能在不改动 Google 应用的情况下可用。然而，Dapper 还允许应用程序开发人员在 Dapper 跟踪的过程中添加额外的信息，以监控更高级别的系统行为，或帮助调试问题。我们允许用户通过一个简单的 API 定义带时间戳的 Annotation，核心的示例代码入图 4 所示。这些 Annotation 可以添加任意内容。为了保护 Dapper 的用户意外的过分热衷于日志的记录，每一个跟踪 span 有一个可配置的总 Annotation 量的上限。但是，应用程序级的 Annotation 是不能替代用于表示 span 结构的信息和记录着 RPC 相关的信息。</p>

<p>除了简单的文本 Annotation，Dapper 也支持的 key-value 映射的 Annotation，提供给开发人员更强的跟踪能力，如持续的计数器，二进制消息记录和在一个进程上跑着的任意的用户数据。键值对的 Annotation 方式用来在分布式追踪的上下文中定义某个特定应用程序的相关类型。</p>

<h2 id="toc_7">2.4 采样率</h2>

<p>低损耗的是 Dapper 的一个关键的设计目标，因为如果这个工具价值未被证实但又对性能有影响的话，你可以理解服务运营人员为什么不愿意部署它。况且，我们想让开发人员使用 Annotation 的 API，而不用担心额外的开销。我们还发现，某些类型的 Web 服务对植入带来的性能损耗确实非常敏感。因此，除了把 Dapper 的收集工作对基本组件的性能损耗限制的尽可能小之外，我们还有进一步控制损耗的办法，那就是遇到大量请求时只记录其中的一小部分。我们将在 4.4 节中讨论跟踪的采样率方案的更多细节。</p>

<p><img src="media/15327611910129/15327613531913.jpg" alt=""/></p>

<p>图 5：Dapper 收集管道的总览</p>

<h2 id="toc_8">2.5 跟踪的收集</h2>

<p>Dapper 的跟踪记录和收集管道的过程分为三个阶段（参见图 5）。首先，span 数据写入（1）本地日志文件中。然后 Dapper 的守护进程和收集组件把这些数据从生产环境的主机中拉出来（2），最终写到（3）Dapper 的 Bigtable 仓库中。一次跟踪被设计成 Bigtable 中的一行，每一列相当于一个 span。Bigtable 的支持稀疏表格布局正适合这种情况，因为每一次跟踪可以有任意多个 span。跟踪数据收集（即从应用中的二进制数据传输到中央仓库所花费的时间）的延迟中位数少于 15 秒。第 98 百分位的延迟 (The 98th percentile latency) 往往随着时间的推移呈现双峰型; 大约 75% 的时间，第 98 百分位的延迟时间小于 2 分钟，但是另外大约 25% 的时间，它可以增涨到几个小时。</p>

<p>Dapper 还提供了一个 API 来简化访问我们仓库中的跟踪数据。 Google 的开发人员用这个 API，以构建通用和特定应用程序的分析工具。第 5.1 节包含更多如何使用它的信息。</p>

<h2 id="toc_9">2.5.1 带外数据跟踪收集</h2>

<p>tip1: 带外数据: 传输层协议使用带外数据 (out-of-band，OOB) 来发送一些重要的数据, 如果通信一方有重要的数据需要通知对方时, 协议能够将这些数据快速地发送到对方。为了发送这些数据，协议一般不使用与普通数据相同的通道, 而是使用另外的通道。</p>

<p>tip2: 这里指的 in-band 策略是把跟踪数据随着调用链进行传送，out-of-band 是通过其他的链路进行跟踪数据的收集，Dapper 的写日志然后进行日志采集的方式就属于 out-of-band 策略</p>

<p>Dapper 系统请求树树自身进行跟踪记录和收集带外数据。这样做是为两个不相关的原因。首先，带内收集方案 -- 这里跟踪数据会以 RPC 响应头的形式被返回 -- 会影响应用程序网络动态。在 Google 里的许多规模较大的系统中，一次跟踪成千上万的 span 并不少见。然而，RPC 回应大小 -- 甚至是接近大型分布式的跟踪的根节点的这种情况下 -- 仍然是比较小的：通常小于 10K。在这种情况下，带内 Dapper 的跟踪数据会让应用程序数据和倾向于使用后续分析结果的数据量相形见绌。其次，带内收集方案假定所有的 RPC 是完美嵌套的。我们发现，在所有的后端的系统返回的最终结果之前，有许多中间件会把结果返回给他们的调用者。带内收集系统是无法解释这种非嵌套的分布式执行模式的。</p>

<h2 id="toc_10">2.6 安全和隐私考虑</h2>

<p>记录一定量的 RPC 有效负载信息将丰富 Dapper 的跟踪能力，因为分析工具能够在有效载荷数据（方法传递的参数）中找到相关的样例，这些样例可以解释被监控系统的为何表现异常。然而，有些情况下，有效载荷数据可能包含的一些不应该透露给未经授权用户 (包括正在 debug 的工程师) 的内部信息。</p>

<p>由于安全和隐私问题是不可忽略的，dapper 中的虽然存储 RPC 方法的名称，但在这个时候不记录任何有效载荷数据。相反，应用程序级别的 Annotation 提供了一个方便的可选机制：应用程序开发人员可以在 span 中选择关联那些为以后分析提供价值的数据。</p>

<p>Dapper 还提供了一些安全上的便利，是它的设计者事先没有预料到的。通过跟踪公开的安全协议参数，Dapper 可以通过相应级别的认证或加密，来监视应用程序是否满足安全策略。例如。Dapper 还可以提供信息，以基于策略的的隔离系统按预期执行，例如支撑敏感数据的应用程序不与未经授权的系统组件进行了交互。这样的测算提供了比源码审核更强大的保障。</p>

<h2 id="toc_11">3. Dapper 部署状况</h2>

<p>Dapper 作为我们生产环境下的跟踪系统已经超过两年。在本节中，我们会汇报系统状态，把重点放在 Dapper 如何满足了我们的目标——无处不在的部署和应用级的透明。</p>

<h2 id="toc_12">3.1 Dapper 运行库</h2>

<p>也许 Dapper 代码中中最关键的部分，就是对基础 RPC、线程控制和流程控制的组件库的植入，其中包括 span 的创建，采样率的设置，以及把日志写入本地磁盘。除了做到轻量级，植入的代码更需要稳定和健壮，因为它与海量的应用对接，维护和 bug 修复变得困难。植入的核心代码是由未超过 1000 行的 C++ 和不超过 800 行 Java 代码组成。为了支持键值对的 Annotation 还添加了额外的 500 行代码。</p>

<h2 id="toc_13">3.2 生产环境下的涵盖面</h2>

<p>Dapper 的渗透可以总结为两个方面：一方面是可以创建 Dapper 跟踪的过程 (与 Dapper 植入的组件库相关)，和生产环境下的服务器上在运行 Dapper 跟踪收集守护进程。Dapper 的守护进程的分布相当于我们服务器的简单的拓扑图，它存在于 Google 几乎所有的服务器上。这很难确定精确的 Dapper-ready 进程部分，因为过程即便不产生跟踪信息 Dapper 也是无从知晓的。尽管如此，考虑到无处不在 Dapper 组件的植入库，我们估计几乎每一个 Google 的生产进程都是支持跟踪的。</p>

<p>在某些情况下 Dapper 的是不能正确的跟踪控制路径的。这些通常源于使用非标准的控制流，或是 Dapper 的错误的把路径关联归到不相关的事件上。Dapper 提供了一个简单的库来帮助开发者手动控制跟踪传播作为一种变通方法。目前有 40 个 C++ 应用程序和 33 个 Java 应用程序需要一些手动控制的追踪传播，不过这只是上千个的跟踪中的一小部分。也有非常小的一部分程序使用的非组件性质的通信库（比如原生的 TCP Socket 或 SOAP RPC），因此不能直接支持 Dapper 的跟踪。但是这些应用可以单独接入到 Dapper 中，如果需要的话。</p>

<p>考虑到生产环境的安全，Dapper 的跟踪也可以关闭。事实上，它在部署的早起就是默认关闭的，直到我们对 Dapper 的稳定性和低损耗有了足够的信心之后才把它开启。Dapper 的团队偶尔会执行审查寻找跟踪配置的变化，来看看那些服务关闭了 Dapper 的跟踪。但这种情况不多见，而且通常是源于对监控对性能消耗的担忧。经过了对实际性能消耗的进一步调查和测量，所有这些关闭 Dapper 跟踪都已经恢复开启了，不过这些已经不重要了。</p>

<h2 id="toc_14">3.3 跟踪 Annotation 的使用</h2>

<p>程序员倾向于使用特定应用程序的 Annotation，无论是作为一种分布式调试日志文件，还是通过一些应用程序特定的功能对跟踪进行分类。例如，所有的 Bigtable 的请求会把被访问的表名也记录到 Annotation 中。目前，70％的 Dapper span 和 90％的所有 Dapper 跟踪都至少有一个特殊应用的 Annotation。</p>

<p>41 个 Java 应用和 68 个 C++ 应用中都添加自定义的 Annotation 为了更好地理解应用程序中的 span 在他们的服务中的行为。值得注意的是，迄今为止我们的 Java 开发者比 C++ 开发者更多的在每一个跟踪 span 上采用 Annotation 的 API。这可能是因为我们的 Java 应用的作用域往往是更接近最终用户 (C++ 偏底层); 这些类型的应用程序经常处理更广泛的请求组合，因此具有比较复杂的控制路径。</p>

<h2 id="toc_15">4. 处理跟踪损耗</h2>

<p>跟踪系统的成本由两部分组成：1. 正在被监控的系统在生成追踪和收集追踪数据的消耗导致系统性能下降，2。需要使用一部分资源来存储和分析跟踪数据。虽然你可以说一个有价值的组件植入跟踪带来一部分性能损耗是值得的，我们相信如果基本损耗能达到可以忽略的程度，那么对跟踪系统最初的推广会有极大的帮助。</p>

<p>在本节中，我们会展现一下三个方面：Dapper 组件操作的消耗，跟踪收集的消耗，以及 Dapper 对生产环境负载的影响。我们还介绍了 Dapper 可调节的采样率机制如何帮我们处理低损耗和跟踪代表性之间的平衡和取舍。</p>

<h2 id="toc_16">4.1 生成跟踪的损耗</h2>

<p>生成跟踪的开销是 Dapper 性能影响中最关键的部分，因为收集和分析可以更容易在紧急情况下被关闭。Dapper 运行库中最重要的跟踪生成消耗在于创建和销毁 span 和 annotation，并记录到本地磁盘供后续的收集。根 span 的创建和销毁需要损耗平均 204 纳秒的时间，而同样的操作在其他 span 上需要消耗 176 纳秒。时间上的差别主要在于需要在跟 span 上给这次跟踪分配一个全局唯一的 ID。</p>

<p>如果一个 span 没有被采样的话，那么这个额外的 span 下创建 annotation 的成本几乎可以忽略不计，他由在 Dapper 运行期对 ThreadLocal 查找操作构成，这平均只消耗 9 纳秒。如果这个 span 被计入采样的话，会用一个用字符串进行标注 -- 在图 4 中有展现 -- 平均需要消耗 40 纳秒。这些数据都是在 2.2GHz 的 x86 服务器上采集的。</p>

<p>在 Dapper 运行期写入到本地磁盘是最昂贵的操作，但是他们的可见损耗大大减少，因为写入日志文件和操作相对于被跟踪的应用系统来说都是异步的。不过，日志写入的操作如果在大流量的情况，尤其是每一个请求都被跟踪的情况下就会变得可以察觉到。我们记录了在 4.3 节展示了一次 Web 搜索的负载下的性能消耗。</p>

<h2 id="toc_17">4.2 跟踪收集的消耗</h2>

<p>读出跟踪数据也会对正在被监控的负载产生干扰。表 1 展示的是最坏情况下，Dapper 收集日志的守护进程在高于实际情况的负载基准下进行测试时的 cpu 使用率。在生产环境下，跟踪数据处理中，这个守护进程从来没有超过 0.3% 的单核 cpu 使用率，而且只有很少量的内存使用（以及堆碎片的噪音）。我们还限制了 Dapper 守护进程为内核 scheduler 最低的优先级，以防在一台高负载的服务器上发生 cpu 竞争。</p>

<p>Dapper 也是一个带宽资源的轻量级的消费者，每一个 span 在我们的仓库中传输只占用了平均 426 的 byte。作为网络行为中的极小部分，Dapper 的数据收集在 Google 的生产环境中的只占用了 0.01% 的网络资源。</p>

<p><img src="media/15327611910129/15327613696297.jpg" alt=""/></p>

<p>表 1：Dapper 守护进程在负载测试时的 CPU 资源使用率</p>

<h2 id="toc_18">4.3 在生产环境下对负载的影响</h2>

<p>每个请求都会利用到大量的服务器的高吞吐量的线上服务，这是对有效跟踪最主要的需求之一；这种情况需要生成大量的跟踪数据，并且他们对性能的影响是最敏感的。在表 2 中我们用集群下的网络搜索服务作为例子，我们通过调整采样率，来衡量 Dapper 在延迟和吞吐量方面对性能的影响。</p>

<p><img src="media/15327611910129/15327613853410.jpg" alt=""/></p>

<p>表 2：网络搜索集群中，对不同采样率对网络延迟和吞吐的影响。延迟和吞吐的实验误差分别是 2.5% 和 0.15%。</p>

<p>我们看到，虽然对吞吐量的影响不是很明显，但为了避免明显的延迟，跟踪的采样还是必要的。然而，延迟和吞吐量的带来的损失在把采样率调整到小于 1/16 之后就全部在实验误差范围内。在实践中，我们发现即便采样率调整到 1/1024 仍然是有足够量的跟踪数据的用来跟踪大量的服务。保持 Dapper 的性能损耗基线在一个非常低的水平是很重要的，因为它为那些应用提供了一个宽松的环境使用完整的 Annotation API 而无惧性能损失。使用较低的采样率还有额外的好处，可以让持久化到硬盘中的跟踪数据在垃圾回收机制处理之前保留更长的时间，这样为 Dapper 的收集组件给了更多的灵活性。</p>

<h2 id="toc_19">4.4 可变采样</h2>

<p>任何给定进程的 Dapper 的消耗和每个进程单位时间的跟踪的采样率成正比。Dapper 的第一个生产版本在 Google 内部的所有进程上使用统一的采样率，为 1/1024。这个简单的方案是对我们的高吞吐量的线上服务来说是非常有用，因为那些感兴趣的事件 (在大吞吐量的情况下) 仍然很有可能经常出现，并且通常足以被捕捉到。</p>

<p>然而，在较低的采样率和较低的传输负载下可能会导致错过重要事件，而想用较高的采样率就需要能接受的性能损耗。对于这样的系统的解决方案就是覆盖默认的采样率，这需要手动干预的，这种情况是我们试图避免在 dapper 中出现的。</p>

<p>我们在部署可变采样的过程中，参数化配置采样率时，不是使用一个统一的采样方案，而是使用一个采样期望率来标识单位时间内采样的追踪。这样一来，低流量低负载自动提高采样率，而在高流量高负载的情况下会降低采样率，使损耗一直保持在控制之下。实际使用的采样率会随着跟踪本身记录下来，这有利于从 Dapper 的跟踪数据中准确的分析。</p>

<h2 id="toc_20">4.5 应对积极采样 (Coping with aggressive sampling)</h2>

<p>新的 Dapper 用户往往觉得低采样率 -- 在高吞吐量的服务下经常低至 0.01％-- 将会不利于他们的分析。我们在 Google 的经验使我们相信，对于高吞吐量服务，积极采样 (aggressive sampling) 并不妨碍最重要的分析。如果一个显着的操作在系统中出现一次，他就会出现上千次。低吞吐量的服务 -- 也许是每秒请求几十次，而不是几十万 -- 可以负担得起跟踪每一个请求，这是促使我们下决心使用自适应采样率的原因。</p>

<h2 id="toc_21">4.6 在收集过程中额外的采样</h2>

<p>上述采样机制被设计为尽量减少与 Dapper 运行库协作的应用程序中明显的性能损耗。Dapper 的团队还需要控制写入中央资料库的数据的总规模，因此为达到这个目的，我们结合了二级采样。</p>

<p>目前我们的生产集群每天产生超过 1TB 的采样跟踪数据。Dapper 的用户希望生产环境下的进程的跟踪数据从被记录之后能保存至少两周的时间。逐渐增长的追踪数据的密度必须和 Dapper 中央仓库所消耗的服务器及硬盘存储进行权衡。对请求的高采样率还使得 Dapper 收集器接近写入吞吐量的上限。</p>

<p>为了维持物质资源的需求和渐增的 Bigtable 的吞吐之间的灵活性，我们在收集系统自身上增加了额外的采样率的支持。我们充分利用所有 span 都来自一个特定的跟踪并分享同一个跟踪 ID 这个事实，虽然这些 span 有可能横跨了数千个主机。对于在收集系统中的每一个 span，我们用 hash 算法把跟踪 ID 转成一个标量 Z，这里 0&lt;=Z&lt;=1。如果 Z 比我们收集系统中的系数低的话，我们就保留这个 span 信息，并写入到 Bigtable 中。反之，我们就抛弃他。通过在采样决策中的跟踪 ID，我们要么保存、要么抛弃整个跟踪，而不是单独处理跟踪内的 span。我们发现，有了这个额外的配置参数使管理我们的收集管道变得简单多了，因为我们可以很容易地在配置文件中调整我们的全局写入率这个参数。</p>

<p>如果整个跟踪过程和收集系统只使用一个采样率参数确实会简单一些，但是这就不能应对快速调整在所有部署的节点上的运行期采样率配置的这个要求。我们选择了运行期采样率，这样就可以优雅的去掉我们无法写入到仓库中的多余数据，我们还可以通过调节收集系统中的二级采样率系数来调整这个运行期采样率。Dapper 的管道维护变得更容易，因为我们就可以通过修改我们的二级采样率的配置，直接增加或减少我们的全局覆盖率和写入速度。</p>

<h2 id="toc_22">5. 通用的 Dapper 工具</h2>

<p>几年前，当 Dapper 还只是个原型的时候，它只能在 Dapper 开发者耐心的支持下使用。从那时起，我们逐渐迭代的建立了收集组件，编程接口，和基于 Web 的交互式用户界面，帮助 Dapper 的用户独立解决自己的问题。在本节中，我们会总结一下哪些的方法有用，哪些用处不大，我们还提供关于这些通用的分析工具的基本的使用信息。</p>

<h2 id="toc_23">5.1 Dapper Depot API</h2>

<p>Dapper 的 “Depot API” 或称作 DAPI，提供在 Dapper 的区域仓库中对分布式跟踪数据一个直接访问。DAPI 和 Dapper 跟踪仓库被设计成串联的，而且 DAPI 意味着对 Dapper 仓库中的元数据暴露一个干净和直观的的接口。我们使用了以下推荐的三种方式去暴露这样的接口：</p>

<ul>
<li>  通过跟踪 ID 来访问：DAPI 可以通过他的全局唯一的跟踪 ID 读取任何一次跟踪信息。</li>
<li>  批量访问：DAPI 可以利用的 MapReduce 提供对上亿条 Dapper 跟踪数据的并行读取。用户重写一个虚拟函数，它接受一个 Dapper 的跟踪信息作为其唯一的参数，该框架将在用户指定的时间窗口中调用每一次收集到的跟踪信息。</li>
<li>  索引访问：Dapper 的仓库支持一个符合我们通用调用模板的唯一索引。该索引根据通用请求跟踪特性 (commonly-requested trace features) 进行绘制来识别 Dapper 的跟踪信息。因为跟踪 ID 是根据伪随机的规则创建的，这是最好的办法去访问跟某个服务或主机相关的跟踪数据。</li>
</ul>

<p>所有这三种访问模式把用户指向不同的 Dapper 跟踪记录。正如第 2.1 节所述的，Dapper 的由 span 组成的跟踪数据是用树形结构建模的，因此，跟踪数据的数据结构，也是一个简单的由 span 组成遍历树。Span 就相当于 RPC 调用，在这种情况下，RPC 的时间信息是可用的。带时间戳的特殊的应用标注也是可以通过这个 span 结构来访问的。</p>

<p>选择一个合适的自定义索引是 DAPI 设计中最具挑战性的部分。压缩存储要求在跟踪数据种建立一个索引的情况只比实际数据小 26%，所以消耗是巨大的。最初，我们部署了两个索引：第一个是主机索引，另一个是服务名的索引。然而，我们并没有找到主机索引和存储成本之间的利害关系。当用户对每一台主机感兴趣的时候，他们也会对特定的服务感兴趣，所以我们最终选择把两者相结合，成为一个组合索引，它允许以服务名称，主机，和时间戳的顺序进行有效的查找。</p>

<h2 id="toc_24">5.1.1 DAPI 在 Google 内部的使用</h2>

<p>DAPI 在谷歌的使用有三类：使利用 DAPI 的持续的线上 Web 应用，维护良好的可以在控制台上调用的基于 DAPI 的工具，可以被写入，运行、不过大部分已经被忘记了的一次性分析工具。我们知道的有 3 个持久性的基于 DAPI 的应用程序，8 个额外的按需定制的基于 DAPI 分析工具，以及使用 DAPI 框架构建的约 15~20 一次性的分析工具。在这之后的工具就这是很难说明了，因为开发者可以构建、运行和丢弃这些项目，而不需要 Dapper 团队的技术支持。</p>

<h2 id="toc_25">5.2 Dapper 的用户接口</h2>

<p>绝大多数用户使用发生在基于 web 的用户交互接口。篇幅有限，我们不能列出每一个特点，而只能把典型的用户工作流在图 6 中展示。</p>

<p><img src="media/15327611910129/15327614146760.jpg" alt=""/></p>

<p>图 6</p>

<ol>
<li> 用户描述的他们关心的服务和时间，和其他任何他们可以用来区分跟踪模板的信息（比如，span 的名称）。他们还可以指定与他们的搜索最相关的成本度量 (cost metric)(比如，服务响应时间)。</li>
<li> 一个关于性能概要的大表格，对应确定的服务关联的所有分布式处理图表。用户可以把这些执行图标排序成他们想要的，并选择一种直方图去展现出更多的细节。</li>
<li> 一旦某个单一的分布式执行部分被选中后，用户能看到关于执行部分的的图形化描述。被选中的服务被高亮展示在该图的中心。</li>
<li> 在生成与步骤 1 中选中的成本度量 (cost metric) 维度相关的统计信息之后，Dapper 的用户界面会提供了一个简单的直方图。在这个例子中，我们可以看到一个大致的所选中部分的分布式响应时间分布图。用户还会看到一个关于具体的跟踪信息的列表，展现跟踪信息在直方图中被划分为的不同区域。在这个例子中，用户点击列表种第二个跟踪信息实例时，会在下方看到这个跟踪信息的详细视图(步骤 5)。</li>
<li> 绝大多数 Dapper 的使用者最终的会检查某个跟踪的情况，希望能收集一些信息去了解系统行为的根源所在。我们没有足够的空间来做跟踪视图的审查，但我们使用由一个全局时间轴（在上方可以看到），并能够展开和折叠树形结构的交互方式，这也很有特点。分布式跟踪树的连续层用内嵌的不同颜色的矩形表示。每一个 RPC 的 span 被从时间上分解为一个服务器进程中的消耗（绿色部分）和在网络上的消耗（蓝色部分）。用户 Annotation 没有显示在这个截图中，但他们可以选择性的以 span 的形式包含在全局时间轴上。</li>
</ol>

<p>为了让用户查询实时数据，Dapper 的用户界面能够直接与 Dapper 每一台生产环境下的服务器上的守护进程进行交互。在该模式下，不可能指望能看到上面所说的系统级的图表展示，但仍然可以很容易基于性能和网络特性选取一个特定的跟踪。在这种模式下，可在几秒钟内查到实时的数据。</p>

<p>根据我们的记录，大约有 200 个不同的 Google 工程师在一天内使用的 Dapper 的 UI; 在一周的过程中，大约有 750-1000 不同的用户。这些用户数，在新功能的内部通告上，是按月连续的。通常用户会发送特定跟踪的连接，这将不可避免地在查询跟踪情况时中产生很多一次性的，持续时间较短的交互。</p>

<h2 id="toc_26">6. 经验</h2>

<p>Dapper 在 Google 被广泛应用，一部分直接通过 Dapper 的用户界面，另一部分间接地通过对 Dapper API 的二次开发或者建立在基于 api 的应用上。在本节中，我们并不打算罗列出每一种已知的 Dapper 使用方式，而是试图覆盖 Dapper 使用方式的 “基本向量”，并努力来说明什么样的应用是最成功的。</p>

<h2 id="toc_27">6.1 在开发中使用 Dapper</h2>

<p>Google AdWords 系统是围绕一个大型的关键词定位准则和相关文字广告的数据库搭建的。当新的关键字或广告被插入或修改时，它们必须通过服务策略术语的检查（如检查不恰当的语言，这个过程如果使用自动复查系统来做的话会更加有效）。</p>

<p>当轮到从头重新设计一个广告审查服务时，这个团队迭代的从第一个系统原型开始使用 Dapper，并且，最终用 Dapper 一直维护着他们的系统。Dapper 帮助他们从以下几个方面改进了他们的服务：</p>

<ul>
<li>  性能：开发人员针对请求延迟的目标进行跟踪，并对容易优化的地方进行定位。Dapper 也被用来确定在关键路径上不必要的串行请求 -- 通常来源于不是开发者自己开发的子系统 -- 并促使团队持续修复他们。</li>
<li>  正确性：广告审查服务围绕大型数据库系统搭建。系统同时具有只读副本策略（数据访问廉价）和读写的主策略（访问代价高）。Dapper 被用来在很多种情况中确定，哪些查询是无需通过主策略访问而可以采用副本策略访问。Dapper 现在可以负责监控哪些主策略被直接访问，并对重要的系统常量进行保障。</li>
<li>  理解性：广告审查查询跨越了各种类型的系统，包括 BigTable—之前提到的那个数据库，多维索引服务，以及其他各种 C++ 和 Java 后端服务。Dapper 的跟踪用来评估总查询成本，促进重新对业务的设计，用以在他们的系统依赖上减少负载。</li>
<li>  测试：新的代码版本会经过一个使用 Dapper 进行跟踪的 QA 过程，用来验证正确的系统行为和性能。在跑测试的过程中能发现很多问题，这些问题来自广告审查系统自身的代码或是他的依赖包。</li>
</ul>

<p>广告审查团队广泛使用了 Dapper Annotation API。Guice[13] 开源的 AOP 框架用来在重要的软件组件上标注 “@Traced”。这些跟踪信息可以进一步被标注，包含：重要子路径的输入输出大小、基础信息、其他调试信息，所有这些信息将会额外发送到日志文件中。</p>

<p>同时，我们也发现了一些广告审查小组在使用方面的不足。比如：他们想根据他们所有跟踪的 Annotation 信息，在一个交互时间段内进行搜索，然而这就必须跑一个自定义的 MapReduce 或进行每一个跟踪的手动检查。另外，在 Google 还有一些其他的系统在也从通用调试日志中收集和集中信息，把那些系统的海量数据和 Dapper 仓库整合也是有价值的。</p>

<p>总的来说，即便如此，广告审查团队仍然对 Dapper 的作用进行了以下评估，通过使用 Dapper 的跟踪平台的数据分析，他们的服务延迟性已经优化了两个数量级。</p>

<h2 id="toc_28">6.1.1 与异常监控的集成</h2>

<p>Google 维护了一个从运行进程中不断收集并集中异常信息报告的服务。如果这些异常发生在 Dapper 跟踪采样的上下文中，那么相应的跟踪 ID 和 span 的 ID 也会作为元数据记录在异常报告中。异常监测服务的前端会提供一个链接，从特定的异常信息的报告直接导向到他们各自的分布式跟踪。广告审查团队使用这个功能可以了解 bug 发生的更大范围的上下文。通过暴露基于简单的唯一 ID 构建的接口，Dapper 平台被集成到其他事件监测系统会相对容易。</p>

<h2 id="toc_29">6.2 解决延迟的长尾效应</h2>

<p>考虑到移动部件的数量、代码库的规模、部署的范围，调试一个像全文搜索那样服务（第 1 节里提到过）是非常具有挑战性的。在这节，我们描述了我们在减轻全文搜索的延迟分布的长尾效应上做的各种努力。Dapper 能够验证端到端的延迟的假设，更具体地说，Dapper 能够验证对于搜索请求的关键路径。当一个系统不仅涉及数个子系统，而是几十个开发团队的涉及到的系统的情况下，端到端性能较差的根本原因到底在哪，这个问题即使是我们最好的和最有经验的工程师也无法正确回答。在这种情况下，Dapper 可以提供急需的数据，而且可以对许多重要的性能问题得出结论。</p>

<p><img src="media/15327611910129/15327614290031.jpg" alt=""/></p>

<p>图 7：全局搜索的跟踪片段，在不常遇到高网络延迟的情况下，在沿着关键路径的端到端的请求延迟，如图所示。</p>

<p>在调试延迟长尾效应的过程中，工程师可以建立一个小型库，这个小型库可以根据 DAPI 跟踪对象来推断关键路径的层级结构。这些关键路径的结构可以被用来诊断问题，并且为全文搜索提供可优先处理的预期的性能改进。Dapper 的这项工作导致了下列发现：</p>

<ul>
<li>  在关键路径上的短暂的网络性能退化不影响系统的吞吐量，但它可能会对延迟异常值产生极大的影响。在图 7 中可以看出，大部分的全局搜索的缓慢的跟踪都来源于关键路径的网络性能退化。</li>
<li>  许多问题和代价很高的查询模式来源于一些意想不到的服务之间的交互。一旦发现，往往容易纠正它们，但是 Dapper 出现之前想找出这些问题是相当困难的。</li>
<li>  通用的查询从 Dapper 之外的安全日志仓库中收取，并使用 Dapper 唯一的跟踪 ID，与 Dapper 的仓库做关联。然后，该映射用来建立关于在全局搜索中的每一个独立子系统都很慢的实例查询的列表。</li>
</ul>

<h2 id="toc_30">6.3 推断服务依赖</h2>

<p>在任何给定的时间内，Google 内部的一个典型的计算集群是一个汇集了成千上万个逻辑 “任务” 的主机，一套的处理器在执行一个通用的方法。Google 维护着许多这样的集群，当然，事实上，我们发现在一个集群上计算着的这些任务通常依赖于其他的集群上的任务。由于任务们之间的依赖是动态改变的，所以不可能仅从配置信息上推断出所有这些服务之间的依赖关系。不过，除了其他方面的原因之外，在公司内部的各个流程需要准确的服务依赖关系信息，以确定瓶颈所在，以及计划服务的迁移。Google 的可称为 “Service Dependencies” 的项目是通过使用跟踪 Annotation 和 DAPI MapReduce 接口来实现自动化确定服务依赖归属的。</p>

<p>Dapper 核心组件与 Dapper 跟踪 Annotation 一并使用的情况下，“Service Dependencies” 项目能够推算出任务各自之间的依赖，以及任务和其他软件组件之间的依赖。比如，所有的 BigTable 的操作会加上与受影响的表名称相关的标记。运用 Dapper 的平台，Service Dependencies 团队就可以自动的推算出依赖于命名的不同资源的服务粒度。</p>

<h2 id="toc_31">6.4 不同服务的网络使用率</h2>

<p>Google 投入了大量的人力和物力资源在他的网络结构上。从前网络管理员可能只关注独立的硬件信息、常用工具及以及搭建出的各种全局网络鸟瞰图的 dashboard 上的信息。网络管理员确实可以一览整个网络的健康状况，但是，当遇到问题时，他们很少有能够准确查找网络负载的工具，用来定位应用程序级别的罪魁祸首。</p>

<p>虽然 Dapper 不是设计用来做链路级的监控的，但是我们发现，它是非常适合去做集群之间网络活动性的应用级任务的分析。Google 能够利用 Dapper 这个平台，建立一个不断更新的控制台，来显示集群之间最活跃的网络流量的应用级的热点。此外，使用 Dapper 我们能够为昂贵的网络请求提供指出的构成原因的跟踪，而不是面对不同服务器之间的信息孤岛而无所适从。建立一个基于 Dapper API 的 dashboard 总共没花超过 2 周的时间。</p>

<h2 id="toc_32">6.5 分层和共享存储系统</h2>

<p>在 Google 的许多存储系统是由多重独立复杂层级的分布式基础设备组成的。例如，Google 的 App Engine[5] 就是搭建在一个可扩展的实体存储系统上的。该实体存储系统在基于 BigTable 上公开某些 RDBMS 功能。 BigTable 的同时使用 Chubby[7]（分布式锁系统）及 GFS。再者，像 BigTable 这样的系统简化了部署，并更好的利用了计算资源。</p>

<p>在这种分层的系统，并不总是很容易确定最终用户资源的消费模式。例如，来自于一个给定的 BigTable 单元格的 GFS 大信息量主要来自于一个用户或是由多个用户产生，但是在 GFS 层面，这两种明显的使用场景是很难界定。而且，如果缺乏一个像 Dapper 一样的工具的情况下，对共享服务的竞争可能会同样难于调试。</p>

<p>第 5.2 节中所示的 Dapper 的用户界面可以聚合那些调用任意公共服务的多个客户端的跟踪的性能信息。这就很容易让提供这些服务的源从多个维度给他们的用户排名。（例如，入站的网络负载，出站的网络负载，或服务请求的总时间）</p>

<h2 id="toc_33">6.6 Dapper 的救火能力 (Firefighting)</h2>

<p>对于一些 “救火” 任务，Dapper 可以处理其中的一部分。“救火”任务在这里是指一些有风险很高的在分布式系统上的操作。通常情况下，Dapper 用户当正在进行 “救火” 任务时需要使用新的数据，并且没有时间写新的 DAPI 代码或等待周期性的报告运行。</p>

<p>对于那些高延迟，不，可能更糟糕的那些在正常负载下都会响应超时的服务，Dapper 用户界面通常会把这些延迟瓶颈的位置隔离出来。通过与 Dapper 守护进程的直接通信，那些特定的高延迟的跟踪数据轻易的收集到。当出现灾难性故障时，通常是没有必要去看统计数据以确定根本原因，只查看示例跟踪就足够了 (因为前文提到过从 Dapper 守护进程中几乎可以立即获得跟踪数据)。</p>

<p>但是，如在 6.5 节中描述的共享的存储服务，要求当用户活动过程中突然中断时能尽可能快的汇总信息。对于事件发生之后，共享服务仍然可以利用汇总的的 Dapper 数据，但是，除非收集到的 Dapper 数据的批量分析能在问题出现 10 分钟之内完成，否则 Dapper 面对与共享存储服务相关的 “救火” 任务就很难按预想的那般顺利完成。</p>

<h2 id="toc_34">7. 其他收获</h2>

<p>虽然迄今为止，我们在 Dapper 上的经验已经大致符合我们的预期，但是也出现了一些积极的方面是我们没有充分预料到的。首先，我们获得了超出预期的 Dapper 使用用例的数量，对此我们可谓欢心鼓舞。另外，在除了几个的在第 6 节使用经验中提到过的一些用例之外，还包括资源核算系统，对指定的通讯模式敏感的服务的检查工具，以及一种对 RPC 压缩策略的分析器，等等。我们认为这些意想不到的用例一定程度上是由于我们向开发者以一种简单的编程接口的方式开放了跟踪数据存储的缘故，这使得我们能够充分利用这个大的多的社区的创造力。除此之外，Dapper 对旧的负载的支持也比预期的要简单，只需要在程序中引入一个用新版本的重新编译过的公共组件库 (包含常规的线程使用，控制流和 RPC 框架) 即可。</p>

<p>Dapper 在 Google 内部的广泛使用还为我们在 Dapper 的局限性上提供了宝贵的反馈意见。下面我们将介绍一些我们已知的最重要的 Dapper 的不足：</p>

<ul>
<li>  合并的影响：我们的模型隐含的前提是不同的子系统在处理的都是来自同一个被跟踪的请求。在某些情况下，缓冲一部分请求，然后一次性操作一个请求集会更加有效。（比如，磁盘上的一次合并写入操作）。在这种情况下，一个被跟踪的请求可以看似是一个大型工作单元。此外，当有多个追踪请求被收集在一起，他们当中只有一个会用来生成那个唯一的跟踪 ID，用来给其他 span 使用，所以就无法跟踪下去了。我们正在考虑的解决方案，希望在可以识别这种情况的前提下，用尽可能少的记录来解决这个问题。</li>
<li>  跟踪批处理负载：Dapper 的设计，主要是针对在线服务系统，最初的目标是了解一个用户请求产生的系统行为。然而，离线的密集型负载，例如符合 MapReduce[10] 模型的情况，也可以受益于性能挖潜。在这种情况下，我们需要把跟踪 ID 与一些其他的有意义的工作单元做关联，诸如输入数据中的键值（或键值的范围），或是一个 MapReduce shard。</li>
<li>  寻找根源：Dapper 可以有效地确定系统中的哪一部分致使系统整个速度变慢，但并不总是能够找出问题的根源。例如，一个请求很慢有可能不是因为它自己的行为，而是由于队列中其他排在它前面的 (queued ahead of) 请求还没处理完。程序可以使用应用级的 annotation 把队列的大小或过载情况写入跟踪系统。此外，如果这种情况屡见不鲜，那么在 ProfileMe[11]中提到的成对的采样技术可以解决这个问题。它由两个时间重叠的采样率组成，并观察它们在整个系统中的相对延迟。</li>
<li>  记录内核级的信息：一些内核可见的事件的详细信息有时对确定问题根源是很有用的。我们有一些工具，能够跟踪或以其他方式描述内核的执行，但是，想用通用的或是不那么突兀的方式，是很难把这些信息到捆绑到用户级别的跟踪上下文中。我们正在研究一种妥协的解决方案，我们在用户层面上把一些内核级的活动参数做快照，然后绑定他们到一个活动的 span 上。</li>
</ul>

<h2 id="toc_35">8. 相关产品</h2>

<p>在分布式系统跟踪领域，有一套完整的体系，一部分系统主要关注定位到故障位置，其他的目标是针对性能进行优化。 Dapper 确实被用于发现系统问题，但它更通常用于探查性能不足，以及提高全面大规模的工作负载下的系统行为的理解。</p>

<p>与 Dapper 相关的黑盒监控系统，比如 Project5[1]，WAP5[15] 和 Sherlock[2]，可以说不依赖运行库的情况下，黑盒监控系统能够实现更高的应用级透明。黑盒的缺点是一定程度上不够精确，并可能在统计推断关键路径时带来更大的系统损耗。</p>

<p>对于分布式系统监控来说，基于 Annotation 的中间件或应用自身是一个可能是更受欢迎的解决办法. 拿 Pip[14] 和 Webmon[16] 系统举例，他们更依赖于应用级的 Annotation，而 X-Trace[12]，Pinpoint[9] 和 Magpie[3] 大多集中在对库和中间件的修改。Dapper 更接近后者。像 Pinpoint，X-Trace，和早期版本的 Magpie 一样，Dapper 采用了全局标识符把分布式系统中各部分相关的事件联系在一起。和这些系统类似，Dapper 尝试避免使用应用级 Annotation，而是把的植入隐藏在通用组件模块内。Magpie 放弃使用全局 ID，仍然试图正确的完成请求的正确传播，他通过采用应用系统各自写入的事件策略，最终也能精确描述不同事件之间关系。但是目前还不清楚 Magpie 在实际环境中实现透明性这些策略到底多么有效。 X-Trace 的核心 Annotation 比 Dapper 更有野心一些，因为 X-Trace 系统对于跟踪的收集，不仅在跟踪节点层面上，而且在节点内部不同的软件层也会进行跟踪。而我们对于组件的低性能损耗的要求迫使我们不能采用 X-Trace 这样的模型，而是朝着把一个请求连接起来完整跟踪所能做到的最小代价而努力。而 Dapper 的跟踪仍然可以从可选的应用级 Annotation 中获益。</p>

<h2 id="toc_36">9. 总结</h2>

<p>在本文中，我们介绍 Dapper 这个 Google 的生产环境下的分布式系统跟踪平台，并汇报了我们开发和使用它的相关经验。 Dapper 几乎在部署在所有的 Google 系统上，并可以在不需要应用级修改的情况下进行跟踪，而且没有明显的性能影响。Dapper 对于开发人员和运维团队带来的好处，可以从我们主要的跟踪用户界面的广泛使用上看出来，另外我们还列举了一些 Dapper 的使用用例来说明 Dapper 的作用，这些用例有些甚至都没有 Dapper 开发团队参与，而是被应用的开发者开发出来的。</p>

<p>据我们所知，这是第一篇汇报生产环境下分布式系统跟踪框架的论文。事实上，我们的主要贡献源于这个事实：论文中回顾的这个系统已经运行两年之久。我们发现，结合对开发人员提供简单 API 和对应用系统完全透明来增强跟踪的这个决定，是非常值得的。</p>

<p>我们相信，Dapper 比以前的基于 Annotation 的分布式跟踪达到更高的应用透明度，这一点已经通过只需要少量人工干预的工作量得以证明。虽然一定程度上得益于我们的系统的同质性，但它本身仍然是一个重大的挑战。最重要的是，我们的设计提出了一些实现应用级透明性的充分条件，对此我们希望能够对更错杂环境下的解决方案的开发有所帮助。</p>

<p>最后，通过开放 Dapper 跟踪仓库给内部开发者，我们促使更多的基于跟踪仓库的分析工具的产生，而仅仅由 Dapper 团队默默的在信息孤岛中埋头苦干的结果远达不到现在这么大的规模，这个决定促使了设计和实施的展开。</p>

<h3 id="toc_37">Acknowledgments</h3>

<p>We thank Mahesh Palekar, Cliff Biffle, Thomas Kotzmann, Kevin Gibbs, Yonatan Zunger, Michael Kleber, and Toby Smith for their experimental data and feedback about Dapper experiences. We also thank Silvius Rus for his assistance with load testing. Most importantly, though, we thank the outstanding team of engineers who have continued to develop and improve Dapper over the years; in order of appearance, Sharon Perl, Dick Sites, Rob von Behren, Tony DeWitt, Don Pazel, Ofer Zajicek, Anthony Zana, Hyang-Ah Kim, Joshua MacDonald, Dan Sturman, Glenn Willen, Alex Kehlenbeck, Brian McBarron, Michael Kleber, Chris Povirk, Bradley White, Toby Smith, Todd Derr, Michael De Rosa, and Athicha Muthitacharoen. They have all done a tremendous amount of work to make Dapper a day-to-day reality at Google.</p>

<h3 id="toc_38">References</h3>

<p>[1] M. K. Aguilera, J. C. Mogul, J. L. Wiener, P. Reynolds, and A. Muthitacharoen. Performance Debugging for Distributed Systems of Black Boxes. In Proceedings of the 19th ACM Symposium on Operating Systems Principles, December 2003.</p>

<p>[2] P. Bahl, R. Chandra, A. Greenberg, S. Kandula, D. A. Maltz, and M. Zhang. Towards Highly Reliable Enterprise Network Services Via Inference of Multi-level Dependencies. In Proceedings of SIGCOMM, 2007.</p>

<p>[3] P. Barham, R. Isaacs, R. Mortier, and D. Narayanan. Magpie: online modelling and performance-aware systems. In Proceedings of USENIX HotOS IX, 2003.</p>

<p>[4] L. A. Barroso, J. Dean, and U. Holzle. Web Search for a Planet: The Google Cluster Architecture. IEEE Micro, 23(2):22–28, March/April 2003.</p>

<p>[5] T. O. G. Blog. Developers, start your engines. <a href="http://googleblog.blogspot.com/2008/04/developers-start-your-engines.html,2007">http://googleblog.blogspot.com/2008/04/developers-start-your-engines.html,2007</a>.</p>

<p>[6] T. O. G. Blog. Universal search: The best answer is still the best answer. <a href="http://googleblog.blogspot.com/2007/05/universal-search-best-answer-is-still.html">http://googleblog.blogspot.com/2007/05/universal-search-best-answer-is-still.html</a>, 2007.</p>

<p>[7] M. Burrows. The Chubby lock service for loosely-coupled distributed systems. In Proceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation, pages 335 – 350, 2006.</p>

<p>[8] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A. Wallach, M. Burrows, T. Chandra, A. Fikes, and R. E. Gruber. Bigtable: A Distributed Storage System for Structured Data. In Proceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation (OSDI’06), November 2006.</p>

<p>[9] M. Y. Chen, E. Kiciman, E. Fratkin, A. fox, and E. Brewer. Pinpoint: Problem Determination in Large, Dynamic Internet Services. In Proceedings of ACM International Conference on Dependable Systems and Networks, 2002.</p>

<p>[10] J. Dean and S. Ghemawat. MapReduce: Simplified Data Processing on Large Clusters. In Proceedings of the 6th USENIX Symposium on Operating Systems Design and Implementation (OSDI’04), pages 137 – 150, December 2004.</p>

<p>[11] J. Dean, J. E. Hicks, C. A. Waldspurger, W. E. Weihl, and G. Chrysos. ProfileMe: Hardware Support for Instruction-Level Profiling on Out-of-Order Processors. In Proceedings of the IEEE/ACM International Symposium on Microarchitecture, 1997.</p>

<p>[12] R. Fonseca, G. Porter, R. H. Katz, S. Shenker, and I. Stoica. X-Trace: A Pervasive Network Tracing Framework. In Proceedings of USENIX NSDI, 2007.</p>

<p>[13] B. Lee and K. Bourrillion. The Guice Project Home Page. <a href="http://code.google.com/p/google-guice/">http://code.google.com/p/google-guice/</a>, 2007.</p>

<p>[14] P. Reynolds, C. Killian, J. L. Wiener, J. C. Mogul, M. A. Shah, and A. Vahdat. Pip: Detecting the Unexpected in Distributed Systems. In Proceedings of USENIX NSDI, 2006.</p>

<p>[15] P. Reynolds, J. L. Wiener, J. C. Mogul, M. K. Aguilera, and A. Vahdat. WAP5: Black Box Performance Debugging for Wide-Area Systems. In Proceedings of the 15th International World Wide Web Conference, 2006.</p>

<p>[16] P. K. G. T. Gschwind, K. Eshghi and K. Wurster. WebMon: A Performance Profiler for Web Transactions. In E-Commerce Workshop, 2002.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[以Dapper、Zipkin和LightStep [x]PM为例阐述分布式跟踪的过去、现在和未来]]></title>
    <link href="http://panlw.github.io/15327601601753.html"/>
    <updated>2018-07-28T14:42:40+08:00</updated>
    <id>http://panlw.github.io/15327601601753.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>原文地址 <a href="http://www.infoq.com/cn/articles/distributed-tracing-microservices">http://www.infoq.com/cn/articles/distributed-tracing-microservices</a></p>

<h2 id="toc_0">核心要点</h2>

<ul>
<li>  在观测分布式系统和微服务时，分布式跟踪已经成为一个越来越重要的组件。现在有一些流行的开源标准和框架，比如 OpenTracing API 和 OpenZipkin；</li>
<li>  分布式跟踪的基本理念是非常简单直接的：在系统中，特定请求的转折点必须要识别出来并且要检测。所有的跟踪数据需要协调和整理，为请求提供一个有意义的流视图；</li>
<li>  请求跟踪在理念上类似于应用性能管理（Application Performance Management，APM），这两个生态系统都面临一个挑战，那就是不断增长的大规模系统所生成的大量数据；</li>
<li>  Google 在实现其分布式监控系统 Dapper 时解决了这个问题，他们采取的方式是采样跟踪，一般是 1000 个请求中采样 1 个请求，但是现代的商业跟踪产品都宣称能够分析 100% 的请求。</li>
</ul>
</blockquote>

<p>在观测分布式系统和微服务时，分布式跟踪成为一个越来越重要的组件。本文将会介绍该技术，让读者对其有一个整体的了解，首先我们会探讨一下 <a href="https://research.google.com/pubs/pub36356.html">Google 的 Dapper</a> 请求跟踪论文，该论文反过来促成了 Zipkin 和 OpenTracing 项目的创建，随后我们会与 Ben Sigelman 讨论一下请求跟踪的未来，他是新的 <a href="https://lightstep.com/product">LightStep [x]PM</a> 跟踪系统的创建者。</p>

<p>正如最初的 Dapper 论文所述，现代互联网服务通常实现为复杂的大规模系统，比如采用流行的微服务架构模式。应用是由一组服务组合起来的，这些服务可能是由不同的团队开发的，而且可能采用不同的编程语言。在 Google 这种级别，应用会跨越多个基础设施的上千台机器，即便是相对较小的云计算用例，推荐的做法也是使用跨地域的 “availability zone” 和“region”运行服务的多个版本。在这种复杂的系统和环境中，能够辅助我们理解系统的行为、帮助调试和排查性能问题的工具是非常有价值的。</p>

<p>分布式跟踪的基本理念是非常简单直接的：在系统、应用、网络以及中间件中，请求（一般是用户发起的）路径上的每个转折点，甚至可以说每个点必须要识别并检测（instrument）。这些点有着特殊的意义，因为它们通常代表了执行流上的分支，比如使用多个线程并行处理、进行异步计算或者发起进程外的网络调用。这些独立生成的跟踪数据必须要收集、协调和整理，在系统范围内为请求提供一个有意义的流视图。<a href="https://twitter.com/copyconstruct/">Cindy Sridharan</a> 提供了一个<a href="https://medium.com/@copyconstruct/monitoring-in-the-time-of-cloud-native-c87c7a5bfa3e">非常有用的指南</a>，该指南探讨了请求跟踪的基本原理，并将这项技术应用于现代监控和 “可观察性（observability）” 的两大支柱之中：日志和指标收集。</p>

<h2 id="toc_1">剖析 Trace</h2>

<p>按照<a href="https://www.cncf.io/">云原生计算基金会（Cloud Native Computing Foundation，CNCF）</a>的 <a href="http://opentracing.io/">OpenTracing API</a> 项目的定义，<a href="http://opentracing.io/documentation/#what-is-a-trace">trace</a> 能够告诉我们事务或工作流在整个系统的传播过程中经历的所有事情。在 OpenTracing 和 Dapper 中，trace 是由 “span” 所组成的一个有向无环图（directed acyclic graph，DAG），在有些工具中 “span” 也被称为“segment”，比如在 <a href="https://aws.amazon.com/xray/">AWS X-Ray</a> 中。span 是一个带有名称和计时的操作，它代表了 trace 中一个持续的工作片段。被检测的组件还可以将额外的上下文注释（元数据或 “<a href="https://github.com/opentracing/specification/blob/master/specification.md#user-content-set-a-baggage-item">baggage</a>”）添加到 span 中，例如，应用开发人员可能会使用一个跟踪 SDK 添加任意的 key-value 条目到当前的 span 中。需要注意的是，添加注释数据会带来内在的侵入性：添加注释的组件必须要感知跟踪框架的存在性。</p>

<p>Trace 数据一般会 “按照不同的频道（out of band）” 进行收集，并写入到本地数据文件中（由 agent 或 daemon 来生成），然后通过单独的网络进程拉取到中心化的存储中，这与当前日志和指标收集的做法非常类似。Trace 数据不会添加到请求本身上，因为这样能够保持请求的大小和语义不发生变化，本地存储的数据会在方便的时候被拉取到出来。</p>

<p>当请求初始化的时候，将会生成一个 “parent” span，该 span 可以与多个 “child” span 建立具有因果关系和临时的关联。图 1 来源于 OpenTracing 的文档，以可视化的方式展现了一个请求流中一系列的 span 及其关联关系。这种类型的可视化会添加一些上下文信息，包括时间、服务调用的层级以及进程 / 任务执行的串行或并行性。这种视图能够突出显示系统的关键路径，并且为我们提供了一个起点，让我们识别瓶颈以及需要提升的地方。很多分布式跟踪系统还提供了 API 或 UI，实现对 span 细节的进一步 “钻取”。</p>

<p><a href="https://s3.amazonaws.com/infoq.content.live.0/articles/distributed-tracing-microservices/zh/resources/4101-1520271955968.png"><img src="https://res.infoq.com/articles/distributed-tracing-microservices/zh/resources/4101-1520271955968.png" alt=""/></a></p>

<p><small><strong>图 1 按照请求的生命线，以一系列 span 的形式可视化基本的跟踪（图片来源于 <a href="http://opentracing.io/documentation/#a-basic-trace">OpenTracing 文档</a>）</strong></small></p>

<h2 id="toc_2">实现分布式跟踪所面临的挑战</h2>

<p>在历史上，为各种类型的分布式系统实现分布式跟踪会面临很多挑战。例如，使用多种编程语言实现的微服务架构可能并没有共享通用的检测点。Google 和 Twitter 分别创建了 Dapper 和 Zipkin 来实现跟踪，这相对较为简单，因为它们大多数的跨进程（跨服务）通信是通过同质的 RPC 框架完成的，Google 创建了 <a href="https://landing.google.com/sre/book/chapters/production-environment.html#our-software-infrastructure-XQs4iw">Stubby</a>（它的一个开源变种就是 <a href="https://grpc.io/">gRPC</a>），Twitter 则创建了 <a href="https://blog.twitter.com/engineering/en_us/a/2011/finagle-a-protocol-agnostic-rpc-system.html">Finagle</a>。</p>

<p>Dapper 论文明确跟踪的价值只能通过如下的方式才能体现出来：（1）广泛部署，也就是系统的所有组成部分都要纳入检测，不能出现 “黑点（dark）”；（2）持续监控，也就是系统必须要一直处于监控之中，因为感兴趣的异常事件通常难以再现。</p>

<p>“service mesh” 网络代理的流行程度正在不断上升，比如 <a href="https://www.envoyproxy.io/">Envoy</a>、<a href="https://linkerd.io/">Linkerd</a> 和 <a href="https://conduit.io/">Conduit</a>（以及关联的控制层，如 <a href="https://istio.io/">Istio</a>），它们可能会推进多类型分布式系统中跟踪功能的采用，因为它们能够提供缺失的通用检测点。Sridharan 在它的 Medium 博客文章中详细讨论了<a href="https://medium.com/@copyconstruct/monitoring-in-the-time-of-cloud-native-c87c7a5bfa3e">可见性的问题：</a></p>

<p>“Lyft 为所有的应用提供了跟踪支持，通过采用 service mesh 模式 [使用 Envoy 代理]，无需更改一行代码。Service mesh 能够帮助实现可见性，这是通过在 mesh 级别实现跟踪和状态收集做到的，它允许我们将单个服务视为黑盒，但是依然能够在整个 mesh 级别实现非常棒的可见性”;</p>

<h2 id="toc_3">对速度的需求：请求跟踪与 APM</h2>

<p>Web 页面的加载速度会极大地影响用户的行为和转变。Google 使用其搜索引擎运行了一个<a href="https://research.googleblog.com/2009/06/speed-matters.html">延迟实验</a>，他们发现如果将结果页面的展现增加 100 到 400 毫秒的延迟，将会显著影响用户执行搜索的次数。Greg Linden 提到，在 2006 年 Amazon.com 运行了一个实验，如果页面加载的延迟增加 100 毫秒，<a href="http://glinden.blogspot.co.uk/2006/11/marissa-mayer-at-web-20.html">将会造成收入的大幅下降</a>。尽管理解整个系统中 Web 请求的流程非常具有挑战性，但是识别和消除性能瓶颈会带来显著的商业收益。</p>

<p>请求跟踪的理念类似于应用性能监控（Application Performance Management，APM），它们都与监控有关，并且都关系到软件应用的性能和可用性的管理。APM 的目标在于探查和诊断复杂应用的性能问题，达到预期的服务等级协议（Service Level Agreement，SLA）。现代软件架构的分布式特性在不断增加，APM 工具也进行了适配以监控（可视化）这种类型的软件。图 2 展现了开源的 <a href="https://github.com/naver/pinpoint">Pinpoint APM</a> 工具的可视化界面，类似的视图在商业工具中也能见到，比如 <a href="https://www.dynatrace.com/">Dynatrace APM</a> 和 <a href="https://newrelic.com/application-monitoring">New Relic APM</a>。</p>

<p><a href="https://s3.amazonaws.com/infoq.content.live.0/articles/distributed-tracing-microservices/zh/resources/3232-1520271955650.png"><img src="https://res.infoq.com/articles/distributed-tracing-microservices/zh/resources/3232-1520271955650.png" alt=""/></a></p>

<p><small><strong>图 2 现代 APM 工具中的跟踪（图片来源 <a href="https://github.com/naver/pinpoint">Pinpoint APM GitHub 仓库</a>）</strong></small></p>

<p>在请求跟踪和 APM 领域都面临一项挑战，那就是大规模系统不断生成的大量数据。AWS 云架构战略（Cloud Architecture Strategy）的 VP <a href="https://www.linkedin.com/in/adriancockcroft/">Adrian Cockcroft</a> 说到，公有云能够让大众更容易地使用强大且可扩展的基础设施和服务，但是监控系统必须要比被监控的系统 <a href="https://www.infoq.com/news/2015/06/monitoring-microservices">更加可用（也要更加可扩展）</a>。Google 在实现 Dapper 时通过采样跟踪解决了这个问题，一般是 1000 个请求中采样 1 个请求，他们发现通过这种比例依然能够生成有意义的观察结果。很多的工程师和思想领袖都在从事该领域的工作，包括可观察性平台 Honeycomb 的 CEO <a href="https://www.linkedin.com/in/charity-majors-826b765">Charity Majors</a>，他们都相信<a href="https://twitter.com/mipsytipsy/status/936484900286296064">监控数据的采样是非常重要的</a>：</p>

<blockquote>
<p>这非常简单：如果你不采样的话，就无法扩展。如果你认为这是一种有争议的说法的话，那么说明你还没有真正处理过大规模的可观察性，或者你之前做得非常糟糕和浪费。</p>
</blockquote>

<p>InfoQ 最近参加了在美国奥斯汀举行的 <a href="https://events.linuxfoundation.org/events/kubecon-cloudnativecon-north-america-2018/">CNCF CloudNativeCon</a>，并与 <a href="https://www.linkedin.com/in/bensigelman">Ben Sigelman</a> 进行了交流，他是 Dapper 论文的作者之一，同时也是 <a href="https://lightstep.com/">LightStep</a> 的 CEO 和联合创始人，他最近宣布了一个新的商用跟踪平台 <a href="https://lightstep.com/blog/launching-lightstep/">“LightStep [x]PM”</a>。Sigelman 讨论了 LightStep 的非传统架构（它会在本地安装的 agent 上使用机器学习技术），允许分析 100.0% 的事务数据，而不是 Dapper 所实现的 0.01%：</p>

<p>“我们过去和现在依然构建的工具对长期的性能分析是非常重要的，但是为了应对被监控系统的规模，Dapper 只会中心化地记录 0.01% 的性能数据，这意味着在特定的使用场景下，它是难以应对的，比如实时的事件响应（‘也就是最紧急的’）”。</p>

<p>LightStep 在过去的 18 个月中已经与很多客户合作过，包括 Lyft（使用 Envoy 代理作为集成点）、Twilio、GitHub 和 DigitalOcean，业已证明他们的方案能够处理大量的数据：</p>

<p>“Lyft 给我们发送了大量的数据，LightStep 每天分析 100,000,000,000 个微服务调用。乍一看上去，这是数据全是噪音，没有什么有用的信息：大量的数据混杂在一起并且不相关，但是通过全盘考虑，LightStep 能够衡量出性能是如何影响 Lyft 的不同方面的，然后使用端到端的跟踪展现问题和异常情况，这种跟踪能够从移动应用一直延伸到微服务技术栈的底部。”</p>

<p><a href="https://lightstep.com/product">LightStep [x]PM</a> 目前可以作为 SaaS 平台来使用。Sigelman 想要强调的是，尽管可以分析 100% 的请求，但是在本地安装的 agent 所收集的数据并不会全部传送到中心化的平台中。Sigelman 将这个产品视为” 新一代的 APM“工具，如果用户正在寻找针对复杂分布式应用的性能监控和自动分析的工具的话，那么它可以为用户带来价值。</p>

<h2 id="toc_4">结论</h2>

<p>在分布式系统中，响应延迟可能会带来严重的商业影响，但是理解复杂系统中的请求流并识别瓶颈也是很有挑战性的任务。通过使用分布式跟踪，再结合其他的技术，如日志和监控指标，能够了解分布式应用的内部状况，这些应用可能是采用微服务的架构模式创建的。在分布式跟踪领域，开放的标准和工具正在不断组合，比如 OpenTracing API 和 OpenZipkin，商业的工具也在涌现，可能会与现有的 APM 供应商产生竞争。在为现代互联网服务实现分布式跟踪时，会面临一些挑战，比如处理大量的跟踪数据并生成有意义的输出，但是开源的生态系统和供应商正在应对这些挑战。</p>

<h2 id="toc_5">关于作者</h2>

<p><strong><img src="https://res.infoq.com/articles/distributed-tracing-microservices/en/resources/6daniel-bryant-1519132850908.jpg" alt=""/>Daniel Bryant</strong> 一直在组织内部和技术方面引领变化。他目前的工作包括通过引入更好的需求收集和计划技术推进企业内部的敏捷性，关注于敏捷开发中的架构关联性，并且搭建持续集成 / 交付环境。Daniel 现在的技术专长是 “DevOps” 工具、云 / 容器平台和微服务实现。他还是伦敦 Java 社区（LJC）的领导者，参与多个开源项目，为 InfoQ、DZone 和 Voxxed 这样的技术网站撰写文章，并且经常在 QCon、JavaOne 和 Devoxx 这样的国际会议上发表演讲。</p>

<p><strong>查看英文原文：</strong><a href="https://www.infoq.com/articles/distributed-tracing-microservices">Distributed Tracing: Exploring the Past, Present and Future with Dapper, Zipkin and LightStep [x]PM</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[理解OAuth 2.0]]></title>
    <link href="http://panlw.github.io/15327406535943.html"/>
    <updated>2018-07-28T09:17:33+08:00</updated>
    <id>http://panlw.github.io/15327406535943.html</id>
    <content type="html"><![CDATA[
<p><a href="http://en.wikipedia.org/wiki/OAuth">OAuth</a> 是一个关于授权（authorization）的开放网络标准，在全世界得到广泛应用，目前的版本是 2.0 版。</p>

<p>本文对 OAuth 2.0 的设计思路和运行流程，做一个简明通俗的解释，主要参考材料为 <a href="http://www.rfcreader.com/#rfc6749">RFC 6749</a>。</p>

<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051201.png" alt=""/></p>

<h2 id="toc_0">一、应用场景</h2>

<p>为了理解 OAuth 的适用场合，让我举一个假设的例子。</p>

<p>有一个 &quot;云冲印&quot; 的网站，可以将用户储存在 Google 的照片，冲印出来。用户为了使用该服务，必须让 &quot;云冲印&quot; 读取自己储存在 Google 上的照片。</p>

<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051202.png" alt=""/></p>

<p>问题是只有得到用户的授权，Google 才会同意 &quot;云冲印&quot; 读取这些照片。那么，&quot;云冲印&quot; 怎样获得用户的授权呢？</p>

<p>传统方法是，用户将自己的 Google 用户名和密码，告诉 &quot;云冲印&quot;，后者就可以读取用户的照片了。这样的做法有以下几个严重的缺点。</p>

<blockquote>
<p>（1）&quot;云冲印&quot; 为了后续的服务，会保存用户的密码，这样很不安全。</p>

<p>（2）Google 不得不部署密码登录，而我们知道，单纯的密码登录并不安全。</p>

<p>（3）&quot;云冲印&quot; 拥有了获取用户储存在 Google 所有资料的权力，用户没法限制 &quot;云冲印&quot; 获得授权的范围和有效期。</p>

<p>（4）用户只有修改密码，才能收回赋予 &quot;云冲印&quot; 的权力。但是这样做，会使得其他所有获得用户授权的第三方应用程序全部失效。</p>

<p>（5）只要有一个第三方应用程序被破解，就会导致用户密码泄漏，以及所有被密码保护的数据泄漏。</p>
</blockquote>

<p>OAuth 就是为了解决上面这些问题而诞生的。</p>

<h2 id="toc_1">二、名词定义</h2>

<p>在详细讲解 OAuth 2.0 之前，需要了解几个专用名词。它们对读懂后面的讲解，尤其是几张图，至关重要。</p>

<blockquote>
<p>（1） <strong>Third-party application</strong>：第三方应用程序，本文中又称 &quot;客户端&quot;（client），即上一节例子中的 &quot;云冲印&quot;。</p>

<p>（2）<strong>HTTP service</strong>：HTTP 服务提供商，本文中简称 &quot;服务提供商&quot;，即上一节例子中的 Google。</p>

<p>（3）<strong>Resource Owner</strong>：资源所有者，本文中又称 &quot;用户&quot;（user）。</p>

<p>（4）<strong>User Agent</strong>：用户代理，本文中就是指浏览器。</p>

<p>（5）<strong>Authorization server</strong>：认证服务器，即服务提供商专门用来处理认证的服务器。</p>

<p>（6）<strong>Resource server</strong>：资源服务器，即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。</p>
</blockquote>

<p>知道了上面这些名词，就不难理解，OAuth 的作用就是让 &quot;客户端&quot; 安全可控地获取 &quot;用户&quot; 的授权，与 &quot;服务商提供商&quot; 进行互动。</p>

<h2 id="toc_2">三、OAuth 的思路</h2>

<p>OAuth 在 &quot;客户端&quot; 与 &quot;服务提供商&quot; 之间，设置了一个授权层（authorization layer）。&quot;客户端&quot; 不能直接登录 &quot;服务提供商&quot;，只能登录授权层，以此将用户与客户端区分开来。&quot;客户端&quot; 登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。</p>

<p>&quot;客户端&quot; 登录授权层以后，&quot;服务提供商&quot; 根据令牌的权限范围和有效期，向 &quot;客户端&quot; 开放用户储存的资料。</p>

<h2 id="toc_3">四、运行流程</h2>

<p>OAuth 2.0 的运行流程如下图，摘自 RFC 6749。</p>

<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051203.png" alt=""/></p>

<blockquote>
<p>（A）用户打开客户端以后，客户端要求用户给予授权。</p>

<p>（B）用户同意给予客户端授权。</p>

<p>（C）客户端使用上一步获得的授权，向认证服务器申请令牌。</p>

<p>（D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。</p>

<p>（E）客户端使用令牌，向资源服务器申请获取资源。</p>

<p>（F）资源服务器确认令牌无误，同意向客户端开放资源。</p>
</blockquote>

<p>不难看出来，上面六个步骤之中，B 是关键，即用户怎样才能给于客户端授权。有了这个授权以后，客户端就可以获取令牌，进而凭令牌获取资源。</p>

<p>下面一一讲解客户端获取授权的四种模式。</p>

<h2 id="toc_4">五、客户端的授权模式</h2>

<p>客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。OAuth 2.0 定义了四种授权方式。</p>

<ul>
<li>  授权码模式（authorization code）</li>
<li>  简化模式（implicit）</li>
<li>  密码模式（resource owner password credentials）</li>
<li>  客户端模式（client credentials）</li>
</ul>

<h2 id="toc_5">六、授权码模式</h2>

<p>授权码模式（authorization code）是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与 &quot;服务提供商&quot; 的认证服务器进行互动。</p>

<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051204.png" alt=""/></p>

<p>它的步骤如下：</p>

<blockquote>
<p>（A）用户访问客户端，后者将前者导向认证服务器。</p>

<p>（B）用户选择是否给予客户端授权。</p>

<p>（C）假设用户给予授权，认证服务器将用户导向客户端事先指定的 &quot;重定向 URI&quot;（redirection URI），同时附上一个授权码。</p>

<p>（D）客户端收到授权码，附上早先的 &quot;重定向 URI&quot;，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。</p>

<p>（E）认证服务器核对了授权码和重定向 URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）。</p>
</blockquote>

<p>下面是上面这些步骤所需要的参数。</p>

<p>A 步骤中，客户端申请认证的 URI，包含以下参数：</p>

<ul>
<li>  response_type：表示授权类型，必选项，此处的值固定为 &quot;code&quot;</li>
<li>  client_id：表示客户端的 ID，必选项</li>
<li>  redirect_uri：表示重定向 URI，可选项</li>
<li>  scope：表示申请的权限范围，可选项</li>
<li>  state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。</li>
</ul>

<p>下面是一个例子。</p>

<blockquote>
<pre><code>
GET /authorize?response_type=code&amp;client_id=s6BhdRkqt3&amp;state=xyz
        &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1
Host: server.example.com

</code></pre>
</blockquote>

<p>C 步骤中，服务器回应客户端的 URI，包含以下参数：</p>

<ul>
<li>  code：表示授权码，必选项。该码的有效期应该很短，通常设为 10 分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端 ID 和重定向 URI，是一一对应关系。</li>
<li>  state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。</li>
</ul>

<p>下面是一个例子。</p>

<blockquote>
<pre><code>
HTTP/1.1 302 Found
Location: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA
          &amp;state=xyz

</code></pre>
</blockquote>

<p>D 步骤中，客户端向认证服务器申请令牌的 HTTP 请求，包含以下参数：</p>

<ul>
<li>  grant_type：表示使用的授权模式，必选项，此处的值固定为 &quot;authorization_code&quot;。</li>
<li>  code：表示上一步获得的授权码，必选项。</li>
<li>  redirect_uri：表示重定向 URI，必选项，且必须与 A 步骤中的该参数值保持一致。</li>
<li>  client_id：表示客户端 ID，必选项。</li>
</ul>

<p>下面是一个例子。</p>

<blockquote>
<pre><code>
POST /token HTTP/1.1
Host: server.example.com
Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW
Content-Type: application/x-www-form-urlencoded

grant_type=authorization_code&amp;code=SplxlOBeZQQYbYS6WxSbIA
&amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb

</code></pre>
</blockquote>

<p>E 步骤中，认证服务器发送的 HTTP 回复，包含以下参数：</p>

<ul>
<li>  access_token：表示访问令牌，必选项。</li>
<li>  token_type：表示令牌类型，该值大小写不敏感，必选项，可以是 bearer 类型或 mac 类型。</li>
<li>  expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。</li>
<li>  refresh_token：表示更新令牌，用来获取下一次的访问令牌，可选项。</li>
<li>  scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。</li>
</ul>

<p>下面是一个例子。</p>

<blockquote>
<pre><code>
     HTTP/1.1 200 OK
     Content-Type: application/json;charset=UTF-8
     Cache-Control: no-store
     Pragma: no-cache

     {
       &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;,
       &quot;token_type&quot;:&quot;example&quot;,
       &quot;expires_in&quot;:3600,
       &quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;,
       &quot;example_parameter&quot;:&quot;example_value&quot;
     }

</code></pre>
</blockquote>

<p>从上面代码可以看到，相关参数使用 JSON 格式发送（Content-Type: application/json）。此外，HTTP 头信息中明确指定不得缓存。</p>

<h2 id="toc_6">七、简化模式</h2>

<p>简化模式（implicit grant type）不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了 &quot;授权码&quot; 这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。</p>

<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051205.png" alt=""/></p>

<p>它的步骤如下：</p>

<blockquote>
<p>（A）客户端将用户导向认证服务器。</p>

<p>（B）用户决定是否给于客户端授权。</p>

<p>（C）假设用户给予授权，认证服务器将用户导向客户端指定的 &quot;重定向 URI&quot;，并在 URI 的 Hash 部分包含了访问令牌。</p>

<p>（D）浏览器向资源服务器发出请求，其中不包括上一步收到的 Hash 值。</p>

<p>（E）资源服务器返回一个网页，其中包含的代码可以获取 Hash 值中的令牌。</p>

<p>（F）浏览器执行上一步获得的脚本，提取出令牌。</p>

<p>（G）浏览器将令牌发给客户端。</p>
</blockquote>

<p>下面是上面这些步骤所需要的参数。</p>

<p>A 步骤中，客户端发出的 HTTP 请求，包含以下参数：</p>

<ul>
<li>  response_type：表示授权类型，此处的值固定为 &quot;token&quot;，必选项。</li>
<li>  client_id：表示客户端的 ID，必选项。</li>
<li>  redirect_uri：表示重定向的 URI，可选项。</li>
<li>  scope：表示权限范围，可选项。</li>
<li>  state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。</li>
</ul>

<p>下面是一个例子。</p>

<blockquote>
<pre><code>
    GET /authorize?response_type=token&amp;client_id=s6BhdRkqt3&amp;state=xyz
        &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1
    Host: server.example.com

</code></pre>
</blockquote>

<p>C 步骤中，认证服务器回应客户端的 URI，包含以下参数：</p>

<ul>
<li>  access_token：表示访问令牌，必选项。</li>
<li>  token_type：表示令牌类型，该值大小写不敏感，必选项。</li>
<li>  expires_in：表示过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间。</li>
<li>  scope：表示权限范围，如果与客户端申请的范围一致，此项可省略。</li>
<li>  state：如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。</li>
</ul>

<p>下面是一个例子。</p>

<blockquote>
<pre><code>
     HTTP/1.1 302 Found
     Location: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA
               &amp;state=xyz&amp;token_type=example&amp;expires_in=3600

</code></pre>
</blockquote>

<p>在上面的例子中，认证服务器用 HTTP 头信息的 Location 栏，指定浏览器重定向的网址。注意，在这个网址的 Hash 部分包含了令牌。</p>

<p>根据上面的 D 步骤，下一步浏览器会访问 Location 指定的网址，但是 Hash 部分不会发送。接下来的 E 步骤，服务提供商的资源服务器发送过来的代码，会提取出 Hash 中的令牌。</p>

<h2 id="toc_7">八、密码模式</h2>

<p>密码模式（Resource Owner Password Credentials Grant）中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向 &quot;服务商提供商&quot; 索要授权。</p>

<p>在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分，或者由一个著名公司出品。而认证服务器只有在其他授权模式无法执行的情况下，才能考虑使用这种模式。</p>

<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051206.png" alt=""/></p>

<p>它的步骤如下：</p>

<blockquote>
<p>（A）用户向客户端提供用户名和密码。</p>

<p>（B）客户端将用户名和密码发给认证服务器，向后者请求令牌。</p>

<p>（C）认证服务器确认无误后，向客户端提供访问令牌。</p>
</blockquote>

<p>B 步骤中，客户端发出的 HTTP 请求，包含以下参数：</p>

<ul>
<li>  grant_type：表示授权类型，此处的值固定为 &quot;password&quot;，必选项。</li>
<li>  username：表示用户名，必选项。</li>
<li>  password：表示用户的密码，必选项。</li>
<li>  scope：表示权限范围，可选项。</li>
</ul>

<p>下面是一个例子。</p>

<blockquote>
<pre><code>
     POST /token HTTP/1.1
     Host: server.example.com
     Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW
     Content-Type: application/x-www-form-urlencoded

     grant_type=password&amp;username=johndoe&amp;password=A3ddj3w

</code></pre>
</blockquote>

<p>C 步骤中，认证服务器向客户端发送访问令牌，下面是一个例子。</p>

<blockquote>
<pre><code>
     HTTP/1.1 200 OK
     Content-Type: application/json;charset=UTF-8
     Cache-Control: no-store
     Pragma: no-cache

     {
       &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;,
       &quot;token_type&quot;:&quot;example&quot;,
       &quot;expires_in&quot;:3600,
       &quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;,
       &quot;example_parameter&quot;:&quot;example_value&quot;
     }

</code></pre>
</blockquote>

<p>上面代码中，各个参数的含义参见《授权码模式》一节。</p>

<p>整个过程中，客户端不得保存用户的密码。</p>

<h2 id="toc_8">九、客户端模式</h2>

<p>客户端模式（Client Credentials Grant）指客户端以自己的名义，而不是以用户的名义，向 &quot;服务提供商&quot; 进行认证。严格地说，客户端模式并不属于 OAuth 框架所要解决的问题。在这种模式中，用户直接向客户端注册，客户端以自己的名义要求 &quot;服务提供商&quot; 提供服务，其实不存在授权问题。</p>

<p><img src="http://www.ruanyifeng.com/blogimg/asset/2014/bg2014051207.png" alt=""/></p>

<p>它的步骤如下：</p>

<blockquote>
<p>（A）客户端向认证服务器进行身份认证，并要求一个访问令牌。</p>

<p>（B）认证服务器确认无误后，向客户端提供访问令牌。</p>
</blockquote>

<p>A 步骤中，客户端发出的 HTTP 请求，包含以下参数：</p>

<ul>
<li>  grant_type：表示授权类型，此处的值固定为 &quot;client_credentials&quot;，必选项。</li>
<li>  scope：表示权限范围，可选项。</li>
</ul>

<blockquote>
<pre><code>
     POST /token HTTP/1.1
     Host: server.example.com
     Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW
     Content-Type: application/x-www-form-urlencoded

     grant_type=client_credentials

</code></pre>
</blockquote>

<p>认证服务器必须以某种方式，验证客户端身份。</p>

<p>B 步骤中，认证服务器向客户端发送访问令牌，下面是一个例子。</p>

<blockquote>
<pre><code>
     HTTP/1.1 200 OK
     Content-Type: application/json;charset=UTF-8
     Cache-Control: no-store
     Pragma: no-cache

     {
       &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;,
       &quot;token_type&quot;:&quot;example&quot;,
       &quot;expires_in&quot;:3600,
       &quot;example_parameter&quot;:&quot;example_value&quot;
     }

</code></pre>
</blockquote>

<p>上面代码中，各个参数的含义参见《授权码模式》一节。</p>

<h2 id="toc_9">十、更新令牌</h2>

<p>如果用户访问的时候，客户端的 &quot;访问令牌&quot; 已经过期，则需要使用 &quot;更新令牌&quot; 申请一个新的访问令牌。</p>

<p>客户端发出更新令牌的 HTTP 请求，包含以下参数：</p>

<ul>
<li>  grant_type：表示使用的授权模式，此处的值固定为 &quot;refresh_token&quot;，必选项。</li>
<li>  refresh_token：表示早前收到的更新令牌，必选项。</li>
<li>  scope：表示申请的授权范围，不可以超出上一次申请的范围，如果省略该参数，则表示与上一次一致。</li>
</ul>

<p>下面是一个例子。</p>

<blockquote>
<pre><code>
     POST /token HTTP/1.1
     Host: server.example.com
     Authorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JW
     Content-Type: application/x-www-form-urlencoded

     grant_type=refresh_token&amp;refresh_token=tGzv3JOkF0XG5Qx2TlKWIA

</code></pre>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spring Boot Application as a Service]]></title>
    <link href="http://panlw.github.io/15325941121250.html"/>
    <updated>2018-07-26T16:35:12+08:00</updated>
    <id>http://panlw.github.io/15325941121250.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://www.baeldung.com/spring-boot-app-as-a-service">http://www.baeldung.com/spring-boot-app-as-a-service</a></p>
</blockquote>

<h2 id="toc_0"><strong>1. Overview</strong></h2>

<p>This article explores some options of running Spring Boot applications as a service.</p>

<p>Firstly, we are going to explain web applications’ packaging options and system services. In the subsequent sections, we explore different alternatives we have when setting up a service for both Linux as Windows based systems.</p>

<p>Finally, we will conclude with some references to additional sources of information.</p>

<h2 id="toc_1"><strong>2. Project Setup and Build Instructions</strong></h2>

<h3 id="toc_2"><strong>2.1. Packaging</strong></h3>

<p>Web applications are traditionally packaged as a Web Application aRchives (WAR) and deployed to a web server.</p>

<p>Spring Boot applications may be packaged both as WAR and JAR files. The latter embeds a web server within a JAR file, which allows you to run applications without the need of an installation and configuration of an application server.</p>

<h3 id="toc_3"><strong>2.2. Maven Configuration</strong></h3>

<p>Let’s start by defining the configuration of our <u>pom.xml</u> file:</p>

<pre><code class="language-xml">&lt;packaging&gt;jar&lt;/packaging&gt;
 
&lt;parent&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
    &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;
&lt;/parent&gt;
 
&lt;dependencies&gt;
    ....
&lt;/dependencies&gt;
 
&lt;build&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;configuration&gt;
                &lt;executable&gt;true&lt;/executable&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
</code></pre>

<p>The packaging must be set to <u>jar</u>. We are using the latest stable version of Spring Boot at the time of writing, but any version after 1.3 will be enough. You can find more information about available versions <a href="http://projects.spring.io/spring-boot/">here</a>.</p>

<p>Notice that we have set the <u><executable></u> parameter to <u>true</u> for the <u>spring-boot-maven-plugin</u> artifact. This makes sure that a <u>MANIFEST.MF</u> file is added to the JAR package. This manifest contains a <u>Main-Class</u> entry that specifies which class defines the main method for your application.</p>

<h3 id="toc_4"><strong>2.3. Building Your Application</strong></h3>

<p>Run the following command inside your application’s root directory:</p>

<pre><code>$ mvn clean package
</code></pre>

<p>The executable JAR file is now available in the <u>target</u> directory and we may start up the application by executing the following command on the command line:</p>

<pre><code>$ java -jar your-app.jar
</code></pre>

<p>At this point, you still need to invoke the Java interpreter with the <u>-jar</u> option. There are many reasons why it would be preferable to have your app started by being able to invoke it as a service.</p>

<h2 id="toc_5"><strong>3. On Linux</strong></h2>

<p>In order to run a program as a background process, we could simply use the <u>nohup</u> Unix command, but this is not the preferred way either for various reasons. A good explanation is provided in this <a href="http://stackoverflow.com/questions/958249/whats-the-difference-between-nohup-and-a-daemon">thread</a>.</p>

<p>Instead, we are going to <u>daemonize</u> our process. Under Linux, we may choose to configure a daemon either with a traditional <u>System V init</u> script or with a <u>Systemd</u> configuration file. The former is traditionally the most well-known option but is gradually being replaced by the latter.</p>

<p>You may find more details on this difference <a href="http://www.tecmint.com/systemd-replaces-init-in-linux/">here</a>.</p>

<p>For enhanced security we first create a specific user to run the service with and change the executable JAR file permissions accordingly:</p>

<pre><code>$ sudo useradd baeldung
$ sudo passwd baeldung
$ sudo chown baeldung:baeldung your-app.jar
$ sudo chmod 500 your-app.jar
</code></pre>

<h3 id="toc_6"><strong>3.1. System V Init</strong></h3>

<p>A Spring Boot executable JAR file makes the service setup process very easy:</p>

<pre><code>$ sudo ln -s /path/to/your-app.jar /etc/init.d/your-app
</code></pre>

<p>The above command creates a symbolic link to your executable JAR file. You must use the full path to your executable JAR file, otherwise, the symbolic link will not work properly. This link enables you to start the application as a service:</p>

<pre><code>$ sudo service your-app start
</code></pre>

<p>The script supports the standard service <u>start</u>, <u>stop</u>, <u>restart</u> and <u>status</u> commands. Moreover:</p>

<ul>
<li>  it starts the services running under the user <u>baeldung</u> we have just created</li>
<li>  it tracks the application’s process ID in <u>/var/run/your-app/your-app.pid</u></li>
<li>  it writes console logs to <u>/var/log/your-app.log</u>, which you may want to check in case your application fails to start properly</li>
</ul>

<h3 id="toc_7"><strong>3.2. Systemd</strong></h3>

<p>The <u>systemd</u> service setup is very simple as well. Firstly, we create a script named <u>your-app.service</u> using the following example and put it in <u>/etc/systemd/system</u> directory:</p>

<pre><code class="language-service">[Unit]
Description=A Spring Boot application
After=syslog.target
 
[Service]
User=baeldung
ExecStart=/path/to/your-app.jar SuccessExitStatus=143 
 
[Install] 
WantedBy=multi-user.target
</code></pre>

<p>Remember to modify <u>Description</u>, <u>User</u> and <u>ExecStart</u> fields to match your application. You should be able to execute the aforementioned standard service commands at this point as well.</p>

<p>As opposed to the <u>System V init</u> approach described in the previous section, the process ID file and console log file should be configured explicitly using appropriate fields in the service script. An exhaustive list of options may be found <a href="http://www.freedesktop.org/software/systemd/man/systemd.service.html">here</a>.</p>

<h3 id="toc_8"><strong>3.3. Upstart</strong></h3>

<p><a href="http://upstart.ubuntu.com/">Upstart</a> is an event-based service manager, a potential replacement for the <u>System V init</u> that offers more control on the behavior of the different daemons.</p>

<p>The site has good <a href="http://upstart.ubuntu.com/getting-started.html">setup instructions</a> that should work for almost any Linux distribution. When using Ubuntu you probably have it installed and configured already (check if there are any jobs with a name starting with “upstart” in <u>/etc/init</u>).</p>

<p>We create a job <u>your-app.conf</u> to start our Spring Boot application:</p>

<pre><code># Place in /home/{user}/.config/upstart
 
description &quot;Some Spring Boot application&quot;
 
respawn # attempt service restart if stops abruptly
 
exec java -jar /path/to/your-app.jar
</code></pre>

<p>Now run “start your-app” and your service will start.</p>

<p>Upstart offers many job configuration options, you can find most of them <a href="http://upstart.ubuntu.com/cookbook/">here</a>.</p>

<h2 id="toc_9"><strong>4. On Windows</strong></h2>

<p>In this section, we present a couple of options that may be used to run a Java JAR as a Windows service.</p>

<h3 id="toc_10"><strong>4.1. Windows Service Wrapper</strong></h3>

<p>Due to difficulties with the GPL license of the <a href="http://wrapper.tanukisoftware.org/doc/english/index.html">Java Service Wrapper</a> (see next subsection) in combination with e.g. the MIT license of Jenkins, the <a href="https://github.com/kohsuke/winsw">Windows Service Wrapper</a> project, also known as <u>winsw</u>, was conceived.</p>

<p><u>Winsw</u> provides programmatic means to install/uninstall/start/stop a service. In addition, it may be used to run any kind of executable as a service under Windows, whereas Java Service Wrapper, as implied by its name, only supports Java applications.</p>

<p>First, you download the binaries <a href="http://repo.jenkins-ci.org/releases/com/sun/winsw/winsw/">here</a>. Next, the configuration file that defines our Windows service, <u>MyApp.xml</u>, should look like this:</p>

<pre><code class="language-xml">&lt;service&gt;
    &lt;id&gt;MyApp&lt;/id&gt;
    &lt;name&gt;MyApp&lt;/name&gt;
    &lt;description&gt;This runs Spring Boot as a Service.&lt;/description&gt;
    &lt;env name=&quot;MYAPP_HOME&quot; value=&quot;%BASE%&quot;/&gt;
    &lt;executable&gt;java&lt;/executable&gt;
    &lt;arguments&gt;-Xmx256m -jar &quot;%BASE%\MyApp.jar&quot;&lt;/arguments&gt;
    &lt;logmode&gt;rotate&lt;/logmode&gt;
&lt;/service&gt;
</code></pre>

<p>Finally, you have to rename the <u>winsw.exe</u> to <u>MyApp.exe</u> so that its name matches with the <u>MyApp.xml</u> configuration file. Thereafter you can install the service like so:</p>

<pre><code>$ MyApp.exe install
</code></pre>

<p>Similarly, you may use <u>uninstall</u>, <u>start</u>, <u>stop</u>, etc.</p>

<h3 id="toc_11"><strong>4.2. Java Service Wrapper</strong></h3>

<p>In case you don’t mind the GPL licensing of the <a href="http://wrapper.tanukisoftware.org/doc/english/index.html">Java Service Wrapper</a> project, this alternative may address your needs to configure your JAR file as a Windows service equally well. Basically, the Java Service Wrapper also requires you to specify in a configuration file which specifies how to run your process as a service under Windows.</p>

<p><a href="http://edn.embarcadero.com/article/32068">This article</a> explains in a very detailed way how to set up such an execution of a JAR file as a service under Windows, so we there’s no need to repeat the info.</p>

<h2 id="toc_12"><strong>5. Additional References</strong></h2>

<p>Spring Boot applications may also be started as Windows service using <a href="http://commons.apache.org/proper/commons-daemon/procrun.html">Procrun</a> of the <a href="http://commons.apache.org/daemon/index.html">Apache Commons Daemon</a> project. Procrun is a set of applications that allow Windows users to wrap Java applications as Windows services. Such a service may be set to start automatically when the machine boots and will continue to run without any user being logged on.</p>

<p>More details on starting Spring Boot applications under Unix may be found <a href="http://docs.spring.io/spring-boot/docs/current/reference/html/deployment-install.html">here</a>. There are also detailed instructions on how to modify <a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/System_Administrators_Guide/sect-Managing_Services_with_systemd-Unit_Files.html">Systemd unit files for Redhat</a> based systems. Finally</p>

<p>Finally, <a href="https://coderwall.com/p/ssuaxa/how-to-make-a-jar-file-linux-executable">this quick howto</a> describes how to incorporate a Bash script into your JAR file, so that it becomes an executable itself!</p>

<h2 id="toc_13"><strong>6. Conclusion</strong></h2>

<p>Services allow you to manage your application state very efficiently and, as we have seen, service setup for Spring Boot applications is now easier than ever.</p>

<p>Just remember to follow the important and simple security measures on user permissions to run your service.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[推荐11个实用的JavaScript库]]></title>
    <link href="http://panlw.github.io/15325721584114.html"/>
    <updated>2018-07-26T10:29:18+08:00</updated>
    <id>http://panlw.github.io/15325721584114.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://www.infoq.com/cn/news/2018/07/javascript-11library-mustknow">http://www.infoq.com/cn/news/2018/07/javascript-11library-mustknow</a></p>
</blockquote>

<pre><code>作者 | Jonathan Saring
编辑 | 无明
</code></pre>

<p>JavaScript 仍然是 2018 年最受欢迎和使用最为广泛的编程语言，因此 JavaScript 生态系统也会继续发展壮大。</p>

<p>然而，JavaScript 的标准库仍然继续保持 “短小精悍” 的身材。为了填补标准库功能方面的空白，在过去几年中，GitHub 上出现了很多流行的 JavaScript 库。以下列出了 11 个有用的库，这些库的维护状态均很活跃。</p>

<h3 id="toc_0">1.Underscore 和 Lodash（dah）</h3>

<p>可能大多数人都知道这两个库。Underscore 的目的是为 JavaScript 中的常见任务提供实用的函数。Lodash 是下载量最大和被依赖最多的库之一，旨在为数组、字符串、object 和 argument 对象提供更一致的跨环境迭代支持，并已成为 Underscore 的超集。这两个库由相同的核心贡献者维护，在技术选型时完全可以考虑使用它们。</p>

<p>Lodash - <a href="https://github.com/lodash/lodash">https://github.com/lodash/lodash</a></p>

<p>Underscore - <a href="https://github.com/jashkenas/underscore">https://github.com/jashkenas/underscore</a></p>

<h3 id="toc_1">2. Ramda</h3>

<p>在 GitHub 上的 Star 已经超过 12,000，这个库专为函数式编程而设计，可以轻松创建不改变用户数据状态的函数式管道。Ramda 的核心设计理念是创建具有不变性和无副作用的函数。所有的函数会被自动柯里化，并根据易用性安排参数的顺序。</p>

<p>Ramda - <a href="https://github.com/ramda/ramda">https://github.com/ramda/ramda</a></p>

<h3 id="toc_2">3. MathJS</h3>

<p>在 GitHub 上的 Star 已经超过 6000，这个库是 JavaScript 和 Node.js 的数学扩展库，与 JavaScript 内置的 Math 库兼容。该库包含一个灵活的表达式解析器，能够运行符号计算，并提供了一系列内置函数和常量。用户还可以对其进行扩展。</p>

<p>MathJS - <a href="https://github.com/josdejong/mathjs">https://github.com/josdejong/mathjs</a></p>

<h3 id="toc_3">4. Moment</h3>

<p>在 GitHub 上的 Star 已经超过 37,000，是一个 JavaScript 日期和时间操作库，用于解析、验证、操作和格式化日期。Moment 可以在浏览器和 Node.js 中运行。从 2.10.0 版本开始迁移到 ECMAScript 6。</p>

<p>Moment - <a href="https://github.com/moment/moment">https://github.com/moment/moment</a></p>

<p>另外两个同类的库：</p>

<p>Date-fns（10,000 个 Star）- <a href="https://github.com/date-fns/date-fns">https://github.com/date-fns/date-fns</a></p>

<p>DateJS - <a href="https://github.com/datejs/Datejs">https://github.com/datejs/Datejs</a></p>

<h3 id="toc_4">5. Sugar</h3>

<p>在 GitHub 上的 Star 已经超过 3500，主要用于处理本地对象。这个库支持自定义构建，还提供了模块化的 npm 包，因此可以只使用其中必要的部分模块（也可以与 Bit 结合使用），用户还可以通过自定义方法或使用插件来应对特定的使用场景。</p>

<p>Sugar - <a href="https://github.com/andrewplummer/Sugar">https://github.com/andrewplummer/Sugar</a></p>

<h3 id="toc_5">6. Lazy</h3>

<p>在 GitHub 上的 Star 将近 5000，是一个功能强大的 JavaScript 库，它的 lazy 引擎 “尽可能地少做一些工作”，同时保持足够的灵活性。</p>

<p>Lazy - <a href="https://github.com/dtao/lazy.js">https://github.com/dtao/lazy.js</a></p>

<h3 id="toc_6">7. CollectJS</h3>

<p>在 GitHub 上的 Star 超过 3200，主要用于处理 JavaScript 中的数组和对象，无需其他依赖，提供了几十个有用的功能和 API，这些 API 几乎与 Laravel Collections 5.5 相同。该库的维护状态很活跃，值得关注。</p>

<p>CollectJS - <a href="https://github.com/ecrmnn/collect.js">https://github.com/ecrmnn/collect.js</a></p>

<h3 id="toc_7">8. ChanceJS</h3>

<p>Chance 在 GitHub 上的 Star 超过 3200，一个简单的随机对象生成器，用于生成随机的字符串、数字等。在编写自动化测试代码或任何需要随机对象的地方，可以用它来减少单调的工作。</p>

<p>ChanceJS - <a href="https://github.com/chancejs/chancejs">https://github.com/chancejs/chancejs</a></p>

<h3 id="toc_8">9. ChartJS</h3>

<p>在 GitHub 上的 Star 将近 40,000 个，提供了 8 种不同类型的数据可视化，每种类型都支持动画和定制。借助 Chart.js，我们可以使用 <canvas> 标签创建简单的 HTML5 图表，而且在所有现代浏览器中都具有出色的渲染性能。</p>

<p>ChartJS - <a href="https://github.com/chartjs/Chart.js">https://github.com/chartjs/Chart.js</a></p>

<h3 id="toc_9">10. Polished</h3>

<p>在 GitHub 上的 Star 超过 3500 个，由 styled-components 团队开发，是一个非常优秀的轻量级工具集，支持使用 JavaScript 编写具有 SASS 风格辅助函数和 mixin 的样式。该库与 styled-components、Aphrodite、Radium 或简单的内联样式兼容。这个库可以在 GitHub 上找到，Bit 社区（非官方）也单独提供所有的功能，因此可以单独安装、导入和使用。</p>

<p>Polished - <a href="https://github.com/styled-components/polished">https://github.com/styled-components/polished</a></p>

<p>Bit 社区提供的单独安装版 - <a href="https://bitsrc.io/ranm8/polished">https://bitsrc.io/ranm8/polished</a></p>

<h3 id="toc_10">11. Mout</h3>

<p>Mout.js 是一组模块化的 JavaScript 库，可以在浏览器或 node.js 中运行，提供类似于其他语言标准库（Python、Ruby、PHP 等）中的辅助方法。mout.js 允许仅加载必需的模块或函数，并提供了一致的 API，规范了跨浏览器行为。</p>

<p>Mout - <a href="https://github.com/mout/mout">https://github.com/mout/mout</a></p>

<p><strong>特别推荐</strong></p>

<h3 id="toc_11">* Bit utils</h3>

<p>一个模块化和高性能的库，已经被用在 Bit 的 web hub 中。这些函数可使用 NPM/Yarn 进行单独安装，用户也可以创建自己的集合，并从不同的库和项目中收集有用的功能。</p>

<p>Bit utils - <a href="https://bitsrc.io/bit/utils">https://bitsrc.io/bit/utils</a></p>

<h3 id="toc_12">* Voca</h3>

<p>一个用于操作字符串的 JavaScript 库。它提供的功能包括大小写转换、trim、pad、slugify、latinise、sprintf、truncate、escape 等。用户可以加载单个函数，以便最小化应用程序的构建。该库具有很高的测试覆盖率，并且不依赖其他库。</p>

<p>Voca - <a href="https://github.com/panzerdp/voca">https://github.com/panzerdp/voca</a></p>

<h3 id="toc_13">* Licia</h3>

<p>只有 400 个 Star，这个有趣的项目基本上是一个简单但有用的 JavaScript 片段集合，具有很高的测试覆盖率，文档也很齐全。</p>

<p>Licia - <a href="https://github.com/liriliri/licia">https://github.com/liriliri/licia</a></p>

<p>感谢<a href="http://www.infoq.com/cn/profile/%E8%A6%83%E4%BA%91">覃云</a>对本文的审校。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[微服务架构—服务降级]]></title>
    <link href="http://panlw.github.io/15325712994221.html"/>
    <updated>2018-07-26T10:14:59+08:00</updated>
    <id>http://panlw.github.io/15325712994221.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://my.oschina.net/yu120/blog/1790398">https://my.oschina.net/yu120/blog/1790398</a></p>
</blockquote>

<h1 id="toc_0">1 简介</h1>

<p>        什么是服务降级？当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作。</p>

<p>        如果还是不理解，那么可以举个栗子：假如目前有很多人想要给我付钱，但我的服务器除了正在运行支付的服务之外，还有一些其它的服务在运行，比如搜索、定时任务和详情等等。然而这些不重要的服务就占用了 JVM 的不少内存与 CPU 资源，为了能把钱都收下来（钱才是目标），我设计了一个动态开关，把这些不重要的服务直接在最外层拒掉，这样处理后的后端处理收钱的服务就有更多的资源来收钱了（收钱速度更快了），这就是一个简单的服务降级的使用场景。</p>

<h1 id="toc_1">2 使用场景</h1>

<p>        服务降级主要用于什么场景呢？当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，我们可以将一些 <strong>不重要</strong> 或 <strong>不紧急</strong> 的服务或任务进行服务的 <strong>延迟使用</strong> 或 <strong>暂停使用</strong>。</p>

<h1 id="toc_2">3 核心设计</h1>

<h2 id="toc_3">3.1 分布式开关</h2>

<p>        根据上述需求，我们可以设置一个分布式开关，用于实现服务的降级，然后集中式管理开关配置信息即可。具体方案如下：</p>

<p><img src="https://static.oschina.net/uploads/space/2018/0406/105147_dBiu_873167.png" alt=""/></p>

<p>服务降级 - 分布式开关</p>

<h2 id="toc_4">3.2 自动降级</h2>

<ul>
<li><p><strong>超时降级</strong> —— 主要配置好超时时间和超时重试次数和机制，并使用异步机制探测恢复情况</p></li>
<li><p><strong>失败次数降级</strong> —— 主要是一些不稳定的 API，当失败调用次数达到一定阀值自动降级，同样要使用异步机制探测回复情况</p></li>
<li><p><strong>故障降级</strong> —— 如要调用的远程服务挂掉了（网络故障、DNS 故障、HTTP 服务返回错误的状态码和 RPC 服务抛出异常），则可以直接降级</p></li>
<li><p><strong>限流降级</strong> —— 当触发了限流超额时，可以使用暂时屏蔽的方式来进行短暂的屏蔽</p></li>
</ul>

<p>        当我们去秒杀或者抢购一些限购商品时，此时可能会因为访问量太大而导致系统崩溃，此时开发者会使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级；降级后的处理方案可以是：排队页面（将用户导流到排队页面等一会重试）、无货（直接告知用户没货了）、错误页（如活动太火爆了，稍后重试）。</p>

<h2 id="toc_5">3.3 配置中心</h2>

<p>        微服务降级的配置信息是集中式的管理，然后通过可视化界面进行友好型的操作。配置中心和应用之间需要网络通信，因此可能会因网络闪断或网络重启等因素，导致配置推送信息丢失、重启或网络恢复后不能再接受、变更不及时等等情况，因此服务降级的配置中心需要实现以下几点特性，从而尽可能的保证配置变更即使达到：</p>

<p><img src="https://static.oschina.net/uploads/space/2018/0406/105300_ygtF_873167.png" alt=""/></p>

<p>服务降级 - 配置中心</p>

<ul>
<li><p><strong>启动主动拉取配置</strong> —— 用于初始化配置（减少第一次定时拉取周期）</p></li>
<li><p><strong>发布订阅配置</strong> —— 用于实现配置及时变更（可以解决 90% 左右的配置变更）</p></li>
<li><p><strong>定时拉取配置</strong> —— 用于解决发布订阅失效或消失丢失的情况（可以解决 9% 左右的发布订阅失效的消息变更）</p></li>
<li><p><strong>离线文件缓存配置</strong> —— 用于临时解决重启后连接不上配置中心的问题</p></li>
<li><p><strong>可编辑式配置文档</strong> —— 用于直接编辑文档的方式来实现配置的定义</p></li>
<li><p><strong>提供 Telnet 命令变更配置</strong> —— 用于解决配置中心失效而不能变更配置的常见</p></li>
</ul>

<h2 id="toc_6">3.4 处理策略</h2>

<p>        当触发服务降级后，新的交易再次到达时，我们该如何来处理这些请求呢？从微服务架构全局的视角来看，我们通常有以下是几种常用的降级处理方案：</p>

<ul>
<li><p><strong>页面降级</strong> —— 可视化界面禁用点击按钮、调整静态页面</p></li>
<li><p><strong>延迟服务</strong> —— 如定时任务延迟处理、消息入 MQ 后延迟处理</p></li>
<li><p><strong>写降级</strong> —— 直接禁止相关写操作的服务请求</p></li>
<li><p><strong>读降级</strong> —— 直接禁止相关度的服务请求</p></li>
<li><p><strong>缓存降级</strong> —— 使用缓存方式来降级部分读频繁的服务接口</p></li>
</ul>

<p>        针对后端代码层面的降级处理策略，则我们通常使用以下几种处理措施进行降级处理：</p>

<ul>
<li><p><strong>抛异常</strong></p></li>
<li><p><strong>返回 NULL</strong></p></li>
<li><p><strong>调用 Mock 数据</strong></p></li>
<li><p><strong>调用 Fallback 处理逻辑</strong></p></li>
</ul>

<h1 id="toc_7">4 高级特性</h1>

<p>        我们已经为每个服务都做好了一个降级开关，也已经在线上验证通过了，感觉完全没问题了。<br/>
<strong>        场景一</strong>：某一天，运营搞了一次活动，突然跑过来说，现在流量已经快涨到上限了，有没有批量降级所有不重要服务的方式？开发一脸懵逼的看着，这又不是操作 DB，哪里有批量操作呀。<br/>
<strong>        场景二</strong>：某一天，运营又搞事了，说我们等下要搞一个活动，让我们赶紧提前把不重要的服务都降级了，开发又是一脸懵逼，我怎么知道要降级哪些服务呀。<br/>
<strong>        反思</strong>：服务降级的功能虽然是实现了，可是没有考虑实施时的体验。服务太多，不知道该降级哪些服务，单个操作降级速度太慢……</p>

<h2 id="toc_8">4.1 分级降级</h2>

<p>        当微服务架构发生不同程度的情况时，我们可以根据服务的对比而进行选择式舍弃（即丢车保帅的原则），从而进一步保障核心的服务的正常运作。</p>

<p>        如果等线上服务即将发生故障时，才去逐个选择哪些服务该降级、哪些服务不能降级，然而线上有成百上千个服务，则肯定是来不及降级就会被拖垮。同时，在大促或秒杀等活动前才去梳理，也是会有不少的工作量，因此建议在开发期就需要架构师或核心开发人员来提前梳理好，是否能降级的初始评估值，即是否能降级的默认值。</p>

<p>        为了便于批量操作微服务架构中服务的降级，我们可以从全局的角度来建立服务重要程度的评估模型，如果有条件的话，建议可以使用 <strong>层次分析法（The analytic hierarchy process，简称 AHP）</strong> 的数学建模模型（或其它模型）来进行定性和定量的评估（肯定比架构师直接拍脑袋决定是否降级好很多倍，当然难度和复杂度也会高许多，即你需要一个会数学建模人才），而层次分析法的基本思路是人对一个复杂的决策问题的思维和判断过程大体上是一样的。</p>

<p>        以下是个人给出的最终评价模型，可作为服务降级的评价参考模型进行设计：</p>

<p>        我们利用数学建模的方式或架构师直接拍脑袋的方式，结合服务能否降级的优先原则，并根据台风预警（都属于风暴预警）的等级进行参考设计，可将微服务架构的所有服务进行故障风暴等级划分为以下四种：</p>

<p><strong>评估模型</strong>：</p>

<ul>
<li><p><strong>蓝色风暴</strong> —— 表示需要小规模降级非核心服务</p></li>
<li><p><strong>黄色风暴</strong> —— 表示需要中等规模降级非核心服务</p></li>
<li><p><strong>橙色风暴</strong> —— 表示需要大规模降级非核心服务</p></li>
<li><p><strong>红色风暴</strong> —— 表示必须降级所有非核心服务</p></li>
</ul>

<p><strong>设计说明</strong>：</p>

<ul>
<li><p>故障严重程度为：蓝色＜黄色＜橙色＜红色</p></li>
<li><p>建议根据二八原则可以将服务划分为：80% 的非核心服务 + 20% 的核心服务</p></li>
</ul>

<p>        以上模型只是整体微服务架构的服务降级评估模型，具体大促或秒杀活动时，建议以具体主题为中心进行建立（不同主题的活动，因其依赖的服务不同，而使用不同的进行降级更为合理）。当然模型可以使用同一个，但其数据需要有所差异。最好能建立一套模型库，然后实施时只需要输入相关服务即可输出最终降级方案，即输出本次大促或秒杀时，当发生蓝色风暴时需要降级的服务清单、当发生黄色风暴时需要降级的服务清单……</p>

<h2 id="toc_9">4.2 降级权值</h2>

<p>        微服务架构中有服务权值的概念，主要用于负载时的权重选择，同样服务降级权值也是类似，<strong>主要用于服务降级选择时的细粒度优先级抉择</strong>。所有的服务直接使用以上简单的四级划分方式进行统一处理，显然粒度太粗，或者说出于同一级的多个服务需要降级时的 <strong>降级顺序</strong> 该如何？甚至我想要人工智能化的 <strong>自动降级</strong>，又该如何更细粒度的控制？</p>

<p>        基于上述的这些 AI 化的需求，我们可以为每一个服务分配一个降级权值，从而便于更加智能化的实现服务治理。而其评估的数值，同样也可以使用数学模型的方式进行 <strong>定性</strong> 与 <strong>定量</strong> 的评估出来，也可以架构师根据经验直接拍脑袋来确定。</p>

<h1 id="toc_10">5 总结与展望</h1>

<p>        以上提供了半实际与半理论的服务降级方案，使用者可以根据其公司的实际情况进行适当的选择，而完整的方案，笔者目前也没有发现有实施过的，但可以建议有长远服务治理规划的大厂进行完整方案的研究与实施，会对未来人工智能万物互联的时代有较好的治理价值存在（个人看法）。而小厂出于成本和其发挥的价值的考虑，不建议使用这么复杂的方案，但可以实现分布式开关和简单分级降级的功能特性。</p>

<p>        本文主要以服务降级为核心进行更加理想的治理微服务架构，其中建议运用数学领域的适当模型来实现 <strong>定性</strong> 和 <strong>定量</strong> 的合理分析和治理微服务，为未来 <strong>人工智能治理微服务</strong>（Artificial Intelligence Governance Micro Service，简称 AIGMS）提供方案支持。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[通俗易懂的 Redis 数据结构基础教程]]></title>
    <link href="http://panlw.github.io/15323949340201.html"/>
    <updated>2018-07-24T09:15:34+08:00</updated>
    <id>http://panlw.github.io/15323949340201.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="https://juejin.im/post/5b53ee7e5188251aaa2d2e16">https://juejin.im/post/5b53ee7e5188251aaa2d2e16</a></p>

<p><img src="media/15323949340201/15323950551611.jpg" alt=""/></p>
</blockquote>

<p>Redis 有 5 个基本数据结构，string、list、hash、set 和 zset。它们是日常开发中使用频率非常高应用最为广泛的数据结构，把这 5 个数据结构都吃透了，你就掌握了 Redis 应用知识的一半了。</p>

<h2 id="toc_0">string</h2>

<p><img src="media/15323949340201/15323950630668.jpg" alt=""/></p>

<p>首先我们从 string 谈起。string 表示的是一个可变的字节数组，我们初始化字符串的内容、可以拿到字符串的长度，可以获取 string 的字串，可以覆盖 string 的字串内容，可以追加子串。</p>

<p><strong>初始化字符串</strong> 需要提供「变量名称」和「变量的内容」</p>

<pre><code>&gt; set ireader beijing.zhangyue.keji.gufen.youxian.gongsi
OK
复制代码
</code></pre>

<p><strong>获取字符串的内容</strong> 提供「变量名称」</p>

<pre><code>&gt; get ireader
&quot;beijing.zhangyue.keji.gufen.youxian.gongsi&quot;
复制代码
</code></pre>

<p><strong>获取字符串的长度</strong> 提供「变量名称」</p>

<pre><code>&gt; strlen ireader
(integer) 42
复制代码
</code></pre>

<p><strong>获取子串</strong> 提供「变量名称」以及开始和结束位置 [start, end]</p>

<pre><code>&gt; getrange ireader 28 34
&quot;youxian&quot;
复制代码
</code></pre>

<p><strong>覆盖子串</strong> 提供「变量名称」以及开始位置和目标子串</p>

<pre><code>&gt; setrange ireader 28 wooxian
(integer) 42  # 返回长度
&gt; get ireader
&quot;beijing.zhangyue.keji.gufen.wooxian.gongsi&quot;
复制代码
</code></pre>

<p><strong>追加子串</strong></p>

<pre><code>&gt; append ireader .hao
(integer) 46 # 返回长度
&gt; get ireader
&quot;beijing.zhangyue.keji.gufen.wooxian.gongsi.hao&quot;
复制代码
</code></pre>

<p>遗憾的是字符串没有提供字串插入方法和子串删除方法。</p>

<p><strong>计数器</strong> 如果字符串的内容是一个整数，那么还可以将字符串当成计数器来使用。</p>

<pre><code>&gt; set ireader 42
OK
&gt; get ireader
&quot;42&quot;
&gt; incrby ireader 100
(integer) 142
&gt; get ireader
&quot;142&quot;
&gt; decrby ireader 100
(integer) 42
&gt; get ireader
&quot;42&quot;
&gt; incr ireader  # 等价于incrby ireader 1
(integer) 143
&gt; decr ireader  # 等价于decrby ireader 1
(integer) 142
复制代码
</code></pre>

<p>计数器是有范围的，它不能超过 Long.Max，不能低于 Long.MIN</p>

<pre><code>&gt; set ireader 9223372036854775807
OK
&gt; incr ireader
(error) ERR increment or decrement would overflow
&gt; set ireader -9223372036854775808
OK
&gt; decr ireader
(error) ERR increment or decrement would overflow
复制代码
</code></pre>

<p><strong>过期和删除</strong> 字符串可以使用 del 指令进行主动删除，可以使用 expire 指令设置过期时间，到点会自动删除，这属于被动删除。可以使用 ttl 指令获取字符串的寿命。</p>

<pre><code>&gt; expire ireader 60
(integer) 1  # 1表示设置成功，0表示变量ireader不存在
&gt; ttl ireader
(integer) 50  # 还有50秒的寿命，返回-2表示变量不存在，-1表示没有设置过期时间
&gt; del ireader
(integer) 1  # 删除成功返回1
&gt; get ireader
(nil)  # 变量ireader没有了
复制代码
</code></pre>

<h2 id="toc_1">list</h2>

<p><img src="media/15323949340201/15323950770201.jpg" alt=""/></p>

<p>Redis 将列表数据结构命名为 list 而不是 array，是因为列表的存储结构用的是链表而不是数组，而且链表还是双向链表。因为它是链表，所以随机定位性能较弱，首尾插入删除性能较优。如果 list 的列表长度很长，使用时我们一定要关注链表相关操作的时间复杂度。</p>

<p><strong>负下标</strong> 链表元素的位置使用自然数<code>0,1,2,....n-1</code>表示，还可以使用负数<code>-1,-2,...-n</code>来表示，<code>-1</code>表示「倒数第一」，<code>-2</code>表示「倒数第二」，那么<code>-n</code>就表示第一个元素，对应的下标为<code>0</code>。</p>

<p><strong>队列／堆栈</strong> 链表可以从表头和表尾追加和移除元素，结合使用 rpush/rpop/lpush/lpop 四条指令，可以将链表作为队列或堆栈使用，左向右向进行都可以</p>

<pre><code># 右进左出
&gt; rpush ireader go
(integer) 1
&gt; rpush ireader java python
(integer) 3
&gt; lpop ireader
&quot;go&quot;
&gt; lpop ireader
&quot;java&quot;
&gt; lpop ireader
&quot;python&quot;
# 左进右出
&gt; lpush ireader go java python
(integer) 3
&gt; rpop ireader
&quot;go&quot;
...
# 右进右出
&gt; rpush ireader go java python
(integer) 3
&gt; rpop ireader 
&quot;python&quot;
...
# 左进左出
&gt; lpush ireader go java python
(integer) 3
&gt; lpop ireader
&quot;python&quot;
...
复制代码
</code></pre>

<p>在日常应用中，列表常用来作为异步队列来使用。</p>

<p><strong>长度</strong> 使用 llen 指令获取链表长度</p>

<pre><code>&gt; rpush ireader go java python
(integer) 3
&gt; llen ireader
(integer) 3
复制代码
</code></pre>

<p><strong>随机读</strong> 可以使用 lindex 指令访问指定位置的元素，使用 lrange 指令来获取链表子元素列表，提供 start 和 end 下标参数</p>

<pre><code>&gt; rpush ireader go java python
(integer) 3
&gt; lindex ireader 1
&quot;java&quot;
&gt; lrange ireader 0 2
1) &quot;go&quot;
2) &quot;java&quot;
3) &quot;python&quot;
&gt; lrange ireader 0 -1  # -1表示倒数第一
1) &quot;go&quot;
2) &quot;java&quot;
3) &quot;python&quot;
复制代码
</code></pre>

<p>使用 lrange 获取全部元素时，需要提供 end_index，如果没有负下标，就需要首先通过 llen 指令获取长度，才可以得出 end_index 的值，有了负下标，使用 - 1 代替 end_index 就可以达到相同的效果。</p>

<p><strong>修改元素</strong> 使用 lset 指令在指定位置修改元素。</p>

<pre><code>&gt; rpush ireader go java python
(integer) 3
&gt; lset ireader 1 javascript
OK
&gt; lrange ireader 0 -1
1) &quot;go&quot;
2) &quot;javascript&quot;
3) &quot;python&quot;
复制代码
</code></pre>

<p><strong>插入元素</strong> 使用 linsert 指令在列表的中间位置插入元素，有经验的程序员都知道在插入元素时，我们经常搞不清楚是在指定位置的前面插入还是后面插入，所以 antirez 在 linsert 指令里增加了方向参数 before/after 来显示指示前置和后置插入。不过让人意想不到的是 linsert 指令并不是通过指定位置来插入，而是通过指定具体的值。这是因为在分布式环境下，列表的元素总是频繁变动的，意味着上一时刻计算的元素下标在下一时刻可能就不是你所期望的下标了。</p>

<pre><code>&gt; rpush ireader go java python
(integer) 3
&gt; linsert ireader before java ruby
(integer) 4
&gt; lrange ireader 0 -1
1) &quot;go&quot;
2) &quot;ruby&quot;
3) &quot;java&quot;
4) &quot;python&quot;
复制代码
</code></pre>

<p>到目前位置，我还没有在实际应用中发现插入指定的应用场景。</p>

<p><strong>删除元素</strong> 列表的删除操作也不是通过指定下标来确定元素的，你需要指定删除的最大个数以及元素的值</p>

<pre><code>&gt; rpush ireader go java python
(integer) 3
&gt; lrem ireader 1 java
(integer) 1
&gt; lrange ireader 0 -1
1) &quot;go&quot;
2) &quot;java&quot;
复制代码
</code></pre>

<p><strong>定长列表</strong> 在实际应用场景中，我们有时候会遇到「定长列表」的需求。比如要以走马灯的形式实时显示中奖用户名列表，因为中奖用户实在太多，能显示的数量一般不超过 100 条，那么这里就会使用到定长列表。维持定长列表的指令是 ltrim，需要提供两个参数 start 和 end，表示需要保留列表的下标范围，范围之外的所有元素都将被移除。</p>

<pre><code>&gt; rpush ireader go java python javascript ruby erlang rust cpp
(integer) 8
&gt; ltrim ireader -3 -1
OK
&gt; lrange ireader 0 -1
1) &quot;erlang&quot;
2) &quot;rust&quot;
3) &quot;cpp&quot;
复制代码
</code></pre>

<p>如果指定参数的 end 对应的真实下标小于 start，其效果等价于 del 指令，因为这样的参数表示需要需要保留列表元素的下标范围为空。</p>

<h2 id="toc_2">hash</h2>

<p><img src="media/15323949340201/15323950947257.jpg" alt=""/></p>

<p>哈希等价于 Java 语言的 HashMap 或者是 Python 语言的 dict，在实现结构上它使用二维结构，第一维是数组，第二维是链表，hash 的内容 key 和 value 存放在链表中，数组里存放的是链表的头指针。通过 key 查找元素时，先计算 key 的 hashcode，然后用 hashcode 对数组的长度进行取模定位到链表的表头，再对链表进行遍历获取到相应的 value 值，链表的作用就是用来将产生了「hash 碰撞」的元素串起来。Java 语言开发者会感到非常熟悉，因为这样的结构和 HashMap 是没有区别的。哈希的第一维数组的长度也是 2<sup>n。</sup></p>

<p><img src="media/15323949340201/15323951077108.jpg" alt=""/></p>

<p><strong>增加元素</strong> 可以使用 hset 一次增加一个键值对，也可以使用 hmset 一次增加多个键值对</p>

<pre><code>&gt; hset ireader go fast
(integer) 1
&gt; hmset ireader java fast python slow
OK
复制代码
</code></pre>

<p><strong>获取元素</strong> 可以通过 hget 定位具体 key 对应的 value，可以通过 hmget 获取多个 key 对应的 value，可以使用 hgetall 获取所有的键值对，可以使用 hkeys 和 hvalues 分别获取所有的 key 列表和 value 列表。这些操作和 Java 语言的 Map 接口是类似的。</p>

<pre><code>&gt; hmset ireader go fast java fast python slow
OK
&gt; hget ireader go
&quot;fast&quot;
&gt; hmget ireader go python
1) &quot;fast&quot;
2) &quot;slow&quot;
&gt; hgetall ireader
1) &quot;go&quot;
2) &quot;fast&quot;
3) &quot;java&quot;
4) &quot;fast&quot;
5) &quot;python&quot;
6) &quot;slow&quot;
&gt; hkeys ireader
1) &quot;go&quot;
2) &quot;java&quot;
3) &quot;python&quot;
&gt; hvals ireader
1) &quot;fast&quot;
2) &quot;fast&quot;
3) &quot;slow&quot;
复制代码
</code></pre>

<p><strong>删除元素</strong> 可以使用 hdel 删除指定 key，hdel 支持同时删除多个 key</p>

<pre><code>&gt; hmset ireader go fast java fast python slow
OK
&gt; hdel ireader go
(integer) 1
&gt; hdel ireader java python
(integer) 2
复制代码
</code></pre>

<p><strong>判断元素是否存在</strong> 通常我们使用 hget 获得 key 对应的 value 是否为空就直到对应的元素是否存在了，不过如果 value 的字符串长度特别大，通过这种方式来判断元素存在与否就略显浪费，这时可以使用 hexists 指令。</p>

<pre><code>&gt; hmset ireader go fast java fast python slow
OK
&gt; hexists ireader go
(integer) 1
复制代码
</code></pre>

<p><strong>计数器</strong> hash 结构还可以当成计数器来使用，对于内部的每一个 key 都可以作为独立的计数器。如果 value 值不是整数，调用 hincrby 指令会出错。</p>

<pre><code>&gt; hincrby ireader go 1
(integer) 1
&gt; hincrby ireader python 4
(integer) 4
&gt; hincrby ireader java 4
(integer) 4
&gt; hgetall ireader
1) &quot;go&quot;
2) &quot;1&quot;
3) &quot;python&quot;
4) &quot;4&quot;
5) &quot;java&quot;
6) &quot;4&quot;
&gt; hset ireader rust good
(integer) 1
127.0.0.1:6379&gt; hincrby ireader rust 1
(error) ERR hash value is not an integer
复制代码
</code></pre>

<p><strong>扩容</strong> 当 hash 内部的元素比较拥挤时 (hash 碰撞比较频繁)，就需要进行扩容。扩容需要申请新的两倍大小的数组，然后将所有的键值对重新分配到新的数组下标对应的链表中 (rehash)。如果 hash 结构很大，比如有上百万个键值对，那么一次完整 rehash 的过程就会耗时很长。这对于单线程的 Redis 里来说有点压力山大。所以 Redis 采用了渐进式 rehash 的方案。它会同时保留两个新旧 hash 结构，在后续的定时任务以及 hash 结构的读写指令中将旧结构的元素逐渐迁移到新的结构中。这样就可以避免因扩容导致的线程卡顿现象。</p>

<p><strong>缩容</strong> Redis 的 hash 结构不但有扩容还有缩容，从这一点出发，它要比 Java 的 HashMap 要厉害一些，Java 的 HashMap 只有扩容。缩容的原理和扩容是一致的，只不过新的数组大小要比旧数组小一倍。</p>

<h2 id="toc_3">set</h2>

<p>Java 程序员都知道 HashSet 的内部实现使用的是 HashMap，只不过所有的 value 都指向同一个对象。Redis 的 set 结构也是一样，它的内部也使用 hash 结构，所有的 value 都指向同一个内部值。</p>

<p><strong>增加元素</strong> 可以一次增加多个元素</p>

<pre><code>&gt; sadd ireader go java python
(integer) 3
复制代码
</code></pre>

<p><strong>读取元素</strong> 使用 smembers 列出所有元素，使用 scard 获取集合长度，使用 srandmember 获取随机 count 个元素，如果不提供 count 参数，默认为 1</p>

<pre><code>&gt; sadd ireader go java python
(integer) 3
&gt; smembers ireader
1) &quot;java&quot;
2) &quot;python&quot;
3) &quot;go&quot;
&gt; scard ireader
(integer) 3
&gt; srandmember ireader
&quot;java&quot;
复制代码
</code></pre>

<p><strong>删除元素</strong> 使用 srem 删除一到多个元素，使用 spop 删除随机一个元素</p>

<pre><code>&gt; sadd ireader go java python rust erlang
(integer) 5
&gt; srem ireader go java
(integer) 2
&gt; spop ireader
&quot;erlang&quot;
复制代码
</code></pre>

<p><strong>判断元素是否存在</strong> 使用 sismember 指令，只能接收单个元素</p>

<pre><code>&gt; sadd ireader go java python rust erlang
(integer) 5
&gt; sismember ireader rust
(integer) 1
&gt; sismember ireader javascript
(integer) 0
复制代码
</code></pre>

<h2 id="toc_4">sortedset</h2>

<p><img src="media/15323949340201/15323951222864.jpg" alt=""/></p>

<p>SortedSet(zset) 是 Redis 提供的一个非常特别的数据结构，一方面它等价于 Java 的数据结构<code>Map&lt;String, Double&gt;</code>，可以给每一个元素 value 赋予一个权重<code>score</code>，另一方面它又类似于<code>TreeSet</code>，内部的元素会按照权重 score 进行排序，可以得到每个元素的名次，还可以通过 score 的范围来获取元素的列表。</p>

<p>zset 底层实现使用了两个数据结构，第一个是 hash，第二个是跳跃列表，hash 的作用就是关联元素 value 和权重 score，保障元素 value 的唯一性，可以通过元素 value 找到相应的 score 值。跳跃列表的目的在于给元素 value 排序，根据 score 的范围获取元素列表。</p>

<p><strong>增加元素</strong> 通过 zadd 指令可以增加一到多个 value/score 对，score 放在前面</p>

<pre><code>&gt; zadd ireader 4.0 python
(integer) 1
&gt; zadd ireader 4.0 java 1.0 go
(integer) 2
复制代码
</code></pre>

<p><strong>长度</strong> 通过指令 zcard 可以得到 zset 的元素个数</p>

<pre><code>&gt; zcard ireader
(integer) 3
复制代码
</code></pre>

<p><strong>删除元素</strong> 通过指令 zrem 可以删除 zset 中的元素，可以一次删除多个</p>

<pre><code>&gt; zrem ireader go python
(integer) 2
复制代码
</code></pre>

<p><strong>计数器</strong> 同 hash 结构一样，zset 也可以作为计数器使用。</p>

<pre><code>&gt; zadd ireader 4.0 python 4.0 java 1.0 go
(integer) 3
&gt; zincrby ireader 1.0 python
&quot;5&quot;
复制代码
</code></pre>

<p><strong>获取排名和分数</strong> 通过 zscore 指令获取指定元素的权重，通过 zrank 指令获取指定元素的正向排名，通过 zrevrank 指令获取指定元素的反向排名 [倒数第一名]。正向是由小到大，负向是由大到小。</p>

<pre><code>&gt; zscore ireader python
&quot;5&quot;
&gt; zrank ireader go  # 分数低的排名考前，rank值小
(integer) 0
&gt; zrank ireader java
(integer) 1
&gt; zrank ireader python
(integer) 2
&gt; zrevrank ireader python
(integer) 0
复制代码
</code></pre>

<p><strong>根据排名范围获取元素列表</strong> 通过 zrange 指令指定排名范围参数获取对应的元素列表，携带 withscores 参数可以一并获取元素的权重。通过 zrevrange 指令按负向排名获取元素列表 [倒数]。正向是由小到大，负向是由大到小。</p>

<pre><code>&gt; zrange ireader 0 -1  # 获取所有元素
1) &quot;go&quot;
2) &quot;java&quot;
3) &quot;python&quot;
127.0.0.1:6379&gt; zrange ireader 0 -1 withscores
1) &quot;go&quot;
2) &quot;1&quot;
3) &quot;java&quot;
4) &quot;4&quot;
5) &quot;python&quot;
6) &quot;5&quot;
&gt; zrevrange ireader 0 -1 withscores
1) &quot;python&quot;
2) &quot;5&quot;
3) &quot;java&quot;
4) &quot;4&quot;
5) &quot;go&quot;
6) &quot;1&quot;
复制代码
</code></pre>

<p><strong>根据 score 范围获取列表</strong> 通过 zrangebyscore 指令指定 score 范围获取对应的元素列表。通过 zrevrangebyscore 指令获取倒排元素列表。正向是由小到大，负向是由大到小。参数<code>-inf</code>表示负无穷，<code>+inf</code>表示正无穷。</p>

<pre><code>&gt; zrangebyscore ireader 0 5
1) &quot;go&quot;
2) &quot;java&quot;
3) &quot;python&quot;
&gt; zrangebyscore ireader -inf +inf withscores
1) &quot;go&quot;
2) &quot;1&quot;
3) &quot;java&quot;
4) &quot;4&quot;
5) &quot;python&quot;
6) &quot;5&quot;
&gt; zrevrangebyscore ireader +inf -inf withscores  # 注意正负反过来了
1) &quot;python&quot;
2) &quot;5&quot;
3) &quot;java&quot;
4) &quot;4&quot;
5) &quot;go&quot;
6) &quot;1&quot;
复制代码
</code></pre>

<p><strong>根据范围移除元素列表</strong> 可以通过排名范围，也可以通过 score 范围来一次性移除多个元素</p>

<pre><code>&gt; zremrangebyrank ireader 0 1
(integer) 2  # 删掉了2个元素
&gt; zadd ireader 4.0 java 1.0 go
(integer) 2
&gt; zremrangebyscore ireader -inf 4
(integer) 2
&gt; zrange ireader 0 -1
1) &quot;python&quot;
复制代码
</code></pre>

<p><strong>跳跃列表</strong> zset 内部的排序功能是通过「跳跃列表」数据结构来实现的，它的结构非常特殊，也比较复杂。这一块的内容深度读者要有心理准备。</p>

<p>因为 zset 要支持随机的插入和删除，所以它不好使用数组来表示。我们先看一个普通的链表结构。</p>

<p><img src="media/15323949340201/15323951426599.jpg" alt=""/></p>

<p>我们需要这个链表按照 score 值进行排序。这意味着当有新元素需要插入时，需要定位到特定位置的插入点，这样才可以继续保证链表是有序的。通常我们会通过二分查找来找到插入点，但是二分查找的对象必须是数组，只有数组才可以支持快速位置定位，链表做不到，那该怎么办？</p>

<p>想想一个创业公司，刚开始只有几个人，团队成员之间人人平等，都是联合创始人。随着公司的成长，人数渐渐变多，团队沟通成本随之增加。这时候就会引入组长制，对团队进行划分。每个团队会有一个组长。开会的时候分团队进行，多个组长之间还会有自己的会议安排。公司规模进一步扩展，需要再增加一个层级——部门，每个部门会从组长列表中推选出一个代表来作为部长。部长们之间还会有自己的高层会议安排。</p>

<p>跳跃列表就是类似于这种层级制，最下面一层所有的元素都会串起来。然后每隔几个元素挑选出一个代表来，再将这几个代表使用另外一级指针串起来。然后在这些代表里再挑出二级代表，再串起来。最终就形成了金字塔结构。</p>

<p>想想你老家在世界地图中的位置：亚洲 --&gt; 中国 -&gt; 安徽省 -&gt; 安庆市 -&gt; 枞阳县 -&gt; 汤沟镇 -&gt; 田间村 -&gt;xxxx 号，也是这样一个类似的结构。</p>

<p><img src="media/15323949340201/15323951514093.jpg" alt=""/></p>

<p>「跳跃列表」之所以「跳跃」，是因为内部的元素可能「身兼数职」，比如上图中间的这个元素，同时处于 L0、L1 和 L2 层，可以快速在不同层次之间进行「跳跃」。</p>

<p>定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。你也许会问那新插入的元素如何才有机会「身兼数职」呢？</p>

<p>跳跃列表采取一个随机策略来决定新元素可以兼职到第几层，首先 L0 层肯定是 100% 了，L1 层只有 50% 的概率，L2 层只有 25% 的概率，L3 层只有 12.5% 的概率，一直随机到最顶层 L31 层。绝大多数元素都过不了几层，只有极少数元素可以深入到顶层。列表中的元素越多，能够深入的层次就越深，能进入到顶层的概率就会越大。</p>

<p>这还挺公平的，能不能进入中央不是靠拼爹，而是看运气。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Formatting Java Time with Spring Boot using JSON]]></title>
    <link href="http://panlw.github.io/15323511610918.html"/>
    <updated>2018-07-23T21:06:01+08:00</updated>
    <id>http://panlw.github.io/15323511610918.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://lewandowski.io/2016/02/formatting-java-time-with-spring-boot-using-json/">http://lewandowski.io/2016/02/formatting-java-time-with-spring-boot-using-json/</a></p>
</blockquote>

<p><strong>The aim of this post is to summarize and review ways of formatting Java Time objects using Spring Boot and Jackson library.</strong></p>

<p>This post is organized in five steps. Each step represents one aspect of the issue and it is also related to one commit in example project repository.</p>

<h2 id="toc_0"><a href="#Step-0-Prerequirements" title="Step 0 - Prerequirements"></a>Step 0 - Prerequirements</h2>

<h3 id="toc_1"><a href="#Versions-and-dependencies" title="Versions and dependencies"></a>Versions and dependencies</h3>

<p>This tutorial is based on <code>Spring Boot</code> version <code>1.3.1.RELEASE</code> with <code>spring-boot-starter-web</code>. It uses <code>jackson-datatype-jsr310</code> from <code>com.fasterxml.jackson.datatype</code> in version <code>2.6.4</code>, which is a default version of <code>Spring Boot</code>. All of these is based on Java 8.</p>

<h3 id="toc_2"><a href="#The-Code" title="The Code"></a>The Code</h3>

<p>In the example <a href="https://github.com/mlevvy/spring-boot-json-dates">code repository</a>, you can find one HTTP service made with <code>Spring Boot</code>. This service is a <code>GET</code> operation, which returns a class with Java Time objects.<br/>
You can also find the integration test that deserializes the response.</p>

<h2 id="toc_3"><a href="#Step-1-The-goal" title="Step 1 - The goal"></a>Step 1 - The goal</h2>

<p>I would like to return class <code>Clock</code>, containing <code>LocalDate</code>,<code>LocalTime</code> and <code>LocalDateTime</code>, preinitialized in constructor.</p>

<p><em>Clock - Service response class</em></p>

<pre><code class="language-java">public final class Clock {
    private final LocalDate localDate;
    private final LocalTime localTime;
    private final LocalDateTime localDateTime;
    ...
}
</code></pre>

<p>Response class is serialized to JSON Map, which is a default behaviour. To some extent it is correct, but ISO formatted Strings in response are preferable.</p>

<p><em>LocalDate - response as JSON Map</em></p>

<pre><code class="language-json">{  
   &quot;localDate&quot;:{  
      &quot;year&quot;:2016,
      &quot;month&quot;:&quot;JANUARY&quot;,
      &quot;era&quot;:&quot;CE&quot;,
      &quot;dayOfYear&quot;:1,
      &quot;dayOfWeek&quot;:&quot;FRIDAY&quot;,
      &quot;leapYear&quot;:true,
      &quot;dayOfMonth&quot;:1,
      &quot;monthValue&quot;:1,
      &quot;chronology&quot;:{  
         &quot;id&quot;:&quot;ISO&quot;,
         &quot;calendarType&quot;:&quot;iso8601&quot;
      }
   }
}
</code></pre>

<p>Unfortunately, tests are not passing, because of deserialization problems. The exception with message is thrown <code>can not instantiate from JSON object</code>.</p>

<h2 id="toc_4"><a href="#Step-2-Adds-serialization" title="Step 2 - Adds serialization"></a>Step 2 - Adds serialization</h2>

<p>First things first. We have to add JSR-310 module. It is a datatype module to make <a href="http://jackson.codehaus.org">Jackson</a> recognize Java 8 Date &amp; Time API data types.</p>

<p>Note that in this example <code>jackson-datatype-jsr310</code> version is inherited from <code>spring-boot-dependencies</code> dependency management.</p>

<p><em>Dependency in pom.xml</em></p>

<pre><code class="language-xml">&lt;dependency&gt;
  &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt;
  &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>

<p>Response is now consistent but still, not perfect. Dates are serialized as numbers:</p>

<p><em>Dates serialized to numbers and integers</em></p>

<pre><code class="language-json">{  
   &quot;version&quot;:2,
   &quot;localDate&quot;:[  
      2016,
      1,
      1
   ],
   &quot;localTime&quot;:[  
      10,
      24
   ],
   &quot;localDateTime&quot;:[  
      2016,
      1,
      1,
      10,
      24
   ],
   &quot;zonedDateTime&quot;:1451640240.000000000
}
</code></pre>

<p>We are one step closer to our goal. Tests are passing now because this format can deserialized without any additional deserializers.<br/>
How do I know?<br/>
Start an application server on commit <code>Step 2 - Adds Object Mapper</code>, then checkout to <code>Step 1 - Introduce types and problems</code>, and run integration tests without <code>@WebIntegrationTest</code> annotation.</p>

<h2 id="toc_5"><a href="#Step-3-Enables-ISO-formatting" title="Step 3 - Enables ISO formatting"></a>Step 3 - Enables ISO formatting</h2>

<p><a href="https://en.wikipedia.org/wiki/ISO_8601">ISO 8601</a> formatting is a standard. I’ve found it in many projects. We are going to enable and use it.<br/>
Edit spring boot properties file <code>application.properties</code> and add the following line:</p>

<p><em>application.properties file - disabling timestamps write</em></p>

<pre><code class="language-properties">spring.jackson.serialization.WRITE_DATES_AS_TIMESTAMPS = false
</code></pre>

<h2 id="toc_6"><a href="#Step-4-Adds-on-demand-formatting-pattern" title="Step 4 - Adds on demand formatting pattern"></a>Step 4 - Adds on demand formatting pattern</h2>

<p>Imagine one of your client systems does not have a capability of formatting time. It may be a primitive device, or microservice that treats this date as a collection of characters. That is why special formatting is required.</p>

<p>We can change formatting in response class by adding <code>JsonFormat</code> annotation with pattern parameter. Standard <a href="https://docs.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html">SimpleDateFormat</a> rules apply.</p>

<p><em>Using <code>@JsonFormat</code> annotation</em></p>

<pre><code class="language-java">@JsonFormat(pattern = &quot;dd::MM::yyyy&quot;)
private final LocalDate localDate;
@JsonFormat(pattern = &quot;KK:mm a&quot;)
private final LocalTime localTime;
</code></pre>

<p>Below there is a service response using custom <code>@JsonFormat</code> pattern:</p>

<p><em>Custom response style</em></p>

<pre><code>{  
   &quot;version&quot;:2,
   &quot;localDate&quot;:&quot;01::01::2016&quot;,
   &quot;localTime&quot;:&quot;10:24 AM&quot;,
   &quot;localDateTime&quot;:&quot;2016-01-01T10:24&quot;,
   &quot;zonedDateTime&quot;:&quot;2016-01-01T10:24:00+01:00&quot;
}
</code></pre>

<p>Our tests are still passing. It means that this pattern is used for serialization in service and deserialization in tests.</p>

<h2 id="toc_7"><a href="#Step-5-Globally-changes-formatting" title="Step 5 - Globally changes formatting"></a>Step 5 - Globally changes formatting</h2>

<p>There are situations where you have to resign from <code>ISO 8601</code> formatting in your whole application, and apply custom made standards.</p>

<p>In this part, we will redefine format pattern for LocalDate. This will change formatting of LocalDate in <strong>every endpoint</strong> of your API.</p>

<p>We have to define:</p>

<ul>
<li>  <code>DateTimeFormatter</code> with our pattern.</li>
<li>  <code>Serializer</code> using defined pattern.</li>
<li>  <code>Deserializer</code> using defined pattern.</li>
<li>  <code>ObjectMapper</code> bean with custom serializer and deserializer.</li>
<li>  <code>RestTemplate</code> that uses our <code>ObjectMapper</code>.</li>
</ul>

<p>Bean ObjectMapper is defined with annotation <code>@Primary</code>, to override default configuration.<br/>
My custom pattern for <code>LocalDate</code> is <code>dd::MM::yyyy</code></p>

<p><em>Object mapper bean with custom pattern</em></p>

<pre><code class="language-java">public static final DateTimeFormatter FORMATTER = ofPattern(&quot;dd::MM::yyyy&quot;);
@Bean
@Primary
public ObjectMapper serializingObjectMapper() {
    ObjectMapper objectMapper = new ObjectMapper();
    JavaTimeModule javaTimeModule = new JavaTimeModule();
    javaTimeModule.addSerializer(LocalDate.class, new LocalDateSerializer());
    javaTimeModule.addDeserializer(LocalDate.class, new LocalDateDeserializer());
    objectMapper.registerModule(javaTimeModule);
    return objectMapper;
}
</code></pre>

<p>Definitions of serializer and deserializer for all LocalDate classes:</p>

<p><em>Custom serializer and deserializer</em></p>

<pre><code class="language-java">public class LocalDateSerializer extends JsonSerializer&lt;LocalDate&gt; {
    @Override
    public void serialize(LocalDate value, JsonGenerator gen, SerializerProvider serializers) throws IOException {
        gen.writeString(value.format(FORMATTER));
    }
}
public class LocalDateDeserializer extends JsonDeserializer&lt;LocalDate&gt; {
    @Override
    public LocalDate deserialize(JsonParser p, DeserializationContext ctxt) throws IOException {
        return LocalDate.parse(p.getValueAsString(), FORMATTER);
    }
}
</code></pre>

<p>Now, the response is formatted with our custom pattern:</p>

<p><em>Formatted response</em></p>

<pre><code class="language-json">{  
   &quot;localDate&quot;:&quot;01::01::2016&quot;
}
</code></pre>

<h3 id="toc_8"><a href="#Tests" title="Tests"></a>Tests</h3>

<p>When we define custom serializer, our tests start to fail. It is because RestTemplate knows nothing about our deserializer. We have to create custom RestTemplateFactory that creates RestTemplate with object mapper containing our deserializer.</p>

<p><em>Custom RestTemplateFactory</em></p>

<pre><code class="language-java">@Configuration
public class RestTemplateFactory {
    @Autowired
    private ObjectMapper objectMapper;
    @Bean
    public RestTemplate createRestTemplate() {
        RestTemplate restTemplate = new RestTemplate();
        List&lt;HttpMessageConverter&lt;?&gt;&gt; converters = new ArrayList&lt;&gt;();
        MappingJackson2HttpMessageConverter jsonConverter = new MappingJackson2HttpMessageConverter();
        jsonConverter.setObjectMapper(objectMapper);
        converters.add(jsonConverter);
        restTemplate.setMessageConverters(converters);
        return restTemplate;
    }
}
</code></pre>

<h2 id="toc_9"><a href="#Conclusion" title="Conclusion"></a>Conclusion</h2>

<p>Custom formatting Dates is relatively simple, but you have to know how to set up it. Luckily, <code>Jackson</code> works smoothly with <code>Spring</code>. If you know other ways of solving this problem or you have other observations, please comment or let me know.</p>

<p>Photo credits: <a href="http://www.flickr.com/photos/19511776@N00/286814746">Banner</a>, <a href="http://www.flickr.com/photos/49968232@N00/2474880917">Thumbnail</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[用漫画描述各种排序算法]]></title>
    <link href="http://panlw.github.io/15322360379929.html"/>
    <updated>2018-07-22T13:07:17+08:00</updated>
    <id>http://panlw.github.io/15322360379929.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://www.techug.com/post/cartoon-sort-arithmetic.html">http://www.techug.com/post/cartoon-sort-arithmetic.html</a><br/>
<a href="https://idea-instructions.com/">https://idea-instructions.com/</a></p>
</blockquote>

<p>IDEA 是由 SándorP. Fekete、Sebastian Morr 和 Sebastian Stiller 共同推出的图解算法系列。 它们最初是为 Sándor 在德国不伦瑞克工业大学开设的算法和数据结构讲座而设计的，作者希望它们能够有更广的用途，因此在网上发布了这个项目，希望能够帮助到教师、学生和有好奇心的人们。算法将会不断更新，可以访问页面了解更多信息：</p>

<p><a href="https://idea-instructions.com/">https://idea-instructions.com/</a>。</p>

<p>这些图片使用 Inkscape 绘制，可以使用任意一款向量图编辑软件来编辑它们。每个算法下面都有相应的图片下载地址。</p>

<h2 id="toc_0">快速排序</h2>

<p>快速排序是一种 “分而治之” 的排序算法，通过随机选择 “分区点” 来避免出现最坏的情况。</p>

<p><img src="http://www.techug.com/wordpress/wp-content/uploads/2018/04/640-1000x706.gif" alt=""/></p>

<ol>
<li> 随机选择 “分区点”。</li>
<li> 按照 “分区点” 的高度划条线。</li>
<li> 高出 “分局点” 的元素需要向右移动。</li>
<li> 低于 “分区点” 的元素需要向左移动。</li>
<li> 移动元素。</li>
<li> 重复上述的步骤分别对位于 “分区点” 两边的元素进行排序。</li>
</ol>

<p>下载地址：<a href="https://idea-instructions.com/quick-sort/">https://idea-instructions.com/quick-sort/</a></p>

<h2 id="toc_1">Bogo 排序</h2>

<p>Bogo 排序也被称为 “愚蠢的排序”，是一种非常简单但低效的排序算法，就是不断打乱元素的顺序，直到达到有序为止。</p>

<p><img src="http://www.techug.com/wordpress/wp-content/uploads/2018/04/640-1-1000x706.gif" alt=""/></p>

<ol>
<li> 查看元素是否有序。</li>
<li> 元素无序，那么就打乱顺序。</li>
<li> 再次检查元素是否有序。</li>
<li> 如果有序，排序成功，否则继续重复上述步骤。</li>
</ol>

<p>下载地址：<a href="https://idea-instructions.com/bogo-sort/">https://idea-instructions.com/bogo-sort/</a></p>

<h2 id="toc_2">二分查找</h2>

<p>二分查找是一种快速从一个有序数组中找到某个元素位置的查找算法。这有点类似于猜数字游戏，通过不断问 “目标数字是大于还是小于某个数” 这样的问题，最终猜出目标数字。</p>

<p><img src="http://www.techug.com/wordpress/wp-content/uploads/2018/04/640-2-1000x706.gif" alt=""/></p>

<ol>
<li> 限定元素区间。</li>
<li> 待查找元素在区间的某个位置吗？</li>
<li> 不在。</li>
<li> 那么看看待查找元素是不是在当前位置的左边或者右边。</li>
</ol>

<p>下载地址：<a href="https://idea-instructions.com/binary-search/">https://idea-instructions.com/binary-search/</a></p>

<h2 id="toc_3">归并排序</h2>

<p>归并排序也是一种 “分而治之” 的递归排序算法。</p>

<p><img src="http://www.techug.com/wordpress/wp-content/uploads/2018/04/640-3-1000x706.gif" alt=""/></p>

<ol>
<li> 把元素分成两部分，对每一个部分采用递归的归并排序。</li>
<li> 比较已经排好序的元素。</li>
<li> 合并已经排好序的元素。</li>
<li> 排序完毕。</li>
</ol>

<p>下载地址：<a href="https://idea-instructions.com/merge-sort/">https://idea-instructions.com/merge-sort/</a></p>

<h2 id="toc_4">平衡二叉树</h2>

<p>平衡二叉树是自平衡的二叉树变种，可以保证快速的查找、插入和删除操作。</p>

<p><img src="http://www.techug.com/wordpress/wp-content/uploads/2018/04/640-4-1000x706.gif" alt=""/><img src="http://www.techug.com/wordpress/wp-content/uploads/2018/04/640-5-1000x706.gif" alt=""/></p>

<p>以图中的平衡二叉树为例：</p>

<ul>
<li>  左子节点比父节点小，而父节点比右子节点小。如果根节点左右子树的高度差超过 1，就变得不平衡。</li>
<li>  想知道树中是否包含了元素 11？11 比 10 大，那么就查找 10 的右子节点 12。11 比 12 小，所以就查找 12 的左子节点，12 的左子节点刚好是要查找的 11。同样的，树中是否包含了元素 8？8 比 10 小，那么就查找 10 的左子节点 6。8 比 6 大，那么就查找 6 的右子节点。6 的右子节点不存在，说明树中不存在元素 8。</li>
<li>  如何找到树中最小的元素？从根节点开始，一直顺着左子节点，找到最后一个叶子节点就是树中最小的元素。</li>
<li>  如何找到 10 的下一个元素？如果根节点刚好是 10，那么就从 10 的右子树中找到最小的那个元素。如果根节点不是 10，那么先找到 10，如果 10 没有右子节点，那么就一直往父节点找，直到找到比 10 大的元素为止。</li>
<li>  在树种加入 17 或删除 10，破坏了树的平衡，这个时候需要通过旋转恢复树的平衡。</li>
</ul>

<p>下载地址：<a href="https://idea-instructions.com/avl-tree/">https://idea-instructions.com/avl-tree/</a></p>

<h2 id="toc_5">图遍历</h2>

<p>图遍历算法会遍历图中所有可达的顶点，可以通过辅助数据结构来实现各种遍历，比如使用无序集合实现随机遍历，使用堆栈实现深度优先遍历，使用队列实现广度优先遍历。</p>

<p><img src="http://www.techug.com/wordpress/wp-content/uploads/2018/04/640-6-1000x706.gif" alt=""/></p>

<ul>
<li>  随机查找：选定一个顶点，把它放入一个无序集合中。从集合中取出一个顶点，访问该顶点，把该顶点的相邻顶点放入集合中，并把该顶点移出集合。重复这一过程，直到集合中的元素全部被遍历完毕。</li>
<li>  深度优先遍历：选定一个顶点压入栈中，把该顶点其中的一个相邻顶点也压入栈中。访问栈顶的顶点，如果该顶点没有其他相邻的顶点，就出栈。如果有其他相邻顶点，就把其中的一个相邻顶点压入栈中。重复这一过程，直到栈中的元素全部被遍历完毕。</li>
<li>  广度优先遍历：选定一个顶点，把该顶点的相邻顶点放进队列尾部。访问队列头部的顶点，把该顶点移出队列，如果该顶点有相邻顶点，就把相邻顶点放进队列尾部。重复这一过程，直到队列中的元素全部遍历完毕。</li>
</ul>

<p>下载地址：<a href="https://idea-instructions.com/graph-scan/">https://idea-instructions.com/graph-scan/</a></p>

<h2 id="toc_6">一笔画</h2>

<p>一笔画是一种 Fleury 算法，旨在优雅地找出图中的欧拉（Eulerian）路径。欧拉路径是图中的一条路径，刚好经过每条边，并且每条边只被访问一次。</p>

<p><img src="http://www.techug.com/wordpress/wp-content/uploads/2018/04/640-7-1000x706.gif" alt=""/></p>

<ol>
<li> 顶点度数表示该顶点有几条边。</li>
<li> 如果图中有且仅有两个顶点的度数为奇数，其他为偶数，或者不存在奇数度数的顶点，则存在欧拉路径。</li>
<li> 选定一个顶点开始画路径。</li>
<li> 如果存在两个以上的桥，那么可以走桥。如果只剩下一个桥，就不能走桥，除非只剩下桥可以走。</li>
<li> 如果还有没有走过的边，重复步骤 4。</li>
<li> 成功画出欧拉路径。</li>
</ol>

<p>下载地址：<a href="https://idea-instructions.com/euler-path/">https://idea-instructions.com/euler-path/</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[React JS: what is a PureComponent?]]></title>
    <link href="http://panlw.github.io/15322166489736.html"/>
    <updated>2018-07-22T07:44:08+08:00</updated>
    <id>http://panlw.github.io/15322166489736.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://lucybain.com/blog/2018/react-js-pure-component/">http://lucybain.com/blog/2018/react-js-pure-component/</a></p>

<p>Published on: January 14, 2018</p>

<p>Tags: <a href="/blog/tags/react/">react</a>, <a href="/blog/tags/js/">js</a>, and <a href="/blog/tags/performance/">performance</a></p>
</blockquote>

<p>Early on, React developers had the idea of “pure” components. This concept went by a variety of names (stateful/pure, smart/dumb, container/presentational, etc.) but were all fairly similar. These components still used the <code>React.Component</code> class, but the idea provided a useful mental model for developers to work with.</p>

<p>But then on June 29, 2016 React 15.3 was released a new <code>PureComponent</code> class. The <code>PureComponent</code> kind of summed up the previous concept of “pure” components, and put a large speed boost in as well. This article is about the <code>PureComponent</code> class, and only touches on the “pure” component mental model. I’ve added some links in the references section to cover why the idea of “pure” components is useful. Because of <code>PureComponent</code>’s emphasis on performance, this is also a continuation from my previous article about <a href="/blog/2017/react-js-when-to-rerender/">when React re-renders</a> (I recommend reading that one first if you haven’t already).</p>

<h3 id="toc_0">What problem does it solve?</h3>

<p>By default, a plain <code>React.Component</code> has <code>shouldComponentUpdate</code> set to always return <code>true</code>. This is good because it means React errs on the side of always updating the component in case there’s any new data to show. However, it’s bad because it means React might trigger unnecessary re-renders. One way to deal with these extra re-renders is to change the <code>shouldComponentUpdate</code> function to check when your component needs to update (see my <a href="/blog/2017/react-js-when-to-rerender/">previous post</a> for more information).</p>

<p>Another way to stop extra re-renders is to use a <code>PureComponent</code>. Let’s build out the example from the previous performance post...</p>

<h3 id="toc_1">Example setup</h3>

<p><strong>Note:</strong> I’ve written intentionally bad code in the <code>componentDidMount</code> methods throughout. This is to keep the examples small and to show some gotchas along the way. Please do not write this kind of code for reals!</p>

<pre><code class="language-js">class Todos extends React.PureComponent {

    constructor(props) {
        super(props);
        this.state = { 
            todos: [
                { title: &#39;take out the trash&#39;, done: false, notes: [&#39;boring&#39;] },
                { title: &#39;walk dog&#39;, done: true, notes: [&#39;exercise&#39;] },
                { title: &#39;read about React&#39;, done: false, notes: [&#39;fun!&#39;] },
            ]
        };
    }

    componentDidMount() {
        setInterval(() =&gt; {
            this.setState((oldState) =&gt; {
                return { todos: [...oldState.todos] }
            });
        }, 1000);
    }

    render() {
        console.log(&#39;Todos render called&#39;);
        return (&lt;div&gt;
            {this.state.todos.map((todo, i) =&gt; {
              return (&lt;TodoItem
                key={i}
                title={todo.title}
                done={todo.done}
                notes={todo.notes}
              /&gt;);
            })}
          &lt;/div&gt;);
    }
}

class TodoItem extends React.Component {

    render() {
        console.log(&#39;TodoItem render called&#39;);
        return (&lt;div&gt;
                {this.props.done ? &#39;✓&#39;: &#39;▢&#39;} {this.props.title}
                ({this.props.notes.join(&#39;, &#39;)})
            &lt;/div&gt;);
    }
}

ReactDOM.render(&lt;Todos /&gt;, document.getElementById(&#39;app&#39;));
</code></pre>

<p>It’s bigger than most of the examples I write, but it’s all relevant - promise! We’ll break it down (feel free to skip down to the next section if the above is clear to you already):</p>

<h4 id="toc_2"><code>Todos</code></h4>

<p>First we have a React component, this is the one that <code>ReactDOM</code> will render (see the last line in the example).</p>

<p>We have the constructor method so we can set the initial state - in this case an array of <code>todos</code>, each of which has <code>title</code>, <code>done</code>, and <code>notes</code> attributes. (Typically this kind of state would be passed in through <code>props</code> but I’ve written it in the <code>state</code> to keep the example smaller and self contained.)</p>

<pre><code class="language-js">constructor(props) {
    super(props);
    this.state = { 
        todos: [
            { title: &#39;take out the trash&#39;, done: false, notes: [&#39;boring&#39;] },
            { title: &#39;walk dog&#39;, done: true, notes: [&#39;exercise&#39;] },
            { title: &#39;read about React&#39;, done: false, notes: [&#39;fun!&#39;] },
        ]
    };
}
</code></pre>

<p>Then there’s the <code>componentDidMount</code> method. Its only purpose is to change the state every second so we can see how React deals with those changes. Right now it updates <code>state.todos</code> to be the same as the previous <code>state.todos</code>.</p>

<pre><code class="language-js">componentDidMount() {
    setInterval(() =&gt; {
        this.setState((oldState) =&gt; {
            return { todos: [...oldState.todos] }
        });
    }, 1000);
}
</code></pre>

<p>Finally <code>Todos</code> has the render method. It renders a list of the <code>TodoItem</code> components, and passes in their respective <code>title</code>, <code>done</code>, and <code>notes</code> attributes. The main thing we’re interested in here is seeing when this component is rendered.</p>

<pre><code class="language-js">render() {
    console.log(&#39;Todos render called&#39;);
    return (&lt;div&gt;
        {this.state.todos.map((todo, i) =&gt; {
            return (&lt;TodoItem
            key={i}
            title={todo.title}
            done={todo.done}
            notes={todo.notes}
            /&gt;);
        })}
        &lt;/div&gt;);
}
</code></pre>

<h4 id="toc_3"><code>TodoItem</code></h4>

<p><u>It’s a lot simpler than <code>Todos</code></u></p>

<p>Yes, that’s right <code>TodoItem</code> inherits from <code>React.Component</code> just like <code>Todos</code>, but it only implements the <code>render</code> function (which is required) to display the <code>title</code>, <code>done</code>, and <code>notes</code> values. Here again we’re mostly interested in knowing <u>when</u> the <code>render</code> method is called, not really what is displayed (yet!).</p>

<pre><code class="language-js">render() {
    console.log(&#39;TodoItem render called&#39;);
    return (&lt;div&gt;
            {this.props.done ? &#39;✓&#39;: &#39;▢&#39;} {this.props.title}
            ({this.props.notes.join(&#39;, &#39;)})
        &lt;/div&gt;);
}
</code></pre>

<h3 id="toc_4">What’s the problem?</h3>

<p>Well, if you <a href="https://codepen.io/lbain/pen/GyOXye">look at it yourself</a> you’ll see the console spits out:</p>

<pre><code class="language-log">Todos render called
TodoItem render called
TodoItem render called
TodoItem render called
Todos render called
TodoItem render called
TodoItem render called
TodoItem render called
</code></pre>

<p>Over and over, every second.</p>

<p><u>That seems silly, the data isn’t even changing!</u></p>

<p>You’re right - there’s no need to re-render any of these components because the data doesn’t change. But React doesn’t know this - the <code>setState</code> method from the <code>onComponentDidmount</code> triggers a re-render every second for the <code>Todos</code> component and its children.</p>

<h3 id="toc_5">How do we re-render less?</h3>

<p>Let’s focus on <code>TodoItem</code> for now. It’s rendering three times for each <code>Todos</code> render so we can optimise it first. We’ll talk about <code>Todos</code> later on.</p>

<p><u>How can we fix <code>TodoItem</code> re-rendering too much?</u></p>

<p>That brings us nicely to the <code>React.PureComponent</code> this post is supposed to be all about. The <code>TodoItem</code> doesn’t need to re-render since none of its data changes. The <code>props</code> coming in each time are the same, and there’s no internal <code>state</code>. Let’s try converting <code>TodoItem</code> to a <code>React.PureComponent</code>:</p>

<pre><code class="language-js">class TodoItem extends React.PureComponent { // This line changed

    render() {
        console.log(&#39;TodoItem render called&#39;);
        return (&lt;div&gt;
                {this.props.done ? &#39;✓&#39;: &#39;▢&#39;} {this.props.title}
                ({this.props.notes.join(&#39;, &#39;)})
            &lt;/div&gt;);
    }
}
</code></pre>

<p>If you make that change in the <a href="https://codepen.io/lbain/pen/GyOXye">CodePen</a> you’ll see the following in the console:</p>

<pre><code class="language-log">Todos render called
TodoItem render called
TodoItem render called
TodoItem render called
Todos render called
Todos render called
Todos render called
Todos render called
...
</code></pre>

<p>After the initial <code>TodoItem</code>s render, they never render again <u>even though their parent renders multiple times.</u></p>

<p><strong>Boom.</strong></p>

<p>Did you catch that? We just saved ourselves a <u>bunch</u> of unnecessary <code>TodoItem</code> renders simply by converting it to a <code>PureComponent</code>. Aw yeah.</p>

<h3 id="toc_6">How does <code>PureComponent</code> work?</h3>

<p><u>Ok, you’ve had your big reveal. How does it actually work?</u></p>

<p>You know how we’d normally need to write our own <code>shouldComponentUpdate</code> to check if the component should re-render or not? Well, React has written that check for us in <code>PureComponent</code>. The <a href="https://github.com/facebook/react/blob/9d310e0bc7b9d5ce39d82536dfcb67f98462a346/packages/react-test-renderer/src/ReactShallowRenderer.js#L170-L173">relevant shouldComponentUpdate code</a> is:</p>

<pre><code class="language-js">if (type.prototype &amp;&amp; type.prototype.isPureReactComponent) {
    shouldUpdate = !shallowEqual(oldProps, props) ||
                   !shallowEqual(oldState, state);
}
</code></pre>

<p><strong>Note:</strong> React checks both <code>props</code> and <code>state</code>. Throughout this article I focus on <code>state</code> because it makes the examples easier and self contained, however it’s important to note that everything we talk about here equally applies to <code>props</code>.</p>

<p><a href="https://github.com/facebook/fbjs/blob/c69904a511b900266935168223063dd8772dfc40/packages/fbjs/src/core/shallowEqual.js">Here</a> is the code for that <code>shallowEqual</code> function. Of particular interest is the <a href="https://github.com/facebook/fbjs/blob/c69904a511b900266935168223063dd8772dfc40/packages/fbjs/src/core/shallowEqual.js#L35-L37">method documentation</a>:</p>

<blockquote>
<p>Performs equality by iterating through keys on an object and returning false when any key has values which are not strictly equal between the arguments. Returns true when the values of all keys are strictly equal.</p>
</blockquote>

<p><u>But wait, what does “strictly equal” mean?</u></p>

<p>That is a <strong>very</strong> good question, so we’ll dedicate a whole section to it.</p>

<h3 id="toc_7">Side note: shallow equality</h3>

<p>Feel free to skip if this isn’t new for you.</p>

<p>A <u>shallow</u> equality check means that JS only checks that the value’s object <u>ids</u> (as in, the memory address for where JS stores the information for that particular object) are the same, not that their <u>content</u> is the same. So here’s an example where shallow equality is what you and I would usually think of as “equal”:</p>

<pre><code class="language-js">const value = &#39;cat&#39;;

const item1 = value;
const item2 = value;

console.log(item1 === item2); // true
</code></pre>

<p>And here’s an example where JS’s definition of “equal” and our definition might differ:</p>

<pre><code class="language-js">const value = &#39;cat&#39;;

const array1 = [value];
const array2 = [value];

console.log(array1 === array2); // false
</code></pre>

<p>Even though we can clearly see the <u>content</u> of <code>array2</code> is the same as <code>array1</code> JS registers them as different since their <u>ids</u> are different. In this case we created two completely separate arrays, that just happened to have the same data in them.</p>

<p><u>What’s the alternative?</u></p>

<p>We can check inside each item and see if all the values are the same - this is called a “deep” equality check. Something like this:</p>

<pre><code class="language-js">const value = &#39;cat&#39;;

const array1 = [value];
const array2 = [value];

let equal = true;
array1.forEach((item, index) =&gt; {
    equal = equal &amp;&amp; array1[index] === array2[index];
});

console.log(equal); // true
</code></pre>

<p><u>Why would shallow equality ever be useful?</u></p>

<p>Well, it’s <u>really</u> fast. In the previous example we have to loop through every single item in the array to find that the arrays are equal. Assuming you’ve got more than one thing in your array that gets slow quickly.</p>

<h3 id="toc_8">Warning: PureComponent does a shallow equality check</h3>

<p>React uses a shallow equality check because it is is <u>way</u> more performant than doing a deep equal. In fact, React doesn’t even offer doing a deep equality check. You can do a shallow check (with <code>PureComponent</code>), write your own check (with <code>shouldComponentUpdate</code>), or not check at all and just always re-render (the default). It’s too risky for React to do a deep equality check since you might have really deeply nested data. Instead React errs on the side of not checking and doing the re-render automatically.</p>

<p>All if this is generally good news if your component is working with shallow-equality-friendly data. If the <code>state</code> and <code>prop</code> value ids change when their content changes then the components re-render when the should - yay! However, if you don’t handle your data properly, then you can accidentally not re-render when you should - boo!</p>

<p><u>Could you give an example?</u></p>

<p>As it happens, we already have one ready to go! Let’s leave <code>TodoItem</code> as a <code>PureComponent</code>, and change <code>Todo</code>&#39;s <code>componentDidMount</code> to mess with some data:</p>

<pre><code class="language-js">componentDidMount() {
    setInterval(() =&gt; {
        this.setState((oldState) =&gt; {
            oldState.todos[0].done = !oldState.todos[0].done; // new line
            return { todos: [...oldState.todos] }
        });
    }, 1000);
}
</code></pre>

<p>If you run this you’ll see the “done” state for the first todo item flash on and off every second. This is good news - we’re updating the data and it’s displaying properly.</p>

<p>But... let’s try this one:</p>

<pre><code class="language-js">componentDidMount() {
    setInterval(() =&gt; {
        this.setState((oldState) =&gt; {
            oldState.todos[0].notes.push(&#39;smelly&#39;); // new line
            return { todos: [...oldState.todos] }
        });
    }, 1000);
}
</code></pre>

<p>The first todo item <u>should</u> re-render every second with a new “smelly” note displaying. But it doesn’t, there’s just the initial render (without the “smelly” note), and that’s it.</p>

<p><u>Why doesn’t React re-render?</u></p>

<p>Because doing a <code>push</code> on an array <a href="http://gunnariauvinen.com/difference-between-concat-and-push-in-javascript/">does <u>not</u> create a <u>new</u> array.</a> When React does the shallow equality check for the <code>PureComponent</code> it only checks <code>oldState.notes === newState.notes</code>, which is <code>true</code> <u>even though</u> the data in <code>notes</code> has changed. In order to render this properly we need to change <code>TodoItem</code> back to a <code>React.Component</code>, <strong>or</strong> we can use <code>forceUpdate</code> to tell React that the data actually has changed. However using <code>forceUpdate</code> is kind of a code smell, so I won’t cover it here.</p>

<h3 id="toc_9">Warning: think of the children!</h3>

<p>A common pitfall when converting from <code>Component</code> to <code>PureComponent</code> is to forget that the children need to re-render too. As with all React - if the parent doesn’t re-render the children won’t either. So if you have a <code>PureComponent</code> with children, those children can only update if the parent’s <code>state</code> or <code>props</code> are shallowly different (causing the parent to re-render).</p>

<p>You can only have a <code>PureComponent</code> parent if you know none of the children should re-render if the parent doesn’t re-render. Let’s see an example of this pitfall by converting the <code>Todos</code> component from a <code>Component</code> to a <code>PureComponent</code> :</p>

<pre><code class="language-js">class Todos extends React.PureComponent { // new line
    // ...

    componentDidMount() {
        setInterval(() =&gt; {
            this.setState((oldState) =&gt; {
                oldState.todos[0].done = !oldState.todos[0].done; // new line
                return oldState; // new line
            });
        }, 1000);
    }

    // ...
}
</code></pre>

<p>As you can see, most of the code is the same. We’ve changed <code>Todos</code> to be a <code>PureComponent</code> and the <code>componentDidMount</code> to return the original <code>oldState</code> object rather than creating a new object (as before).</p>

<p>Now we <u>should</u> see the first todo item flashing its <code>done</code> state on and off. But it doesn’t, again there is only the initial render and that’s it. This happens because <code>Todos</code> is now a <code>PureComponent</code>, when the shallow equal check happens with <code>oldState === newState</code> we find exactly the same object (again, even though the content of that object has changed). So <code>Todos</code> never re-renders, so its <u>children</u> also never re-render. We can fix this really easily by simply changing <code>Todos</code> back to a <code>Component</code>.</p>

<hr/>

<h3 id="toc_10">Wrapping up</h3>

<p><code>PureComponent</code> is very powerful in that it can help you limit the number of unnecessary re-renders that occur. However, it can also cause surprising gotchas. The key thing to keep in mind is that <code>PureComponent</code> only does a shallow equality check on <code>props</code> and <code>state</code> before deciding if it should re-render or not. And that has a cascade effect on if its children re-render or not. So use <code>PureComponent</code> and love the performance gains, but be sure to check that it is always re-rendering when it should. When in doubt fall back to a <code>Component</code> instead.</p>

<h3 id="toc_11">Resources</h3>

<p>I read a <u>lot</u> of posts and questions about <code>PureComponent</code>, <code>Component</code>, and <code>shouldComponentUpdate</code> for this, so the below is not a complete list of resources. Hopefully they’re the most useful though!</p>

<ul>
<li>  <a href="https://reactjs.org/docs/react-api.html#reactpurecomponent">React docs</a></li>
<li>  <a href="https://stackoverflow.com/questions/41340697/react-component-vs-react-purecomponent">StackOverflow</a></li>
<li>  <a href="https://blog.shakacode.com/react-purecomponent-pitfalls-d057882f4b6e">Rob Wise</a> lists more pitfalls of using <code>PureComponent</code> - a good one to check if your <code>PureComponents</code> are rendering <u>more</u> than you’d expect (whereas I focused on not triggering re-renders enough)</li>
<li>  <a href="https://medium.com/modus-create-front-end-development/component-rendering-performance-in-react-df859b474adc">Grgur Grisogono</a> did some performance testing on <code>PureComponent</code></li>
<li>  <a href="https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0">Dan Abramov</a> and <a href="https://jaketrent.com/post/smart-dumb-components-react/">Jake Trent</a> discuss what “pure” components are</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关键系统的JVM参数推荐(2018仲夏版)]]></title>
    <link href="http://panlw.github.io/15320998566522.html"/>
    <updated>2018-07-20T23:17:36+08:00</updated>
    <id>http://panlw.github.io/15320998566522.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p><a href="http://calvin1978.blogcn.com/?p=1602">http://calvin1978.blogcn.com/?p=1602</a></p>
</blockquote>

<p>年更贴，因为两年里遇到的事情，一些想法变了。也补充了不少 <a href="https://github.com/vipshop/vjtools/">VJTools</a> 的内容，比如为伸手党们准备的 <a href="https://github.com/vipshop/vjtools/blob/master/vjstar/src/main/script/jvm-options">jvm-options.sh</a>。</p>

<p>在关键的业务系统里，除了继续追求技术人员最爱的高吞吐与低延时之外，系统的稳定性与排查问题的便捷性也很重要。这是本文的一个原则，后面也会一次又一次的强调。</p>

<h4 id="toc_0">前言 1，资料</h4>

<p>1. 学习开源项目的启动脚本是个不错的主意，比如 <a href="https://github.com/elastic/elasticsearch/blob/master/distribution/src/config/jvm.options">ElasticSearch 家的</a>，<a href="https://github.com/apache/cassandra/blob/trunk/conf/jvm.options">Cassandra 家的</a>， 附送一篇<a href="http://tobert.github.io/pages/als-cassandra-21-tuning-guide.html">解释它的文章</a>。</p>

<p>2. VJTools 的 <a href="https://github.com/vipshop/vjtools/blob/master/vjstar/src/main/script/jvm-options">jvm-options.sh</a>，伸手党们最爱，根据自己需要稍微定制一下就行。</p>

<p>3. <a href="http://hllvm.group.iteye.com/group/topic/27945">JVM 调优的 &quot;标准参数&quot; 的各种陷阱</a> ，R 大的文章，在 JDK6 时写的，年年期待更新。</p>

<h4 id="toc_1">前言 2， -XX:+PrintFlagsFinal 打印参数值</h4>

<p>当你在网上兴冲冲找到一个可优化的参数时，先用 - XX: +PrintFlagsFinal 看看，它可能已经默认打开了，再找到一个，还是默认打开了...</p>

<p>JDK7 与 JDK8，甚至 JDK7 中的不同小版本，有些参数值都不一样，所以不要轻信网上任何文章，一切以生产环境同版本的 JDK 打出来的为准。</p>

<p>经常以类似下面的语句去查看参数，偷懒不起应用，用 - version 代替。有些参数设置后会影响其他参数，所以也要带上。</p>

<blockquote>
<p>java -Xmx1024m -Xms1024m -XX:+UseConcMarkSweepGC -XX:+PrintFlagsFinal -version| grep ParallelGCThreads</p>
</blockquote>

<p>对于不同版本里的默认值，建议是顺势而为，JDK 在那个版本默认打开不打开总有它的理由。安全第一，没有很好的因由，不要随便因为网上某篇文章的推荐 (包括你现在在读的这篇) 就去设置。</p>

<h3 id="toc_2">1. 性能篇</h3>

<h4 id="toc_3">1.1 建议的性能参数</h4>

<p><strong>1. 取消偏向锁 -XX:-UseBiasedLocking</strong></p>

<p>JDK1.6 开始默认打开的偏向锁，会尝试把锁赋给第一个访问它的线程，取消同步块上的 synchronized 原语。如果始终只有一条线程在访问它，就成功略过同步操作以获得性能提升。</p>

<p>但一旦有第二条线程访问这把锁，JVM 就要撤销偏向锁恢复到未锁定线程的状态，如果打开安全点日志，可以看到不少 RevokeBiasd 的纪录，像 GC 一样 Stop The World 的干活，虽然只是很短的停顿，但对于多线程并发的应用，取消掉它反而有性能的提升，所以 Cassandra 就取消了它。</p>

<p><strong>2. 加大 Integer Cache -XX:AutoBoxCacheMax=20000</strong></p>

<p><code>Integer i=3;</code>这语句有着 int 自动装箱成 Integer 的过程，JDK 默认只缓存 -128 ~ +127 的 Integer 和 Long，超出范围的数字就要即时构建新的 Integer 对象。设为 20000 后，我们应用的 QPS 有足足 4% 的影响。为什么是 2 万呢，因为 <strong>-XX:+AggressiveOpts</strong> 里也是这个值。详见 <a href="http://blog.csdn.net/chengzhezhijian/article/details/9628251">Java Integer(-128~127) 值的 == 和 equals 比较产生的思考</a>。</p>

<p><strong>3. 启动时访问并置零内存页面 -XX:+AlwaysPreTouch</strong></p>

<p>启动时就把参数里说好了的内存全部舔一遍，可能令得启动时慢上一点，但后面访问时会更流畅，比如页面会连续分配，比如不会在晋升新生代到老生代时才去访问页面使得 GC 停顿时间加长。ElasticSearch 和 Cassandra 都打开了它。</p>

<p><strong>4. SecureRandom 生成加速 -Djava.security.egd=file:/dev/./urandom</strong></p>

<p>此江湖偏方原因为 Tomcat 的 SecureRandom 显式使用 SHA1PRNG 算法时，初始因子默认从 / dev/random 读取会存在堵塞。额外效果是 SecureRandom 的默认算法也变成合适的 SHA1 了。详见 <a href="http://calvin1978.blogcn.com/articles/securerandom.html">SecureRandom 的江湖偏方与真实效果</a></p>

<h4 id="toc_4">1.2 可选的性能参数</h4>

<p><strong>1. -XX:+PerfDisableSharedMem</strong></p>

<p>Cassandra 家的一个参数，一直没留意，直到发生高 IO 时的 JVM 停顿。原来 JVM 经常会默默的在 / tmp/hperf 目录写上一点 statistics 数据，如果刚好遇到 PageCache 刷盘，把文件阻塞了，就不能结束这个 Stop the World 的安全点了。<br/>
禁止 JVM 写 statistics 数据的代价，是 jps 和 jstat 用不了，只能用 JMX，而 JMX 取新老生代的使用百分比还真没 jstat 方便，VJTools VJTools 里的 <a href="https://github.com/vipshop/vjtools/tree/master/vjmxcli">vjmxcli</a> 弥补了这一点。详见 <a href="http://www.evanjones.ca/jvm-mmap-pause.html">The Four Month Bug: JVM statistics cause garbage collection pauses</a></p>

<p><strong>2. -XX:-UseCounterDecay</strong></p>

<p>禁止 JIT 调用计数器衰减。默认情况下，每次 GC 时会对调用计数器进行砍半的操作，导致有些方法一直温热，永远都达不到触发 C2 编译的 1 万次的阀值。</p>

<p><strong>3. -XX:-TieredCompilation</strong></p>

<p>多层编译是 JDK8 后默认打开的比较骄傲的功能，先以 C1 静态编译，采样足够后 C2 编译。</p>

<p>但我们实测，性能最终略降 2%，可能是因为有些方法 C1 编译后 C2 不再编译了。应用启动时的偶发服务超时也多了，可能是忙于编译。所以我们将它禁止了，但记得打开前面的 - XX:-UseCounterDecay，避免有些温热的方法永远都要解释执行。</p>

<h4 id="toc_5">1.3 不建议的性能参数</h4>

<p><strong>1. -XX:+AggressiveOpts</strong></p>

<p>一些还没默认打开的优化参数集合, -XX:AutoBoxCacheMax 是其中的一项。但如前所述，关键系统里不建议打开。虽然通过 - XX:+AggressiveOpts 与 -XX:-AggressiveOpts 的对比，目前才改变了三个参数，但为免以后某个版本的 JDK 里默默改变更多激进的配置，还是不要打开了。</p>

<p>2. JIT Compile 相关的参数，函数调用多少次之后开始编译的阀值，内联函数大小的阀值等等，不要乱改。</p>

<p>3. <strong>-server</strong>，在 64 位多核的 linux 中，你想设成 - client 都不行的，所以写了也是白写。</p>

<h3 id="toc_6">2. 内存与 GC 篇</h3>

<h4 id="toc_7">2.1 GC 策略</h4>

<p>为了稳健，还是 8G 以下的堆还是 CMS 好了，G1 现在虽然是默认了，但其实在小堆里的表现也没有比 CMS 好，还是 JDK11 的 ZGC 引人期待。</p>

<p><strong>1.CMS 基本写法</strong></p>

<blockquote>
<p>-XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly</p>
</blockquote>

<p>因为我们的监控系统会通过 JMX 监控内存达到 90% 的状况，所以设置让它 75% 就开始跑了，早点开始也能减少 Full GC 等意外情况 (概念重申，这种主动的 CMS GC，和 JVM 的老生代、永久代、堆外内存完全不能分配内存了而强制 Full GC 是不同的概念)。<br/>
为了让这个设置生效，还要设置 - XX:+UseCMSInitiatingOccupancyOnly，否则 75％只被用来做开始的参考值，后面还是 JVM 自己算。</p>

<p><strong>2. -XX:MaxTenuringThreshold=2</strong></p>

<p>这是改动效果最明显的一个参数了。对象在 Survivor 区最多熬过多少次 Young GC 后晋升到年老代，JDK8 里 CMS 默认是 6，其他如 G1 是 15。</p>

<p>Young GC 是最大的应用停顿来源，而新生代里 GC 后存活对象的多少又直接影响停顿的时间，所以如果清楚 Young GC 的执行频率和应用里大部分临时对象的最长生命周期，可以把它设的更短一点，让其实不是临时对象的新生代对象赶紧晋升到年老代，别呆着。</p>

<p>用 - XX:+PrintTenuringDistribution 观察下，如果后面几代的大小总是差不多，证明过了某个年龄后的对象总能晋升到老生代，就可以把晋升阈值设小，比如 JMeter 里 2 就足够了。</p>

<p><strong>3. -XX:+ExplicitGCInvokesConcurrent 但不要 - XX:+DisableExplicitGC</strong></p>

<p>​full gc 时，使用 CMS 算法，不是全程停顿，必选。</p>

<p>但像 R 大说的，System GC 是保护机制（如堆外内存满时清理它的堆内引用对象），禁了 system.gc() 未必是好事，只要没用什么特别烂的类库，真有人调了总有调的原因，所以不应该加这个烂大街的参数。</p>

<p><strong>4. ParallelRefProcEnabled 和 CMSParallelInitialMarkEnabled</strong></p>

<p>并行的处理 Reference 对象，如 WeakReference，默认为 false，除非在 GC log 里出现 Reference 处理时间较长的日志，否则效果不会很明显，但我们总是要 JVM 尽量的并行，所以设了也就设了。同理还有 - XX:+CMSParallelInitialMarkEnabled，JDK8 已默认开启，但小版本比较低的 JDK7 甚至不支持。</p>

<p><strong>5. ParGCCardsPerStrideChunk</strong></p>

<p>Linkined 的黑科技， 上一个版本的文章不建议打开，后来发现有些场景的确能减少 YGC 时间，详见<a href="https://toutiao.io/posts/hltb1e/preview">难道他们说的都是真的</a>，简单说就是影响 YGC 时扫描老生代的时间，默认值 256 太小了，但 32K 也未必对，需要自己试验。</p>

<p><code>-XX:+UnlockDiagnosticVMOptions -XX: ParGCCardsPerStrideChunk=1024</code></p>

<h4 id="toc_8">2.2 可选的 GC 参数</h4>

<p><strong>1. 并发收集线程数</strong></p>

<blockquote>
<p>ParallelGCThreads＝8+(Processor - 8) ( 5/8 )；<br/>
ConcGCThreads = (ParallelGCThreads + 3)/4</p>
</blockquote>

<p>比如双 CPU，六核，超线程就是 24 个处理器，小于 8 个处理器时 ParallelGCThreads 按处理器数量，大于时按上述公式 YGC 线程数＝18， CMS GC 线程数＝5。</p>

<p>CMS GC 线程数的公式太怪，也有人提议简单改为 YGC 线程数的 1/2。</p>

<p>一些不在乎停顿时间的后台辅助程序，比如日志收集的 logstash，建议把它减少到 2，避免在 GC 时突然占用太多 CPU 核，影响主应用。</p>

<p>而另一些并不独占服务器的应用，比如旁边跑着一堆 sidecar 的，也建议减少 YGC 线程数。</p>

<p>一个真实的案例，24 核的服务器，默认 18 条 YGC 线程，但因为旁边有个繁忙的 Service Mesh Proxy 在跑着，这 18 条线程并不能 100% 的抢到 CPU，出现了不合理的慢 GC。把线程数降低到 12 条之后，YGC 反而快了很多。 所以那些贪心的把 YGC 线程数＝CPU 核数的，通常弄巧成拙。</p>

<p><strong>2. -XX:－CMSClassUnloadingEnabled</strong></p>

<p>在 CMS 中清理永久代中的过期的 Class 而不等到 Full GC，JDK7 默认关闭而 JDK8 打开。看自己情况，比如有没有运行动态语言脚本如 Groovy 产生大量的临时类。它有时会大大增加 CMS 的暂停时间。所以如果新类加载并不频繁，这个参数还是显式关闭的好。</p>

<p><strong>3. -XX:+CMSScavengeBeforeRemark</strong></p>

<p>默认为关闭，在 CMS remark 前，先执行一次 minor GC 将新生代清掉，这样从老生代的对象引用到的新生代对象的个数就少了，停止全世界的 CMS remark 阶段就短一些。如果打开了，会让一次 YGC 紧接着一次 CMS GC，使得停顿的总时间加长了。</p>

<p>又一个真实案例，CMS GC 的时间和当时新生代的大小成比例，新生代很小时很快完成，新生代 80％时 CMS GC 停顿时间超过一秒，这时候就还是打开了划算。</p>

<h4 id="toc_9">2.3 不建议的 GC 参数</h4>

<p><strong>1. -XX:+UseParNewGC</strong></p>

<p>用了 CMS，新生代收集默认就是，不用自己设。</p>

<p><strong>2. -XX:CMSFullGCsBeforeCompaction</strong><br/>
默认为 0，即每次 full gc 都对老生代进行碎片整理压缩。Full GC 不同于 老生代 75% 时触发的 CMS GC，只在老生代达到 100%，老生代碎片过大无法分配空间给新晋升的大对象，堆外内存满，这些特殊情况里发生，所以设为每次都进行碎片整理是合适的，详见<a href="http://hllvm.group.iteye.com/group/topic/28854">此贴里 R 大的解释</a>。</p>

<p><strong>3.-XX:+GCLockerInvokesConcurrent</strong></p>

<p>我们犯过的错，不是所有 Concurrent 字样的参数都是好参数，加上之后，原本遇上 JNI GCLocker 只需要补偿 YGC 就够的，变成要执行 YGC ＋ CMS GC 了。</p>

<h4 id="toc_10">2.4 内存大小的设置</h4>

<p>其实 JVM 除了显式设置的 <strong>-Xmx</strong> 堆内存，还有一堆其他占内存的地方 (堆外内存，线程栈，永久代，二进制代码 cache)，在容量规划的时候要留意。</p>

<p>关键业务系统的服务器上内存一般都是够的，所以尽管设得宽松点。</p>

<p><strong>1. -Xmx, -Xms,</strong> <br/>
堆内存大小，2～4G 均可。</p>

<p><strong>2. -Xmn or -XX:NewSize or -XX:NewRatio</strong></p>

<p>JDK 默认新生代占堆大小的 1/3， 个人喜欢把对半分， 因为增大新生代能减少 GC 的频率，如果老生代里没多少长期对象的话，占 2/3 通常太多了。可以用 - Xmn 直接赋值 (等于 - XX:NewSize and -XX:MaxNewSize 同值的缩写)，或把 NewRatio 设为 1 来对半分。</p>

<p><strong>3. -XX: PermSize=128m -XX:MaxPermSize=512m （JDK7）</strong><br/>
<strong>-XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m（JDK8）</strong></p>

<p>现在的应用有 Hibernate/Spring 这些闹腾的家伙 AOP 之后类都比较多，可以一开始就把初始值从 64M 设到 128M（否则第一次自动扩张会造成大约 3 秒的 JVM 停顿），并设一个更大的 Max 值以求保险。</p>

<p>JDK8 的永生代几乎可用完机器的所有内存，同样设一个 128M 的初始值，512M 的最大值保护一下。</p>

<h4 id="toc_11">2.5 其他内存大小的设置</h4>

<p><strong>1. -Xss</strong></p>

<p>在堆之外，线程占用栈内存，默认每条线程为 1M（以前是 256K）。存放方法调用出参入参的栈，局部变量，标量替换后掉局部变量等，有人喜欢把它设回 256k，节约内存并开更多线程，有人则会在遇到错误后把它再设大点，特别是有很深的 JSON 解析之类的递归调用时。</p>

<p><strong>2. -XX:SurvivorRatio</strong></p>

<p>新生代中每个存活区的大小，默认为 8，即 1/10 的新生代 1/(SurvivorRatio+2)，有人喜欢设小点省点给新生代如 Cassandra，但要避免太小使得存活区放不下临时对象而被迫晋升到老生代，还是从 GC 日志里看实际情况了。</p>

<p><strong>3. -XX:MaxDirectMemorySize</strong></p>

<p>堆外内存的最大值，默认为 Heap 区总内存减去一个 Survivor 区的大小，详见 <a href="http://calvin1978.blogcn.com/articles/directbytebuffer.html">Netty 之堆外内存扫盲篇</a>，如果肯定用不了这么多，也可以把它主动设小，来获得一个比较清晰内存占用预估值，特别是在容器里。</p>

<p><strong>4. -XX:ReservedCodeCacheSize</strong></p>

<p>JIT 编译后二进制代码的存放区，满了之后就不再编译，对性能影响很大。 JDK7 默认不开多层编译 48M，开了 96M，而 JDK8 默认开多层编译 240M。可以在 JMX 里看看 CodeCache 的占用情况，也可以用 VJTools 里的 <a href="https://github.com/vipshop/vjtools/tree/master/vjtop">vjtop</a> 来看，JDK7 下默认的 48M 可以设大点，不抠这么点。</p>

<h3 id="toc_12">3. 监控篇</h3>

<p>JVM 输出的各种日志，如果未指定路径，通常会生成到运行应用的相同目录，为了避免有时候在不同的地方执行启动脚本，一般将日志路径集中设到一个固定的地方。</p>

<h4 id="toc_13">3.1 监控建议配置</h4>

<p><strong>1. -XX:+PrintCommandLineFlags</strong></p>

<p>运维有时会对启动参数做一些临时的更改，将每次启动的参数输出到 stdout，将来有据可查。<br/>
打印出来的是命令行里设置了的参数以及因为这些参数隐式影响的参数，比如开了 CMS 后，-XX:+UseParNewGC 也被自动打开。</p>

<p><strong>2. -XX:-OmitStackTraceInFastThrow</strong></p>

<p>为异常设置 StackTrace 是个昂贵的操作，所以当应用在相同地方抛出相同的异常 N 次 (两万?) 之后，JVM 会对某些特定异常如 NPE，数组越界等进行优化，不再带上异常栈。此时，你可能会看到日志里一条条 Nul Point Exception，而之前输出完整栈的日志早被滚动到不知哪里去了，也就完全不知道这 NPE 发生在什么地方，欲哭无泪。 所以，将它禁止吧，ElasticSearch 也这样干。</p>

<h4 id="toc_14">3.2 Crash 文件</h4>

<p><strong>1. -XX:ErrorFile</strong></p>

<p>JVM crash 时，hotspot 会生成一个 error 文件，提供 JVM 状态信息的细节。如前所述，将其输出到固定目录，避免到时会到处找这文件。文件名中的 %p 会被自动替换为应用的 PID</p>

<p><code>-XX:ErrorFile=${MYLOGDIR}/hs_err_%p.log</code></p>

<p><strong>2. coredump</strong></p>

<p>当然，更好的做法是生成 coredump，从 CoreDump 能够转出 Heap Dump 和 Thread Dump 还有 crash 的地方，非常实用。</p>

<p>在启动脚本里加上 ulimit -c unlimited 或其他的设置方式，如果有 root 权限，设一下输出目录更好</p>

<p><code>echo &quot;/{MYLOGDIR}/coredump.%p&quot; &gt; /proc/sys/kernel/core_pattern</code></p>

<p>什么？你不知道 coredump 有什么用？看来你是没遇过 JVM Segment Fault 的幸福人。</p>

<p><strong>3. -XX:+HeapDumpOnOutOfMemoryError(可选)</strong></p>

<p>在 Out Of Memory，JVM 快死掉的时候，输出 Heap Dump 到指定文件。不然开发很多时候还真不知道怎么重现错误。</p>

<p>路径只指向目录，JVM 会保持文件名的唯一性，叫 java_pid${pid}.hprof。因为如果指向文件，而文件已存在，反而不能写入。</p>

<p><code>-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=${LOGDIR}/</code></p>

<p>但在容器环境下，输出 4G 的 HeapDump，在普通硬盘上会造成 20 秒以上的硬盘 IO 跑满，也是个十足的恶邻，影响了同一宿主机上所有其他的容器。</p>

<h4 id="toc_15">3.3 GC 日志</h4>

<p>JDK9 完全不一样了，这里还是写 JDK7/8 的配置。</p>

<p><strong>1. 基本配置</strong></p>

<p><code>-Xloggc:/dev/shm/gc-myapp.log -XX:+PrintGCDateStamps -XX:+PrintGCDetails</code></p>

<p>有人担心写 GC 日志会影响性能，但测试下来实在没什么影响，GC 问题是 Java 里最常见的问题，没日志怎么行。</p>

<p>后来又发现如果遇上高 IO 的情况，GC 时操作系统正在 flush pageCache 到磁盘，也可能导致 GC log 文件被锁住，从而让 GC 结束不了。所以把它指向了 / dev/shm 这种内存中文件系统，避免这种停顿，详见 <a href="%E2%80%9Chttp://engineering.linkedin.com/blog/2016/02/eliminating-large-jvm-gc-pauses-caused-by-background-io-traffic%E2%80%9D">Eliminating Large JVM GC Pauses Caused by Background IO Traffic</a></p>

<p>用 PrintGCDateStamps 而不是 PrintGCTimeStamps，打印可读的日期而不是时间戳。</p>

<p><strong>2. -XX:+PrintGCApplicationStoppedTime</strong></p>

<p>这是个非常非常重要的参数，但它的名字没起好，其实除了打印清晰的完整的 GC 停顿时间外，还可以打印其他的 JVM 停顿时间，比如取消偏向锁，class 被 agent redefine，code deoptimization 等等，有助于发现一些原来没想到的问题。如果真的发现了一些不知是什么的停顿，需要打印安全点日志找原因（见后）。</p>

<p><strong>3. -XX:+PrintGCCause</strong></p>

<p>打印产生 GC 的原因，比如 AllocationFailure 什么的，在 JDK8 已默认打开，JDK7 要显式打开一下。</p>

<p><strong>4. -XX:+PrintPromotionFailure</strong></p>

<p>打开了就知道是多大的新生代对象晋升到老生代失败从而引发 Full GC 时的。</p>

<p><strong>5. GC 日志滚动与备份</strong></p>

<p>GC 日志默认会在重启后清空，有人担心长期运行的应用会把文件弄得很大，所以 &quot;-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M&quot; 的参数可以让日志滚动起来。但真正用起来重启后的文件名太混乱太让人头痛，GC 日志再大也达不到哪里去，所以我们没有加滚动，而且自行在启动脚本里对旧日志做备份。</p>

<h4 id="toc_16">3.4 安全点日志</h4>

<p>如果 GC 日志里有非 GC 的 JVM 停顿时间，你得打出安全点日志来知道详情，详见 <a href="http://calvin1978.blogcn.com/articles/safepoint.html">JVM 的 Stop The World，安全点，黑暗的地底世界</a></p>

<p><code>-XX:+PrintSafepointStatistics -XX: PrintSafepointStatisticsCount=1 -XX:+UnlockDiagnosticVMOptions -XX:- DisplayVMOutput -XX:+LogVMOutput -XX:LogFile=/dev/shm/vm-myapp.log</code></p>

<h4 id="toc_17">3.5 JMX</h4>

<blockquote>
<p>-Dcom.sun.management.jmxremote.port=7001 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=127.0.0.1</p>
</blockquote>

<p>以上设置，只让本地的 Zabbix 之类监控软件通过 JMX 监控 JVM，不允许远程访问。</p>

<p>如果应用忘记了加上述参数，又不想改参数重启服务，可以用 VJTools 的 <a href="https://github.com/vipshop/vjtools/tree/master/vjmxcli">vjmxcli</a> 来救急，它能通过 PID 直接连入目标 JVM 打开 JMX。</p>

<h3 id="toc_18">4. 小结</h3>

<p><a href="https://github.com/vipshop/vjtools/">VJTools</a> 刚刚开源了，里头东西不少，比如 <a href="https://github.com/vipshop/vjtools/blob/master/vjstar/src/main/script/jvm-options">jvm-options.sh</a>，伸手党们最爱，再啰嗦一次，麻烦大家给项目点个 Star。</p>

<p>有什么写得不对的地方，明年再来更新啦。祝大家生产环境里的 JVM 都稳健无比，永远没 bug。</p>

<p><a href="http://calvin1978.blogcn.com/?p=1602">《关键业务系统的 JVM 启动参数推荐》</a>，转载请保留链接。</p>

<h3 id="toc_19">有关的...</h3>

<ul>
<li>  2018-06-06 -- <a href="http://calvin1978.blogcn.com/articles/vjtools123.html" title="唯品会Java核心项目VJTools开源了">唯品会 Java 核心项目 VJTools 开源了</a></li>
<li>  2016-10-29 -- <a href="http://calvin1978.blogcn.com/articles/javatuning.html" title="Java性能优化指南1.8版，及唯品会的实战">Java 性能优化指南 1.8 版，及唯品会的实战</a></li>
<li>  2016-09-14 -- <a href="http://calvin1978.blogcn.com/articles/btrace1.html" title="Btrace入门到熟练小工完全指南">Btrace 入门到熟练小工完全指南</a></li>
<li>  2016-08-27 -- <a href="http://calvin1978.blogcn.com/articles/hashmap.html" title="高性能场景下，Map家族的优化使用建议">高性能场景下，Map 家族的优化使用建议</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
