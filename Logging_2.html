<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  Logging - Junkman
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="Junkman" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:panlw.github.io ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; Junkman</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
       
       <li><a href="index.html">HOME</a></li>
    <li><a href="archives.html">Archives</a></li>
    <li><a href="about.html">ABOUT</a></li>

    <li><label>Categories</label></li>

        
            <li><a href="Infra.html">Infra</a></li>
        
            <li><a href="Coding.html">Coding</a></li>
        
            <li><a href="Modeling.html">Modeling</a></li>
        
            <li><a href="Archtecting.html">Archtecting</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="15282782041132.html">
                
                  <h1>Enabling Centralized Logging</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<blockquote>
<p><a href="https://dzone.com/articles/centralized-logging">https://dzone.com/articles/centralized-logging</a></p>
</blockquote>

<p>An essential requirement for microservices architecture is the ability to look through the request propagation between multiple microservices. If you have only few microservices, you might be able to ssh to all the servers and tail the logs. However, if you happen to have multiple servers per service, this is not something that is easy to do. The solution is to build a centralized logging system that could gather all our application logs into a single service. The logging system should meet the following requirements:</p>

<ol>
<li> It should work in real-time.</li>
<li> It should be easy to search.</li>
<li> It should help developers correlate requests between microservices.</li>
<li> It should be application agnostic.</li>
<li> It should place very little overhead on the application.</li>
</ol>

<p>There are some helpful tools which can be used for building the logging system.</p>

<ul>
<li>  <strong>Spring Cloud Sleuth -</strong> Library from Spring cloud project that provides automatic instrumentation of communication channels. It lets you track the progress of subsequent microservices by adding the appropriate headers to the HTTP requests.</li>
<li>  <strong>Zipkin</strong> - Zipkin is a distributed tracing system. It helps gather timing data needed to troubleshoot latency problems in microservice architectures. It manages both the collection and lookup of this data. Zipkin’s design is based on the Google Dapper paper.</li>
<li>  <strong>Splunk -</strong> Splunk is centralized logs analysis tool for machine generated data, unstructured/structured and complex multi-line data which provides the following features such as Easy Search/Navigate, Real-Time Visibility, Historical Analytics, Reports, Alerts, Dashboards and Visualization.</li>
<li>  <strong>ELK -</strong> Elasticsearch, Logstash, Kibana: three different tools usually used together. They are used for searching, analyzing, and visualizing log data in a real time.</li>
</ul>

<h2 id="toc_0">Architecture</h2>

<p><img src="https://dzone.com/storage/temp/6480958-image001v1.png" alt=""/></p>

<h2 id="toc_1">Instrument Your Application</h2>

<p>The first step is to instrument your application so that each log statement includes traceId and spanId that will help in tracing a call as it propagates through different microservices. In the following sections, instructions are provided for instrumenting Spring Boot, NodeJS and Python applications.</p>

<h2 id="toc_2">Enabling Tracing for SpringBoot Applications With the Sleuth Library</h2>

<p>1. Update the POM file to include the Sleuth Spring Boot starter library:</p>

<p><strong>pom.xml</strong></p>

<pre><code class="language-xml">&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-sleuth&lt;/artifactId&gt;
            &lt;version&gt;1.2.2.RELEASE&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;
&lt;dependency&gt;
&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>

<p>2. Update application.properties to include spring.application.name and logging.file.</p>

<p><strong>application.properties</strong></p>

<pre><code class="language-properties">spring.application.name=&quot;Spring Boot 1&quot;
logging.file=/var/log/logs/springboot1.log
</code></pre>

<p>3. Use SLF4J for logging.</p>

<p><strong>Application.java</strong></p>

<pre><code class="language-java">import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
private static final Logger logger = LoggerFactory.getLogger(Application.class);
logger.info(quote.toString());
</code></pre>

<p>4. Use a RestTemplate object that is autowired by Spring. This is necessary because Spring Cloud Sleuth adds the trace id and span id via headers in the request.</p>

<p><strong>Application.java</strong></p>

<pre><code class="language-java">import org.springframework.web.client.RestTemplate;
@Bean
RestTemplate restTemplate() {
return new RestTemplate();
}
@Autowired
RestTemplate restTemplate;
    Quote quote = restTemplate.getForObject(&quot;http://localhost:8082/quote&quot;, Quote.class);
</code></pre>

<p>As an example, let&#39;s say we have a case like the following:</p>

<p><img src="https://dzone.com/storage/temp/6461026-image002.png" alt=""/></p>

<p>Now, if you run the microservices and hit the endpoint, you should see your logging statement printed in the in the log file of Microservice 1:</p>

<pre><code class="language-log">2017-08-21 06:09:41.925  INFO [&quot;Spring Boot 1&quot;,945690e8fc53b5b5,945690e8fc53b5b5,false] 25841 --- [http-nio-8080-exec-10] c.b.l.controller.LoggingController       : Quote{type=&#39;success&#39;, value=Value{id=10, quote=&#39;Really loving Spring Boot, makes stand alone Spring apps easy.&#39;}}
2017-08-21 06:29:44.244  INFO [&quot;Spring Boot 1&quot;,b9184768fa226280,b9184768fa226280,false] 25841 --- [http-nio-8080-exec-2] c.b.l.controller.LoggingController       : Quote{type=&#39;success&#39;, value=Value{id=11, quote=&#39;I have two hours today to build an app from scratch. @springboot to the rescue!&#39;}}
2017-08-21 06:36:13.698  INFO [&quot;Spring Boot 1&quot;,f21c03b4f86f31a8,f21c03b4f86f31a8,false] 25841 --- [http-nio-8080-exec-4] c.b.l.controller.LoggingController       : Quote{type=&#39;success&#39;, value=Value{id=4, quote=&#39;Previous to Spring Boot, I remember XML hell, confusing set up, and many hours of frustration.&#39;}}
</code></pre>

<p>and Microservice 2:</p>

<pre><code class="language-log">2017-08-21 06:29:44.238  INFO [&quot;Spring Boot 2&quot;,b9184768fa226280,7a80e050a5c4aa2c,false] 25867 --- [http-nio-8082-exec-5] c.b.l.controller.LoggingController       : Quote{type=&#39;success&#39;, value=Value{id=11, quote=&#39;I have two hours today to build an app from scratch. @springboot to the rescue!&#39;}}
2017-08-21 06:36:13.693  INFO [&quot;Spring Boot 2&quot;,f21c03b4f86f31a8,cbeb473567ccd74a,false] 25867 --- [http-nio-8082-exec-6] c.b.l.controller.LoggingController       : Quote{type=&#39;success&#39;, value=Value{id=4, quote=&#39;Previous to Spring Boot, I remember XML hell, confusing set up, and many hours of frustration.&#39;}}
</code></pre>

<p>The portion of the log statement that Sleuth adds is [&quot;Spring Boot 1&quot;, 945690e8fc53b5b5, 945690e8fc53b5b5, false]. The first part is the application name (whatever you set spring.application.name to in application.properties). The second value is the trace id. The third value is the span id. Finally, the last value indicates whether the span should be exported to Zipkin. The trace ids are the same but the span ids are different. The trace ids are what is going to allow you to trace a request as it travels from one service to the next. The span ids are different because we have two different “units of work” occurring, one for each request.</p>

<h2 id="toc_3">Enabling Tracing for NodeJS Applications</h2>

<p>The instrumentation to include traceId and spanId in logs for NodeJS and JavaScript is manual unlike in case of Spring Boot applications where these are added to each log by Spring Cloud Sleuth.</p>

<p>1. Instrument the NodeJS application following the steps listed here - <a href="https://github.com/openzipkin/zipkin-js-example">https://github.com/openzipkin/zipkin-js-example</a>. This project shows an example of how to use Zipkin in JavaScript.</p>

<p>2. Add a logger to include traceId and spanId in the logs.</p>

<p><strong>logger.js</strong></p>

<pre><code class="language-js">const winston = require(&#39;winston&#39;),
  moment = require(&#39;moment&#39;);
var logger = new winston.Logger({
  transports: [
    new winston.transports.Console({
      formatter: (options) =&gt; {
        const traceId = options.meta.TraceId;
        const spanId = options.meta.SpanId;
        const service = options.meta.serviceName;
        const logLevel = options.level.toUpperCase();
        const time = moment();
        const message = options.message || &#39;&#39;;
        return JSON.stringify({
          timestamp: time.toISOString(),
          logLevel,
          message,
          traceId,
          spanId,
          service
        });
      }
    }),
    new winston.transports.File({
      filename: &#39;frontend.log&#39;,
      formatter: (options) =&gt; {
        const traceId = options.meta.TraceId;
        const spanId = options.meta.SpanId;
        const service = options.meta.serviceName;
        const logLevel = options.level.toUpperCase();
        const time = moment();
        const message = options.message || &#39;&#39;;
        return JSON.stringify({
          timestamp: time.toISOString(),
          logLevel,
          message,
          traceId,
          spanId,
          service
        });
      }
    })
  ]
}); 
module.exports.logger = logger;
</code></pre>

<p>3. Use the logger to log.</p>

<p><strong>frontend.js</strong></p>

<pre><code class="language-js">const {logger} = require(&#39;./logger&#39;);
app.get(&#39;/&#39;, (req, res) =&gt; {
  zipkinRest(&#39;http://localhost:9000/api&#39;)
    .then(response =&gt; {
      logger.log(&#39;info&#39;, &#39;Hello distributed log files!&#39;, 
        { &#39;serviceName&#39;:&#39;frontend&#39;, &#39;TraceId&#39;: req.header(&#39;X-B3-TraceId&#39;), &#39;SpanId&#39;: req.header(&#39;X-B3-SpanId&#39;) });
      res.send(response.entity);
    })
    .catch(err =&gt; logger.error(&#39;Error&#39;, err.stack));
});
</code></pre>

<p><strong>backend.js</strong></p>

<pre><code class="language-js">const {logger} = require(&#39;./logger&#39;);
app.get(&#39;/api&#39;, (req, res) =&gt; {
  logger.log(&#39;info&#39;, &#39;Hello distributed log files!&#39;, 
    { &#39;serviceName&#39;:&#39;backend&#39;, &#39;TraceId&#39;: req.header(&#39;X-B3-TraceId&#39;), &#39;SpanId&#39;: req.header(&#39;X-B3-SpanId&#39;) });
  res.send(new Date().toString())
});
</code></pre>

<p>The logfile will have traceId and spanId with the log message.</p>

<p><strong>frontend.log</strong></p>

<pre><code class="language-log">{&quot;level&quot;:&quot;info&quot;,&quot;message&quot;:&quot;Frontend listening on port 8085!&quot;,&quot;timestamp&quot;:&quot;2017-08-24T06:26:58.536Z&quot;}
{&quot;serviceName&quot;:&quot;frontend&quot;,&quot;TraceId&quot;:&quot;2c97a4bac4820ef8&quot;,&quot;SpanId&quot;:&quot;2c97a4bac4820ef8&quot;,&quot;level&quot;:&quot;info&quot;,&quot;message&quot;:&quot;Hello distributed log files!&quot;,&quot;timestamp&quot;:&quot;2017-08-24T06:27:02.990Z&quot;}
{&quot;serviceName&quot;:&quot;backend&quot;,&quot;TraceId&quot;:&quot;2c97a4bac4820ef8&quot;,&quot;SpanId&quot;:&quot;7a0eff44fc42fde9&quot;,&quot;level&quot;:&quot;info&quot;,&quot;message&quot;:&quot;Hello distributed log files!&quot;,&quot;timestamp&quot;:&quot;2017-08-24T06:27:02.977Z&quot;}
</code></pre>

<p>Notice that the traceId is the same across two microservices.</p>

<h2 id="toc_4">Enabling Tracing for Python Applications</h2>

<p>We&#39;ll be using the py_zipkin python package to instrument our Python applications. Here again, the instrumentation is manual.</p>

<p>1. Install py_zipkin and use the examples from <a href="https://github.com/Yelp/py_zipkin">https://github.com/Yelp/py_zipkin</a> to instrument your Python application.</p>

<p>2. Add service_name, span_id and trace_id in your logging configuration.</p>

<p><strong>logging.conf</strong></p>

<pre><code class="language-conf">[formatter_myFormatter]
format=%(asctime)s - %(name)s - %(levelname)s - %(service_name)s - %(trace_id)s - %(span_id)s - %(message)s
</code></pre>

<p>3. Trace a service call.</p>

<p><strong>demo.py</strong></p>

<pre><code class="language-py">from py_zipkin.zipkin import zipkin_span, create_http_headers_for_new_span
@zipkin_span(service_name=&#39;webapp&#39;, span_name=&#39;do_stuff&#39;)
def do_stuff():
    headers = create_http_headers_for_new_span()
    app.logger.info(&#39;From demo app&#39;, extra={&#39;service_name&#39;:&#39;demo&#39;, &#39;trace_id&#39;:headers[&#39;X-B3-TraceId&#39;], &#39;span_id&#39;:headers[&#39;X-B3-SpanId&#39;]})
    requests.get(&#39;http://localhost:6000/service1/&#39;, headers=headers)
return &#39;OK&#39;
</code></pre>

<p><strong>service1.py</strong></p>

<pre><code class="language-py">@app.route(&#39;/service1/&#39;)
def index():
    with zipkin_span(
        service_name=&#39;service1&#39;,
        zipkin_attrs=ZipkinAttrs(
            trace_id=request.headers[&#39;X-B3-TraceID&#39;],
            span_id=request.headers[&#39;X-B3-SpanID&#39;],
            parent_span_id=request.headers[&#39;X-B3-ParentSpanID&#39;],
            flags=request.headers[&#39;X-B3-Flags&#39;],
            is_sampled=request.headers[&#39;X-B3-Sampled&#39;],
        ),
        span_name=&#39;index_service1&#39;,
        transport_handler=http_transport,
        port=6000,
        sample_rate=100, #0.05, # Value between 0.0 and 100.0
    ) as zipkin_context:
        headers = create_http_headers_for_new_span()
        app.logger.info(&#39;From service1 app&#39;, extra={&#39;service_name&#39;:&#39;service1&#39;, &#39;trace_id&#39;:headers[&#39;X-B3-TraceId&#39;], &#39;span_id&#39;:headers[&#39;X-B3-SpanId&#39;]})
        do_stuff()
    return &#39;OK&#39;, 200
</code></pre>

<p>4. The log file will have traceId and spanId from the calls.</p>

<p><strong>demo.log</strong></p>

<pre><code class="language-log">2017-08-29 08:29:36,065 - __main__ - INFO - demo - 884f9f20a9172104 - 2352d7d1fadd521c - From demo app
2017-08-29 08:29:36,069 - __main__ - INFO - service1 - 884f9f20a9172104 - d7867b21585a9ba1 - From service1 app
</code></pre>

<p>Note that the traceId is the same across the two services.</p>

<h2 id="toc_5">Aggregate Logs</h2>

<p>Once you have instrumented your application to automatically include tracing information in the logs, now let us look at Splunk and ELK for aggregating logs at a central place and correlating requests as it propagates through various services.</p>

<h2 id="toc_6">Enabling Centralized Logging Using Splunk</h2>

<p>Splunk works on the client-server model. Splunk Forwarder is used to collect the machine-generated data from the client side and forward it to the Splunk server. We tested with the Splunk free license for a low volume of logs; it provides a maximum 500 MB of indexing per day.</p>

<p><img src="https://dzone.com/storage/temp/6461050-image003.jpg" alt=""/></p>

<p>1. Download and install Splunk server.</p>

<pre><code class="language-sh">wget -O splunk-6.6.2-4b804538c686-Linux-x86_64.tgz &#39;https://www.splunk.com/bin/splunk/DownloadActivityServlet?architecture=x86_64&amp;platform=linux&amp;version=6.6.2&amp;product=splunk&amp;filename=splunk-6.6.2-4b804538c686-Linux-x86_64.tgz&amp;wget=true&#39;
sudo cp splunk-6.6.2-4b804538c686-Linux-x86_64.tgz /opt
cd /opt
sudo tar xvzf splunk-6.6.2-4b804538c686-Linux-x86_64.tgz
cd splunk
cd bin
sudo ./splunk start --accept-license
</code></pre>

<p>Splunk will be available at: http://<ip>:8000 (admin/admin)</p>

<p>2. Enable the receiving port to get logs from Splunk Forwarder. We can do this from GUI and CLI as well. Port 9997 is the default and it can be changed.</p>

<p>3. Download and install Splunk Forwarder.</p>

<pre><code class="language-sh">wget -O splunkforwarder-6.6.2-4b804538c686-Linux-x86_64.tgz &#39;https://www.splunk.com/bin/splunk/DownloadActivityServlet?architecture=x86_64&amp;platform=linux&amp;version=6.6.2&amp;product=universalforwarder&amp;filename=splunkforwarder-6.6.2-4b804538c686-Linux-x86_64.tgz&amp;wget=true&#39;
sudo cp splunkforwarder-6.6.2-4b804538c686-Linux-x86_64.tgz /opt
cd /opt
sudo tar xvzf splunkforwarder-6.6.2-4b804538c686-Linux-x86_64.tgz
cd splunkforwarder
cd bin
sudo ./splunk enable boot-start --accept-license
sudo ./splunk add forward-server &lt;ip&gt;:9997
sudo ./splunk list forward-server
sudo ./splunk add monitor /var/log
sudo ./splunk restart
</code></pre>

<p>Now login into Splunk web console and search for configured logs.<br/>
<img src="https://dzone.com/storage/temp/6461051-image004.jpg" alt=""/></p>

<h2 id="toc_7">Enabling Centralized Logging Using ELK</h2>

<p>There are three options that you have if you want Elasticsearch on AWS:</p>

<ul>
<li>  Get an EC2, install on your own, Elastic.co has written a simple and comprehensive article on this.</li>
<li>  Get a third party managed Elastic search as a service, again Elastic.co is pretty good for that.</li>
<li>  Get the AWS Elasticsearch as a service.</li>
</ul>

<p>We have installed ELK on our AWS. Learn how to access Kibana <a href="https://www.elastic.co/guide/en/kibana/current/access.html">here</a>.</p>

<p>1. To send application logs to the central Elasticsearch, follow <a href="https://www.elastic.co/guide/en/beats/filebeat/5.3/filebeat-getting-started.html">these steps</a> on each server. </p>

<p><strong>/etc/filebeat/filebeat.yml</strong></p>

<pre><code class="language-yml">filebeat.prospectors:
- input_type: log
  # Paths that should be crawled and fetched. Glob based paths.
  paths:
    - /var/log/logs/*.log
    #- c:\programdata\elasticsearch\logs\*
output.logstash:
  # The Logstash hosts
  hosts: [&quot;&lt;ip&gt;:5044&quot;]
</code></pre>

<p>2. FileBeat sends the logs to logstash, which has been configured to send the logs to Elasticsearch. Kibana has been configured to query indices in Elasticsearch.</p>

<p><img src="https://dzone.com/storage/temp/6461053-image005.png" alt=""/></p>

<p>3. By default, Kibana does not require login credentials. Hit the url http://<ip>:5601 in the browser, and search for logs.</p>

<p><img src="https://dzone.com/storage/temp/6461055-image006.jpg" alt=""/></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2018/6/6</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='Logging.html'>Logging</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="Logging_1.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="Logging_3.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="./asset/img/logo.jpg" /></div>
            
                <h1>Junkman</h1>
                <div class="site-des">“拾荒者”一词来自凯文・凯利的《失控》中关于机器学习的故事（“收集癖好机”如何完成他的收集工作）。</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="https://github.com/panlw/" title="GitHub">GitHub</a>

  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="Infra.html"><strong>Infra</strong></a>
        
            <a href="Coding.html"><strong>Coding</strong></a>
        
            <a href="Modeling.html"><strong>Modeling</strong></a>
        
            <a href="Archtecting.html"><strong>Archtecting</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="15517999043443.html">The Art of Crafting Architectural Diagrams</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15517997955971.html">为什么说我们需要软件架构图？</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15516128677869.html">DNS Servers That Offer Privacy and Filtering</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15516123108194.html">Airbnb's Migration from Monolith to Services</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15516097487470.html">Events As First-Class Citizens</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    <script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
